
\begin{abstract}
We introduce Probabilistic Dependency Graphs (PDGs), a new class of
directed graphical models.   PDGs can capture inconsistent beliefs in a
natural way and are more modular than Bayesian Networks (BNs), in that
they make it easier to incorporate new information and restructure the  
representation.    We show by example how PDGs are an especially natural
modeling tool.
We provide three semantics for PDGs, each of which can be derived from a
%oli22: inserted "parameterized", so I can refer to it below.
parameterized
%oli22 end insert
scoring function (on joint distributions over the
variables in the network) that can be viewed as representing a
distribution's incompatibility with the PDG.
%oli22 insert
The scoring function's parameter controls a trade-off between qualitative and quantitative fit. 
%oli22 end insert
For the PDG corresponding
to a BN, this function is uniquely minimized
%oli22: inserted 
at every parameter setting
by the distribution the BN represents
%oli22: add word "naturally"
% , showing that PDG semantics extend BN semantics.  
, showing that PDG semantics naturally extend BN semantics.  
%oli22: there are better uses of space
% We show further that 
Factor graphs
%oli22: remove "also" because of "further" above.
% can also be faithfully represented as PDGs
can be faithfully represented as PDGs
%oli22: added
but only when the trade-off parameter has been fixed, so that the qualitative 
and quantitative scores cannot be separated.
Finally, we relate PDGs to Dependency Networks, and point out that the PDGs 
provide many of the same benefits, but are much more expressive. 

\end{abstract}
