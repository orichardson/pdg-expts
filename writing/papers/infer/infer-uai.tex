\documentclass{uai2023} % for initial submission
% \documentclass[accepted]{uai2023} % after acceptance, for a revised
                                    % version; also before submission to
                                    % see how the non-anonymous paper
                                    % would look like
%% There is a class option to choose the math font
% \documentclass[mathfont=ptmx]{uai2023} % ptmx math instead of Computer
                                         % Modern (has noticable issues)
% \documentclass[mathfont=newtx]{uai2023} % newtx fonts (improves upon
                                          % ptmx; less tested, no support)
% NOTE: Only keep *one* line above as appropriate, as it will be replaced
%       automatically for papers to be published. Do not make any other
%       change above this note for an accepted version.

%% Choose your variant of English; be consistent
\usepackage[american]{babel}
% \usepackage[british]{babel}



%% Some suggested packages, as needed:
\usepackage{natbib} % has a nice set of citation styles and commands
    \bibliographystyle{plainnat}
    \renewcommand{\bibsection}{\subsubsection*{References}}
% \usepackage{mathtools} % amsmath with fixes and additions
% \usepackage{siunitx} % for proper typesetting of numbers and units
\usepackage{booktabs} % commands to create good-looking tables
% \usepackage{tikz} % nice language for creating drawings and diagrams
\usepackage{algorithm}
\usepackage{algorithmic}


%%% flags
\newif\ifbiblatex
    % \biblatextrue % use the more modern & extensible biblatex+biber for bibliography.
    \biblatexfalse % use BibTeX instead.  ICML .bib file works better here.
    
\newif\ifvfull
    % \vfulltrue % longer version of the paper
    \vfullfalse % shorter conference version of the paper
    
    \newif\ifvfullred % keep longer version, but mark it in red.
    \vfullredtrue
        
    \newcommand\vfull[1]{{\ifvfullred\color{red}\fi\ifvfull#1\fi}}

\usepackage{microtype}
\input{inference-preamble.tex}

% \usepackage{times}
% \renewcommand\ttdefault{cmvtt} % selects CM typewriter proportional font
% \renewcommand\sfdefault{cmvsf} % selects CM typewriter proportional font

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
\usepackage[disable,textsize=tiny]{todonotes}
% \usepackage[textsize=tiny]{todonotes}
% \usepackage[normalem]{ulem}

\newcommand\discard[1]{}

\newcommand\obslimit{observational facet} %(distribution)
\newcommand\ObsLimit{Observational Facet} %(distribution)
% depiction / manifestiation / materialization / portrayal / image / expression / delegate / aspect / facet / form / representative / intermediary / surrogate / proxy
\newcommand\zogamma{{\bar\gamma}}

\colorlet{mayyybe}{blue!50!red!20!white}
\colorlet{rewrite}{purple!80!black}

\colorlet{olicolor}{blue!50!red!70!black}
\colorlet{joecolor}{green!50!blue!70!black}

\newcommand\vjoe[1]{{\color{joecolor}\textbf{$\boldsymbol\{$Joe: }#1 \textbf{$\boldsymbol\}$}}} 
\newcommand\voli[1]{{\color{olicolor}\textbf{$\boldsymbol\{$Oli: }#1 \textbf{$\boldsymbol\}$}}}
\newcommand\otodo[2][]{\todo[color=olicolor!30!white,#1]{#2}}



%% Provided macros
% \smaller: Because the class footnote size is essentially LaTeX's \small,
%           redefining \footnotesize, we provide the original \footnotesize
%           using this macro.
%           (Use only sparingly, e.g., in drawings, as it is quite small.)

%% Self-defined macros
\newcommand{\swap}[3][-]{#3#1#2} % just an example

\title{Inference for Probabilistic Dependency Graphs}

% The standard author block has changed for UAI 2022 to provide
% more space for long author lists and allow for complex affiliations
%
% All author information is authomatically removed by the class for the
% anonymous submission version of your paper, so you can already add your
% information below.
%
% Add authors
\author[1]{\href{mailto:<jj@example.edu>?Subject=Your UAI 2022 paper}{Jane~J.~von~O'L\'opez}{}}
\author[1]{Harry~Q.~Bovik}
\author[1,2]{Further~Coauthor}
\author[3]{Further~Coauthor}
\author[1]{Further~Coauthor}
\author[3]{Further~Coauthor}
\author[3,1]{Further~Coauthor}
% Add affiliations after the authors
\affil[1]{%
    Computer Science Dept.\\
    Cranberry University\\
    Pittsburgh, Pennsylvania, USA
}
\affil[2]{%
    Second Affiliation\\
    Address\\
    …
}
\affil[3]{%
    Another Affiliation\\
    Address\\
    …
  }
  
  \begin{document}
\maketitle

\begin{abstract}
    %joe4: you need to tell the rader what PDGs are; I pulled the first sentence from the intro
    %joe5
      %  Probabilistic Dependency Graphs (PDGs)
    \emph{Probabilistic dependency graphs (PDGs)}
    %oli4: would prefer to avoid the citation in the abstract
    % \parencite{pdg-aaai}
    are a flexible class of probabilistic graphical models,
    %joe4: subsumes -> subsume
    %oli4: the subject is "a class" (singular), so I still think "subsumes" is correct?
    %oli4: it looks slightly wrong to me either way. I think this is becaus of the phrase
    %   " PDGs (plural) are (plural) a class (singular) ... "
    % We could do "PDGs *form* a class ... which subsumes"
    % ... or  "PDGs are flexible graphical models ... which subsume" ?
    %which subsumes Bayesian Networks and Factor Graphs.
    %joe5: this avoids the problem
    % They subsume Bayesian Networks and Factor Graphs.
    %oli5: it's also really choppy with two short sentences next to each other that have the same point. What about:
    subsuming Bayesian Networks and Factor Graphs.
    % which subsume Bayesian Networks and Factor Graphs.
    %oli4:
    % They can also capture inconsistent beliefs, and the degree of this inconsistency can be measured canonically.
    %joe5: we are not mesauring the inconsistency of a PDG, and I see
    %nothing canonical about our approach.
    %oli5: I wasn't not referring to the incompatibility of a probability distribution with the PDG; I'm referring to the degree of inconsistency of the PDG, which is conceptually more straightforward (if mathematically more complex).  Perhaps this measure is not the only one worth entertaining, but it has special properties.
    %oli5: perhaps natural is up for debate, but it is canonical by definition: it's how we set up the model in the last two papers (the canon), and essentially all results about PDGs are predicated on this decisision.  
    % They can also capture inconsistent beliefs; moreover, we can measure how
    % inconsistent a probability distribution is with a PDG.  
    %joe6: I don't find it so natural.  I just cut "natural"
    %oli6: ok.  I'll convince you sooner or later. 
    They can also capture inconsistent beliefs, and provide a way of measuring the degree of this inconsistency.
    % A PDG can contain inconsistent beliefs, and there is a natural way measuring its degree of inconsistency.
    %
    We provide the first tractable inference algorithm for
    % Probabilistic Dependency Graphs (PDGs)
    PDGs with discrete variables,
    %oli4: now that we have the new sentence, we can simplify this:
    % thereby placing PDGs on asymptotically similar footing as other graphical models,
    % such as Bayesian Networks and Factor Graphs, despite the fact that PDGs are more expressive.
    %joe6: I find this clunky.  More importantly, what does
    %"asymptotically" mean in this context.  It doesn't seem correct
    %thereby placing PDGs on asymptotically similar footing as the
    making the complexity of inference for PDGs asymptotically comparable to that of the
    graphical models they generalize. 
    %joe5: (2) and (3) seem to be saying ore or less the same thing.  I prefer the earlier approach that combined them
    %(2) that this can be done efficiently for PDGs of bounded tree-width, and
    %(3) the recent development of interior-point methods
    % that can solve such problems efficiently (Dahl \& Anderson, 2022).
    %oli5: Hmm, I'm trying to make two very distinct points.  Point (2) is the clever contructions done in section 5 to show polynomial size of  the problem for bounded tree width, while point (3) is prior work on solving these problems in polynomial time. Point (2) is more important and has been erased with your re-write.
    % (2) the recent development of interior-point methods that can solve
    % the exponential cones programs that arise for PDGs of bounded tree
    % width efficiently.
    % The key components of our approach are
    % (1) the observation that inference in PDGs can be reduced to a convex optimization problem with exponential cone constraints, 
    % efficiently so for PDGs of bounded tree-width, and 
    % %oli6: after revisiting the literature, it's not worth emphasizing the recency.
    % (2) the recent development
    % of interior-point methods
    %  that can solve such problems efficiently.
    % We evaluate our approach by ...
    The key components are
    % of our approach are
    (1) the observation that PDG inference can be reduced to convex optimization with exponential cone constraints, 
    (2) a construction that allows us to express these problems compactly for PDGs of boundeed treewidth, for which we needed to further develop the theory of PDGs, and
    (3) an appeal to interior point methods that can solve such problems in polynomial time.
    %oli8:
    % We verify the correctness and complexity of our approach, provide an implementation, and an analysis. 
    % We prove that our approach is correct, runs
    % in $\tilde O(N^4)$ time.    
    We verify the correctness and time complexity of our approach, 
    provide an implementation of it.
    We then evaluate our implementation, and demonstrate that it  
    it outperforms black-box optimization baselines.
\end{abstract}

\input{inference-paper-body.tex}

% \subsubsection*{Acknowledgements} hello
% All acknowledgments go at the end of the paper, including thanks to reviewers who gave useful comments, to colleagues who contributed to the ideas, and to funding agencies and corporate sponsors that provided financial support.
% To preserve the anonymity, please include acknowledgments \emph{only} in the camera-ready papers.

\section*{Acknowledgements}

% \textbf{Do not} include acknowledgements in the initial version of
% the paper submitted for blind review.
% 
% If a paper is accepted, the final camera-ready version can (and
% probably should) include acknowledgements. In this case, please
% place such acknowledgements in an unnumbered section at the
% end of the paper. Typically, this will include thanks to reviewers
% who gave useful comments, to colleagues who contributed to the ideas,
% and to funding agencies and corporate sponsors that provided financial
% support.

\ifbiblatex
    \subsubsection*{References}
    \printbibliography
\else
%joe7: you need to fix the author in the MOSEK refeference
    % \bibliographystyle{apalike}
    % \bibliographystyle{icml2023}
    \bibliography{refs}\fi


\clearpage
\onecolumn
\appendix
\input{appendix.tex}

\end{document}
