We provide the first tractable inference algorithm for Probabilistic Dependency Graphs (PDGs) with finite variables, placing PDGs on asymptotically similar footing as other graphical models, such as Bayesian Networks and Factor Graphs. This may be surprising, because PDGs are much more expressive than these other models, and also because (as we show) a PDG inference algorithm can be used to resolve inconsistencies, which has been proposed as a generic modeling task. 
    
The key to our approach is combining 
(1) our finding that inference in PDGs with bounded tree-width can be reduced to a tractable linear optimization problem with exponential cone constraints,  with
(2) a recent interior point method that can (provably) solve such problems efficiently (Dahl \& Anderson, 2022).
We provide a concrete implementation and emperical evaluation.
In addition, we prove auxiliary results about complexity of this problem, and discuss other approaches to it. 
