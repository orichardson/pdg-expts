\documentclass[twoside]{article}

\usepackage{aistats2023}

% If your paper is accepted, change the options for the package
% aistats2023 as follows:
%
%\usepackage[accepted]{aistats2023}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the end of
% the first column of the first page.

% If you set papersize explicitly, activate the following three lines:
%\special{papersize = 8.5in, 11in}
%\setlength{\pdfpageheight}{11in}
%\setlength{\pdfpagewidth}{8.5in}

% If you use natbib package, activate the following three lines:
%\usepackage[round]{natbib}
%\renewcommand{\bibname}{References}
%\renewcommand{\bibsection}{\subsubsection*{\bibname}}

% If you use BibTeX in apalike style, activate the following line:
%\bibliographystyle{apalike}
\input{inference-preamble.tex}
\input{pdg-preamble-v2.tex}

% \author{$\{$Oliver E Richardson, Joseph Y Halpern, Christopher De Sa$\}$}

\begin{document}
% If your paper is accepted and the title of your paper is very long,
% the style will print as headings an error message. Use the following
% command to supply a shorter title of your paper so that it can be
% used as headings.
%
%\runningtitle{I use this title instead because the last one was very long}

% If your paper is accepted and the number of authors is large, the
% style will print as headings an error message. Use the following
% command to supply a shorter version of the authors names so that
% they can be used as headings (for example, use only the surnames)
%
%\runningauthor{Surname 1, Surname 2, Surname 3, ...., Surname n}

\twocolumn[

\aistatstitle{Inference in Probabilistic Dependency Graphs,\\
    via Exponential Cones and Otherwise}

\aistatsauthor{ Oliver E Richardson \And Joseph Y Halpern \And  Christopher De Sa }

% \aistatsaddress{ Institution 1 \And  Institution 2 \And Institution 3 } 
\aistatsaddress{Cornell University \And Cornell University \And Cornell University}
]

\begin{abstract}
    We provide the first tractable inference algorithm for Probabilistic Dependency Graphs (PDGs) with discrete variables, thereby placing PDGs on asymptotically similar footing as other graphical models, such as Bayesian Networks and Factor Graphs.
    This may be surprising, because PDGs are much more expressive than these other models, and also because a PDG inference algorithm can be used 
    % for ``inconsistency minimization'', 
    % which has been argued to be widely useful. 
    to resolve inconsistencies, which has been proposed as a generic modeling task. 
    
    The key to our approach is combining 
    (1) our finding that inference in PDGs with bounded tree-width can be reduced to a tractable linear optimization problem with exponential cone constraints,
    with (2) a recent interior point method that can (provably) solve such problems efficiently (Dahl \& Anderson, 2022).
    We provide a concrete implementation and emperical evaluation.
    In addition, we prove auxiliary results about complexity of this problem, and discuss other approaches to it. 
\end{abstract}




% \begin{narrow}
% %%-----------    A FRANK SUMMARY    ---------------
% Measuring / Estimating /  Inconsistency is very useful.
% For instance, (1) propogating it backwards through layers of computation = differentiable learning. 
% 
% Certain localized versions of it can be used to do other algorithms.

% How hard is it? 
% With interior point methods (convex programs with exponential cone constraints) we can do it in $O(n^4 \log n)$ time \& space, worst case for exact inference. So far, this means slightly harder than inference in Graphical models.
% \end{narrow}


% \tableofcontents

\section{INTRODUCTION}

% How expensive 
% This paper provides some partial answers to the 
How difficult is it to estimate how inconsistent your beliefs are?
How difficult is it to best sort through these inconsistencies? 
This paper formalizes and partially answers to these questions.

Probabilistic Dependency Graphs, or pdgs \parencite{pdg-aaai},
are a particularly flexible class of probabilistic graphical models, which subsumes Bayesian Networks and Markov Random Fields.
The primary force behind the expressiveness of pdgs is their ability to capture inconsistent beliefs and measure the degree of this inconsistency.
%
Beyond its role in undergirding the semantics of pdgs, 
this measurement of inconsistency  


 \parencite{one-true-loss}.
Diagrammatic Calculus.
All of this paints a story 

But what use is a model without an inference algorithm? 
We analyze the complexity of inference and updating in pdgs, and 
provide an efficient algorithm and exponenital cones.
We then lean heavily on recent work 
\parencite{dahl2022primal} showing that 
such problems can be 

In practice, we find that our algorithms are not as fast as exact inference methods for existing graphical models, such as beleif propogation.   
However, their asymptotics are not much worse.

\section{PRELIMINARIES}

\textbf{Basic notation.}
% This paper concerns the 
Let $\mat 1$ denote the all-ones vector.

{\color{red}\tt
TODO: unexplained notation / concepts
\begin{enumerate}[nosep]
\raggedright
\item tensor product $\otimes$
\item relative entropy $\kldiv\mu\nu$, conditional entropy $\H(Y|X)$
\item jusxtaposition of variables to make new variables, e.g., $XY$ is a variable.
\item PDG unions via $+$
\item Extended reals $\Rext := \mathbb R \cup \{\infty\}$
\item Tree width
\end{enumerate}
}


We write $\Delta S$ to denote the set of proability distributions over a finite set $S$.
Every variable $X$ can take on a finite set $\V(X)$ of possible values. 
% If $S$ is a finite set, we write $\Delta S$ for the set of probability distributions over $S$, i.e., the simplex over its elements. 
A conditional probability distribution (cpd) $p(Y|X)$ is a map 
$p : \V(X) \to \Delta \V(Y)$, so it assigns, to every $x \in \V(X)$, a probability distribution $p(Y|x) \in \Delta Y$, which is shorthand for $p(Y|X\!\!=\!x)$.
Given a joint distribution $\mu$ over many variables including both $X$ and $Y$, 
we write $\mu(X)$ for its marginal distribution on $X$, and $\mu(Y|X)$ for the cpd obtained by first conditioning on $X$ and then marginalizing to $Y$. 

\textbf{Graph Theory.}

\textbf{Probabilistic Dependency Graphs.}
% \textbf{PDGs.}
We now give a quick overview of the PDG formalism,
following the more carefully motivated
expositions of \textcite{pdg-aaai,one-true-loss}.
%
% Let $\N$ be a set of variables, and 
%
% Fix a set $\N$ of variables. 
A probabilistic dependency graph (pdg) is just a collection of cpds, weighted by two kinds of confidence. More precisely:

\begin{defn}
    a pdg $\dg M
     % = (\mathcal P, \balpha, \bbeta)$ 
    $
    over $\N$ is a set $\Ed$ of edges, 
    each $L \in \Ed$ of which is associated with:
    \begin{itemize}[nosep]
        % \item (subsets of) variables $\Src L, \Tgt L \subset \N$, indicating the respective source and target variables of the edge;
        \item variables $\Src L, \Tgt L \in \N$, the source and target of $L$;
        \item a cpd $p\ssub L (\Tgt L | \Src L)$ on the target variables given the source variables,
        \item a weight $\beta\ssub L \in \Rext$ indicating 
            the modeler's confidence in the cpd $p\ssub L(\Tgt L | \Src L)$, and 
        \item a weight $\alpha\ssub L \in \mathbb R$ indicating 
            the modeler's confidence that the edge $L$ corresponds to an independent mechanism that determines $\Tgt L$ given $\Src L$. 
        \qedhere
    %     % \item $\mathcal P = \{ p\ssub L (\mat T_L | \mat S_L) \}_{L \in \Ed}$ is an indexed set of cpds   
    %     \item $\bbeta$ 
    \end{itemize}
\end{defn}

The incompatibility of a joint distribution $\mu(\N)$ over all variables, with such a PDG is given by a weighted sum of relative entropies:
\begin{align*}
    \Inc_{\dg M}(\mu) :=
        \sum_{L \in \Ed} \beta\ssub L\, \kldiv[\Big]{\mu(\Tgt L,\Src L)}{p\ssub L(\Tgt L | \Src L) \mu(\Src L)}.
        % \Ex_{\mu} \sum_{L \in \Ed} \beta\ssub L 
        %     \log \frac{\mu(\Tgt_L \mid \Src_L)}{p\ssub L(\Tgt_L \mid \Src_L)}
\end{align*}
$\Inc$ is called the ``quantitative'' term because it measures $\mu$'s discrepency
with the quantitative data in the cpds. 
Meanwhile, there is also a ``qualitative'' term, called the \emph{information deficiency}, given by
% \begin{align*}
$
    \IDef{\dg M}(\mu) := - \H(\mu) + \sum_{L \in \Ed} \alpha\ssub L\, \H_\mu(\Tgt L | \Src L).
$
% Although we won't motivate it here, 

Note that $\IDef{}$ does not depend on the cpds (``quantitative beliefs'') of $\dg M$, nor even the possible values of the variables---it is defined purely in terms of the topology of the graph and the weights $\balpha$. 
% \end{align*}
The PDG semantics are then given by a scoring fuction: 
$\bbr{\dg M}: \Delta \V\N \to \Rext$
the linear combination
\begin{align*}
    \bbr{\dg M}_\gamma(\mu) &:= \Inc_{\dg M}(\mu) + \gamma \IDef{\dg M}(\mu) 
        \\&= \EX_{\mu}\left[\, \sum_{L \in \Ed} \log \frac
            {\mu(\Tgt L| \Src L)^{\beta\ssub L - \gamma \alpha \ssub L}}
            {p\ssub L(\Tgt L | \Src L)^{\beta \ssub L}}
        \right] - \gamma \H(\mu)
        .
\end{align*}

The notation $\bbr{\dg M}^*_\gamma := \argmin_\mu \bbr{\dg M}_\gamma(\mu)$ denotes the set of optimal distributions at a particular $\gamma$.
Of particular interest is the ``quantitative limit'' as $\gamma \to 0$, 
at which there is a unique optimal joint distribution, $\bbr{\dg M}^*$.
This distribution uniquely achieves the smallest information deficiency among those distributions maximally compatible with $\dg M$. 

One should be careful to distinguish this joint distribution $\bbr{\dg M}^* \in \Delta\V \N$, which arises in the limit as $\gamma \to 0$, from $\bbr{\dg M}^*_0$, the set of distributions that minimize $\Inc_{\dg M}$ which contains $\bbr{\dg M}^*$, and possibly many others. 

The inconsistency of a PDG $\dg M$ is the smallest possible score of any distribution:
\begin{align*}
    \aar{\dg M}_\gamma := \inf_{\mu \in \Delta\!\V\!\N}\, \bbr{\dg M}_\gamma(\mu).
\end{align*}
To parallel the notation for scoring functions, when we omit the subscript, we refer to the limit as $\gamma\to 0$, which, unlike before, obeys $\aar{\dg M} = \aar{\dg M}_0$. 

\textbf{Exponential Cones.}
The exponential cone is the convex set
\begin{align*}
    K_{\mskip-1mu\exp} &:=\!\!\!\!\!\!
        \begin{aligned}
        \big\{ (x_1, x_2, x_3) &: 
                x_1 \ge x_2 e^{x_3 / x_2},\, x_2 > 0 \big\} 
        \\\quad \mathbin{\cup}\, \big\{ (x_1, 0, x_3) &: x_1 \ge 0,\, x_3 \le 0 \big\} 
    \end{aligned}
    \subset \mathbb R^3.
\end{align*}

\TODO[Should I talk about disciplined convex programming here? 
    It might go something like this:]



\section{UPDATING AND INFERENCE VIA INCONSISTENCY MINIMIZATION}





\begin{linked}{prop}{optimalYgivenX}
	% \label{prop:optimalYgivenX}
	% For all $\dg M$, $X,Y\in\N^{\dg M}$, and $\gamma > 0$, we have that
    For all variables $X,Y$, and $\gamma > 0$, 
	$$\displaystyle
		% \argmin_{p : X \to \Delta Y}
		\argmin_{p(Y|X)}\,
        \aar{\dg M + p}_\gamma =
		\Big\{ \mu(Y | X) :  \mu \in \bbr{\dg M}_\gamma^* \Big\}
	.$$
\end{linked}
In the limit, of small $\gamma$, since there is only one such distribution,
the expression beomes simpler.

\begin{linked}{coro}{smallgammaopt}
	$\displaystyle
		\bbr{\dg M}^*(Y | X)
	$ uniquely minimizes $p(Y\mid X) \mapsto \aar{\dg M + p}$.
\end{linked}


% \begin{prop}
% \begin
%     	% \label{prop:optimalYgivenX}
%     	% For all $\dg M$, $X,Y\in\N^{\dg M}$, and $\gamma > 0$, we have that
%     	$\displaystyle
%     		\argmin_{p : X \to \Delta Y} \aar{\dg M + p}_\gamma =
%     		\Big\{ \mu(Y | X) :  \mu \in \bbr{\dg M}_\gamma^* \Big\}
%     	$.
% \end{prop}

\section{REDUCTION TO A CONVEX PROGRAM WITH EXPONENTIAL CONE CONSTRAINTS}

We now present the central finding of our paper: formalizing the critical observation that the PDG objective $\bbr{\dg M}_\gamma$ can be written
as a linear optimization problem with exponential cone constraints.

We will proceed as follows: 
\begin{enumerate}[itemsep=0pt]
    \item
    illustrate how to find the minimizers of $\Inc$, in a simple setting with only one variable and no conditional distributions.
    \item
    show how the same approach can be generalized to find minimizers of $\Inc$ in general PDGs,
    \item \label{item:+idef}
    show how to find $\bbr{\dg M}^*$, the unique distribution specified by $\dg M$ in the quantitative limit.
    
    % \item \label{item:cccp}
    % employ the convex-concave procedure 
    % \parencite{yuille2003concave}, to find some minimizer $\mu^* \in \bbr{\dg M}^*_\gamma$ (although it may not be unique), for fixed $\gamma > 0$.
    % 
    \item 
    % Finally, show how \cref{item:+idef,item:cccp} can also be achieved 
    Finally, show how this can all be done
    with a more efficient compact representation, for PDGs that have
    bounded tree-width.
\end{enumerate}

\subsection{}\label{sec:illust}

To illustrate the idea, consider the special case in which our PDG contains only one variable $X$, which takes values $\V(X) = \{1, \ldots, n\}$. 
Suppose further that for every edge $j \in \Ed = \{1, \ldots, m\}$, the cpd $p_j(X)$ is an unconditional dsitribution over $X$. 
    % i.e., $\Tgt k = X$, and $\Src k = \emptyset$.
% Such unconditional probabilities may be identified with unit vectors $\mat p\ssub L \in \mathbb R^n$.  Similarly a candidate (``joint'') distribution $\mu(X)$
Such unconditional probabilities may be identified with unit vectors $\mat p_j \in \mathbb R^n$, and all $m$ of them may conjoined to form a stochastic matrix $\mat P = [\,p_{ij}] \in [0,1]^{n \times m}$.
Of course, a candidate (``joint'') distribution $\mu(X)$
may be represented as a unit vector $\mat m \in \mathbb R^n$. 
%
% Now, consider another collection of vectors $\{\mat t\ssub {\,L}\,\in \mathbb R^n\}_{L \in \Ed}$ and notice that:
% \begin{align*}
%     \forall  L &\in \Ed.~~ 
%     (-\mat t\ssub L\,, \mat m, \mat p\ssub L) \in K_{\exp}^n \\
%         &\iff 
%             \forall  L \in \Ed.~~
%             \mat t \succeq {\mat m} \log \frac{\mat m}{\mat p}
%         \\&\implies \sum_{L \in \Ed}\sum_{i=1}^n t_i  \ge \kldiv{\mat m}{\mat p}
% \end{align*}
Now consider a matrix $\mat U = [u_{ij}] \in \Rext^{n \times m}$,
and observe that:
\begin{align*}
    &(- \mat U,~ \mat m \otimes \mat 1,~ \mat P) \in K_{\exp}^{n \times m} \\
    &\iff \forall  i,j \in [n]\!\times\![m].~~ 
        (- u_{ij}, m_{i}, p_{ij}) \in K_{\exp} \\
    &\iff \forall  i,j \in [n]\!\times\![m].~~ 
            u_{ij} \ge m_i \log \frac{m_i}{p_{ij}} \\
    &\implies \forall j \in [n].~~  {\textstyle\sum_i} u_{ij}  \ge \kldiv{\mu}{p_j} \\
    &\implies \sum_{i,j} \beta_j u_{ij}  \ge \beta_j \kldiv{\mu}{p_j} \\
    &\iff \mat 1^{\sf T} \mat U \bbeta \ge \Inc(\mu)
    .
    % &\implies \sum_{L \in \Ed}\sum_{i=1}^n t_i  \ge \kldiv{\mat m}{\mat p}
\end{align*}

So now, if $(\mat U, \mat m)$ are a solution to the convex program
\[
    % \mathop{\text{minimize}}
    \min
    \limits_{\mat m, \mat T}~~
        \mat 1^{\sf T} \mat U \bbeta 
    \quad\text{subject to}\quad 
    \begin{cases}
        (-\mat U, \mat m\otimes \mat 1,\, \mat P) \in K_{\exp}^{n \times m} \\
        \mat 1^{\sf T} \mat m  = 1
    \end{cases},
\]
then (1) the inconsistency $\aar{\dg M} = \mat 1^{\sf T} \mat U \bbeta$ equals the optimal objective value, and 
(2) $\mu \in \bbr{\dg M}^*_0$ is maximally compatible with $\mu$. 
% This illustrates the general principle, but 

\subsection{Adding More Variables, Conditionals, Marginals}

% Having seen some of the details of the maxtrix computations, let's now move up a level, and make the identifications between distributions and vectors implicitly. 
% For example, we will implicitly identify a joint distribution $\mu$ 
% with the appropriate vector 
Now, let's consider the general case of a pdg 
$\dg M = (\N, \Ed, \mathcal P, \balpha, \bbeta)$.
For each $L \in \Ed$, let $N_L := |\V(\Src L, \Tgt L)|$ be the dimension of joint settings of the source and target values of $L$, i.e., the dimension of the cpd $p \ssub L$.

Let $K := \sum_{L \in \Ed} N_L$ be the total dimension
of all of the condtional probabilities in $\dg M$.

Let $t = (t^L)_{L \in \Ed} \in \Rext^{K}$.
let $\Pi_{X}$ be the projection map that marginalizes to the variables $X$. 

Consider the problem

\begin{align*}
    % \min_{\mu, t} &\qquad
    \min_{\mat m, \mat t} &\quad
        % \Vert t \Vert_1  
        \sum_{L}\beta_L | t^L |
    \\
    \text{subject to:}&\quad
        % (-t^L, \mu(\Src L, \Tgt L), \mu(\Src L) p\ssub L(\Tgt L | \Src L)) 
        % (-t^L, \Pi_{(\Src L \Tgt L)}\mu, \Pi_{(\Src L)} (\mu) p\ssub L(\Tgt L | \Src L)) 
        \big(-t^L,~ \Pi_{\Src L\!\Tgt L}\mat m,~
            (\mat 1 \otimes \mat P\!\ssub L ) (\Pi_{\Src L} \mat m) \big) 
        % (-t^L_{xy}, \mu(x,y), )
            \in K_{\exp},\\
        &\qquad 
            % \mu \ge 0, ~~ | \mu | = 1.
            \mat m \ge 0, ~~ | \mat m | = 1.
            \numberthis\label{eq:joint-prob}
\end{align*}

% This convex program has $K+1$ constraints 
\TODO[ I've rewritten this a couple times, and it's always pretty ugly.
    One higher level question: should we convert this to a different form? 
    The fact that we can even write constraints this way hinges on the fact
    that the arguments to the exponential cone are
    affine transformations of the program variables, which 
    this presentation sweeps under the rug entirely.
    \hfill ]

Logic similar to that in \cref{sec:illust} gives yields: 
\begin{prop}
    If $(\mu, t)$ are a solution to \eqref{eq:joint-prob}, then
    $\mu \in \bbr{\dg M}_0^*$,
    % i.e., is maximally compatible with $\dg M$, and
    and
    $\sum_{L}\beta_L |t^L| = \aar{\dg M}$.
\end{prop}

This is a start, but what we were really after was the unique distribution
$\bbr{\dg M}^*$ that also minimizes $\IDef{\dg M}$.

\subsection{Incorporating IDef}

% To do this second pass, we will need this second property
% As $\gamma \to 0$, the limit of $\bbr{\dg M}_\gamma$

So far, we have only found \emph{some} distribution that minimizes $\Inc$; 
we really wanted to find the unique distribution $\bbr{\dg M}^*$.
% Fortunately, this can be done by simply running a second optimization problem, 
It turns out that a solution to \eqref{eq:joint-prob}  to construct a second optimization problem of a similar size.
% To justify our approach, we will to prove two more results.
To justify our approach, we need a little more math. 
% First, a characterization of 
First, a characterization of the set $\bbr{\dg M}^*_0$ of distributions that are maximally compatible with $\dg M$. 

\begin{prop}\label{prop:marginonly}
	For any PDG $\dg M$, 
	the highest-compatibility distributions (the minimizers $\bbr{\dg M}_0^*$ of $\Inc_{\dg M}$) all have the same conditional probabilities along the edges of $\dg M$.   
	That is to say, if there is an edge $\ed LXY \in \Ed^{\dg M}$, and $\mu_1, \mu_2 \in \bbr{\dg M}_0^*$ are quantitatively optimal distributions, then $\mu_1(Y|X) = \mu_2(Y|X)$.  
\end{prop}

As a result, having already found one minimizer of $\Inc_{\dg M}$ via \eqref{eq:joint-prob}, it suffices to constrain distributions that have the same conditional marginals along the edges, and now optimize $\IDef{}$. 

We now run into a second issue: IDef is not convex in $\mu$. 
Fortunately, when we constrain to distributions that optimize $\Inc$, 
% it equals another function that is. 
it is.
Moreover, this function can also be represented with exponential cones.

\begin{prop}
For $\mu \in \bbr{\dg M}_0^*$, 
we have
\[
    \IDef{\dg M}(\mu) = \kldiv[\bigg]{\mu}{ \prod_{L \in \Ed} \nu(\Tgt L | \Src L) }
        + K(\dg M)
\]
where $\{ \nu(\Tgt L | \Src L ) \}_{L \in \Ed}$ are the
conditional marginals along the edges $\Ed$ 
shared by all distributions in $\bbr{\dg M}^*_0$,
(per \cref{prop:marginonly}),
and $K(\dg M)$ does not depend on $\mu$. 
\end{prop}



% \footnote{Indeed, $K_{\exp}$ is sometimes called the ``relative entropy cone'' for this reason.} 


% \subsection{Tree Deomposition
\subsection{A Polynomial Algorithm for the Case of Bounded Tree-Width}
The first property that makes this possible is 

\begin{linked}[Markov Property for PDGs]{prop}{markov-property}
	% Suppose $\dg M_1$ and $\dg M_2$ are compatible PDGs, and let $\mathbf X$ denote the variables they have in common.
	% Then for all $\gamma > 0$, we have that
	% \[
	%  	\bbr{\dg M_1 \bundle \dg M_2}^*_\gamma
	% 		% \subset
	% 		~\models~
	% 	% \mathrm I( \N_1 ; \N_2 \mid \mathbf X)
	% 	\N_1 \mathbin{\bot\!\!\!\bot} \N_2 \mid \mat X
	% \]
	% That is: in every optimizing distribution, for any value of $\gamma$, the variables of $\dg M_1$ and the variables of $\dg M_2$ are conditionally independent given their shared variables $\mat X$.
	% Suppose $\dg M_1$ and $\dg M_2$ are value-compatible PDGs,
	% with respective sets of nodes $\mat X_1 := \N^{\dg M_1}$ and
	% $\mat X_2 := \N^{\dg M_2}$.
	Suppose $\dg M_1$ and $\dg M_2$, over respective sets of variables $\mat X_1$ and $\mat X_2$.
	 % and let $\mathbf X$ denote the variables they have in common.
	Then for all $\gamma > 0$, we have that
	\[
	 	\bbr{\dg M_1 \bundle \dg M_2}^*_\gamma
			% \subset
			~\models~
		% \mathrm I( \N_1 ; \N_2 \mid \mathbf X)
		% \N_1 \mathbin{\bot\!\!\!\bot} \N_2 \mid \mat X
		% \N^{\dg M_1} \mathbin{\bot\!\!\!\bot} \N^{\dg M_2} \mid \mat X
		\mat X_1 \mathbin{\bot\!\!\!\bot} \mat X_2 \mid \mat X_1 \cap \mat X_2.
	\]
	That is to say: in every optimal distribution $\mu^* \in \bbr{\dg M_1 \bundle \dg M_2}^*_\gamma$,
     % for some $\gamma>0$, 
    the variables of $\dg M_1$ and of $\dg M_2$ are conditionally independent given the variables they have in common.
\end{linked}

One consequence of \cref{prop:markov-property} is that every distribution that a PDG
can pick out (for any choice of $\gamma > 0$ and also in the limit as $\gamma \to 0$), can also be described as a factor graph with the same structure as that PDG.
How do we square this with the \citeauthor{pdg-aaai}'s claim that PDGs are more general than factor graphs?


% This may be surprising, given how \citeauthor{pdg-aaai} position their model as strictly more expressive than other graphical models, because it implies that the optimal distribution 

\TODO[TODO: answer this question.\\
    The short answer: PDGs still compose differently, and in a way that respects the meaning of the probabilities. And just because you can find a factor graph that would have given you the right distribution after the fact, doesn't mean you could have specified the component factors.]
% The answer is simply that 



\section{THEORETICAL ANALYSIS: THE COMPLEXITY OF INFERENCE}

Since inference in other graphical models is already NP-hard, 
and the class of PDGs subsumes capture them, it should be no surprise 
that inference in PDGs is NP hard as well.
%
%
One might imagine that \emph{resolving} the inconsistency is the hard part,
    as opposed to noticing it. 
Might it easier to simply determine whether or not a PDG is inconsistent?
% With some wishful thinking, one might imagine it possible
Alas, it is not.
% this is not the case either.

\begin{linked}{prop}{consistent-NP-hard}\label{sharp-p-hard}
    \begin{enumerate}[nosep,label={\rm{(\alph*)}}]
    \item Deciding if $\dg M$ is consistent is NP-hard.
    \item Computing $\aar{\dg M}_\gamma$ is \#P-hard, for all $\gamma > 0$.
    \end{enumerate}
\end{linked}

After all, as we saw in \Cref{sec:}, an oracle that tells you your degree
of inconsistency can be combined with a convex optimization algorithm to determine marginals in a way that does not scale with the rest of the graph. 

If we do not restrict to finite variables, then the problem is much worse.

\begin{linked}{conj}{incomputable}
    The problem of deciding whether a PDG whose variables take values in $\mathbb N$ is not computable.
\end{linked}

Now, essentially all of this is true for  

\begin{linked}{theorem}{main}
    % For   O( 3 n * ((3n+m+1)^3 ) * log(√n / ϵ) )  =   O( n^4 log(n)  log(1 / ϵ) )
There is an algorithm that takes $O(n^4 \log n  \log \nf1\epsilon )$ time,
and finds a point $\epsilon$-close in residual norm to the optimal distribution
$\bbr{\dg M}^*$, where $n$ is the total number of parameters needed to cover a clique tree.
\end{linked}

\TODO[ Finding the optimal clique tree is NP-hard. 
    So how can we guarantee we won't get a bad clique tree (i.e., much wider than the tree-width) so as to claim that we can do inference much faster than in polynomial time? \hskip-1.1em ]

The proof relies almost entirely on the analysis of \textcite{badenbroek2021algorithm},
which certifies that the optimization algorithm 
proposed in \textcite{dahl2022primal} works in polynomial time. 

\begin{table}
    % Let $m$ denote the 
    \begin{tabular}{ccc}
        & Belief Propogation (for MRFs / BNs) &  Exponential Cone Optimizatin (for PDGs) \\
        Time & $O(m t)$ & $O( m^4 \log m )$ \\
        Space & $O(m + )$ & $O( m )$
    \end{tabular}
    \caption{ }
\end{table}


\section{INFERENCE WHEN
    \texorpdfstring{$\boldsymbol\gamma \boldsymbol> \mat 0$}{gamma > 0},
    VIA THE CONVEX-CONCAVE PROCEDURE }

We have now given an algorithm that will efficiently    


employ the convex-concave procedure 
\parencite{yuille2003concave}, to find some minimizer $\mu^* \in \bbr{\dg M}^*_\gamma$ (although it may not be unique), for fixed $\gamma > 0$.
        
\section{OTHER APPROACHES TO PDG INFERENCE}

\subsection{Relaxations}
Just as it is possible to do belief propogation on cluster graphs that are not trees,
so too is it possible to apply 
\cref{alg:ip-expcone}

\subsection{Variational Approaches}

Because of the deep connection between variational approaches 
shown in \parencite{one-true-loss}, 



\section{IMPLEMENTATION}
\section{EMPERICAL EVALUATION}
\section{DISCUSSION}

% Our anaysis 
Our analysis shows that inference in PDGs with bounded tree-width can be done 

\subsubsection*{Acknowledgements}
% All acknowledgments go at the end of the paper, including thanks to reviewers who gave useful comments, to colleagues who contributed to the ideas, and to funding agencies and corporate sponsors that provided financial support. 
% To preserve the anonymity, please include acknowledgments \emph{only} in the camera-ready papers.

\subsubsection*{References}
\printbibliography


\clearpage
\onecolumn
\appendix
\section{Proofs}

\recall{theorem:main}
\begin{lproof}\label{proof:main}
\end{lproof}

\subsection{}
\recall{prop:markov-property}
\begin{lproof}
	Choose $\mu \in \bbr{\dg M_1 \bundle \dg M_2}^*_\gamma$.
	% Choose $\mu \in \mu^*_\gamma (\dg M_1 \bundle \dg M_2)$.
	Let $\mu' := \mu(\N_1) \mu(\N_2)$
	
	\TODO[Finish Transcribing Proof]
\end{lproof}


\subsection{Hardness Results}

\recall{prop:consistent-NP-hard}
\begin{lproof} \label{proof:consistent-NP-hard}
	We can directly encode SAT problems as PDGs.
	Specifically, let
	$$\varphi := \bigwedge_{j \in \mathcal J} \bigvee_{i \in \mathcal I(j)} (X_{j,i})$$
	be a CNF formula over binary variables $\mat X := \bigcup_{j,i} X_{j,i}$. Let
	$\dg M_\varphi$ be the PDG containing every variable $X \in \mat X$ and a binary
	variable $C_j$ (taking the value 0 or 1) for each clause $j \in \mathcal J$, as well as the following edges, for each $j \in \mathcal J$:
	%\{$``$\varphi(\mat X)$''$\}$ with $\V(\varphi) = \{0,1\}$, and
	\begin{itemize}
		\item a hyper-edge $\{X_{j,i} : i \in \mathcal I(j)\} \tto C_j$, together with a degenerate cpd
			encoding the boolean OR function (i.e., the truth of $C_j$ given $\{X_{j,i}\}$);
		\item an edge $\pdgunit \tto C_j$, together with a cpd asserting $C_j$ be equal to 1.
	\end{itemize}
	% We give each edge $\alpha = 0$ and $\beta = 1$.
	First, note that the number of nodes, edges, and non-zero entries in the cpds are polynomial in the $|\mathcal J|, |\mat X|$, and the total number of parameters in a simple matrix representation of the cpds is also polynomial if $\mathcal I$ is bounded (e.g., if $\varphi$ is a 3-CNF formula).
	A satisfying assignment $\mat x \models \varphi$ of the variables $\mat X$ can be regarded as a degenerate joint distribution $\delta_{\mat X = \mat x}$ on $\mat X$, and extends uniquely to a full joint distribution $\mu_{\mat x} \in \Delta \V(\dg M_\varphi)$ consistent with all of the edges, by
	\[ \mu_{\mat x} = \delta_{\mat x} \otimes \delta_{\{C_j = \vee_i  x_{j,i}\}} \]

 	Conversely, if $\mu$ is a joint distribution consistent with the edges above, then any point $\mat x$ in the support of $\mu(\mat X)$ must be a satisfying assignment, since the two classes of edges respectively ensure that $1 =\mu(C_j\!=\! 1 \mid \mat X \!=\! \mat x) = \bigvee_{i \in \mathcal I(j)} \mat x_{j,i}$ for all $j \in \mathcal J$, and so $\mat x \models \varphi$.

	Thus, $\SD{\dg M_\varphi} \ne \emptyset$ if and only if $\varphi$ is satisfiable, so
	an algorithm for determining if a PDG is consistent can also be adapted (in polynomial space and time) for use as a SAT solver, and so the problem of determining if a PDG consistent is NP-hard.

% \end{lproof}
% \recall{prop:sharp-p-hard}
% \begin{lproof}\label{proof:sharp-p-hard}
    
    \medskip\hrule\smallskip
    
	\textbf{PART (b).}
    We prove this by reduction to \#SAT. Again, let $\varphi$ be some CNF formula over $\mat X$, and construct
	$\dg M_\varphi$ as in \hyperref[proof:consistent-NP-hard]{the proof} of
	\Cref{prop:consistent-NP-hard}.
	Furthemore, let $\bbr{\varphi} := \{ \mat x : \mat x \models \varphi \}$ be the set of  assingments to $\mat X$ satisfying $\varphi$, and $\#_\varphi := |\bbr{\dg M}|$ denote the number such assignments. We now claim that
	\begin{equation}\label{eqn:number-of-solns}
		\#_\varphi = \exp \left[- \frac1\gamma \aar{ \dg M_\varphi }_\gamma \right].
	\end{equation}
 	If true, we would have a reduced the \#P-hard problem of computing $\#_\varphi$ to the problem of computing $\aar{\dg M}_\gamma$ for fixed $\gamma$. We now proceed with proof \eqref{eqn:number-of-solns}.
	By definition, we have
	\[ \aar{\dg M_\varphi}_\gamma = \inf_\mu \Big[ \Inc_{\dg M_\varphi}(\mu) + \gamma \IDef{\dg M_\varphi}(\mu) \Big]. \]
	We start with a claim about first term.
	% For the particular PDG $\dg M_\varphi$, the

	\begin{iclaim} \label{claim:separate-inc-varphi}
		% $\Inc(\dg M_\varphi)$ is finite if and only if $\varphi$ is statisfiable.
		$\Inc_{\dg M_\varphi}\!(\mu) =
		% \begin{cases}
		% 	0 & \text{if}~  \mat x \models \varphi~\text{and}~\mat c = \mat 1
		% 	 	~\text{for all}~(\mat x, \mat c) \in \supp \mu\\
		% 	\infty & \text{otherwise}
		% \end{cases}
		\begin{cases}
			0 & \text{if}~  \supp \mu \subseteq \bbr{\varphi} \times \{ \mat 1\} \\
			\infty & \text{otherwise}
		\end{cases}$.
	\end{iclaim}
	\vspace{-1em}
	\begin{lproof}
		Writing out the definition explicitly, the first can be written as
		\begin{equation}
			\Inc_{\dg M_\varphi}\!(\mu) = \sum_{j} \left[ \kldiv[\Big]{\mu(C_j)}{\delta_1} +
				\Ex_{\mat x \sim \mu(\mat X_j)} \kldiv[\Big]{\mu(C_j \mid \mat X_j = \mat x)}{\delta_{\lor_i \mat x_{j,i}}} \right], \label{eqn:explicit-INC-Mvarphi}
				% &= \sum_{j} \left[
				% 	\begin{matrix} \mu(C_j\!=\!0) (\infty) \\
				% 	 	+ \mu(C_j \!=\! 1) \log \mu(C_j \!=\! 1)
				% 	\end{matrix} +
				% 	\Ex_{\mat x \sim \mu(\mat X_j)} \kldiv[\Big]{\mu(C_j \mid \mat X_j = \mat x)}{\delta_{\lor_i \mat x_i}} \right],
		\end{equation}
		where $\mat X_j = \{X_{ij} : j \in \mathcal I(j)\}$ is the set of variables that
		appear in clause $j$, and $\delta_{(-)}$ is the probability distribution placing all mass on the point indicated by its subscript.
		As a reminder, the relative entropy is given by
		\[ \kldiv[\Big]{\mu(\Omega)}{\nu(\Omega)} := \Ex_{\omega \sim \mu} \log \frac{\mu(\omega)}{\nu(\omega)},
		\quad\parbox{1.4in}{\centering and in particular, \\ if $\Omega$ is binary,}\quad
			\kldiv[\big]{\mu(\Omega)}{\delta_\omega} = \begin{cases}
				0 &  \text{if}~\mu(\omega) = 1 ; \\
				\infty & \text{otherwise}.
		\end{cases} \]
		Applying this to \eqref{eqn:explicit-INC-Mvarphi}, we find that either:
		\begin{enumerate}[itemsep=0pt]
			\item Every term of \eqref{eqn:explicit-INC-Mvarphi} is finite (and zero) so $\Inc_{\dg M_\varphi}(\mu) = 0$, which happens when $\mu(C_j = 1) = 1$ and $\mu(C_j = \vee_i~ x_{j,i}) = 1$ for all $j$.  In this case, $\mat c = \mat 1 = \{ \vee_i~x_{j,i} \}_j$ so $\mat x \models \varphi$ for every $(\mat{c,x}) \in \supp \mu$;
			\item Some term of \eqref{eqn:explicit-INC-Mvarphi} is infinite, so that $\Inc_{\dg M_\varphi}(\mu) = \infty$, which happens if some $j$, either

			\begin{enumerate}
				\item $\mu(C_j \ne 1) > 0$ --- in which case there is some $(\mat{x,c}) \in \supp \mu$ with $\mat c \ne 1$, or
				\item $\supp \mu(\mat C) = \{\mat 1\}$, but $\mu(C_j \ne \vee_i~ x_{j,i}) > 0$ --- in which case there is some $(\mat{x,1}) \in \supp \mu$ for which $1 = c_j \ne \vee_i~x_{j,i}\;$, and so $\mat x \not\models \varphi$.
			\end{enumerate}
		\end{enumerate}
		Condensing and rearranging slightly, we have shown that
		\[
			\Inc_{\dg M_\varphi}(\mu) =
			\begin{cases}
				0 & \text{if}~  \mat x \models \varphi~\text{and}~\mat c = \mat 1
				 	~\text{for all}~(\mat x, \mat c) \in \supp \mu\\
				\infty & \text{otherwise}
			\end{cases}~.
		\]
		% So if $\mat x \models \varphi$ for all $\mat x \in \supp \mu(X)$,
		%
		% $\Inc_{\dg M_\varphi}(\mu) = 0$
		% The first term is infinite if $\mu(C_j = 1) < 1$, and the second is infinite
		% if $\mu(C_j = \lor_i X_{i,j}) < 1$. Thus, if $\Inc_{\dg M_\varphi}(\mu)$ is finite, then $\mat x \sim \mu(\mat X)$ satisfies $\varphi$ with probability 1, and $\varphi$ must be satisfiable.
		% Conversely,
	\end{lproof}

	% Thus, if $\Inc_{\dg M_\varphi}(\mu)$ is finite, then every $\mat x \in \supp \mu$ is a satisfying assignment of $\varphi$.
	Because $\IDef{}$ is bounded, it follows immediately that
 	$\aar{\dg M_\varphi}_\gamma$, is finite if and only if
	there is some distribution $\mu \in \Delta\V(\mat X,\mat C)$ for which $\Inc_{\dg M_\varphi}(\mu)$ is finite, or equivalently, by \Cref{claim:separate-inc-varphi}, iff there exists some $\mu(\mat X) \in \Delta \V(\mat X)$ for which $\supp \mu(\mat X) \subseteq \bbr{\varphi}$, which in turn is true if and only if $\varphi$ is satisfiable.

	In particular, if $\varphi$ is not satisfiable (i.e., $\#_\varphi = 0$), then $\aar{\dg M_\varphi}_\gamma = +\infty$, and
	\[
		\exp \left[ -\frac1\gamma \aar{\dg M_\varphi}_\gamma \right] =
	 		\exp [ - \infty ] = 0 = \#_\varphi,
	\]
	so in this case \eqref{eqn:number-of-solns} holds as promised. On the other hand, if $\varphi$ \emph{is} satisfiable, then, again by \Cref{claim:separate-inc-varphi}, every $\mu$ minimizing $\bbr{\dg M_\varphi}_\gamma$, (i.e., every $\mu \in \bbr{\dg M_\varphi}_\gamma^*$) must be supported entirely on $\bbr{\varphi}$ and have $\Inc_{\dg M_\varphi}\!(\mu) = 0$.  As a result, we have
	\[
		\aar{\dg M_\varphi}_\gamma =
			\inf\nolimits_{\mu \in \Delta \big[\bbr{\varphi} \times \{\mat 1\}\big]} \gamma\; \IDef{\dg M_\varphi}(\mu) .
	\]
	A priori, by the definition of $\IDef{\dg M_\varphi}$, we have
	\[
		\IDef{\dg M_\varphi}(\mu) =
		 	- \H(\mu) + \sum_{j} \Big[ \alpha_{j,1} \H_\mu(C_j \mid \mat X_j)
						+ \alpha_{j,0} \H_\mu(C_j) \Big],
	\]
	where $\alpha_{j,0}$ and $\alpha_{j,1}$ are values of $\alpha$ for the edges of $\dg M_\varphi$, which we have not specified because they are rendered irrelevant by the fact that their corresponding cpds are deterministic. We now show how this plays out in the present case.
	Any $\mu \in \Delta\big[\bbr{\varphi} \times \{\mat 1\}\big]$ we consider has a degenerate marginal on $\mat C$. Specifcally, for every $j$, we have $\mu(C_j) = \delta_1$, and since entropy is non-negative and never increased by conditioning,
	$$
		0 \le \H_\mu(C_j \mid \mat X_j) \le \H_\mu(C_j) = 0.
	$$
	Therefore, $\IDef{\dg M_\varphi}(\mu)$ reduces to the negative entropy of $\mu$.
	Finally, making use of the fact that the maximum entropy distribution $\mu^*$ supported on a finite set $S$ is the uniform distribution on $S$, and has $\H(\mu^*) = \log | S |$, we have
	\begin{align*}
		\aar{\dg M_\varphi}_\gamma &= \inf\nolimits_{\mu \in \Delta \big[\bbr{\varphi} \times \{\mat 1\}\big]} \gamma\; \IDef{\dg M_\varphi}(\mu) \\
			&= \inf\nolimits_{\mu \in \Delta \big[\bbr{\varphi} \times \{\mat 1\}\big]} -\, \gamma\, \H(\mu) \\
			&= - \gamma\, \sup\nolimits_{\mu \in \Delta \big[\bbr{\varphi} \times \{\mat 1\}\big]}  \H(\mu) \\
			&= - \gamma\, \log (\#_\varphi),
	\end{align*}
	\hspace{1in}giving us
	$$
		\#_\varphi = \exp \left[- \frac1\gamma \aar{ \dg M_\varphi }_\gamma \right],
	$$
	as desired. We have now reduced \#SAT to computing $\aar{\dg M}_\gamma$, for $\gamma \in \mathbb R^{>0}$ and an arbitrary PDG $\dg M$, which is therefore \#P-hard.
\end{lproof}



\end{document}
