\documentclass{article}


\usepackage[margin=1.2in]{geometry}
\usepackage{parskip}

\input{pdg-preamble-v1}

\addbibresource{conf.bib}

\makeatletter
\newcommand{\@minipagerestore}{\setlength{\parskip}{\medskipamount}}
\makeatother

\usepackage{xparse}
\let\realItem\item % save a copy of the original item
\makeatletter
\NewDocumentCommand\myItemboldperiod{ o }{%
   \IfNoValueTF{#1}%
      {\realItem}% add an item
      {\realItem[\textbf{#1.}]\def\@currentlabel{#1}%
        % \def\cref@currentlabel{#1}
        }% add an item and update label
}
\makeatother


% \usepackage{enumitem}
\newlist{URaxioms}{enumerate}{1}
\setlist[URaxioms]{
    resume,%
    label=\textbf{UR\arabic{*}.},
    % label=UR\arabic{*},
    ref={UR\arabic*},
    leftmargin=2cm,
    before=\let\item\myItemboldperiod,
    topsep=1ex
    }
% \crefname{URaxiomsi}{axiom}{axioms}
\crefname{URaxiomsi}{}{}


\DeclareMathOperator{\supp}{\mathrm{Supp}}

% \makeatletter
% \newcommand{\customlabel}[2]{#2\def\@currentlabel{#2}\label{#1}}
% \makeatother



\begin{document}

\begin{center}
    \Huge\scshape Confidence (Belief Opacity?)
\end{center}
\bigskip

% You have confidence in a piece of information.
% The word ``confidence'' is sometimes used to stand in for a piece of information. 
% While high confidence in an event is much like high probability in the event, low confidence in the event and low probability are entriely different. 


\section{Update Rules: Changes in Confidence}

% We now describe our formal approach, in which 
% We now proceed with the formal details. 

\def\X{\mathcal X}
Let $\X = (X, \mathcal A)$ be a measurable space, so that $X$ is a set and $\mathcal A$ be a $\sigma$-algebra over $X$, and let $\Delta \X$ denote the set of probability measures over $\X$.
% maybe??
Let $\Phi$ be the set of statements about $X$ --- that is, the things one can have confidence in. 
A \emph{update rule} for $\Phi$ on $\X$ is a function of the form
\[
    F: \Big(\text{change in confidence}~\,\beta : \mathbb R\Big) 
    \times \Big(\text{statement}~\,\phi : \Phi\Big) \to \Big(\Delta\X  \to \Delta \X\Big),
\]
which describe how to update beliefs about $X$, with the new information, at a certain level of trust.
Given a piece of information $\phi \in \Phi$, and change in confidence $\beta$, we write $F^\beta_\phi : \Delta\X \to \Delta X$ for the \emph{update} prescribed by $F$. 
Note that updates can be composed. For instance, starting with a distribution $\mu_0 \in \Delta \X$, we can \emph{compose} updates.

% \[
%     \mu_0 
%         \xmapsto{\displaystyle F^{.3}_{\mathit{Height}=5'11''}} \mu_1 
%         \xmapsto{\displaystyle F^{.6}_{\Pr(Y=1|X=3)=0.4}} \mu_2
%         \xmapsto{\displaystyle F^{2.1}_{K_i(\varphi)}} \mu_3.
% \]


\begin{example}
    Perhaps we're uncertain about our shoe size. 
    Let space $X$ be the discrete set $\{ 35, \ldots, 50\}$ corresponding to possible shoe sizes, and $\mathcal A = 2^X$ be all possible subsets of it, so that a probability $\mu \in \Delta \X$ is just a 15-dimensional vector $\mat p$.
    For the assertion language, suppose $\Phi = \{\text{``shoe size is $x$''} : x \in X\}$, so that you can make assertions such as ``the shoe size is 42'' or ``the shoe size is 41''.
    
    Now, consider the update rule:
    \[
        % F^{\beta}_h( \mat p ) =   
        % \frac{1}{\mat p \cdot \mat e_h} \mat p \odot \exp(\beta )
        F^{\beta}_{\text{``shoe size is $h$''}} \left( 
            \begin{bmatrix} p_{35} \\ \vdots \\ p_{h} \\ \vdots \\ p_{50} \end{bmatrix}
        \right) =   
            \underbrace{\vphantom{\Bigg|}
                \frac{1}{1 + p_h (e^{\beta} - 1) } 
            }_{\text{normalizing constant}}
            \begin{bmatrix}
                \vdots \\
                \hphantom{e^\beta} p_{h-1} \\
                e^\beta \cdot p_h  \\
                \hphantom{e^\beta} p_{h+1}\\
                \vdots
            \end{bmatrix}
    \] 
    
    As mentioned above, you can compose udpates. For instance, suppose we had a prior $\mat p_0$ over shoe sizes, and then three people come up to us and tell us the shoe size---first an aquaintance, then our friend, and then our tailor.
    We trust them to different degrees, and may obtain a chain of updates as follows:
    \[
        \mat p_0 
            \xmapsto{\displaystyle F^{\,0.3}_{\text{``shoe size is 38''}}} 
        \mat p_1 
            \xmapsto{\displaystyle F^{\,0.6}_{\text{``shoe size is 49''}}}
        \mat p_2
            \xmapsto{\displaystyle F^{\,2.1}_{\text{``shoe size is 43''}}}
        \mat p_3.
    \]
    
    The choices of $\beta=0.3, 0,.6, 2.1$ seem meaningless, but one aim of this paper is to argue that they are meaningful relative to an update rule. 
    
    More notes:
    \begin{enumerate}
        \item The order might matter.
        \item If we are certain of our own shoe size, then nothing can sway us. 
        \item betas are meaningless if we mix and match update rules
    \end{enumerate}
        
\end{example}

How should we get the numbers $\beta$?  Their meaning depends on the precise nature of the update rule.

% We would like update rules to satisfy the following axioms:
\subsection{Basic Properties of Update Rules}
Here are some reasonable properties one might expect an udpate rule to have. 
% For all $A \in \mathcal A$,
For all $\phi \in \Phi$,
and all $\beta,\beta_1, \beta_2 \in \mathbb R$:

%% OLD VERSION
% \begin{enumerate}[label=\textbf{UR\arabic{*}.},leftmargin=2cm]
%     \item $F_A$ is a continuous function
%         \hfill\textbf{(continuity)}
%     \item For all automorphisms $\sigma \in \mathrm{Aut}(X)$,\\
%         $\sigma \circ F_{A} = F_{\sigma(A)}(\sigma \circ \Pr)$.
%         % That is, $\sigma^\# F_{A}(\Pr) = F_{\sigma(A)}( \sigma^\# \Pr)$.
%         % That is, $F_{A}(\Pr) = F_{\sigma(A)}(\Pr)$.
%         \hfill\textbf{(symmetry)}
%
%     % \item \textbf{(zero)} $F^{0}_A(\Pr) = (\Pr)$
%     \item  $F^{0}_A  =  \mathrm{1}_{\Delta\X}$.\\
%         (That is, $F^{0}_A(\Pr) = \Pr$ for all $\Pr \in \Delta\X$.)
%         \hfill \textbf{(zero)}
%     \item $F^{\beta_1}_A \circ F^{\beta_2}_A = F^{\beta_1 + \beta_2}_A$
%         \hfill \textbf{(additivity)}
%     \item $\displaystyle \lim_{\beta\to\infty} F^\beta_A (\Pr) = \Pr|A$
%         \hfill \textbf{(absolute certainty)}
%
%
% \end{enumerate}
% \begin{enumerate}[label=\textbf{UR\arabic{*}.},leftmargin=2cm]
\begin{URaxioms}
    % \item \textbf{(zero)} $F^{0}_A(\Pr) = (\Pr)$
    % \item  $F^{0}_A  = {1}_{\Delta\X}$. (That is, $F^{0}_A(\Pr) = \Pr$ for all $\Pr \in \Delta\X$.)
    \item  $F^{0}_\phi  = {1}_{\Delta\X}$. (That is, $F^{0}_\phi(\Pr) = \Pr$ for all $\Pr \in \Delta\X$.)
        \hfill \textbf{(zero)} \label{ax:zero}
    % \item $F^{\beta_1}_A \circ F^{\beta_2}_A = F^{\beta_1 + \beta_2}_A$
    \item $F^{\beta_1}_\phi \circ F^{\beta_2}_\phi = F^{\beta_1 + \beta_2}_\phi$
        \hfill \textbf{(additivity)} \label{ax:additivity}
        
    % \item The function $\beta\mapsto F_A(\beta, \Pr)$ is continuously differentiable.
    \item Fixing $\Pr$, the function $\beta\mapsto F_\phi^\beta(\Pr)$ is
    % continuously
    differentiable.
        %(in pairs $(\beta,\Pr)$).
            \hfill \textbf{(differentiability)} \label{ax:diffble}
\end{URaxioms}


We would also like update rules to preserve any symmetries shared by the state space $\X$ and the assertion language $\Phi$, so that updates are not sensitive to irrelevant labelings of points. 
Concretely, let $\mathrm{Aut}(X, \Phi)$ be the set of automorphisms $\sigma : X \to X$, together with an action on assertions, so that $\sigma\phi \in \Phi$ is the appropriately relabeled assertion equivalent to $\phi$ after the relabeling. 
This requirement is captured by: 

\begin{URaxioms}
    \item
        % All symmetries of $\X$ are reflected in the update rule.
        % Concretely, for all  $\sigma
        For all $\sigma
            % : X \to X
            \in \mathrm{Aut}(X, \Phi)$, we have 
        % \\ \indent\hspace{2em}
        % $F^\beta_A(\sigma_\#(\Pr)) = \sigma_\#\Big(F^\beta_{\{\sigma(a) : a \in A \}}(\Pr)\Big)$,
        $F^\beta_\phi (\sigma_\#(\Pr)) = \sigma_\#\Big(F^\beta_{\sigma\phi}(\Pr)\Big)$,
            \hfill \textbf{(symmetry)} \label{ax:symmetry}
        \\
        where $\sigma_\#(\Pr)$ is the pushforward of $\Pr$ under $\sigma$.
\end{URaxioms}
% \end{enumerate}

% \begin{enumerate}[resume,label=\textbf{UR\arabic{*}.},nosep,leftmargin=2cm]
%     \item If $A$ and $B$ are independent, then $F^{\beta}_A \circ F^{\beta}_B = F^{\beta}_{A \cap B}$.
%         \hfill \textbf{(decomposition)}
% \end{enumerate}

One possible choice of $\Phi$ statements with the $\sigma$-algebra $\mathcal A$ of measurable sets, which are closed under union and complementation, and on which probabilistic conditioning is defined, we also have:

\begin{URaxioms}
    \item $\displaystyle \lim_{\beta\to\infty} F^\beta_A (\Pr) = \Pr|A$
    \hfill \textbf{(absolute certainty)} \label{ax:certainty}


    \item
    % $F^\beta_A$ and $F_{\bar A}^\beta$ are inverses.
    $F^\beta_A \circ F_{\bar A}^\beta = 1_{\Delta\X}$.
        \hfill \textbf{(complementation)} \label{ax:comp}
\end{URaxioms}


We can also consider the weaker variant of \Cref{ax:certainty}:
\begin{URaxioms}
    % \item[U3$'$.]  \textbf{(effectiveness)~} $\supp F^\infty_A (\Pr) \subset A $
    % customlabel
    \item[\Cref*{ax:certainty}$'$]  $F^\infty_A (\Pr)(A) = 1$
    % \item[\customlabel{ax:effectiveness}{\textbf{\Cref*{ax:certainty}$'$.}}]
        $F^\infty_A (\Pr)(A) = 1$
        % \makeatletter
        % \@currentlabel
        % \makeatother
        \hfill \textbf{(effectiveness)} \label[URaxiomsi]{ax:effectiveness}
\end{URaxioms}
in which the limit of infinite confidence in $A$ is not required be the same as conditioning the starting point on $A$, but still must have the same effect of ensuring that $A$ occurs with probability 1. 



% \subsection{Further Axiomitization: Compatibility with Structure}
% \textit{DIVERGENCE.~~}
% \textbf{Divergence.}
\subsubsection*{Compatibility with Divergences and Cost Functions}
Suppose that, in addition, we have a ``divergence'' function $d : X \times X \to \mathbb R^+$ on $X$, with the property that $d(x,y) = 0$ iff $x = y$.
For sets $A \subset X$, let $d(x, A) := \inf_{a \in A} d(x,a)$ be the smallest possible divergence between $x$ and any member of $A$; symmetrically, define $d(A, x) := \inf_{a \in A} d(a,x)$.

% What we are trying to do with divergence functions here is an example of a
% slightly more broader definition,
If we drop the requirement that the smallest possible value of $d(A,x)$ must equal zero, we obtain the more general notion of a cost (or loss) function, $c :\mathcal A \times X \to \mathbb R_{\ge 0}$ satisfying
\[
% c : \mathcal A \times X \to \mathbb R_{\ge 0}
% \quad\text{such that}\quad
\forall A \in \mathcal A.~\arg\min_{x} c_A(x) = A.
% \forall A \in \mathcal A.\quad c_A(x) = 0 ~\Leftrightarrow~ x \in A.%
% \footnote{Any $c$ with the property that $\arg\min_{x} c_A(x) = A$ for all $A$ only differs from such a $c$ by a constant.}
% \qquad \text{and}\qquad
% \inf_{a \in A} c_A()
\]
The idea is that, if $c(x)$ is some cost that ``incentivises'' membership in $A$, then increasing confidence in $A$ ought decrease expected cost. 
% Note that given a divergence function $d$ as described above, the expression $d(A, x) = \inf_{a \in A} d(a,x)$ satisfies this criterion.
\begin{URaxioms}
    \item For all $\beta > 0$ and $A\in\mathcal A$, we have 
    $\Ex_{F^{\beta}_A(\Pr)} [ c_A ]
        \le
        \Ex_{\Pr}[ c_A ]
    $
        \hfill \textbf{($c$\,-monotonicity)}
\end{URaxioms}


We can also use $c$ to define a notion of independence.

\begin{defn}[$c$-independence]
For $A,B,Z \subset X$,
we say that $A$ and $B$ are $c$-independent given $Z$ iff
% $d(A, b) = d(a, B)$ for all $a\in A$ and $b \in B$.
for all $z \in Z$, we have that
% $c(z, A \cap B) = c(z, A) + c(z,B)$.
$c_{A\cap B}(z) = c_{A}(z) + c_{B}(z)$.
\end{defn}

To give a few examples:
\begin{enumerate}
    \item Every set $A \in\mathcal A$ is independent of the trivial event $X$, since
        $
            c(z, A\cap X) = c(z, A)
        $
        and $c(z, X) = 0$.
    \item Suppose $\X$ is a subset of $\mathbb R^n$, so that $x = (x_1, \ldots, x_n)$, and cost is L1 distance, given by $c(x,A) = \inf_{a \in A} \sum_{i=1}^n {|a_i - x_i|}$. Now for $i\ne j$,
    the sets $A_i(b) := \{ x : x_i = b \}$
    and $A_j(b') := \{x : x_j = b' \}$ are unconditionally $c$-independent.
    This makes sense, since they are orthogonal hyperplanes.

    % \item  
    % \begin{wip}
    % Suppose $\X \cong Y \times Z$ is a product space, to be thought of as the set of possible joint settings of two variables $Y$ and $Z$.
    % Now, fix a probability measure $p(Y,Z)$ over $\X$
    % and let
    % % $c(x, A) := \I_{p|A}(\{x\}) = -\log P(x | A)$.
    % $c(x, A) := -\log p(A \cap \{x\})$, with the convention that $-\log 0 = \infty$.
    % Then, $A, B$ are $c$-independent given $Z$ iff
    % \[
    %     - \log p(A \cap B \cap \{z\}) =
    %     - \log p(A \cap \{z\}) - \log p(B \cap \{z\})
    % \]
    % If $z \notin A \cap B$, then both sides will be infinite. If $z \in A \cap B$,
    % \[
    %     - \log p(z) = - \log p(z) - \log p(z)
    %     \quad\iff\quad
    %     p(z) = p(z)^2
    %     \quad\iff\quad
    %     p(z) \in \{0,1\}
    % \]
    % \end{wip}
\end{enumerate}

% Once we have a notion of independence such as this one (although we will also consider others), we can articulate another axiom for update rules:
Armed with this notion of independence, we can articulate one further axiom for udpate rules:
\begin{URaxioms}
% \begin{enumerate}[resume,label=\textbf{UR\arabic{*}.},nosep,leftmargin=2cm]
    % \item[\textbf{UR4}.]
    \item
    % \item[\textbf{UR4-d}.]
    % If $A$ and $B$ are $d$-independent, then
    % $F^{\beta}_A \circ F^{\beta}_B = F^{\beta}_{A \cap B}$.
    %     \hfill \textbf{($d$-decomposition)}
    If $A$ and $B$ are independent given $\supp(\Pr)$, then \\
    $F^{\beta}_A \circ F^{\beta}_B (\Pr) = F^{\beta}_{A \cap B}(\Pr)$.
        \hfill \textbf{(decomposition)}
    % \item $\Ex_{F^\beta_A \Pr}[ d(X,A)]$ is (strictly) decreasing in $\beta$, so long as it is positive
    % \hfill \textbf{(monotonicity)}
% \end{enumerate}
\end{URaxioms}
The idea here is that if $A$ and $B$ are independent, then it is equivalent to learn them in either order, or both at once.  


% \begin{enumerate}
%     \item[\textbf{UR4-c}.] If $A$ and $B$ are $d$-independent, then $F^{\beta}_A \circ F^{\beta}_B = F^{\beta}_{A \cap B}$.
%         \hfill \textbf{($c$-decomposition)}
% \end{enumerate}

%%%%%%% OTHER STRUCTURE
% \subsubsection*{A Topology}
% \subsubsection*{A Smooth Manifold Structure}
% \subsubsection*{A Matroid}
% \subsubsection*{A Riemannian Metric}


\section{Characterization of Update Rules}

An update rule $F$ for some set of statements $\Phi$ also naturally suggests a way of updating based on 
\[ 
\Phi^{\mathbb R *} := \Big\{ 
    % \text{finite sequences}~
    %     [(\phi_1, \beta_1), \ldots (\phi_n, \beta_n)] 
    ~\text{sequences}~ (\phi_i, \beta_i)_{i \in \mathbb N}
    ~\Big|~ 
    % \forall i \in \{1 \ldots n \}. ~ \phi_i \in \Phi, \beta_i \in \mathbb R
    ~ \phi_i \in \Phi, \beta_i \in \mathbb R \,\text{ for all }\, i \in \mathbb N~
    \Big\}
\] 
via sequential composition of the underlying updates:
\[
    % \bar F^{\beta}_{\boldsymbol \varphi = (\beta_i \phi_i)_{i =1, \ldots n}}
    \bar F^{k}_{\boldsymbol \varphi \cdot \boldsymbol\beta}
        (\mu) := F^{k \beta_1}_{\phi_1} \circ F^{k \beta_2}_{\phi_2}
            \circ \cdots\circ F^{k \beta_n}_{\phi_n}(\mu).            
\]

$\bar F$ satisfies \cref{ax:zero,ax:diffble,ax:symmetry} because $F$ does. 
However, it will not in general be an update rule, because (unless the updates are commutative), there's no reason for it to inherit additivity (\cref{ax:additivity}) from $F$. 
Nevertheless, there is a natural way of combining the updates \emph{without} order. 

\subsection{Vector Field Representations of Update Rules}
    \label{sec:vecrep}
For a smooth manifold $M$
(such as the space $\Delta \X$ of distributions over $\X$),
and a point $p \in M$, we follow convention by writing $T_p M$ for the tangent space to $M$ at point $p$ \parencite{lee2013smooth}, and % $TM := \sqcup_{p \in M} (p, T_p M)$
$TM := \sum_{p \in M} T_p M$ for the full tangent bundle over $M$.
%
A vector field over $M$ is a smooth map $\mat v : M \to T M$ assigning a tangent vector $\mat v(p) \in T_p M$, to every point $p \in M$, or equivalently, a smooth section of the projection map $\pi : T M \to M$, where $\pi((p, v)) = p$.

\begin{theorem}
    There is a bijection between
    update rules $F : \Phi \times \mathbb R \to \Delta \X \to \Delta \X$
        satisfying \cref{ax:zero,ax:additivity,ax:diffble}, 
    and $\Phi$-indexed collections of vector fields 
        $\{ F'_\phi : \Delta X \to T \Delta X \}_{\phi \in \Phi}$%
        % $F' : \Phi \to \Delta\X \to T\Delta \X$%
    .
\end{theorem}

One defining feature of vector fields is closure under linear 
    (and, in particular, convex) combination. 
Because they are in natural correspondance with differentiable additive update rules, update rules also inherit this natural in mixing operation. 
How shall we interperet this?


% \subsection{}
% \subsection{Characterization Theorem for the PDG Update Rule}

\subsection{}



\newpage%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Examples}

\subsection{The Two-Point Space}
First, suppose $X = \{0,1\}$ and $\mathcal A = 2^X$.

\begin{claim}
The space of update rules satisfying
% UR1-6
\cref{ax:zero,ax:additivity,ax:certainty,ax:symmetry,ax:diffble}
% is in bijection with continuous monotone functions
is in bijection with the space of strictly increasing differentiable functions
$\gamma : [0,\infty) \to [0,1]$
% in the space $\Delta X \cong [0,1]$ of probability distributions over $\{0,1\}$,
such that
% \begin{align*}
%     \gamma_0(0) &= 1
%     &
%         \gamma_1(0) &= 0
%         \\
%     \lim_{t\to\infty}\gamma_0(t) &= 0
%     &
%         \lim_{t\to\infty}\gamma_1(t) &= 1
%         \\
% \end{align*}
$\gamma(0) = 0$ and $\lim_{t\to\infty}\gamma(t) = 1$.
\end{claim}
\begin{lproof}
    Let's first investigate the behavior of an update rule $F$ on the singleton $A := \{1\}$.
    % Fix some $\epsilon > 0$.
    % By \Cref{ax:zero,ax:additivity}
    % \ref{ax:effectiveness}
    % \cref{ax:effectiveness}
    By \ref{ax:effectiveness} or \cref{ax:certainty} we know that, for any $p \in \Delta\{0,1\}$, and particularly for $p$ equal to the degenerate distribution $\delta_0$ that places all mass on the outcome $X=0$, we have
    \[
        \lim_{\beta \to \infty} F^\beta_{\{1\}}(\delta_0) = \delta_1.
    \]
    Define $\gamma(t) := F^{t}_{\{1\}}(\delta_0)(X=1)$.
    By \cref{ax:zero}, we have $F^0_{\{1\}}(\delta_0) = \delta_1$, so $\gamma(0) = 0$. 
    Note that $\Delta\{0,1\}$ is isomorphic to $[0,1]$, with $\delta_0$ and $\delta_1$ as the endpoints.  
    From continuity of $F$ in $\beta$ (\cref{ax:diffble}) and the intermediate value theorem, for all distributions $p \in \mathrm{Int}\, \Delta\{0,1\}$, there is some $\hat\beta_p$ such that
    $F^{\hat\beta_p}_{\{1\}}(\delta_0) = p$, so for all $x \in [0,1)$, there is some $\beta_x$ such that $\gamma(\beta_x) = x$.
    % $\gamma(\beta_p) = p$
    Furthermore, $\gamma$ must be strictly increasing. 
    If
    % $\beta > \beta'$
    $0 < x < y$ then again by the intermediate value theorem, there is some $\beta \in (0, \beta_y)$ 
    % such that $F^{\beta_q}_{\{1\}}(\delta_0)(X=1) $
    such that $\gamma(\beta) = x = \gamma(\beta_x)$. 
    
    \TODO{}

    Thus $\gamma(t) $ is a continuous monotone function from $[0,\infty)$ to $[0,1]$ with $\gamma(0) = 0$,
    % (as $F^0_{\{1\}}(\delta_0)(X=1) = \delta_0(X=1) = 0$)
    and $\lim_{t\to\infty} \gamma(t) = \delta_1$.


    Conversely, given such a function, we can define an update rule for the singleton $A = \{1\}$, as
    \[
        F^{\beta}_{\{1\}}(p) :=
        \begin{bmatrix}
            1 \mapsto& \gamma(\beta - \beta_p) \\
            0 \mapsto& 1-\gamma(\beta - \beta_p)
        \end{bmatrix}.
    \]
    % \[
    %     F^{\beta}_{\{1\}}
    %
\end{lproof}

The selectors are of the form
\begin{align*}
    F_0^\beta(p) &:= \sigma( \sigma^{-1}(p) - \beta a)
\end{align*}
where $\sigma(x) = \frac{1}{1 + e^{-x}}$ is the logistic function,

\subsection{Finite Spaces}
Now, for some $n \in \mathbb N$, suppose $X := [n] = \{1, \ldots, n\}$, and $\mathcal A$ be all subsets of $X$.

\subsection{Gaussians}
Consider the case where $\X$ is the set of real numbers with the Borell $\sigma$-algebra, and $d(x,y) := (x-y)^2$.
Then the cannoncial update rule corresponds to multiplying by a Gaussian density, whose variance is $\nicefrac1\beta$.

Furthermore, applying it to a distribution which is already Gaussian with mean $\mu$ and variance $\sigma^2$, we find that
\begin{align*}
    F^{\beta}_{X=b}(\mathcal N(\mu, \sigma^2))(x) &\propto
        \exp\left\{ - \frac12 \frac{(x-\mu)^2}{ \sigma^2 } - \beta(x-b)^2\right\}
    \\&\propto \mathcal N(x| \mu', \sigma'^2)
\end{align*}
which is itself a Gaussian with mean equal to the weighted average of $\mu$ and $\beta$.

The upshot is that

\subsection{Population Dynamics}
Imagine that $\X$ is a space of possible phenotypes, and that a probability $\Pr \in \Delta\!\X$ represents a population distribution.

\subsubsection{Decay}
Let $\mathcal X = (X, \mathcal A)$ be a a measurable space. 
 
% \[
%     F'(\mu)(x) :=   \ell(x) - \Ex\nolimits_\mu [ \ell ]
% \]


Now, consider a measurable lost function
$\ell: \X\times\mathcal A \to \mathbb R^+$. 
We can now define the \emph{$\ell$-selector}, which is the
update rule governed by exponential decay, by:
% \def\cost#1#2{c(#1,#2)}
% \def\cost#1#2{d(#1,#2)}
\def\cost#1#2{\ell_{#2}(#1)}
\begin{align*}
    F^\beta_A(\Pr)(x) &\propto \Pr(x) \cdot \exp(-\beta \cost xA)  
        \qquad\text{---or more formally,}\\
    F^\beta_A(\Pr)(B) &:=  \frac{1}{\Ex_{\Pr}[\exp(-\beta \cost xA )]}
        \int 1_B(x) \; \exp(-\beta \cost xA ) \,\mathrm d\Pr(x)
    %
\end{align*}

The name comes from the fact that, in our analogy to a population, an update of this kind corresponds to \emph{selection}.
% More concretely, applying $F^\beta_\ell$ to a population distributed according to $P$, is equivalent to the following algorithm:


% \begin{enumerate}[nosep]
%     \item Input: population distribution, a multiset $P$ of values of $x$, distributed according to $p(X)$.
%     \item Select a member $x$ of the population $P$.
%     \item
%         % Replace $x$ with $e^{-\ell(x)}$ copies of $x$.
%         Allow the population of $x$'s to grow/decay with rate $\ell(x)$, over a period $\beta$ of time.
%     \item Repeat.
% \end{enumerate}


% \begin{prop}
%     The cannonical update rule satisfies UR1-6.
% \end{prop}
% 
% 
% \begin{conj}
%     %[Characterization Theorem]
%     % Any update rule $F$ satisfying UR1-6 is a decay update rule for some cost function $c : \mathcal A \times X \to \mathbb R$.
%     Any update rule satisfying UR1-6 (++more) is a decay update rule for some cost function.
% \end{conj}


As a particular example, consider the loss $\ell_A(x) = \mathbbm1[x \in A]$.

It satisfies



\subsubsection{Flow}
\def\vgrad{\boldsymbol\nabla}
% \def\vgrad{\vec\nabla}
The update rule above only ``moves'' distributions by decay. If we imagine a distribution representing a population of individuals, the distribution has shifted by selection: an application of the update rule $F_A^\beta$ corresponds to culling the population, in proportion to their distance from $A$, over a time period of length $\beta$.
It is worth noting that such a population is then smaller, and must be re-normalized later.

A distribution could also shift by genuine motion of the underlying individuals.
In this case, let's model this as a partial differential equation in terms of $\Pr(x,t)$.
Now, we have some kind of conservation of mass, so from the continuity equation, we get
$\frac{\partial }{\partial t}Pr(x,t) = - \vgrad \cdot \mat J$,
where $\mat J(x,t)$ is the flux of individuals at point $x$ and time $t$.
Further assuming that the flux is generated by a combination of diffusion and a potential proportional to distance to $A$, we obtain

\[
    \frac{\partial \Pr(x, t)}{\partial t} = \vgrad_{\!x} \cdot \Big( k \vgrad_{\!x} \Pr (x) - \beta \vgrad_{\!x} d(x, A) \Big)
\]
where $k$ is a diffusion coefficient, and $\beta$

% To draw a different analogy, we can think of


\subsubsection{Drift}
We have talked about selection, but what about the second major force that drives evolution: random mutations?
% The important feature here is that not all information is truly used to find
% The result is that the population tends to ``spread out'', all else being equal,
% and has the effect of mixing the
One effect is that if there's no selection pressure to favor one variant over another, over time both variants will be represented equally.
Suppose that the elements of $\X$ have a canonical coded representation (such as DNA), such that specifying different phenotypes $x \in X$ requires different code lengths.
Because there is a tangible cost to carrying a larger genome, this induces a base measure with an inductive bias towards shorter codes.
% So the effect of random mutations is to mix

% \subsubsection{Sex}
% Sex is the thing that separates ``genetic algorithms'' from vanilla gradient descent.
%
% \begin{align*}
%     F^\beta_A(\Pr)(x) &\propto \Pr(x) \cdot \exp(-\beta \cost xA) \\
% \end{align*}

\subsection{Higher Order Probability Measures}
Now, suppose $\X$ is itself a set or probability measures.

\[
\]



Consider the following ways of extracting an (ordinary) probability measure $\mu(\Omega)$
from a higher order probability $\Pr(\mu(\Omega))$.

\begin{enumerate}
    \item \textbf{Centroid (Mean).}
        % $\mu^* := \textit{centroid}(\Pr)$.\\
        On a measurable set $A \in \mathcal A$, the centroid of $\Pr$ is defined as
        \[
            \mu^{\text{avg}}(A) := \Ex_{\mu \sim \Pr}[ \mu(A)] =
                \iint \Pr(\mu) \mu(x) 1_{A}(x)\, \mathrm d x\,\mathrm d\mu,
        \]
        the centroid is the usual ``flattening'' of a higher-order probability distribution, and corresponds to
        of the Giry Monad.

    \item \textbf{Highest Likelihood (Mode).}
        $\textit{MLE}(\Pr) := A \mapsto (\arg\max_\mu \Pr(\mu))(A)$

        This is the way that people often do inference.

    \item \textbf{MAP Inference.}
        Suppose we have a prior $\Pr_0$ over  $\Pr$

\end{enumerate}


\subsection{PDGs}

Given a PDG $\dg M$, let $\X := \Delta\V(\dg M) = \Delta(\prod_{X\in\N}\V(X))$. For each edge we have
\[
    F_L^{\beta}(\Pr) (\mu) \propto \Pr(\mu) \exp(-\beta \kldiv\mu \bp)
\]
This extends to
\[
    F_{\dg M}^k(\Pr)(\mu) \propto \Pr(\mu) \exp(- k \bbr{\dg M}_0(\mu))
\]
Note that
\begin{align*}
    \lim_{k \to \infty} F_{\dg M}^k(\Pr)(\mu) &\propto
        % \mathbbm1[\mu \in {\displaystyle\SD{\dg M}}]
        \Pr(\mu) \mathbbm1[\mu \in {\bbr{\dg M}^*_0}] \\
        &= \Pr \,|\, \bbr{\dg M}^*_0 \\
        &= \Pr \,|\, \SD{\dg M} \text{~if $\dg M$ is consistent.}
        % &= \mathrm{Unif}_{\{\!\!\{{\dg M}\}\!\!\}} \text{~if $\dg M$ is consistent.}
\end{align*}

On the other hand,
\begin{align*}
    \lim_{k \to 0} F_{\dg M}^k(\Pr)(\mu) &= \Pr \,|\, \Inc(\mu) < \infty \\
        &= \Pr \,|\, \{\mu : \forall L.~\mu(Y|X) \ll \bp \}.
        % \quad\Big(\text{i.e., if $\mu$ is absolutely continuous with respect to $\bp$}
        % \Big)
\end{align*}
That is to say, in the limit of small $\gamma$, applying the update rule is like
On the other hand, $F_{\dg M}^0(\Pr) = \Pr$. So $F$ can only be continuous at $k=0$ for $\Pr$ if, for all edges $L \in \Ed$, we have that $\Pr(\mu(Y|X) \ll \bp) = 1$.




\subsubsection*{The Qualitative Half}


There are a number of different ways to think about alpha.
\begin{enumerate}[nosep]
    \item $\alpha_L$ is your confidence in the functional dependence of $Y$ on $X$, given
    \item $\alpha_L$ is the ``alignment'' of the edge $L$
\end{enumerate}

We need a different distance function for the other half. Now we use
$d(\mu, DET)$.

% \begin{align*}
%
% \end{align*}

We need a different distance function for the qualitative loss function of a PDG.
Why measure distance differently in this case?


\section{Other Notions of Confidence}

\subsection{}

Define an update rule on $\Phi = \mathcal A$ via its vector field,
\[
    F'_A(\mu) := [ \mathbbm 1_{A} ] 
     \qquad = x \mapsto \mathbbm1\{x \in A\} - \mu(A) 
\]
which results in 
\[
    F_A^\beta(\mu)(x) \propto 
    \begin{cases}
        \mu(x) e^{-\beta} & x \in A \\
        \mu(x) & x \notin A
    \end{cases}
\]
\[\text{? or}\quad
    F_A^\beta(\mu) (B) =
    % \frac{1}{\Ex_\mu[ e^{} ]}
    \frac{1}{1 + (e^{-\beta}-1) \mu(A) } \mu(B) e^{-\beta \mu(A \cap B)}
\]

\subsection{Probability Measures}

% Fix a probability $\Pr(X)$, and
We began by remarking that often confidence is taken to mean probability. 
With this framework in mind, here is one explanation why.

Suppose $F$ is an update rule for assertions $\Phi_F = \mathcal A$.
Now consider a modified update rule $\tilde F$ over assertions $\Phi_{\tilde F} = \Delta\X$, given in vector field representation as
% Fix a probability distribution $p(X)$. 
% consider the update rule $G = \mathdcal F_p[F]$ whose vector field is given by 
\[
    \tilde F'_p(\mu) := \sum_{x} p(x) F'_{\{x\}}(\mu)
    = \Ex_{x \sim p} [ F'_{\{x\}} (\mu) ].
\]

More genrally, for the space of assertions $\Phi$ consisting of mass functions $m \in \Delta(2^X)$ that assign each subset of X, encoding a belief function. Then

\[
    \tilde F'_p(\mu) := \sum_{A \in \mathcal A} m(A) F'_{A}(\mu).
\]

% Intuitively, $\mathdcal F_p$ is the rule
% A fixed point of $\mathdcal F_p$ corresponds to an update rule such
% One natural question: what update rules



\subsection{Epistemic Entrenchment}
\subsection{Weighted Probability Measures}

\section{}
% Objective:
Consider a density $\rho : \X \to \mathbb R^+$, and consider the differential equations
\[
    % \frac{1}{u(x,t)}
    \frac{\mathrm d}{\mathrm d t} u(x,t)
    = - \Big\langle\mathrm d\beta(t), \ell(x) \Big\rangle
        \,
        {u(x,t)}
    \qquad\qquad%% OR %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \dot {\mat u} = - \beta \mathrm{Diag}(\ell) \mat u
        % = - \Big\langle\mathrm d\beta(t), \ell(x) \Big\rangle
\]
Which means
\[
    % \Big|
        \log u (x,t)
    % \Big|
    = \int_{0}^{t}  \ell(x) \mathrm d \beta \mathrm d \tau
\]
% And suppose $C(t)$ is such that $u(x,t)$ is conserved, i.e.,



\section{The Opacity Analogy}

% \begin{minipage}{0.48\linewidth}

    So far as a computer display is concerned, what ultimately matters are pixel colors. 
    And yet, in the standard representation of a color color, only three of the four bytes actually encodes color information; the last one describes opacity---in some sense, a \emph{confidence} in the color.
    % Far from an oversight, this enables the possibility of suggest a color with less than complete confidence is incredibly useful. 
    % The result is an ability to suggest a color with less than complete confidence. 
    This enables a great deal in graphics: intricate digital art, via semantically meaningful layers, 
        visual effects such as fire and fog that do not need to be modeled jointly with their surroundings.
    % This is not an oversight; working with translucency can be incredibly valuable.
     % porgrams enables .% 
        % \footnote{just as higher-level programming languages enable programmers to build larger projects by giving larger-scale structure}


    
% \end{minipage}
% \hfill
% \begin{minipage}{0.48\linewidth}
    So far as statistical models are concerned, what ultimately matters are probabilities of events. 
    But that doesn't appear to  
    
    
% \end{minipage}





% What matters in the end are probabilities, as far as probabilistic models are concerned.
% But that doesn't mean that 




% Probabilistic models may , but what matters in the end are probabilities. 
In the opacity analogy, an update rule corresponds to a ``blending strategy'' --- a way of overlaying an image over another one, with a specified translucency.  


\newpage
\printbibliography


\appendix
\section{General Thoughts}
(Variable) confidence is an important aspect of knowledge representation, because we need be able to entertain possibilities and reason about models we aren't sure about.

% The notion of confidence also has
% Confidence is the opposite of uncertainty: you cannot be uncertain about $X$ .
Confidence is often thought of as the opposite of uncertainty.


% Confidence is dual to information.
One has confidence in information.
Confidence and Information are thermodynamically ``conjugate variables''.


``cool-headed'' means calculated (a vote of confidence) while ``hot-headed'' means rash (such an assessment indicates a lack of confidence). Confidence is like inverse temperature.

Can you can be confident that $X$ is uncertain?
There is a huge difference between being certain that a coin has is fair, and knowing nothing about it.


% Here we draw a distinction between confidence and certainty:
% while you are certain that [proposition],

Confidence is intimately related to probability, and our development will largely be couched in probabilistic terms. But they are not the same concept. 
While having high confidence in $\varphi$ is not so different from thinking $\varphi$ likely, having \emph{low confidence} in $\varphi$ is not the same as having thinking $\varphi$ is unlikely.
To illustrate, consider a statement made by friend (a high-confidence source) and an adversary (a low-confidence source). 
 

% Nevertheless, we submit that in many cases---and especially in more subjective or computationally restricted settings---probability alone is not enough, and the higher-order probabilistic picture is far too extreme.

Confidence as learning rate. Bigger confidence ~= bigger step size.
Learning algorithms have learning rate schedules (rates decrease or cycle).  

\subsection*{Our Approach}
% Here is the idea: if you are confident in $X$, then you are
The idea is to view confidence as a property of an update, not as a property of a point of view.
In this telling

This allows us to distinguish between ...
%

% \begin{example}
% Let $X$ be a binary random variable, and suppose you have a prior probability $p$ that $X=1$.
% \begin{enumerate}
%     \item Suppose $p=1$.
%     This is a poor choice of prior.
%     If you then recieve information that $X=0$, something has gone very wrong, and the Bayesian update is undefined.
%
%     If you rceive information that $X = 1$, your internal state should not change.
%     % If we characterize
%
%     \item One might argue that only positive probabilities are relevant.
%     Suppose $p = 1 - \epsilon$.
% \end{enumerate}
% \end{example}


\subsection*{Issues To Address}
\begin{enumerate}
    \item The difference between having confidence in \emph{a source} and confidence in a particular \emph{fact}.  Is one more general than the other?
\end{enumerate}

Some intuitive features we might want to capture:
\begin{enumerate}

    \item \textbf{Trust Dynamics.} If a trusted source tells you something you already believe, your confidence in them goes up (maybe). Certainly if a source tells you something you know to be wrong, your confidence in the source goes down.  Whether or not you adopt the

    Also, if you ultimately end up adopting the belief, and later end upwith a more coherent picture of the world, your trust in the source should go way up.
    This is because in the end we want to place the most trust in sources that tell you the truth, not what you expect (or want) to hear.

    A source that tells you only exactly what you already believe ``artificially'' increases your confidence but does not actually provide you any information, unless they came to hold the same views independently.

\end{enumerate}

\TODO
\clearpage


\end{document}
