\documentclass{article}

\input{pdg-preamble-v1}

\usepackage[margin=1in]{geometry}
\usepackage{parskip}

\begin{document}
    
    


    
\section{General Thoughts}
Confidence is an important aspect of knowledge representation.

% The notion of confidence also has 
% Confidence is the opposite of uncertainty: you cannot be uncertain about $X$ .
Confidence is often thought of as the opposite of uncertainty.

Can you can be confident that $X$ is uncertain?
There is a huge difference between 


% Here we draw a distinction between confidence and certainty:
% while you are certain that [proposition], 

Confidence is intimately related to probability, and our development will largely be couched in (higher-order) probabilistic terms.
Nevertheless, we submit that in many cases---and especially in more subjective or computationally restricted settings---probability alone is not enough, and the higher-order probabilistic picture is far too extreme.

% We want to be able to entertain and reason about models we aren't sure about.

\subsection*{Our Approach}
% Here is the idea: if you are confident in $X$, then you are 
The idea is to view confidence as a property of an update, not as a property of a point of view. 
This allows us to distinguish between ...

\begin{example}
Let $X$ be a binary random variable, and suppose you have a prior probability $p$ that $X=1$.
\begin{enumerate}
    \item Suppose $p=1$. 
    This is a poor choice of prior. 
    If you then recieve information that $X=0$, something has gone very wrong, and the Bayesian update is undefined.
    
    If you rceive information that $X = 1$, your internal state should not change. 
    % If we characterize  
    
    \item One might argue that only positive probabilities are relevant.
    Suppose $p = 1 - \epsilon$.
\end{enumerate}
\end{example}

\section{Formalism}
\def\X{\mathcal X}
Let $\X = (X, \mathcal A)$ be a measurable space, so that $X$ is a set and $\mathcal A$ is a $\sigma$-algebra over $X$, and let $\Delta \X$ denote the set of probability measures over $\X$.

We are interested in updating rules
\[ F: (\text{Confidence} : \mathbb R) \times (\text{Event} : \mathcal A) \to (\Delta\X  \to \Delta \X) \]
The partial application for confidence $\beta \in \mathbb R$ and event $A \in \mathcal A$  

satisfying the following axioms:

For all $A \in \mathcal A$, and all $\beta,\beta_1, \beta_2 \in \mathbb R$
\begin{enumerate}
    % \item \textbf{(zero)} $F^{0}_A(\Pr) = (\Pr)$
    \item \textbf{(zero)} $F^{0}_A  =  \mathrm{Id}_{\Delta\X}$. (That is, $F^{0}_A(\Pr) = (\Pr)$ for all $\Pr \in \Delta\X$.)
    \item \textbf{(additivity)} $F^{\beta_1}_A \circ F^{\beta_2}_A = F^{\beta_1 + \beta_2}_A$
\end{enumerate}

\begin{enumerate}[]
    \item \textbf{(decomposition)} If $A$ and $B$ are independent, then $F^{\beta}_A \circ F^{\beta}_B = F^{\beta}_{A \cap B}$.
\end{enumerate}

\section{Higher Order Probability Measures}
Consider the following two ways of extracting an (ordinary) probability measure $\mu(\Omega)$
from a higher order probability $\Pr(\mu(\Omega))$.

\begin{enumerate}
    \item \textbf{Centroid.}  
        $\mu^* := \textit{centroid}(\Pr)$.\\
        Given by 
        \[
            \mu^*(A) := \Ex_{\mu \sim \Pr} \mu(A) = 
                \iint \Pr(\mu) \mu(x) 1_{A}(x)\, \mathrm d x\,\mathrm d\mu.
        \]
        
        This is the flattening of the Giry Monad.
        
    \item \textbf{Highest Likelihood.}    
        $\textit{MLE}(\Pr) := A \mapsto (\arg\max_\mu \Pr(\mu))(A)$
        
        This is the way that people often do inference.
        
    \item \textbf{MAP Inference.}
        With a prior $\Pr$

\end{enumerate}
 


\section{Weighted Probability Measures}



\end{document}
