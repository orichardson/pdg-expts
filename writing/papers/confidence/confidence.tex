\documentclass{article}

\input{pdg-preamble-v1}

\usepackage[margin=1.2in]{geometry}
\usepackage{parskip}


\DeclareMathOperator{\supp}{\mathrm{Supp}}

\newlist{URaxioms}{enumerate}{1}
\setlist[URaxioms]{resume,label=\textbf{UR\arabic{*}.},ref={UR\arabic*},leftmargin=2cm}
% \crefname{URaxiomsi}{axiom}{axioms}
\crefname{URaxiomsi}{}{}


\begin{document}





\section{General Thoughts}
(Variable) confidence is an important aspect of knowledge representation, because we need be able to entertain possibilities and reason about models we aren't sure about.

% The notion of confidence also has
% Confidence is the opposite of uncertainty: you cannot be uncertain about $X$ .
Confidence is often thought of as the opposite of uncertainty.


% Confidence is dual to information.
One has confidence in information.
Confidence and Information are thermodynamically ``conjugate variables''.


``cool-headed'' means calculated (a vote of confidence) while ``hot-headed'' means rash (such an assessment indicates a lack of confidence). Confidence is like inverse temperature.

Can you can be confident that $X$ is uncertain?
There is a huge difference between being certain that a coin has is fair, and knowing nothing about it.


% Here we draw a distinction between confidence and certainty:
% while you are certain that [proposition],

Confidence is intimately related to probability, and our development will largely be couched in probabilistic terms.
% Nevertheless, we submit that in many cases---and especially in more subjective or computationally restricted settings---probability alone is not enough, and the higher-order probabilistic picture is far too extreme.



\subsection*{Our Approach}
% Here is the idea: if you are confident in $X$, then you are
The idea is to view confidence as a property of an update, not as a property of a point of view.
In this telling

This allows us to distinguish between ...
% 

% \begin{example}
% Let $X$ be a binary random variable, and suppose you have a prior probability $p$ that $X=1$.
% \begin{enumerate}
%     \item Suppose $p=1$.
%     This is a poor choice of prior.
%     If you then recieve information that $X=0$, something has gone very wrong, and the Bayesian update is undefined.
% 
%     If you rceive information that $X = 1$, your internal state should not change.
%     % If we characterize
% 
%     \item One might argue that only positive probabilities are relevant.
%     Suppose $p = 1 - \epsilon$.
% \end{enumerate}
% \end{example}


\subsection*{Issues To Address}
\begin{enumerate}
    \item The difference between having confidence in \emph{a source} and confidence in a particular \emph{fact}.  Is one more general than the other?
\end{enumerate}

Some intuitive features we might want to capture:
\begin{enumerate}

    \item \textbf{Trust Dynamics.} If a trusted source tells you something you already believe, your confidence in them goes up (maybe). Certainly if a source tells you something you know to be wrong, your confidence in the source goes down.  Whether or not you adopt the

    Also, if you ultimately end up adopting the belief, and later end upwith a more coherent picture of the world, your trust in the source should go way up.
    This is because in the end we want to place the most trust in sources that tell you the truth, not what you expect (or want) to hear.

    A source that tells you only exactly what you already believe ``artificially'' increases your confidence but does not actually provide you any information, unless they came to hold the same views independently.

\end{enumerate}

\TODO
\clearpage

\section{Update Rules}
\def\X{\mathcal X}
Let $\X = (X, \mathcal A)$ be a measurable space, so that $X$ is a set and $\mathcal A$ is a $\sigma$-algebra over $X$, and let $\Delta \X$ denote the set of probability measures over $\X$. 
% maybe??
% Let $\Phi$ be the set of possible statements that can be made about $X$.

We are interested in updating rules
\[
    F: (\text{Confidence} : \mathbb R) \times (\text{Event} : \mathcal A) \to (\Delta\X  \to \Delta \X)
\]
which describe how to update beliefs about $X$, with the new information, at a certain level of trust. We write $F^\beta_A : \Delta\X \to \Delta X$ for the update function for a given piece of information $A$ at confidence $\beta$.

We would like update rules to satisfy the following axioms:

For all $A \in \mathcal A$, and all $\beta,\beta_1, \beta_2 \in \mathbb R$:
% \begin{enumerate}[label=\textbf{UR\arabic{*}.},leftmargin=2cm]
\begin{URaxioms}
    % \item \textbf{(zero)} $F^{0}_A(\Pr) = (\Pr)$
    \item  $F^{0}_A  = {1}_{\Delta\X}$. (That is, $F^{0}_A(\Pr) = \Pr$ for all $\Pr \in \Delta\X$.)
        \hfill \textbf{(zero)} \label{ax:zero}
    \item $F^{\beta_1}_A \circ F^{\beta_2}_A = F^{\beta_1 + \beta_2}_A$
        \hfill \textbf{(additivity)} \label{ax:additivity}
    \item For all automorphisms $\sigma \in \mathrm{Aut}(X)$, we have \\
        $F^\beta_A(\sigma_\#(\Pr)) = \sigma_\#(F^\beta_{\sigma(A)}(\Pr))$.
        \hfill \textbf{(symmetry)} \label{ax:symmetry}
    \item $F_A(\beta, \Pr)$ is continuous in both arguments.
        \hfill \textbf{(continuity)} \label{ax:continuity}
\end{URaxioms}
% \end{enumerate}

% \begin{enumerate}[resume,label=\textbf{UR\arabic{*}.},nosep,leftmargin=2cm]
%     \item If $A$ and $B$ are independent, then $F^{\beta}_A \circ F^{\beta}_B = F^{\beta}_{A \cap B}$.
%         \hfill \textbf{(decomposition)}
% \end{enumerate}

Since we have identified the set of possible statements with the $\sigma$-algebra $\mathcal A$ of measurable sets, which are closed under union and complementation, and on which probabilistic conditioning is defined, we also have:

\begin{URaxioms}
    \item $\displaystyle \lim_{\beta\to\infty} F^\beta_A (\Pr) = \Pr|A$
    \hfill \textbf{(absolute certainty)} \label{ax:certainty}

    
    \item
    % $F^\beta_A$ and $F_{\bar A}^\beta$ are inverses.
    $F^\beta_A \circ F_{\bar A}^\beta = 1_{\Delta\X}$.
        \hfill \textbf{(complementation)} \label{ax:comp}
\end{URaxioms}


We can also consider the weaker variant of \Cref{ax:certainty}:
\begin{URaxioms}
    % \item[U3$'$.]  \textbf{(effectiveness)~} $\supp F^\infty_A (\Pr) \subset A $
    \item[\textbf{\Cref*{ax:certainty}$'$.}]  $F^\infty_A (\Pr)(A) = 1$
        \hfill \textbf{(effectiveness)} \label{ax:effectiveness}
\end{URaxioms}





\subsection{Compatibility With Further Structure}
% \textit{DIVERGENCE.~~}
% \textbf{Divergence.}
\subsubsection*{Divergences}
Suppose that, in addition, we have a ``divergence'' function $d : X \times X \to \mathbb R^+$ on $X$, with the property that $d(x,y) = 0$ iff $x = y$.
For sets $A \subset X$, let $d(x, A) := \inf_{a \in A} d(x,a)$ be the smallest possible divergence between $x$ and any member of $A$; symmetrically, define $d(A, x) := \inf_{a \in A} d(a,x)$.

% What we are trying to do with divergence functions here is an example of a 
% slightly more broader definition,
For our purposes, the important feature of $d(A,x)$ is that it is a cost (or loss) function $c :\mathcal A \times X \to \mathbb R_{\ge 0}$, satisfying
\[ 
% c : \mathcal A \times X \to \mathbb R_{\ge 0}
% \quad\text{such that}\quad
% \forall A \in \mathcal A.~\arg\min_{x} c_A(x) = A.
\forall A \in \mathcal A.\quad c_A(x) = 0 ~\Leftrightarrow~ x \in A.%
\footnote{Any $c$ with the property that $\arg\min_{x} c_A(x) = A$ for all $A$ only differs from such a $c$ by a constant.}
% \qquad \text{and}\qquad
% \inf_{a \in A} c_A()
\]
The idea is that, if $c(x)$ is some cost that ``incentivises'' membership in $A$, then increasing confidence in $A$ ought decrease expected cost.
% Note that given a divergence function $d$ as described above, the expression $d(A, x) = \inf_{a \in A} d(a,x)$ satisfies this criterion. 
\begin{URaxioms}
    \item $\Ex_{F^{\beta}_A(\Pr)} [ c_A ] 
        \le
        \Ex_{\Pr}[ c_A ]
    $
        \hfill \textbf{($c$\,-monotonicity)}
\end{URaxioms}


We can also use $c$ to define a notion of independence.

\begin{defn}[$c$-independence]
For $A,B,Z \subset X$,
we say that $A$ and $B$ are $c$-independent given $Z$ iff
% $d(A, b) = d(a, B)$ for all $a\in A$ and $b \in B$.
for all $z \in Z$, we have that
% $c(z, A \cap B) = c(z, A) + c(z,B)$.
$c_{A\cap B}(z) = c_{A}(z) + c_{B}(z)$.
\end{defn}

To give a few examples:
\begin{enumerate}
    \item Every set $A \in\mathcal A$ is independent of the trivial event $X$, since 
        $
            c(z, A\cap X) = c(z, A)  
        $
        and $c(z, X) = 0$.
    \item Suppose $\X$ is a subset of $\mathbb R^n$, so that $x = (x_1, \ldots, x_n)$, and cost is L1 distance, given by $c(x,A) = \inf_{a \in A} \sum_{i=1}^n {|a_i - x_i|}$. Now for $i\ne j$,
    the sets $A_i(b) := \{ x : x_i = b \}$ 
    and $A_j(b') := \{x : x_j = b' \}$ are unconditionally $c$-independent. 
    This makes sense, since they are orthogonal hyperplanes. 

    \item  Suppose $\X \cong Y \times Z$ is a product space, to be thought of as the set of possible joint settings of two variables $Y$ and $Z$.
    Now, fix a probability measure $p(Y,Z)$ over $\X$
    and let 
    % $c(x, A) := \I_{p|A}(\{x\}) = -\log P(x | A)$.
    $c(x, A) := -\log p(A \cap \{x\})$, with the convention that $-\log 0 = \infty$.  
    Then, $A, B$ are $c$-independent given $Z$ iff
    \[
        - \log p(A \cap B \cap \{z\}) = 
        - \log p(A \cap \{z\}) - \log p(B \cap \{z\}) 
    \] 
    If $z \notin A \cap B$, then both sides will be infinite. If $z \in A \cap B$, 
    \[
        - \log p(z) = - \log p(z) - \log p(z) 
        \quad\iff\quad
        p(z) = p(z)^2
        \quad\iff\quad
        p(z) \in \{0,1\}
    \]    
\end{enumerate}

Once we have a notion of independence such as this one (although we will also consider others), we can articulate another axiom for update rules:

\begin{URaxioms}
% \begin{enumerate}[resume,label=\textbf{UR\arabic{*}.},nosep,leftmargin=2cm]
    % \item[\textbf{UR4}.] 
    \item 
    % \item[\textbf{UR4-d}.] 
    % If $A$ and $B$ are $d$-independent, then 
    % $F^{\beta}_A \circ F^{\beta}_B = F^{\beta}_{A \cap B}$.
    %     \hfill \textbf{($d$-decomposition)}
    If $A$ and $B$ are independent given $\supp(\Pr)$, then \\
    $F^{\beta}_A \circ F^{\beta}_B (\Pr) = F^{\beta}_{A \cap B}(\Pr)$.
        \hfill \textbf{(decomposition)}

% \end{enumerate}
\end{URaxioms}
The intuition here is 

\bigskip


\subsubsection*{A Cost Function}
Now for a slightly more general formulation, in terms of cost (or loss) functions.
Suppose we have a uniform way of getting, for every $A \in \mathcal A$, a cost function whose set of minimizers is $A$. That is, we are given a function
\[ c : \mathcal A \times X \to \mathbb R_{\ge 0}
\quad\text{such that}\quad
\forall A \in \mathcal A.~\arg\min_{x} c(A, x) = A.
\]
Note that given a divergence function $d$ as described above, the expression $d(A, x) = \inf_{a \in A} d(a,x)$ satisfies this criterion. The analogous independence property is defined in exactly the same way as before:
$A, B$ are $c$-independent given $Z$ iff $c(A \cap B, z) = c(A, z) + c(B, z)$ for all $z$.
% \begin{defn}
%     For $A,B,Z \subset X$,
%     we say that $A$ and $B$ are $c$-independent given $Z$ iff
%     % $d(A, b) = d(a, B)$ for all $a\in A$ and $b \in B$.
%     for all $z \in Z$, we have that
%     $c(A \cap B, z) = c(A, z) + c(B, z)$.
% \end{defn}
But since this covers a broader set of mathematical objects, let's unpack the intuition here a bit further.

\TODO{}

% \begin{enumerate}
%     \item[\textbf{UR4-c}.] If $A$ and $B$ are $d$-independent, then $F^{\beta}_A \circ F^{\beta}_B = F^{\beta}_{A \cap B}$.
%         \hfill \textbf{($c$-decomposition)}
% \end{enumerate}
\subsubsection*{A Topology}
\subsubsection*{A Smooth Manifold Structure}
\subsubsection*{A Matroid}
\subsubsection*{A Riemannian Metric}



\subsection{The Cannoncial Update Rules}
% To give a non-subjective interpretation of the update rules that follow,
Imagine that $\X$ is a space of possible phenotypes, and that a probability $\Pr \in \Delta\!\X$ represents a population distribution. 

\subsubsection{Decay}
The Canonical Update Rule, for a measurable space $\mathcal X = (X, \mathcal A)$ and measurable cost function\\
$c: \X\times\mathcal A \to \mathbb R^+$ is given by
% \def\cost#1#2{c(#1,#2)}
% \def\cost#1#2{d(#1,#2)}
\def\cost#1#2{c_{#2}(#1)}
\begin{align*}
    F^\beta_A(\Pr)(x) &\propto \Pr(x) \cdot \exp(-\beta \cost xA) \\
    F^\beta_A(\Pr) &= B \mapsto \frac{1}{\Ex_{\Pr}[\exp(-\beta \cost xA )]}
        \int 1_B(x) \; \exp(-\beta \cost xA ) \,\mathrm d\Pr(x)
    %
\end{align*}

In our analogy, an update of this kind corresponds to \emph{selection}.

\begin{prop}
    The cannonical update rule satisfies UR1-6.
\end{prop}


\begin{conj}
    %[Characterization Theorem]
    % Any update rule $F$ satisfying UR1-6 is a decay update rule for some cost function $c : \mathcal A \times X \to \mathbb R$. 
    Any update rule satisfying UR1-6 is a decay update rule for some cost function.
\end{conj}


\subsubsection{Flow}
\def\vgrad{\boldsymbol\nabla}
% \def\vgrad{\vec\nabla}
The update rule above only ``moves'' distributions by decay. If we imagine a distribution representing a population of individuals, the distribution has shifted by selection: an application of the update rule $F_A^\beta$ corresponds to culling the population, in proportion to their distance from $A$, over a time period of length $\beta$.
It is worth noting that such a population is then smaller, and must be re-normalized later.

A distribution could also shift by genuine motion of the underlying individuals.
In this case, let's model this as a partial differential equation in terms of $\Pr(x,t)$.
Now, we have some kind of conservation of mass, so from the continuity equation, we get
$\frac{\partial }{\partial t}Pr(x,t) = - \vgrad \cdot \mat J$,
where $\mat J(x,t)$ is the flux of individuals at point $x$ and time $t$.
Further assuming that the flux is generated by a combination of diffusion and a potential proportional to distance to $A$, we obtain

\[
    \frac{\partial \Pr(x, t)}{\partial t} = \vgrad_{\!x} \cdot \Big( k \vgrad_{\!x} \Pr (x) - \beta \vgrad_{\!x} d(x, A) \Big)
\]
where $k$ is a diffusion coefficient, and $\beta$

% To draw a different analogy, we can think of


\subsubsection{Drift}
We have talked about selection, but what about the second major force that drives evolution: random mutations? 
% The important feature here is that not all information is truly used to find 
% The result is that the population tends to ``spread out'', all else being equal, 
% and has the effect of mixing the 
One effect is that if there's no selection pressure to favor one variant over another, over time both variants will be represented equally.
Suppose that the elements of $\X$ have a canonical coded representation (such as DNA), such that specifying different phenotypes $x \in X$ requires different code lengths.
Because there is a tangible cost to carrying a larger genome, this induces a base measure with an inductive bias towards shorter codes.  
% So the effect of random mutations is to mix 

\subsubsection{Sex}
Sex is the thing that separates ``genetic algorithms'' from vanilla gradient descent. 

\begin{align*}
    F^\beta_A(\Pr)(x) &\propto \Pr(x) \cdot \exp(-\beta \cost xA) \\
\end{align*}



\newpage%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Examples}

\subsection{Simple Discrete Spaces}
First, suppose $X = \{0,1\}$ and $\mathcal A = 2^X$.

\begin{claim}
An update rule satisfying
% UR1-6
\cref{ax:zero,ax:additivity,ax:certainty,ax:symmetry,ax:continuity}
is characterized by a continuous monotone function
$\gamma : [0,\infty) \to [0,1]$ in the space $\Delta X \cong [0,1]$ of probability distributions over $\{0,1\}$, such that
% \begin{align*}
%     \gamma_0(0) &= 1
%     & 
%         \gamma_1(0) &= 0
%         \\
%     \lim_{t\to\infty}\gamma_0(t) &= 0
%     &
%         \lim_{t\to\infty}\gamma_1(t) &= 1
%         \\
% \end{align*}
$\gamma(0) = 0$ and $\lim_{t\to\infty}\gamma(t) = 1$. 
\end{claim}
\begin{proof}
    Let's first investigate the behavior for $A = \{0\}$.
    Fix some $\epsilon > 0$.
    By \Cref{ax:zero,ax:additivity}
\end{proof}

\begin{align*}    
\end{align*}
where $\sigma(x) = \frac{1}{1 + e^{-x}}$ is the logistic function

\subsection{Gaussians}
Consider the case where $\X$ is the set of real numbers with the Borell $\sigma$-algebra, and $d(x,y) := (x-y)^2$.
Then the cannoncial update rule corresponds to multiplying by a Gaussian density, whose variance is $\nicefrac1\beta$.

Furthermore, applying it to a distribution which is already Gaussian with mean $\mu$ and variance $\sigma^2$, we find that
\begin{align*}
    F^{\beta}_{X=b}(\mathcal N(\mu, \sigma^2))(x) &\propto
        \exp\left\{ - \frac12 \frac{(x-\mu)^2}{ \sigma^2 } - \beta(x-b)^2\right\}
    \\&\propto \mathcal N(x| \mu', \sigma'^2)
\end{align*}
which is itself a Gaussian with mean equal to the weighted average of $\mu$ and $\beta$.

The upshot is that


\subsection{Higher Order Probability Measures}
Now, suppose $\X$ is itself a set or probability measures.



Consider the following ways of extracting an (ordinary) probability measure $\mu(\Omega)$
from a higher order probability $\Pr(\mu(\Omega))$.

\begin{enumerate}
    \item \textbf{Centroid (Mean).}
        % $\mu^* := \textit{centroid}(\Pr)$.\\
        On a measurable set $A \in \mathcal A$, the centroid of $\Pr$ is defined as
        \[
            \mu^{\text{avg}}(A) := \Ex_{\mu \sim \Pr} \mu(A) =
                \iint \Pr(\mu) \mu(x) 1_{A}(x)\, \mathrm d x\,\mathrm d\mu,
        \]
        the centroid is the usual ``flattening'' of a higher-order probability distribution, and corresponds to
        of the Giry Monad.

    \item \textbf{Highest Likelihood (Mode).}
        $\textit{MLE}(\Pr) := A \mapsto (\arg\max_\mu \Pr(\mu))(A)$

        This is the way that people often do inference.

    \item \textbf{MAP Inference.}
        Suppose we have a prior $\Pr_0$ over  $\Pr$

\end{enumerate}


\subsection{PDGs}

Given a PDG $\dg M$, let $\X := \Delta\V(\dg M) = \Delta(\prod_{X\in\N}\V(X))$. For each edge we have
\[
    F_L^{\beta}(\Pr) (\mu) \propto \Pr(\mu) \exp(-\beta \kldiv\mu \bp)
\]
This extends to
\[
    F_{\dg M}^k(\Pr)(\mu) \propto \Pr(\mu) \exp(- k \bbr{\dg M}_0(\mu))
\]
Note that
\begin{align*}
    \lim_{k \to \infty} F_{\dg M}^k(\Pr)(\mu) &\propto
        % \mathbbm1[\mu \in {\displaystyle\SD{\dg M}}]
        \Pr(\mu) \mathbbm1[\mu \in {\bbr{\dg M}^*_0}] \\
        &= \Pr \,|\, \bbr{\dg M}^*_0 \\
        &= \Pr \,|\, \SD{\dg M} \text{~if $\dg M$ is consistent.}
        % &= \mathrm{Unif}_{\{\!\!\{{\dg M}\}\!\!\}} \text{~if $\dg M$ is consistent.}
\end{align*}

On the other hand,
\begin{align*}
    \lim_{k \to 0} F_{\dg M}^k(\Pr)(\mu) &= \Pr \,|\, \Inc(\mu) < \infty \\
        &= \Pr \,|\, \{\mu : \forall L.~\mu(Y|X) \ll \bp \}.
        % \quad\Big(\text{i.e., if $\mu$ is absolutely continuous with respect to $\bp$}
        % \Big)
\end{align*}
That is to say, in the limit of small $\gamma$, applying the update rule is like 
On the other hand, $F_{\dg M}^0(\Pr) = \Pr$. So $F$ can only be continuous at $k=0$ for $\Pr$ if, for all edges $L \in \Ed$, we have that $\Pr(\mu(Y|X) \ll \bp) = 1$.




\subsection{The Qualitative Half}


There are a number of different ways to think about alpha.
\begin{enumerate}[nosep]
    \item $\alpha_L$ is your confidence in the functional dependence of $Y$ on $X$, given 
    \item $\alpha_L$ is the ``alignment'' of the edge $L$
\end{enumerate}

We need a different distance function for the other half. Now we use
$d(\mu, DET)$.

% \begin{align*}
% 
% \end{align*}

We need a different distance function for the qualitative loss function of a PDG.
Why measure distance differently in this case?


\section{Epistemic Entrenchment and Confidence}
\section{Weighted Probability Measures}



\end{document}
