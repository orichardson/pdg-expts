\documentclass{article}

\input{pdg-preamble-v1}

\usepackage[margin=1in]{geometry}
\usepackage{parskip}


\DeclareMathOperator{\supp}{\mathrm{Supp}}

\begin{document}





\section{General Thoughts}
Confidence is an important aspect of knowledge representation.

% The notion of confidence also has
% Confidence is the opposite of uncertainty: you cannot be uncertain about $X$ .
Confidence is often thought of as the opposite of uncertainty.


% Confidence is dual to information.
One has confidence in information. 
Confidence and Information are thermodynamically ``conjugate variables''. 


``cool-headed'' -- calculated; ``hot-headed''--rash. Confidence is like inverse temperature.

Can you can be confident that $X$ is uncertain?
There is a huge difference between


% Here we draw a distinction between confidence and certainty:
% while you are certain that [proposition],

Confidence is intimately related to probability, and our development will largely be couched in (higher-order) probabilistic terms.
Nevertheless, we submit that in many cases---and especially in more subjective or computationally restricted settings---probability alone is not enough, and the higher-order probabilistic picture is far too extreme.


% We want to be able to entertain and reason about models we aren't sure about.

\subsection*{Our Approach}
% Here is the idea: if you are confident in $X$, then you are
The idea is to view confidence as a property of an update, not as a property of a point of view.
In this telling
This allows us to distinguish between ...

\begin{example}
Let $X$ be a binary random variable, and suppose you have a prior probability $p$ that $X=1$.
\begin{enumerate}
    \item Suppose $p=1$.
    This is a poor choice of prior.
    If you then recieve information that $X=0$, something has gone very wrong, and the Bayesian update is undefined.

    If you rceive information that $X = 1$, your internal state should not change.
    % If we characterize

    \item One might argue that only positive probabilities are relevant.
    Suppose $p = 1 - \epsilon$.
\end{enumerate}
\end{example}


\subsection*{Issues To Address}
\begin{enumerate}
    \item The difference between having confidence in \emph{a source} and confidence in a particular \emph{fact}.  Is one more general than the other?
\end{enumerate}

Some intuitive features we might want to capture:
\begin{enumerate}

    \item \textbf{Trust Dynamics.} If a trusted source tells you something you already believe, your confidence in them goes up (maybe). Certainly if a source tells you something you know to be wrong, your confidence in the source goes down.  Whether or not you adopt the

    Also, if you ultimately end up adopting the belief, and later end upwith a more coherent picture of the world, your trust in the source should go way up.
    This is because in the end we want to place the most trust in sources that tell you the truth, not what you expect (or want) to hear.

    A source that tells you only exactly what you already believe ``artificially'' increases your confidence but does not actually provide you any information, unless they came to hold the same views independently.

    \item
    \item
\end{enumerate}

\section{Update Rules}
\def\X{\mathcal X}
Let $\X = (X, \mathcal A)$ be a measurable space, so that $X$ is a set and $\mathcal A$ is a $\sigma$-algebra over $X$, and let $\Delta \X$ denote the set of probability measures over $\X$.

Suppose further that we have a ``divergence'' function $d : X \times X \to \mathbb R^+$ on $X$, with the property that $d(x,y) = 0$ iff $x = y$.
For sets $A \subset X$, let $d(x, A) := \inf_{a \in A} d(x,a)$ be the smallest possible divergence between $x$ and any member of $A$; symmetrically, define $d(A, x) := \inf_{a \in A} d(a,x)$.

\begin{defn}
For $A,B,Z \subset X$,
we say that $A$ and $B$ are $d$-independent given $Z$ if
% $d(A, b) = d(a, B)$ for all $a\in A$ and $b \in B$.
for all $z \in Z$, we have that
$d(z, A \cap B) = d(z, A) + d(z,B)$.
\end{defn}

We are interested in updating rules
\[
    F: (\text{Confidence} : \mathbb R) \times (\text{Event} : \mathcal A) \to (\Delta\X  \to \Delta \X)
\]
which describe how to update beliefs about $X$, with the new information, at a certain level of trust. We write $F^\beta_A : \Delta\X \to \Delta X$ for the update function for a given piece of information $A$ at confidence $\beta$.

We would like update rules to satisfy the following axioms:

For all $A \in \mathcal A$, and all $\beta,\beta_1, \beta_2 \in \mathbb R$
\begin{enumerate}[label=UR\arabic{*}.,nosep]
    % \item \textbf{(zero)} $F^{0}_A(\Pr) = (\Pr)$
    \item  $F^{0}_A  =  \mathrm{Id}_{\Delta\X}$. (That is, $F^{0}_A(\Pr) = (\Pr)$ for all $\Pr \in \Delta\X$.)
        \hfill \textbf{(zero)}
    \item $F^{\beta_1}_A \circ F^{\beta_2}_A = F^{\beta_1 + \beta_2}_A$
        \hfill \textbf{(additivity)}
    \item $\displaystyle \lim_{\beta\to\infty} F^\beta_A (\Pr) = \Pr|A$
        \hfill \textbf{(absolute certainty)}
\end{enumerate}

\begin{enumerate}[resume,label=UR\arabic{*}.]
    \item If $A$ and $B$ are independent, then $F^{\beta}_A \circ F^{\beta}_B = F^{\beta}_{A \cap B}$.
        \hfill \textbf{(decomposition)}
\end{enumerate}

We can also consider the weaker variant
\begin{enumerate}
    % \item[U3$'$.]  \textbf{(effectiveness)~} $\supp F^\infty_A (\Pr) \subset A $
    \item[U3$'$.]  \textbf{(effectiveness)~} $F^\infty_A (\Pr)(A) = 1$

\end{enumerate}


\subsection*{Cannoncial Update Rule}
The canonical Update Rule is given by
\begin{align*}
    F^\beta_A(\Pr)(x) &\propto \Pr(x) \cdot \exp(-\beta d(x, A)) \\
    F^\beta_A(\Pr) &= B \mapsto \frac{1}{\Ex_{\Pr}[\exp(-\beta d(x,A))]}\int
        1_B(x) \, \exp(-\beta d(x, A)) \,\mathrm d\Pr(x)
    %
\end{align*}
\begin{prop}
    The cannonical update rule satisfies UR1-4.
\end{prop}


\section{Examples}
\subsection{Gaussians}
Consider the case where $\X$ is the set of real numbers with the Borell $\sigma$-algebra, and $d(x,y) := (x-y)^2$.
Then the cannoncial update rule corresponds to multiplying by a Gaussian density, whose variance is $\nicefrac1\beta$.

Furthermore, applying it to a distribution which is already Gaussian with mean $\mu$ and variance $\sigma^2$, we find that
\begin{align*}
    F^{\beta}_{X=b}(\mathcal N(\mu, \sigma^2))(x) &\propto
     \exp\left\{ - \frac12 \frac{(x-\mu)^2}{ \sigma^2 } - \beta(x-b)^2\right\}
\end{align*}
which is itself a Gaussian with mean equal to the weighted average of $\mu$ and $\beta$, and variance


\subsection{Higher Order Probability Measures}
Consider the following ways of extracting an (ordinary) probability measure $\mu(\Omega)$
from a higher order probability $\Pr(\mu(\Omega))$.

\begin{enumerate}
    \item \textbf{Centroid.}
        % $\mu^* := \textit{centroid}(\Pr)$.\\
        On a measurable set $A \in \mathcal A$, the centroid of $\Pr$ is defined as
        \[
            \mu^{\text{avg}}(A) := \Ex_{\mu \sim \Pr} \mu(A) =
                \iint \Pr(\mu) \mu(x) 1_{A}(x)\, \mathrm d x\,\mathrm d\mu,
        \]
        the centroid is the usual ``flattening'' of a higher-order probability distribution, and corresponds to
        of the Giry Monad.

    \item \textbf{Highest Likelihood.}
        $\textit{MLE}(\Pr) := A \mapsto (\arg\max_\mu \Pr(\mu))(A)$

        This is the way that people often do inference.

    \item \textbf{MAP Inference.}
        Suppose we have a prior $\Pr_0$ over  $\Pr$

\end{enumerate}


\section{Epistemic Entrenchment and Confidence}
\section{Weighted Probability Measures}



\end{document}
