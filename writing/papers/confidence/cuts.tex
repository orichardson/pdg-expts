%%%%%%%%%%%%% INTRO %%%%%%%%%%%
High confidence is in many ways like high probability: if we really trust a statement \stmt, we should fully incorporate it into our beliefs, and thereby come to believe it with high probability.
Similarly, it only makes sense to be extremely confident in a \stmt\ if you believe that \stmt\ is extremely likely to be true.
Low confidence, on the other hand, is quite different from low probability.
If we have little trust in \stmt, we should \emph{ignore} \stmt, rather than coming to believe that \stmt\ is unlikely.
% To say \stmt\ has low probabilty is  high confidence in the $\lnot$\stmt.
For example, if an adversary tells you something that you happen to already believe,
% is likely to be true
you might say you have low confidence in their statement, but nevertheless ascribe it high probability.



For example, we might trust a surprising piece of information despite thinking it unlikely.
Of course, after updating, we would find that same information likely (precisely because we took it seriously in the update).
Thus, high confidence implies high posterior likelihood, making it easy to confuse the two.
The converse, however, is not true:
we should ascribe high (prior \emph{and} posterior) likelihood, but low confidence, to information from an untrusted source which we happen to believe already.


%% in ML example
It is not so clear that a fraction of the way to completion (say 0.7) is as meaningful here as it was before (and it would be difficult to recognize that point in any case),
but we now have a different way to quantify confidence: the number of training iterations. 


%% GEOMETRY
Note that the relevant geometry in \cref{ex:classifier} is not just the geometry of the weight space, but also that induced by the architecture and the loss function.



% Likelihood and trust often tightly coupled, but they are different.
% in an updating context: it's how seriously you take an input
% What we have in mind applies in an updating or learning setting. 
% We take confidence (in an input $\phi$) to be a measure of how seriously we take $\phi$ in updating our beliefs.
% Like probability, confidence lies in continuum between two extremes, but it ranges from untrusted to trusted, rather than from unlikely to likely.
% More concretely, confidence interpolates between prior beliefs and the beliefs one would obtain by fully incorporating $\phi$, so as to obtain posterior beliefs somewhere in between. 
More concretely, confidence interpolates between prior beliefs and those obtained by fully trusting $\phi$, so as to obtain posterior beliefs somewhere in between. 
Consequently, the notion is heavily dependent on the geometry of beliefs.
% This already suffices to characterize our simplest running example:
To take a simple example,
if our prior belief is a probability measure $p$ over a finite set $X$, then to update on event $A$ with confidence $\chi \in [0,1]$ might be to arrive at the posterior belief $p'(X) = (1-\chi) p(X) + (\chi)\, p(X|A)$. 
% In this case, $\chi$ can be viewed as a ``fraction of incorporation''.
Note that 
an update with no confidence ($\chi{\,=\,}0$) ignores new information (since $p' \!=\! p$),
while a
% more customary
full confidence update ($\chi{\,=\,}1$) takes it as seriously as possible,
% (since then $p'(A) \!=\! 1$).  
since afterwards $p'(A) \!=\! 1$ and there is no way to further incorporate $A$.
%
%
% It is less clear that the intermediate points are the ``right'' ones, or that this 
% is the ``appropriate'' parameterization of the path
The particular choice of path, as well as its parameterization,
are open for debate, but are natural consequences of the geometry when we think of probabilities as points in a simplex.



\relax %%%%% 
    In some contexts, both styles of measuring confidence are used. To
    illustrate, we turn to another class of examples of confidence
    based on the work of \citeauthor{shafer1976mathematical}, whose
    \citeyear{shafer1976mathematical} book was written largely to
    develop a theory of what we have been calling confidence, based on
    (and tailored to) to his preferred representation of uncertainty. 


%%%%%%%%%%%%%%
We have now seen two very different ways of describing confidence. 
Are they related? Should we prefer one style over the other?
The number $\alpha \in [0,1]$ used in \cref{ex:prob-simple}
appears to have an intuitive advantage: an intermediate value can be 
viewed as a ``proportion of incorporation'', while the number of
training iterations $n$ used in \cref{ex:classifier} only really
has meaning relative to other values of $n$ for the same training algorithm.
On the other hand,
% % the additive description in \cref{ex:classifier}
% the description in \cref{ex:classifier}
the apprach taken in the second example
appears to be more general. 
% But the approach used in the second example appears to be more general.
% The proportion of incorporation $\alpha \in [0,1]$ does 
	% make as much sense in \cref{ex:classifier},
It is not clear that a proportion $\alpha \in [0,1]$ 
is meaningful in \cref{ex:classifier},
but \cref{ex:prob-simple} can be
readily captured by a number of iterations 
% $n \in [0,\infty]$, as follows.
$n$, as follows.
% capture proportional confidence $\alpha \in [0,1]$ as follows.
% 
% For example, we can use the quantification of uncertainty from \cref{ex:classifier} to treat \cref{ex:prob-simple} as follows. 
%
%joe1: And I still object strongly to "unit of confidence". 
%oli1: I don't understand the objection. What I originally wrote
% needed (and may still needs) fixing, but I'm convinced that 
% this is an important part of how everything fits together. I've
% redone it below because I think it provides a very nice lead-in
% to Shafer's theory of evidence, and brings up some fundemental
% questions early.
%
If we fix some ``unit confidence'', say $\iota=0.01$,
then for any $n \in \mathbb N$,
sequentially performing $n$ updates of confidence $\iota$ is 
equivalent to a single one of confidence $\alpha= 1-(0.99)^n$.
% Therefore, confidence $\alpha$ corresponds to a sequence of
% Therefore, 
% Or to say the same thing backwards:
Or, inverting:
to specify confidence $\alpha$, it suffices to 
instead give a number
% $t = \log (1 - \alpha ) / \log(1-\iota)$
\begin{equation} \label{eq:loglogiota}
 	n = \log (1 - \alpha ) / \log(1-\iota) 
	\quad\in[0,\infty]
\end{equation}
of confidence-$\iota$ updates to be performed in sequence.
% A natural number describing the number of incremental updates (as in  \cref{ex:classifier}) is in some ways less satisfying then a number between zero and one (as in \cref{ex:prob-simple});
% In some ways, the way of describing confidence in \cref{ex:classifier}
% is less satisfying than that of \cref{ex:prob-simple}; 
% it is easy to inteperet 
% ``halfway'' incorporated means in this scale, for example.
% It turns out that, apart frmo 
% So, rougly speaking, the two confidence domains are equivalent once we have a clear picture of what a ``unit update'' means in the second case.
\commentout{
	Thus, in contexts where a proportion of incorporation $\alpha\in[0,1]$ is meaningful,
	% effectively the only difference between the two ways of describing confidence is that the latter has a choice of scale.
	a number of iterations $n$ is meaningful as well, provided the unit
	$\iota$ is understood.
}

In three places now we have seen evidence suggesting that 
% the additive $[0,\infty]$ domain for describing confidence requires an
additive descriptions of confidence do not have objective meaning,
but rather are only meaningful relative to some inscrutible choice.
The meaning of $n$ in \cref{ex:classifier} depends on the learning algorithm,
the quantity in \eqref{eq:loglogiota} requires an irrelevant choice of $\iota$,
and the weight of evidence is only unique up to the constant $k$.
However, we will see in \cref{sec:vecrep} that insofar as there is an 
$\alpha$ with an objective meaning, there is also a natural additive 
scale for confidence: the unique one for which small values of $n$ and 
small values of $\alpha$ are indistinguishable, or equivalently,
the unique base for which derivatives of $\alpha$ and $n$ with respect
to one another (or any third quantity) are identical.
Thus, there is a special scale of additive confidence $n \in [0,\infty]$
for the same reason that there is natural base for exponentiation: 
% a special local indistinguishability from the identity.
% $e^x$ is indistinghishable from $1+x$ for small $x$. 
% a locally, there is only one base that looks like the identity. 
it is the only base whose differential at 0 is the identity. 
(Indeed in these simple cases, this amounts to taking $k = -\log e$ and $\iota = 1-\frac1e$ so that all logarithms are base $e$---but at a deeper level, this is a consequence of the uniqueness of the exponential map of the Lie algebra implicit in our framework.)
% The deeper reason is that there is a 
To summarize: there is a unique way to represent a confidence
$\alpha \in [0,1]$ as a confidence $\beta \in [0, \infty]$
such that the two scales behave identically when both are small. 
But the intuition behind additive confidence $\beta \in [0, \infty]$ 
generalizes past where the intuition for $\alpha \in [0,1]$ will take us.




\textbf{Certainty Axioms.}
    % The simplest thing to do
    At the other extreme, we want to describe learning a certainty as the limit of updating with high confidence, so we require that
    \begin{CFaxioms}
        % \item[Cert1]
        \item
            % $\lim_{c \to \infty} F^{c}_\phi \in \bar\Theta$ exists, where $\bar\Theta$ is the closure of $\Theta$
            $\displaystyle\lim_{c \to \infty} F^{c}_\phi : \Theta \to \bar\Theta$
            exists, so we may abbreviate it as $F^\infty_\phi$
            \label{ax:cert-exists}
    \end{CFaxioms}

    It follows from \Cref{ax:additivity,ax:cert-exists} that
    % learning a certainty
    $F^\infty$
    is a ``projection'', in that is an idempotent operation, since,
    for all $\theta \in \Theta$,
    \[
        F^\infty_\phi (\theta)
            = \lim_{c \to \infty} F^{c}_\phi (\theta)
            % = \lim_{c_1 \to \infty} \lim_{c_2 \to \infty} F^{c_1 + c_2}_\phi (\theta)
            = \lim_{\substack{c_1 \to \infty \\ c_2 \to \infty}}
                F^{c_1 + c_2}_\phi (\theta)
            % = \lim_{c_1 \to \infty} \lim_{c_2 \to \infty}
            = \lim_{\substack{c_1 \to \infty \\ c_2 \to \infty}}
                F^{c_1}_\phi ( F^{c_2}_\phi (\theta))
            % = \lim_{c_2 \to \infty} F^{\infty}_\phi (F^{c_2}_\phi(\theta))
            = \lim_{c_1 \to \infty} F^{c_1}_\phi (F^{\infty}_\phi(\theta))
            % = \lim_{c \to \infty} F^{c}_\phi \,\circ\, F^{c}_\phi %(\theta)
            % F^\infty_\phi
            % = F^{\infty}_\phi (F^{\infty}_\phi(\theta))
            = F^\infty_\phi \,\circ\, F^\infty_\phi  (\theta)
            .
    \]

    Let us return to the setting where $\Theta$ parameterizes a family of probability distributions over $\X = (X, \mathcal A)$, via a function $\Pr : \Theta \to \Delta\X$,
    and suppose that for some assertions $\phi \in \Phi$ represent events $A \in \mathcal A$.
    The result of learning such an assertion with certainty should correspond to conditioning.

    \begin{CFaxioms}
        \item If $\phi$ represents $A \in \mathcal A$, and $\Pr_{\theta}(A) > 0$, then
            $\displaystyle \lim_{\beta\to\infty} \Pr_{ F^\beta_\phi\theta } = \Pr_\theta \mid A$.
            % \hfill \textbf{(absolute certainty)} \label{ax:certainty}
            \hfill \textbf{(conditioning)} \label{ax:conditioning}

        % \item
        % % $F^\beta_A$ and $F_{\bar A}^\beta$ are inverses.
        % $F^\beta_A \circ F_{\bar A}^\beta = 1_{\Delta\X}$.
        %     \hfill \textbf{(complementation)} \label{ax:comp}
    \end{CFaxioms}


    We can also consider the weaker variant of \Cref{ax:conditioning}:
    \begin{CFaxioms}
        % \item[U3$'$.]  \textbf{(effectiveness)~} $\supp F^\infty_A (\Pr) \subset A $
        % customlabel
        \item[\Cref*{ax:conditioning}$'$]
        % \item[\customlabel{ax:effectiveness}{\textbf{\Cref*{ax:conditioning}$'$.}}]
        If $\phi \in \Phi$ represents $A \in \mathcal A$ and $\Pr(A) > 0$, then
            % $F^\infty_A (\Pr)(A) = 1$
            % $\displaystyle \lim_{\beta\to\infty} F^\beta(\Pr)(A) = 1$
            $\displaystyle \lim_{\beta\to\infty} \Pr_{F^\beta_\phi\theta}(A) = 1$.
            \hfill \textbf{(effectiveness)}
            \label[CFaxiomsi]{ax:effectiveness}
            % \label{ax:effectiveness}
            % \label{ax:effectiveness}
    \end{CFaxioms}
    in which the limit of infinite confidence in $A$ is not required be the same as conditioning the starting point on $A$, but still must have the same effect of ensuring that $A$ occurs with probability 1.
    % \cref{ax:effectiveness}


%%%%%%%%%%%%%%% CONTINUITY AXIOMS %%%%%%%%%%%%%%%%%%%%%%%%%%
\commentout{ % definition of restricted global continuity
	\begin{CFaxioms}[nosep]
		\item
		% [TOP]
		% $\Theta$ is a topological space, and
		% $\Theta$ comes with a topology, with respect to which
		$\Theta$ comes with a topology, and
		for all $\phi \in \Phi$	the following restrictions of $F_\phi$
		are continuous
		 % with respect to this topology.
		\begin{itemize}[noitemsep,wide]
		\item
		% $F_{\phi}|_\theta : [0,1] \to \Theta$ is continuous
		% 	for all $\phi \in \Phi$ and $\theta \in \Theta$.
		$F_{\phi}|_\theta : [0,1] \to \Theta$,
			for all $\theta \in \Theta$.
		\item 
		% there is some $\Theta_\phi \subseteq \Theta$ such that
		$F_{\phi} |_{\Theta_\phi} : [0,1) \times \Theta_\phi \to \Theta$
		% is continuous.
		\unskip, for some $\Theta_\phi \subseteq \Theta$.
		\end{itemize}
		\label{ax:cont}
	\end{CFaxioms}}



%%%%%%%%%%%%%% DIFFBILITY AXIOMS %%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{CFaxioms}
	\item \label{ax:diffble}
	\begin{enumerate}
	\item $\Theta$ has a manifold structures, and
		for all $\theta$ and $\phi$, the function $\beta \mapsto F^{\beta}_\phi(\theta) : \confdom \to \Theta$
		is continuously differentiable at $\beta = \bot$. %\label{ax:diffble}
	\item 
		$\Theta$ parameterizes a family of probabilities over $(\X, \mathcal A)$,
		via $\{ \Pr_\theta \}_{\theta \in \Theta}$.
		%  we can avoid talking abot a differentiable structure on $\Theta$ by simply requiring that the update rule be differentiable from the perspective of every event $A \in \mathcal A$.
		%  is a family of probability distributions.
		for all $\theta \in \Theta$, $\phi \in \Phi$, and  $A \in \mathcal A$,
		the function $\beta \mapsto \Pr_{F^{\beta}_\phi(\theta)}(A)
		: \confdom \to \mathbb [0,1]$ is
		continuously differentiable at $\beta=\bot$. 
		%(in pairs $(\beta,\Pr)$).
			% \hfill \textbf{(differentiability)}
			\label{ax:diffble2}
	\end{enumerate}
	\hfill \textbf{(differentiability)}
\end{CFaxioms}

If $\Theta$ is a differentiable manifold and $\Pr: \Theta \to \Delta\X$ is a differentiable map, then the second follows from the first. 
% For simplicity, from this point forwards, we will assume that $\Theta$ itself carries a differentiable structure.
It's simpler to assume that $\Theta$ carries a differentiable structure, so we will assume this when possible.
% In the following result, we will begin to see what makes $\Rplus$ such a natural confidence domain for differentiable update rules.










%%%%%%%%%%%%%%%%% FALSE THEOREM ABOUT UNIQUENESS %%%%%%%%%%%%%
% previously in path section (section 2, at the time of writing).
%
\begin{linked}{conj}{translate}
	{\color{red} false!}
	% If $F, G: \Phi \times [0,1] \times \Theta \to \Theta$ are
	If 
	 % $F: \Phi \times [0,1] \times \Theta \to \Theta$ 
	$F$ and $G$ satisfy
	% $F$ satisfies
	\cref{ax:funcform,ax:zero,ax:idemp,ax:cont,ax:seq-for-more%
		% ,ax:diffble
		},
	and behave the same way under full-confidence,
	then 
	there is a translation 
	$g: [0,1] \to [0,1]$ 
	such that
	$F(\phi, g(\chi), \theta) = G(\phi, \chi, \theta)$. 
	% then there is a unique function $F^*$ 
\end{linked}
Thus, functions satisfying these axioms are unique up to parameterization
of intermediate confidences.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% False / premature claims about combining things

\begin{defn}
For an assertion language $\Phi$, let $\ext\Phi$ denote
the space of weighted formal sums of elements of $\Phi$.
% the space $\mathbb R^{\Phi}_{\mathrm{fin}}$ of finitely supported vectors over $\Phi$,
\end{defn}

% If $\Phi$
\begin{prop}{\color{red} false!}
Every  update rule $F$ on $\Phi$, can be naturally extended to an update rule
$\bar F$ on $\ext\Phi$
% $\mathbb R^{\Phi}$,
via the total vector field
\[
    % \bar F'_{\vec{x}}( \theta ) := \sum_{\phi} F'_\phi(\theta) x_\phi.
    \bar F'_{\textstyle\sum_i a_i \phi_i} ( \theta ) := \sum_{i} a_i F'_{\phi_i}(\theta).
\]
% \end{prop}
%
\end{prop}

If $\Phi$ is itself a measurable space, we can extend this further:
Every  update rule $F$ on $\Phi$, can be naturally extended to an update rule $\bar F$ on the space $\mathcal M(\Phi)$ of measures over $\Phi$, via
\[
% \bar F'(\theta) := \sum_{} \beta_x \
\bar F'_{\beta(\Phi)}( \theta ) := \int_{\Phi} F'_\phi(\theta) \mathrm d\beta.
\]
