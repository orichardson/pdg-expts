%%%%%% INTRO

High confidence is in many ways like high probability: if we really trust a statement \stmt, we should fully incorporate it into our beliefs, and thereby come to believe it with high probability.
Similarly, it only makes sense to be extremely confident in a \stmt\ if you believe that \stmt\ is extremely likely to be true.
Low confidence, on the other hand, is quite different from low probability.
If we have little trust in \stmt, we should \emph{ignore} \stmt, rather than coming to believe that \stmt\ is unlikely.
% To say \stmt\ has low probabilty is  high confidence in the $\lnot$\stmt.
For example, if an adversary tells you something that you happen to already believe,
% is likely to be true
you might say you have low confidence in their statement, but nevertheless ascribe it high probability.




\textbf{Certainty Axioms.}
    % The simplest thing to do
    At the other extreme, we want to describe learning a certainty as the limit of updating with high confidence, so we require that
    \begin{CFaxioms}
        % \item[Cert1]
        \item
            % $\lim_{c \to \infty} F^{c}_\phi \in \bar\Theta$ exists, where $\bar\Theta$ is the closure of $\Theta$
            $\displaystyle\lim_{c \to \infty} F^{c}_\phi : \Theta \to \bar\Theta$
            exists, so we may abbreviate it as $F^\infty_\phi$
            \label{ax:cert-exists}
    \end{CFaxioms}

    It follows from \Cref{ax:additivity,ax:cert-exists} that
    % learning a certainty
    $F^\infty$
    is a ``projection'', in that is an idempotent operation, since,
    for all $\theta \in \Theta$,
    \[
        F^\infty_\phi (\theta)
            = \lim_{c \to \infty} F^{c}_\phi (\theta)
            % = \lim_{c_1 \to \infty} \lim_{c_2 \to \infty} F^{c_1 + c_2}_\phi (\theta)
            = \lim_{\substack{c_1 \to \infty \\ c_2 \to \infty}}
                F^{c_1 + c_2}_\phi (\theta)
            % = \lim_{c_1 \to \infty} \lim_{c_2 \to \infty}
            = \lim_{\substack{c_1 \to \infty \\ c_2 \to \infty}}
                F^{c_1}_\phi ( F^{c_2}_\phi (\theta))
            % = \lim_{c_2 \to \infty} F^{\infty}_\phi (F^{c_2}_\phi(\theta))
            = \lim_{c_1 \to \infty} F^{c_1}_\phi (F^{\infty}_\phi(\theta))
            % = \lim_{c \to \infty} F^{c}_\phi \,\circ\, F^{c}_\phi %(\theta)
            % F^\infty_\phi
            % = F^{\infty}_\phi (F^{\infty}_\phi(\theta))
            = F^\infty_\phi \,\circ\, F^\infty_\phi  (\theta)
            .
    \]

    Let us return to the setting where $\Theta$ parameterizes a family of probability distributions over $\X = (X, \mathcal A)$, via a function $\Pr : \Theta \to \Delta\X$,
    and suppose that for some assertions $\phi \in \Phi$ represent events $A \in \mathcal A$.
    The result of learning such an assertion with certainty should correspond to conditioning.

    \begin{CFaxioms}
        \item If $\phi$ represents $A \in \mathcal A$, and $\Pr_{\theta}(A) > 0$, then
            $\displaystyle \lim_{\beta\to\infty} \Pr_{ F^\beta_\phi\theta } = \Pr_\theta \mid A$.
            % \hfill \textbf{(absolute certainty)} \label{ax:certainty}
            \hfill \textbf{(conditioning)} \label{ax:conditioning}

        % \item
        % % $F^\beta_A$ and $F_{\bar A}^\beta$ are inverses.
        % $F^\beta_A \circ F_{\bar A}^\beta = 1_{\Delta\X}$.
        %     \hfill \textbf{(complementation)} \label{ax:comp}
    \end{CFaxioms}


    We can also consider the weaker variant of \Cref{ax:conditioning}:
    \begin{CFaxioms}
        % \item[U3$'$.]  \textbf{(effectiveness)~} $\supp F^\infty_A (\Pr) \subset A $
        % customlabel
        \item[\Cref*{ax:conditioning}$'$]
        % \item[\customlabel{ax:effectiveness}{\textbf{\Cref*{ax:conditioning}$'$.}}]
        If $\phi \in \Phi$ represents $A \in \mathcal A$ and $\Pr(A) > 0$, then
            % $F^\infty_A (\Pr)(A) = 1$
            % $\displaystyle \lim_{\beta\to\infty} F^\beta(\Pr)(A) = 1$
            $\displaystyle \lim_{\beta\to\infty} \Pr_{F^\beta_\phi\theta}(A) = 1$.
            \hfill \textbf{(effectiveness)}
            \label[CFaxiomsi]{ax:effectiveness}
            % \label{ax:effectiveness}
            % \label{ax:effectiveness}
    \end{CFaxioms}
    in which the limit of infinite confidence in $A$ is not required be the same as conditioning the starting point on $A$, but still must have the same effect of ensuring that $A$ occurs with probability 1.
    % \cref{ax:effectiveness}
