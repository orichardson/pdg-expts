\documentclass{article}

% \input{../model-commands}
\usepackage[margin=1in]{geometry}
\usepackage{mathtools,amssymb,amsfonts}
\usepackage{parskip}

\usepackage{tikz}
	\usetikzlibrary{positioning,fit,calc, decorations, arrows, shapes, shapes.geometric}
	
	\pgfdeclaredecoration{arrows}{draw}{
		\state{draw}[width=\pgfdecoratedinputsegmentlength]{%
			\path [every arrow subpath/.try] \pgfextra{%
				\pgfpathmoveto{\pgfpointdecoratedinputsegmentfirst}%
				\pgfpathlineto{\pgfpointdecoratedinputsegmentlast}%
			};
	}}
	%%%%%%%%%%%%
	\tikzset{AmpRep/.style={ampersand replacement=\&}}
	\tikzset{center base/.style={baseline={([yshift=-.8ex]current bounding box.center)}}}
	\tikzset{paperfig/.style={center base,scale=0.9, every node/.style={transform shape}}}

	% Node Stylings
	\tikzset{dpadded/.style={rounded corners=2, inner sep=0.7em, draw, outer sep=0.3em, fill={black!50}, fill opacity=0.08, text opacity=1}}
	\tikzset{dpad0/.style={outer sep=0.05em, inner sep=0.3em, draw=gray!75, rounded corners=4, fill=black!08, fill opacity=1}}
	\tikzset{dpad/.style args={#1}{every matrix/.append style={nodes={dpadded, #1}}}}
	\tikzset{light pad/.style={outer sep=0.2em, inner sep=0.5em, draw=gray!50}}
		
	\tikzset{arr/.style={draw, ->, thick, shorten <=3pt, shorten >=3pt}}
	\tikzset{arr0/.style={draw, ->, thick, shorten <=0pt, shorten >=0pt}}
	\tikzset{arr1/.style={draw, ->, thick, shorten <=1pt, shorten >=1pt}}
	\tikzset{arr2/.style={draw, ->, thick, shorten <=2pt, shorten >=2pt}}
	\tikzset{archain/.style args={#1}{arr, every arrow subpath/.style={draw,arr, #1}, decoration=arrows, decorate}}


	\tikzset{fgnode/.style={dpadded,inner sep=0.6em, circle},
	factor/.style={light pad, fill=black}}	
	
	\newcommand\cmergearr[4]{
		\draw[arr,-] (#1) -- (#4) -- (#2);
		\draw[arr, shorten <=0] (#4) -- (#3);
	}
	\newcommand\mergearr[3]{
		\coordinate (center-#1#2#3) at (barycentric cs:#1=1,#2=1,#3=1.2);
		\cmergearr{#1}{#2}{#3}{center-#1#2#3}
	}
	\newcommand\cunmergearr[4]{
		\draw[arr,-, , shorten >=0] (#1) -- (#4);
		\draw[arr, shorten <=0] (#4) -- (#2);
		\draw[arr, shorten <=0] (#4) -- (#3);
	}
	\newcommand\unmergearr[3]{
		\coordinate (center-#1#2#3) at (barycentric cs:#1=1.2,#2=1,#3=1);
		\cunmergearr{#1}{#2}{#3}{center-#1#2#3}
	}
	
	\usetikzlibrary{matrix}
	\tikzset{toprule/.style={%
	        execute at end cell={%
	            \draw [line cap=rect,#1] 
	            (\tikzmatrixname-\the\pgfmatrixcurrentrow-\the\pgfmatrixcurrentcolumn.north west) -- (\tikzmatrixname-\the\pgfmatrixcurrentrow-\the\pgfmatrixcurrentcolumn.north east);%
	        }
	    },
	    bottomrule/.style={%
	        execute at end cell={%
	            \draw [line cap=rect,#1] (\tikzmatrixname-\the\pgfmatrixcurrentrow-\the\pgfmatrixcurrentcolumn.south west) -- (\tikzmatrixname-\the\pgfmatrixcurrentrow-\the\pgfmatrixcurrentcolumn.south east);%
	        }
	    },
	    leftrule/.style={%
	        execute at end cell={%
	            \draw [line cap=rect,#1] (\tikzmatrixname-\the\pgfmatrixcurrentrow-\the\pgfmatrixcurrentcolumn.north west) -- (\tikzmatrixname-\the\pgfmatrixcurrentrow-\the\pgfmatrixcurrentcolumn.south west);%
	        }
	    },
	    rightrule/.style={%
	        execute at end cell={%
	            \draw [line cap=rect,#1] (\tikzmatrixname-\the\pgfmatrixcurrentrow-\the\pgfmatrixcurrentcolumn.north east) -- (\tikzmatrixname-\the\pgfmatrixcurrentrow-\the\pgfmatrixcurrentcolumn.south east);%
	        }
	    },
	    table with head/.style={
		    matrix of nodes,
		    row sep=-\pgflinewidth,
		    column sep=-\pgflinewidth,
		    nodes={rectangle,minimum width=2.5em, outer sep=0pt},
		    row 1/.style={toprule=thick, bottomrule},
  	    }
	}
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{mathtools}		%also loads amsmath
\usepackage{amssymb, bbm}
\usepackage{relsize}
\usepackage{color}
%\usepackage{stmaryrd}
\usepackage{amsthm,thmtools}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{coro}{Corollary}[theorem]
\newtheorem{prop}[theorem]{Prop}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{conj}[theorem]{Conjecture}

\theoremstyle{definition}
\declaretheorem[name=Definition,qed=$\square$,numberwithin=section]{defn} %
\declaretheorem[name=Construction,qed=$\square$,sibling=defn]{constr}
\declaretheorem[qed=$\square$]{example}

\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\usepackage{xstring}
\usepackage{enumitem}

\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=blue!50!black, urlcolor=magenta, citecolor=deepgreen}	
\usepackage[noabbrev,nameinlink,capitalize]{cleveref}
\crefname{example}{Example}{Examples}
\crefname{defn}{Definition}{Definitions}
\crefname{prop}{Proposition}{Propositions}
\crefname{claim}{Claim}{Claims}
\crefname{constr}{Construction}{Constructions}
\crefname{conj}{Conjecture}{Conjectures}
\crefname{fact}{Fact}{Facts}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\let\Horig\H
\let\H\relax
\DeclareMathOperator{\H}{\mathrm{H}} % Entropy
\DeclareMathOperator{\I}{\mathrm{I}} % Information
\DeclareMathOperator*{\Ex}{\mathbb{E}} % Expectation
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand\mat[1]{\mathbf{#1}}
\DeclarePairedDelimiterX{\infdivx}[2]{(}{)}{%
	#1\;\delimsize\|\;#2%
}
\newcommand{\thickD}{I\mkern-8muD}
\newcommand{\kldiv}{\thickD\infdivx}

\newcommand{\tto}{\rightarrow\mathrel{\mspace{-15mu}}\rightarrow}
\newcommand{\bp}[1][L]{\mat{p}_{\!_{#1}\!}}
\newcommand{\V}{\mathcal V}
\newcommand{\N}{\mathcal N}
\newcommand{\Ed}{\mathcal E}

\DeclareMathAlphabet{\mathdcal}{U}{dutchcal}{m}{n}
\DeclareMathAlphabet{\mathbdcal}{U}{dutchcal}{b}{n}
\newcommand{\dg}[1]{\mathbdcal{#1}}


\newcommand\smid{\!\mid\!}
\newcommand\MAP{\mathrm{MAP}}
\DeclareMathOperator{\bundle}{\sqcup}
\newcommand\ado{\mathrm{do}}
\newcommand\commentout[1]{}


\newcommand{\pdgunit}{\mathrlap{\mathit 1} \mspace{2.3mu}\mathit 1}

\newcommand\Pa{\mathbf{Pa}}
\newcommand{\IDef}[1]{\mathit{IDef}_{\!#1}}
\newcommand\Inc{\mathit{Inc}}
\newcommand{\PDGof}[1]{{\dg M}_{#1}}
\newcommand{\UPDGof}[1]{{\dg N}_{#1}}
\newcommand{\WFGof}[1]{\Psi_{{#1}}}
\newcommand{\FGof}[1]{\Phi_{{#1}}}
\newcommand{\Gr}{\mathcal G}

% \newcommand\aar[1]{\langle\mskip}

\newcommand{\ed}[3]{%
	\mathchoice%
	{#2\overset{\smash{\mskip-5mu\raisebox{-3pt}{${#1}$}}}{\xrightarrow{\hphantom{\scriptstyle {#1}}}} #3} %display style
	{#2\overset{\smash{\mskip-5mu\raisebox{-3pt}{$\scriptstyle {#1}$}}}{\xrightarrow{\hphantom{\scriptstyle {#1}}}} #3}% text style
	{#2\overset{\smash{\mskip-5mu\raisebox{-3pt}{$\scriptscriptstyle {#1}$}}}{\xrightarrow{\hphantom{\scriptscriptstyle {#1}}}} #3} %script style
	{#2\overset{\smash{\mskip-5mu\raisebox{-3pt}{$\scriptscriptstyle {#1}$}}}{\xrightarrow{\hphantom{\scriptscriptstyle {#1}}}} #3}} %scriptscriptstyle


\newcommand{\alle}[1][L]{_{\ed {#1}XY}}


\DeclarePairedDelimiterX{\SD}[1]{\{}{\}}{\,\llap{\delimsize\{}#1\rlap{\delimsize\}}\,}
%better version.
\DeclarePairedDelimiterX{\bbr}[1]{[}{]}
	{\mspace{3mu}\mathllap{\delimsize[}#1\mathrlap{\delimsize]}\mspace{3mu}}
\DeclarePairedDelimiterX{\aar}[1]{\langle}{\rangle}
	{\mspace{3mu}\mathllap{\delimsize\langle}#1\mathrlap{\delimsize\rangle}\mspace{3mu}}
\DeclarePairedDelimiterXPP{\aard}[1]{}{\langle}{\rangle}{_{\!_\downarrow}}
	{\mspace{-3.5mu}\delimsize\langle#1\delimsize\rangle\mspace{-3.5mu}}


%% Theorem Restatement
\usepackage{xpatch}
\makeatletter
\xpatchcmd{\thmt@restatable}% Edit \thmt@restatable
   {\csname #2\@xa\endcsname\ifx\@nx#1\@nx\else[{#1}]\fi}% Replace this code
   % {\ifthmt@thisistheone\csname #2\@xa\endcsname\typeout{oiii[#1;#2\@xa;#3;\csname thmt@stored@#3\endcsname]}\ifx\@nx#1\@nx\else[#1]\fi\else\csname #2\@xa\endcsname\fi}% with this code
   {\ifthmt@thisistheone\csname #2\@xa\endcsname\ifx\@nx#1\@nx\else[{#1}]\fi
   \else\fi}
   {}{\typeout{FIRST PATCH TO THM RESTATE FAILED}} % execute on success/failure 
\xpatchcmd{\thmt@restatable}% A second edit to \thmt@restatable
   {\csname end#2\endcsname}
   {\ifthmt@thisistheone\csname end#2\endcsname\else\fi}
   {}{\typeout{FAILED SECOND THMT RESTATE PATCH}}

\newcommand{\recall}[1]{\medskip\par\noindent{\bf \expandarg\Cref{thmt@@#1}.} \begingroup\em \noindent
   \expandafter\csname#1\endcsname* \endgroup\par\smallskip}
\makeatother
%oli16: The extra space was because there was extra space in the paragraph, not
%because this length was too big. By breaking arrays, everything will be better.
\allowdisplaybreaks

\newcommand{\begthm}[3][]{\begin{#2}[{name=#1},restate=#3,label=#3]}


\usepackage[framemethod=TikZ]{mdframed}
\allowdisplaybreaks

\surroundwithmdframed[
   topline=false,
   rightline=false,
   bottomline=false,
   leftmargin=\parindent,
   skipabove=\medskipamount,
   skipbelow=\medskipamount
]{proof}


\newcommand{\TODO}[1][INCOMPLETE]{{\centering\Large\color{red}$\langle$~\texttt{#1}~$\rangle$\par}}

\begin{document}
\begin{center}
	{\bfseries\Large PDG Dynamics and Inference}
\end{center}	
	
\section{Introduction}
% In our first paper, we introduced PDGs, their semantics, and some examples.
% PDGs are able to represent an inconsistent collection of local beliefs; we have argued that doing so allows us to represent important states of knowledge, and hinted that it may allow us to make better decisions and
% save computation.

We have introduced PDGs, a powerful graphical model that subsume other graphical
models, such as factor graphs and Bayesian Networks. They are essentially 
collections of conditional probablity distributions (cpds), and have semantics in
terms of a scoring function on joint distributions over all variables.
But how can we use them to make predictions? What kinds of queries can we ask a PDG? How does this interact with the distribution-scoring semantics?

The question has some subtleties for a PDG, as a PDG represents somewhat distinct
from a probability distribution (in general, a PDG may contain no probabilistic
information at all, or  conflicting information about every variable).
Still, all PDGs have semantics in terms of probability distributions, and 
in particular, pick out a \emph{best} distribution (we actually have more: a 
(small set of) distributions for every $\gamma \ge 0$, which is guaranteed to 
be unique small $\gamma$ and converge in the limit as $\gamma\to 0$).
We have argued that this allows them to stand in for Bayesian Networks
and factor graphs, because they represent the same distributions---but this
can only happen to the extent we provide algorithms to answer the queries that 
these other graphical models support. To that end, we now adress the most 
important queries from : 
	conditional probability queries of the form $\Pr(Y \smid X)$, 
	maximum likelihood queries like $\MAP(Y \mid X)$, 
	and causal probabilistic queries, such as $\Pr(Y \smid \ado(X))$.
	


%	 "I would like to ask you, as a first step, to write up carefully the three 
%	 results that you claimed in the AAAI conclusion: how we compute M*(X|Y), 
%	 how we do updating, and variational autoencoders (which you’ll have to
%	 review, since I’m not familiar with them)."   -- Joe

\section{Preliminaries}
\subsection*{Notation and PDGs}
First, a slight change to the notation: we now write $\SD{\dg M}$ to denote
the set of distributions consistent with a PDG $\dg M$, rather than $\bbr{\dg M}_{\textrm{sd}}$. We view a cpd $p(Y \mid X)$ as a special case of a PDG with
a single edge $X \to Y$ annotated with the cpd $p$, and taking 
default weights $\alpha_p = 0$, and $\beta_p = 1$. In cases where we wish
to indicate other weights, we indicate the modifications with a parameter
list. For instance, to give a PDG consisting of the cpd $p$, attached to
a value of $\alpha_p$ equal to $\alpha_0$, and 
a value of $\beta_p$ equal to $\beta_0$, we would write
$ p_{\{\alpha=\alpha_0;\beta = \beta_0\}} $.
%
We call two PDGs $\dg A$ and $\dg B$ \emph{compatible} if they agree
on the values of any variables they have in common --- that is, if
$\V^{\dg A}(X) = \V^{\dg B}(X)$ for all $X \in \N^{\dg A} \cap \N^{\dg B}$. 
%
If $\dg A$ and $\dg B$ are compatible PDGs, we write $\dg A \bundle \dg B$ to indicate the PDG consisting of the disjoint union of all edges, in which each edge $L$ retains its associated parameters $\bp$, $\alpha_L$, and $\beta_L$.


\subsection*{Inconsistency}
We start by introducing a repackaged version of PDG semantics,
	% \footnote{in fact, it is roughly equivalent as far as
	% expressive power by \cref{prop:sementics-via-inconsistency}}
in terms of its degree of ``inconsistency''.

\begin{defn}
	If $\dg M$ is a PDG, let $\aar{\dg M}_\gamma$ denote the \emph{degree of
	inconsistency} of $\dg M$ at $\gamma$, and be given by
	$$ \aar{\dg M}_\gamma := \inf_{\mu \in \Delta[\V(\dg M)]} 
		\bbr{\dg M}_\gamma(\mu)
		% \sum\alle \beta_L \;\kldiv{\mu_{Y|X}}{\bp} + \alpha_L\;\H_\mu(Y\mid X)
		,\qquad\text{which we write as}\qquad
		\aard{\dg M} := \lim_{\gamma\to 0^+} \aar{\dg M}_\gamma
	$$	
	in the limiting case for small $\gamma$.
\end{defn} 

So now, for each $\gamma \in [0, \infty)$, $\aar{\dg M}$ is a real number;
we now justify its name.
First, we have already given a sensible notion of what it means 
for a to be (in)consistent, given by the semantics $\SD{-}$. Fortunately,
this new definition is compatible with it. 

\begin{prop}
	$\dg M$ is a \emph{consistent} PDG, in that $\SD{\dg M} \ne \emptyset$,
	if and only if $\aard{\dg M} = 0$. 
\end{prop}

% \begin{proof}
% 	(an immediate corolary of \cref{prop:inc-is-inconsistency})
% \end{proof}


In the full paper, we defined
$\Inc(\dg M) := \inf_\mu \Inc_{\dg M}(\mu)$, also a property of 
a PDG that is motivated to capture inconsistency. 
Sice $\Inc(\dg M)$ is simply $\aar{\dg M}$ without the qualitative term,
it should come at no surprise that $\aar{-}$ reduces to $\Inc(-)$ in the limit
of small $\gamma$ (though perhaps proving it is not as trivial as it seems).

\begthm{prop}{prop:inc-is-inconsistency}
	$\displaystyle \aard{\dg M} = \Inc (\dg M)
		% \inf_{\mu % \in \Delta[\V(\dg M)]
		% } \Inc{\dg M}(\mu) 
	$.
	\hfill\hyperref[proof:inc-is-inconsistency]{(link to proof)}
\end{prop}
% We might therefore say that $\Inc(\dg M)$ is in some sense the
% ``quantitative end'' of $\aar{\dg M}$. 

What about for fixed values of $\gamma$, or the limit as $\gamma$ becomes large?
These are also worth considering, and correspond to different weightings of the
qualitative information (the parameters $\alpha$ which indicate a qualitative
dependency structure), against the quantitative information (the data in the
cpds $\bp{}$ and the parameters $\beta$ expressing its confidence). 
We will write $\aar{\dg M}$ without a subscript to indicate the function
$\gamma \mapsto \aar{\dg M}_\gamma$, which we will use when $\gamma$ is not
relevant and may be supplied arbitrary by a user.

Although we defined $\aar{-}$ in terms of $\bbr{-}$, 
we note that it is also possible to do the reverse,
defining $\bbr{-}$ in terms of $\aar{-}$.
This is done by adding $\mu$ to $\dg M$ with large $\beta$. 
Intuitively, as our confidence that $\mu$ is the right
joint distribution becomes large, the best distribution
gets closer to $\mu$.

\begin{prop} \label{prop:sementics-via-inconsistency}
	$\displaystyle
		\bbr{\dg M}_\gamma(\mu) 
			= \lim_{\beta_0 \to \infty} \aar{\dg M \bundle \mu_{\{\beta=\beta_0\}}}_\gamma
	% \qquad\text{and}\qquad
	% \bbr{\dg M}(\\)
	$
\end{prop}

As a result, $\aar{-}$  may be taken as primitive, and so PDG
semantics can be couched in terms of inconcistency. For instance, the
PDG $\PDGof{\mathcal B}$ for a Bayesian Network $\mathcal B$ is always
consistent ($\Pr_{\mathcal B} \in \SD{\PDGof{\mathcal B}}$, and $\aar{\PDGof{\mathcal B}} = 0$) 
by construction, because $\mathcal B$ represents a distribution 
$\Pr_{\mathcal B}$ that has the appropriate conditional marginals and
(in)dependence structure, and more explicitly, one might \emph{define}
the semantics of a PDG to be the distribution $\mu$, such that, if combined
with the data of $\mathcal B$, results in a maximally consistent PDG. 


\section{Inference by Gradient Descent}

We now return to the task at hand. 
The most important and standard query is a conditional probability
query: given a PDG $\dg M$, how do you compute the probability of $Y$ given $X$?
We use a similar approach as we did in giving PDGs semantics in the first place
---rather than giving probabilistic information directly, we instead give a
measure the quality of a candidate answer $p(Y\smid X)$.
Intuitively, a cpd $p(Y\smid X)$ makes for a good answer to the query
if it is consistent with the other cpds in $\dg M$, and so we propose
$-\aar{\dg M \bundle p}$ as a measure of quality of the inference $p$.
This is simply a definition, but we now verify that it has nice properties,
which we might expect from such a measure of inference quality. 

Perhaps most importantly, the best cpd(s) according to this measure
are the conditional marginals $\mu(Y\mid X)$ of the best distributions $\mu$ for $\dg M$.

\begin{prop}
	For all $\dg M$, $X,Y\in\N^{\dg M}$, and $\gamma > 0$, we have that 
	$\displaystyle
		\argmin_{p : X \to \Delta Y} \aar{\dg M \bundle p}_\gamma = 
		\Big\{ \mu(Y \smid X) :  \mu \in \bbr{\dg M}_\gamma^* \Big\}
	$.
\end{prop}
\begin{proof}
	Because $\alpha_p = 0$, the new cpd $p$ gives the resulting cpd one 
	additional term in its scoring function, equal to the expected
	divergence from $p$ to the appropriate marginal of $\mu$, giving us
	$$
		\bbr{\dg M \bundle p}_\gamma(\mu) = \bbr{\dg M }_\gamma(\mu)
			+ \Ex_{x\sim\mu_{\!_X}} \kldiv[\Big]{\mu(Y\mid x)}{p(Y\mid x)}
	$$
	Gibbs inequality tells us that the second term is non-negative, and zero
	if and only if $\mu(Y \mid X) = p(Y \mid X)$. 
	%Since the first term is independent of $p$, 
	
	If $\mu$ minimizes the first term, (i.e., $\mu \in \bbr{\dg M}^*_\gamma$), then by definition we have $\bbr{\dg M}_\gamma(\mu) = \aar{\dg M}_\gamma$ and so by choosing $p := \mu(Y \mid X)$, we get
	$$	\bbr{\dg M \bundle p}_\gamma(\mu) =
		\bbr{\dg M \bundle \mu(Y \smid X)}_\gamma(\mu) = \bbr{\dg M}_\gamma(\mu)
		= \aar{\dg M}_\gamma$$ 
	but $\aar{\dg M}_\gamma \leq \aar{\dg M \bundle p}_\gamma$ for all $p$, so
	$\inf_p \aar{\dg M \bundle p}_\gamma = \aar{\dg M}_\gamma$,
	and $\mu(Y\smid X)$ minimizes $\aar{\dg M \bundle p}_\gamma$. 
	This shows that $\big\{\mu(Y\smid X) : \mu \in \bbr{\dg M}_\gamma^* \big\} \subseteq \argmin_p \aar{\dg M \bundle p}$. 
	
	% Conversely, if $p_0 \in \argmin_p \aar{\dg M \bundle p}_\gamma$, then 
	Conversely, suppose $p(Y\mid X)$ cannot be expressed as a conditional marginal
	$\mu_0(Y\mid X)$ for any $\mu_0 \in \bbr{\dg M}_\gamma^*$.
	For all $\mu$ in $\bbr{\dg M}_\gamma^*$, we have
	$$ 
		\bbr{\dg M \bundle p}_\gamma(\mu) = \aar{\dg M}_\gamma + \Ex_{x \sim
		\mu_{\!_X}} \kldiv[\big]{\mu(Y \mid x)}{p(Y \mid x)} > \aar{\dg
		M}_\gamma = \inf_p \aar{\dg M \bundle p}_\gamma,
	$$
	where the strict inequality follows from the fact that $p(Y\mid X) \ne \mu(Y\mid X)$ and Gibbs' inequality. 
	Of course, we could also have chosen a different $\nu \notin \bbr{\dg M}_\gamma^*$, but this does not help, since for all $\nu \notin \bbr{\dg M}_\gamma^*$, we have 	
	% \notin \bbr{\dg M}^*_\gamma$, then
	$$
		\bbr{\dg M \bundle p}_\gamma(\nu) \ge \bbr{\dg M}_\gamma(\nu) > \aar{\dg M}_\gamma.
		% = \inf_p \aar{\dg M \bundle p}_\gamma.
	$$
	Putting the two together, we find that for every joint distribution $\mu$, 
	we have 
	$\bbr{\dg M \bundle p}_\gamma(\mu) > \aar{\dg M}_\gamma$,
	and since $\aar{\dg M}_\gamma = \inf_p \aar{\dg M \bundle p}_\gamma$, 
	$p$ does not minimize $\aar{\dg M \bundle p}_\gamma$. 
	The contrapositive of this argument gives us the other inclusion, $\big\{\mu(Y\smid X) : \mu \in \bbr{\dg M}_\gamma^* \big\} \supseteq \argmin_p \aar{\dg M \bundle p}$, as desired.

\end{proof}
In the limit, of small $\gamma$, since there is only one such distribution,
the expression beomes simpler. 
\begin{prop}
	$\displaystyle
		\bbr{\dg M}^*(Y \smid X)
	$ uniquely minimizes $p \mapsto \aard{\dg M \bundle p}$.
\end{prop}
\begin{proof}
	The argument above works uniformly for all $\gamma$, and so the limit
	factors through it (more concretely, the proof remains valid if we insert a limit as $\gamma \to 0$ in front of every $\aar{-}_\gamma$ or $\bbr{-}_\gamma$). Since $\bbr{\dg M}^*$ the unique element of $\lim_{\gamma\to0}\bbr{\dg M}_\gamma^*$, $\bbr{\dg M}_\gamma^*(Y\smid X)$ 
	is the unique element of $\argmin_p \aard{\dg M \bundle p}$.
	% $$ \bbr{\dg M}_\gamma(\mu) $$
\end{proof}

So $p \mapsto \aar{\dg M bundle p}$ gives the best scores to the marginals of
distributions that the scoring semantics of $\dg M$ view as best. Even supposing
we had oracle access to $\aar{-}$ (which might already be very hard to compute),
the prospect of having to enumerate all possible conditional probability
distributions $p$ to find the best one sound prohibitively expensive.
Fortunately, it is not necessary, as the function $p \mapsto \aar{\dg M \bundle
p}$ has properties which make for efficient search,
given oracle access to $\aar{\dg M}$.  Most importantly, it is smooth and 
%
strictly convex
%
in $p$, 

\begin{prop}
	The function $p \mapsto \aar{\dg M \bundle p}_\gamma$ is smooth and $\gamma$-strongly convex for all $\gamma$ less than $\min (\{1\}\cup\{ \beta^{\dg M}_L : L \in \Ed^{\dg M}\})$. 
\end{prop}
\begin{proof}
	First, we deal with the convexity, for which we make use of \cref{lem:cvx1,lem:cvx2}.
	\commentout{
		\def\mw#1{{\mat w}_{\!_{#1}}}
		\def\ofmw(#1|#2){(\mw{#1} \smid \mw{#2})}
		\begin{align*}
			\aar{\dg M \bundle p}_\gamma &= \inf_\mu \Big[ \Inc_{\dg M \bundle p}(\mu) 
				+ \IDef{\dg M \bundle p}(\mu) \Big] \\
			&=  \inf_{\mu} \Ex_{\mat w \sim \mu} 
				\left[\log \mu(\mat w) +
				 	\beta_p \log \frac{\mu\ofmw(Y|X)}{p\ofmw(Y|X)} \; +  \!\sum_{\ed LAB} \beta_L \log \frac{\mu\ofmw(B|A)}{\bp\ofmw(B|A)} + \alpha_L \log \frac{0}{\mu\ofmw(B|A)}\right] \\
			&= f
		\end{align*}
	}
	We start by expanding the definitions, obtaining
	\begin{align*}
		\aar{\dg M \bundle p}_\gamma &= \inf_\mu ~\bbr{\dg M \bundle p}_\gamma(\mu) \\
			&= \inf_\mu \left[ \bbr{\dg M }_\gamma(\mu)
				+ \Ex_{x\sim\mu_{\!_X}} \kldiv[\Big]{\mu(Y\mid x)}{p(Y\mid x)} \right]\\
			&= \inf_\mu \left[ \bbr{\dg M }_\gamma(\mu)
				+  \kldiv[\big]{\mu_{XY}}{p_{Y \mid X}\; \mu_X} \right].
	\end{align*}
	Choose $\gamma < (\{1\}\cup\{ \beta^{\dg M}_L : L \in \Ed^{\dg M}\})$.
	Since $\bbr{\dg M}_\gamma$ is a $\gamma$-strongly convex function of $\mu$ for all
	such $\gamma$, and 
	$\kldiv{\mu_{XY}}{\mu_X \; p_{Y\mid X}}$ is 1-strongly 
	convex in $p$ for fixed $\mu$ (\cref{lem:cvx3}), 
	% $\thickD$ is convex in both of its arguments,
	their sum is $\gamma$-strongly convex in $\mu$ and in $p$.
	By \cref{lem:cvx2} taking an infemum preserves this convexity,
	and so
	$
	 	\inf_\mu \left[ \bbr{\dg M }_\gamma(\mu)
		+  \kldiv[\big]{\mu_{XY}}{p_{Y \mid X}\; \mu_X} \right]
	$, which equals $\aar{\dg M \bundle p}_\gamma$,
	is $\gamma$-strongly convex in $p$. 
	% $\aar{\dg M \bundle p}_\gamma$ is smooth
	% Smoothness.
	
	Smoothness follows from the fact that the infemum of a convex family of smooth
	convex functions is also smooth (\cref{lem:cvx4}). 
\end{proof}

\begin{prop}
	$\aar{\dg M}_\gamma$ is continuous as a function of $\gamma$, and converges as $\gamma\to 0$. 
\end{prop}
\begin{proof}
	\par
	\TODO
\end{proof}

This suggests using a variant of gradient descent in which
in which $\gamma$ decays to zero during the optimization process, because
progress towards an optimum for $\gamma_0$ will still be progres towards  
the optimum for $\gamma_0 - \epsilon$.  


% {\centering\Large Further Claims \par}


\commentout{%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\begin{defn}[degree of inconsistency]
		If $\dg M$ is a PDG, let $\aar{\dg M}_\gamma$ denote the \emph{degree of
		inconsistency} of $\dg M$ at $\gamma$, and be given by
		$$ \aar{\dg M}_\gamma := \inf_{\mu \in \Delta[\V(\dg M)]} 
			% \bbr{\dg M}_\gamma(\mu)
			\sum\alle \beta_L \;\kldiv{\mu_{Y|X}}{\bp} + \alpha_L\;\H_\mu(Y\mid X)
		$$
		and let $\aar[\Big]{\dg M} = \lim_{\gamma\to 0^+} \aar{\dg M}_\gamma$.
	\end{defn}

	\begin{claim}
		$$\bbr{\dg M}_\gamma(\mu) = $$
	\end{claim}
}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% There is an intuitive story to be told here: simply add a guess to the PDG.
% Sort it out if you have time. 
% Do not sort it out otherwise. 


\subsection{Conditioning, and a Second Approach}
What if we only wanted to know $\Pr(Y \smid X=x)$, for a specific value of $X$, rather than
the full cpd $\Pr(Y\smid X)$ (including the data for every $X$), in the context of a PDG $\dg M$?

In this case, we could add an edge $\pdgunit \to X$ annotated with the degenerate cpd $\delta_x$ 
indicating that $X$ always takes the value $x$. 

\begin{claim}
 	The cpd $q(Y \mid X) := x \mapsto \bbr{\dg M \bundle (X\!=\!x)}^*_\gamma(Y)$
	minimizes $\aar{\dg M \bundle q}_\gamma$
\end{claim} 

\subsection{Complexity}

\begin{prop}
	Computing $\aar{\dg M}$ is NP-hard.  
\end{prop}
\begin{proof}
	We can directly encode SAT problems as PDGs, which are inconsistent.
	Specifically, let $\varphi$ be a formula over variables $\mat X$. The PDG
	whose nodes are $\mat X \cup \{$``$\varphi(\mat X)$''$\}$ with $\V(\varphi) = \{0,1\}$, and
	two edges:
	\begin{itemize}	
		\item an edge $\mat X \tto$``$\varphi(\mat X)$'', together with a degenerate cpd
			(function) indicating the truth of
			$\varphi$ for a value of $X$
		\item an edge $\pdgunit \tto $``$\varphi(\mat X)$'', which asserts that 
			``$\varphi(\mat X)$'' always takes the value 1.
	\end{itemize}
	Such a PDG is consistent if there is a satisfying assignment of variables, and 
	inconsistent otherwise.
\end{proof}

There is still hope for approximating it, given that it is convex (but in an exponentially
large space) and monotonic in that additional edges only increase $\aar{\dg M}$? 

\TODO

\section{Causal Inference}
To do causal inference, we need only make use of the parameter $\alpha$ when considering
potentaial answers. As in section 

\section{Variational Inference}

\section{Belief Propogation in a PDG}

\section{General Dyanmics}
Let $\Theta_\dg M$ be the space of parameters of $\dg M$ (i.e., the parameters for
every cpd and all of the weights). We propose that we update weights by

$$  $$

%%%%%%%%%%%%%%%% VESTIBULE %%%%%%%%%%%%%
\commentout{
	If, rather than fixing $\dg M$ and optimizing $p$, we fix $p$ and optimize $\dg M$,
	this same proces corresponds to an update, rather than an inference. For instance, in
	the case where $X = \pdgunit$, an observation $Y\!=\!y$  can be added to
	$\dg M$ in the form of an edge $\ed{\delta_y}{\pdgunit}Y$, getting the
	(possibly inconsistent) PDG $\dg M'$. The distribution $\bbr{M'}^*$ turns out
	to be the result of conditioning $\bbr{\dg M}^*$ on $Y\!=\!y$.  
}

\section{Misc}

\subsection{Factor Graphs and Inconsistency}
For factor graphs, the story is more complex, as it could involve
inconsistency. The factors of a
factor graph, which in isolation indicate relative probabilities. 
In physics, factored exponential families form a mathematical backbone of statistical
mechanics, in which the normalization constant 
$Z_{\Psi}$ for the WFG $\Psi = (\phi_j, \theta_j)_j$,
given by
$$
	Z_{\Psi} := \sum_{\mat w} \prod_{j} \phi_j(\mat w_j)^{\theta_j} 
	,
$$
is known as the \emph{partition function}. 
Surprisingly, most aggregate thermodynamic quantities 
(e.g., the total energy, free energy, pressure, and entropy) can
be obtained by taking various partial derivatives of $Z_\Psi$.
Because both $Z_{\Psi}$ for a factor graph $\Phi$, and $\aar{\dg M}$ are
both real-valued functions of the state of the system, one might wonder if
there is some connection between them. Indeed, there is.

\begin{conj}
	$\log Z_{\Psi} = \aar{\PDGof{\Psi}}_1$
\end{conj}

\appendix
\section{Proofs and Lemmas}

\begin{lemma} \label{lem:cvx1}
	If $f(x,y)$ is bounded below and convex in both $x$ and $y$, then it is jointly convex in
	$x\otimes y$. 
\end{lemma}
\begin{proof}
	By definition, for $f$ to be convex in either variable separately, we have, for all $\lambda \in [0,1]$ and all $x_0, x_1, x_2, y_0, y_1, y_2$, that
	\begin{align*}
		f(\lambda x_1 + (1-\lambda) x_2, y_0) &\le \lambda f(x_1, y_0) + (1-\lambda) f(x_2, y_0) \\
		\text{and}\qquad
		f(x_0, \lambda y_1 + (1-\lambda) y_2) &\le \lambda f(x_0, y_1) + (1-\lambda) f(x_0, y_2). \\
	\end{align*}
	In particular, for $y_0 = \lambda y_1 + (1-\lambda) y_2$ and $x_0 = \lambda x_1 + (1-\lambda) x_2$, we have
	\begin{align*}
		f\Big(\lambda x_1 + (1-\lambda) x_2,  \lambda y_1 + (1-\lambda) y_2 \Big)
			&\le \lambda f(x_1, \lambda y_1 + (1-\lambda) y_2 ) + (1-\lambda) f(x_2, \lambda y_1 + (1-\lambda) y_2 ) \\
			&\le \lambda \Big( \lambda f(x_1, y_1) + (1-\lambda) f(x_1, y_2) \Big) + (1-\lambda) \Big( \lambda f(x_2, y_1) + (1-\lambda) f(x_2, y_2) \Big) \\
			&=  \lambda^2 f(x_1, y_1) + \lambda(1-\lambda) \big[ f(x_1, y_2) +  f(x_2,y_1) \big] + (1-\lambda)^2 f(x_2, y_2).
	\end{align*}
	Now, supposing that $f$ is positive, then $\lambda^2 f(a,b) \le \lambda f(a,b)$, and so
	\begin{align*}
		f\Big(\lambda x_1 + (1-\lambda) x_2,  \lambda y_1 + (1-\lambda) y_2 \Big)
			&\le  \lambda^2 f(x_1, y_1) + \lambda(1-\lambda) \big[ f(x_1, y_2) +  f(x_2,y_1) \big] + (1-\lambda)^2 f(x_2, y_2) \\
			&\le  \lambda^2 f(x_1, y_1) + (1-\lambda)^2 f(x_2, y_2) \\
			&\le  \lambda f(x_1, y_1) + (1-\lambda) f(x_2, y_2),
	\end{align*}
	as desired. More generally, if $f$ is not positive but merely bounded below, then $f(a,b) = g(a,b) + C$ for some constant $C$ and positive function $g$, which is convex in its arguments. Our previous argument shows that $g$ is jointly convex in $x,y$, and because a constant shift does not alter the convexity of a function, $f$ must be jointly convex in $x,y$ also.
\end{proof}
\begin{lemma} \label{lem:cvx2}
	If $f(x,y)$ is $m$-strongly convex in $x$ and $y$, then $y\mapsto \inf_x f(x,y)$ is an $m$-strongly convex function of $y$.
\end{lemma}


\begin{lemma} \label{lem:cvx3}
	$\kldiv{\mu}{\nu}$ is a 1-strongly in $\nu$, for fixed $\mu$. 
\end{lemma}
\begin{proof}
	\begin{align*}
		\kldiv{\mu}{\nu} &= \Ex_{x\sim\mu} \log \frac{\mu(x)}{\nu(x)} \\
			&= \Ex_{x \sim \mu}\log \mu(x) +  \Ex_{x\sim\mu}\log \frac{1}{\nu(x)}
	\end{align*}
	As the first term depends only on $\mu$, it suffices to consider the behavior
	of the second term, as a function of $\nu$. Let $F(\nu) = - \Ex_{x \sim \mu} \log \nu(x)$.
	Then $\nabla F(\nu) = x\mapsto \frac{\mu(x)}{\nu(x)}$. 
	Let $k^{\mu}_{\nu_1, \nu_2} := \inf_x \frac{\mu(x)}{\nu_1(x)\nu_2(x)}$. 
	Expanding the inner product of the difference in between $\nu_1$ and $\nu_2$, we have
	\begin{align*}
		(\nabla F(\nu_1) - \nabla F(\nu_2) ) \cdot (\nu_1 - \nu_2) 
			&= \sum_{x} \left( \frac{\mu(x)}{\nu_1(x)} - \frac{\mu(x)}{\nu_2(x)} \right)
				(\nu_2(x) - \nu_1(x)) \\
			&= \sum_{x} \mu(x) \left( \frac{\nu_2(x)}{\nu_1(x)\nu_2(x)} - 
				\frac{\nu_1(x)}{\nu_1(x) \nu_2(x)} \right) (\nu_2(x) - \nu_1(x)) \\
			&= \sum_{x} \mu(x) \left( \frac{1}{\nu_1(x)\nu_2(x)} \right)
			 (\nu_2(x) - \nu_1(x))^2
			% &\ge \sum_{x} \mu(x) 
 			%  (\nu_2(x) - \nu_1(x))^2 \\
		 	% &\le \left(\sum_{x} \frac{\mu(x)}{\nu_1(x)\nu_2(x)} \right)
			%    \left(\sum_x (\nu_2(x) - \nu_1(x))^2  \right) & \text{[Cauchy-Schwarz]}\\
	\end{align*}
	\TODO[incomplete; may require weakening]
\end{proof}

\begin{lemma}\label{lem:cvx4}
	If $X$ and $Y$ are compact real manifolds (with boundary), and
	If $f : X \times Y \to \mathbb R$ is strictly convex and smooth,
	then $y\mapsto \inf_x f(x, y)$  is smooth.
\end{lemma}
\begin{proof}
	Let $f_y(x) = f(x,y)$. 
	Since $f$ is smooth and stritly convex, each restriction $f_y$ of $f$ to a 
	particular $y$ is also smooth and strictly convex. 
	As a result, each $f_y$ has a unique minimum $m_y := \inf_{x} f_y(x)$.
	As it is smooth, $m_y$ is either a boundary point, or
	at a point where $\nabla f = 0$. In the latter case, 
			
	\TODO
\end{proof}

\recall{prop:inc-is-inconsistency}
\begin{proof}\label{proof:inc-is-inconsistency}
	Unwrapping the definitions, we have
	\begin{align*}
		\aard{\dg M} = \lim_{\gamma\to 0^+} \aar{\dg M}_\gamma 
			&= \lim_{\gamma\to 0^+} \inf_{\mu}\;
				\bbr{\dg M}_\gamma(\mu) \\
			&= \lim_{\gamma\to 0^+} \inf_{\mu}\; 
				\Big[  \Inc_{\dg M}(\mu) + \gamma \IDef{\dg M}(\mu)  \Big]
		% \inf_{\mu}
	\end{align*}
	Since $\IDef{\dg M}$ is bounded above and below by constants $k \le \IDef{\dg M} \le K$, we have, for all $\gamma$ and $\mu$, that
	$$ 		 
		 \Inc_{\dg M}(\mu) + \gamma k \le  \Inc_{\dg M}(\mu) + \gamma \IDef{\dg M}(\mu) 
		 	\le \Inc_{\dg M}(\mu) + \gamma K.
	$$
	Since this holds for all $\mu$,  $\Inc_{\dg M}$ and $\IDef{\dg M}$ are
	bounded below, and set of possible distriutions $\mu \in \Delta\V(\dg M$)
	is compact, the infemum $\inf_\mu [\Inc_{\dg M}(\mu) + \gamma \IDef{\dg M}(\mu)]$
	is achieved by some $\mu^*$, for which 
	$$
		\Inc_{\dg M}(\mu^*) + \gamma k \le  \Inc_{\dg M}(\mu^*) 
			+ \gamma\;\IDef{\dg M}(\mu^*) 
	   		\le \Inc_{\dg M}(\mu^*) + \gamma K	
	$$
	and of course, $\Inc_{\dg M}(\mu^*) = \Inc(\dg M)$ by definition of the latter, so
	$$
		\Inc(\dg M) + \gamma k \le \inf_\mu 
			\Big[ \Inc_{\dg M}(\mu) + \gamma \IDef{\dg M}(\mu) \Big] 
			\le \Inc(\dg M) + \gamma K	.
	$$
			
	% 		\lim_{\gamma\to 0^+} \inf_{\mu}\; 
	% 			\Big[  \Inc_{\dg M}(\mu) + \gamma \IDef{\dg M}(\mu)  \Big]
	% 	&\geq 
	% 		\lim_{\gamma\to 0^+} \Big[	\inf_{\mu}\;  \Inc_{\dg M}(\mu) +
	% 		 	\gamma \inf_{\mu}\;  \IDef{\dg M}(\mu) \Big]\\
	% 	&\geq 
	% 		\lim_{\gamma\to 0^+} \Big[	\inf_{\mu}\;  \Inc_{\dg M}(\mu) +
	% 		 	\gamma \inf_{\mu}\; k \Big]
	% \end{align*}
	Taking the limit as $\gamma \to 0$ and using the squeeze theorem, we find that
	$$ 
		\Inc(\dg M) = \lim_{\gamma\to 0^+} \inf_{\mu}\; 
			\Big[  \Inc_{\dg M}(\mu) + \gamma \IDef{\dg M}(\mu)  \Big]
			 = \aard{\dg M}
			 ,\qquad\text{as desired.}
	$$
\end{proof}




\end{document}
