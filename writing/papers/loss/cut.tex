

\begin{prop}[Mean squared error as inconsistency]
	\begin{align}
		\aar*{\begin{tikzpicture}[center base]
			\node[dpad0] (Y) {$Y$};
			\node[dpad0,left=1.1 of Y] (X) {$X$};
			%
			\draw[arr2, ->] (X) to[bend left]
				node[pos=0.5, above] {$f!$} (Y);
			\draw[arr2, ->] (X) to[bend right]
				node[pos=0.5, below]{$\mathcal N(h(x), s(x))$} (Y);
			\draw[arr2, <-] (X) to node[pos=0.6, above]{$D!$} +(-1.1, 0);
		\end{tikzpicture}}
		&=
		\aar*{
		\begin{tikzpicture}[scale=1.1,center base]
			\node[dpad0] (Y) {$Y$};
			\node[dpad0,left=2.5 of Y] (X) {$X$};
			% \node[dpad0,above left=0.5 and 1.1 of Y] (mf) {$\mu_f$};
			\node[dpad0,below right=0.6 and 0.8 of X] (mh) {$\mu_h$};
			% \node[dpad0,above left=0.2 and 0.8 of Y] (sf) {$\sigma_f$};
			\node[dpad0,below right=0.1 and 0.8 of X] (sh) {$\sigma_h$};
			%
			% \draw[arr2, ->>] (X) to[bend left]
			% 	node[pos=0.5, above] {$f$} (mf);
			% 	\draw[arr2, ->>] (X) to[bend left]
			% 		node[pos=0.5, above] {$t$} (sf);
			\draw[arr2, ->>] (X) to[bend right=30]
				node[pos=0.6, left] {$h$\,} (mh);
				\draw[arr2, ->>] (X) to[bend right=10]
					node[pos=0.5, above] {$s$} (sh);
			%
			\draw[arr2, <-] (X) to node[pos=0.6, above]{$D!$} +(-1.1, 0);
			\draw[arr2, ->] (X) to[bend left]
			 	node[pos=0.5, fill=white]{$f!$} (Y);
			\coordinate (C1) at ($(mh)!.5!(sh) + (0.85,-0.1)$);
			% \coordinate (C2) at ($ (X)!.5!(Y) + (0,0.8)$);
			\draw[arr2, ->] (mh) to[bend right=15] (C1) to[bend right=20]
			 	node[pos=0.25, below right, inner sep=0] {$\mathcal N$} (Y);
			\draw[arr2, -,shorten >=0pt] (sh) to[bend right=25] (C1);
			% \draw (current bounding box.north east) rectangle (current bounding box.south west);
		\end{tikzpicture}} \label{eq:expandnormal} \\
		 &= \Ex\nolimits_{\subalign{x &\sim D\\y &\sim f(Y\mid x)}} \left[
		  	2 \log f(y \mid x) + \frac\beta2\frac{(y-h(x))^2}{s(x)^2}
				+ \log 2\pi s(x)^2 \right] \label{eq:expandresult}
	\end{align}
\end{prop}
The equivalence of the two diagrams asserted by \eqref{eq:expandnormal} simply reflects the fact that functional composition of deterministic functions works as one would expect in a PDG.



-----------------------------------


In parallel work focusing on PDG inference,
	we prove some nice properties of the inconsistency $\aar{-}$,
	and argue that many standard algorithms for inference and updating in other probablisitc models can be viewed as algorithms for reducing inconsistency, in the corresponding PDG.



-----------------------------------

\textbf{Inconsistency, in a different light.}
Nobody likes building broken things, and so those of who build systems commonly try to eliminate it in models by design. But in doing so, we unwittingly sacrifice tools for dealing with it if (and when) it does arise.


\textbf{A Universal Objective.}
Objective functions in machine learning are often quite opaque to new-comers.
Only a few of them are especially common, and they are often presented in an ad hoc way; there are many loss functions that have the properties we need to train networks. So why do we lean so heavily on a few select choices (dependent on the problem setup), such as the cross entropy, and the ELBO objective?
PDGs provide one answer to this question.

There is perhaps a more important argument for using PDGs over other models. By designing a model, rather than an objective function, it is easier to understand what the pieces are, what is and is not relevant to the task, and no longer possible to twiddle with the objective until you get the results you want --- you can only twiddle with the model, where hacks are more easily spotted.

\textbf{Semantics for ``Graphical Models''.}
Often, autoencoder tutorials will include diagrams, and falsely claim that they are standard ``graphical models''. In these cases, among others, people are already reasoning about local probabilistic information in a graph. We have shown here that PDG semantics can sense of these informal diagrams in a way that is deeply connected with the variational reasoning involed.
