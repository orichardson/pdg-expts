\documentclass{article}

\input{prefs-commands.tex}
\addbibresource{../refs.bib}
\addbibresource{../maths.bib}

\title{MCGs: Transitions and Games}
\author{Oliver Richardson  \texttt{oli@cs.cornell.edu}}


\begin{document}
	\maketitle
	
%	\section{
	There are two different styles of common graphical models, and though their relation is quite clear, they are related in important ways, which is not often enough mentioned explicitly.

	My marginal constraint graphs can capture both. 
	
	The first class of graphical model is BN-like: they represent factorizations of probability distributions. The interpretation 
	
	% Factor graphs are a generalization that people like to use, but I will put less emphasis on these, for reasons in section \ref{sec:factor-graphs-bad}. ]
	The other class of model is automaton-like: a transition model between states. 
	
	\begin{center}
		\begin{tikzpicture}[center base]
			\node[draw, circle] (A) at (0,0){A};
			\node[draw, circle] (B) at (-1,-1){B};
			\node[draw, circle] (C) at (2,0){C};
			\node[draw, circle] (D) at (0.5,-2){D};

			\draw[arr] (A) to[bend right] node[above]{.3}  (B);
			\draw[arr] (A) to[bend left=20] node[above]{.3}  (C);
			\draw[arr] (A) to[bend left=20] node[right]{.2}  (D);
			\draw[arr] (D) to[bend left=20] node[left]{.7}  (A);
			\draw[arr] (B) to[bend right=50] node[below]{.5}  (D);
			\draw[arr] (D) to[bend left=05] node[below]{.3}  (B);
			\draw[arr] (B) to[loop left] node[left]{.5}  (B);
			\draw[arr] (C) to[loop right] node[right]{1} (C);
			
		\end{tikzpicture}
		\hspace{2in}
		\begin{tikzpicture}[center base]
			\node[draw, circle, fill=gray!20] at (0,0) (S) {$S_t$};
			\node[draw, circle, fill=gray!20] at (2,0) (St) {$S_{t+1}$};
			\draw[arr] (S) to[bend left] node[above]{$\tau$} (St);
		\end{tikzpicture}
	\end{center}

	The two pictures represent the same transition matrix:
	\[ \tau = \begin{sqidxmat}{A,B,C,D}
		0 & 0.3 & 0.3 & 0.2 \\
		0 & 0.5 & 0 & 0.5 \\
		0 & 0 & 1 & 0 \\
		0.7 & 0.3 & 0  & 0
	\end{sqidxmat}\]
	but both hide something. On the left we see the individual states, but we've projected out across all of time; on the right, we explicitly see time, but have abstracted out all of the states. We could also have considered a different, cluttered representation which shows both at once, tagging both the time and the states:
	
		
	\begin{center}
		\begin{tikzpicture}[center base]
		\node[draw, circle] (A) at (0,0){A$_{t}$};
		\node[draw, circle] (B) at (-1,-1){B$_{t}$};
		\node[draw, circle] (C) at (1.5,1){C$_{t}$};
		\node[draw, circle] (D) at (0.5,-2){D$_{t}$};
		\node[draw, circle] (A') at (3,0){A$_{t+1}$};
		\node[draw, circle] (B') at (2,-1){B$_{t+1}$};
		\node[draw, circle] (C') at (4.5,1){C$_{t+1}$};
		\node[draw, circle] (D') at (3.5,-2){D$_{t+1}$};
		
		\draw[arr] (A) to[bend right=15] node[above]{.3}  (B');
		\draw[arr] (A) to[bend left=0] node[above]{.3}  (C');
		\draw[arr] (A) to[bend left=32] node[above]{.2}  (D');
		\draw[arr] (D) to[bend right=45] node[below]{.7}  (A');
		\draw[arr] (B) to[bend right=50] node[below]{.5}  (D');
		\draw[arr] (D) to[bend left=05] node[below]{.3}  (B');
		\draw[arr] (B) to[bend right=05] node[below]{.5}  (B');
		\draw[arr] (C) to[bend left=20] node[above]{1} (C');
		
		\end{tikzpicture}
	\end{center}
	At the other extreme, we could have compressed in both directions, giving us
	\begin{center}
		\begin{tikzpicture}
		\node[draw, circle, fill=gray!20] at (0,0) (S) {$S$};
		\draw[arr] (S) to[loop above] node[above]{$\tau$} (S);
		\end{tikzpicture}
	\end{center}
	

%	\begin{tabular}{c|c|c}
%		context & automaton-like & BN-like \\\cline{1-3}
%%		& MEMM & CRF \\
%		&
%	\end{tabular}


	\subsection*{Two Interpretations}

	As usual, there are multiple ways of interpreting the probability:
	\begin{enumerate}
		\item The specification $\tau$ is somehow actually the truth about what happens to $S$ over times. It is defined as the random process which has the statistics in question. 
		\item $\tau$ is just fit to experiential data --- a best case approximation, marginalizing out the things we weren't able (or didn't care to) control for.
	\end{enumerate}
	While both 
		
	\textbf{Temporal.} It is common to model transitions using automata-like graphical models

	\section{Encoding as MCGs} 
	
	Structurally automaton-like graphs are just a special case making heavy use of our extra element $\bullet$ and the fact that we don't require conditioning on it. Each element $s \in S$ can be encoded as a node $\mathbbm 1_s$
	
%
	\subsection*{}
	There is, of course, also an explicit conversion between the two of them, involving packing and unpacking. If the BN-like model is a graph $(V, E, \mathcal S, \mathbf p)$, then we can create a new model whose nodes are every possible value of any node, and whose edges are the unpacked fibers of the edges in the original graph, i.e.,
	
	\[ \left(\bigcup_{v : V}\{ \mathbbm 1_x : x \in \mathcal S_v\}, ~~ \bigcup_{(A,B) : E}(\mathcal S_A \times \mathcal S_B) = \Big\{(a_i, b_j) \in \mathcal S_A \times \mathcal S_B : a_i, b_i \Big\} \right),  \]
	
	if we just 
	
	\footnote{This unpacking / re-packing is in fact exactly the Category of Elements construction}


	
	\section{Relation to Preferences}
%	A probability distribution over your choices and a preference are related. 
	Any binary relation can be turned into a transition graph by normalizing, which gives you the maximum entropy transition graph consistent with a 
	
	
	We can also make use of constraints in MCG's to specify fixed points.
	
	\section{Game Trees}
	
	% bipartite double cover of a graph is 
	
	
	
\end{document}