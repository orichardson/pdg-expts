%	Bayesian Networks may be the best known graphical models, but they are not the most expressive.
	We now review a very general class of \emph{undirected} graphical models, often thought of as a generalization of BNs and Markov Networks. \MNs\ can simulate them, but not without large cpts and sneaky use of inconsistency. 
	We start by reviewing the definitions.
	
	\begin{defn}
		A \emph{factor graph} is a collection of random variables $\mathcal X = \{X_i\}$ and a collection of \emph{factors} $\{\phi_\alpha\colon X_\alpha \to \mathbb R\}_{\alpha \in \mathcal I }$ over subsets $\alpha$ of $\mathcal X$.
	\end{defn}

	A factor graph $F = (\{\phi_\alpha\}_{\alpha \in \cal I})$ defines a probability distribution by 
	\[ \Pr_F(\vec x) \propto \prod_{\alpha \in \cal I} \phi_\alpha(\vec x_{\alpha}) \]
%	In general, this normalization constant so that this is a valid distribution, $Z$, is NP-hard to compute. 
	Factor graphs have a lot in common with \MNs: they are modular, effectively presented as hyper-graphs, generalize \MNs\ by explicitly representing the tables rather than the dependencies, explicitly maximize entropy, and are thought of as soft constraints.
	However, the constraints are on settings of variables, rather than distributions; this is the source of \MNs\ extra expressive power.
	Another huge difference, and the one that makes directed models hard to represent with \MNs, is the global normalization.

	While factor graphs are powerful statistical models, we argue that they are not less well suited to modeling for epistemic state, for several reasons. 
	%over-eager in sweeping all inconsistencies under the same rug. 
	\begin{enumerate}
		\item They are undirected. This means causal modeling, sampling, game trees, path composition, and views of the stored information as programs are all substantially less natural. \label{fgproblem:undirected}
		\item The global normalization is computationally difficult, seems inhuman, and is over-eager in sweeping all inconsistencies. One effect of this very global focus is that looking at a few factors locally may not provide an accurate picture of how they work. \label{fgproblem:global}
		\item Factors cannot be re-weighted by importance while still preserving the ratios of likelihoods between alternatives. \label{fgproblem:reweight}
		\item There is no possibility of corroborating evidence \label{fgproblem:corrob}s
		\item They are volatile: the addition of a new node can arbitrarily change the distribution \label{fgproblem:volatile} (\Cref{ex:fg-volatile,ex:fg-volatile-2})
	\end{enumerate}
	
	
	\begin{example}[continues=ex:planet]
		\begin{figure}[h]
			\centering
			\scalebox{0.8}{
				\begin{tikzpicture}
				\node[dpadded,inner sep=0.6em, circle] (S) at (-0.4, 2) {$S$};
				\node[dpadded,inner sep=0.6em, circle] (C) at (3, 2) {$C$};
				\node[dpadded,inner sep=0.6em, circle] (L) at (1.3,0) {$L$};
				\node[dpadded,inner sep=0.6em, circle] (W) at (-2,0) {$W$};
				
				\node[light pad] (f1) at (1.3, 1.3){$\phi_1$};
				\node[light pad] (f2) at (-0.3, 0){$\phi_2$};
				
				\draw[thick] (S) -- (f1) -- (C) (f1) -- (L);
				\draw[thick] (W) -- (f2) -- (L);
				\end{tikzpicture}
			}
			\caption{Factor graph for \Cref{ex:planet}}
			\label{fig:planet-factorgraph}
		\end{figure}
	
		In our planet example, we treat each edge as a factor, the product of which gives the correct relative likelihoods for each of $S \times C \times W \times L$. Our initial knowledge, consisting only of the cpt , we have 
		\[ \Pr(s, c, w, l) \propto \phi_1(s,c,l)  \]
		where $\phi_1(s,c,l) = p(l \mid s,c)$, and no normalization is required. For this reason, conditional probability distributions are sometimes thought of as locally normalized, which is precisely the condition directed factor graphs \parencite{frey2012extending} impose.

		In contrast with BNs, there is no structural barrier to adding a new node, and factor $\phi_2(w,l) \!=\! \Pr(L\!=\!l\mid W\!=\!w)$ --- though to make sense of this as a probability we have to re-compute the normalization constant. The combination of the two factors is represented graphically in \Cref{fig:planet-factorgraph}, in which circles represent variables, and the boxes represent factors that depend on variables they connect to. 
		 	\vfullfootnote{Perhaps it is worth noting that ($\mathcal N \!=\! \{S,C,W,L\}, \Phi \!=\! \{\phi_1,\phi_2\}$) form a bipartite graph, or a hyper-graph over $\mathcal N$, adding also to the visual similarity between factor graphs and \MNs. }
	\end{example}	
	\begin{example}\label{ex:fg-volatile}
		Take any factor graph $\Phi$, and add a new factor $\phi_0$, connected to no variables, that always takes the value $\phi_0 := 0$. Now the product of the factors is now uniformly zero, and not possible to normalize; note that this has affected the entire graph, despite the fact that $\phi_0$ is not adjacent to any variables. For an agent like this, making any changes at all, particularly in an adversarial setting, could be a hazard.
	\end{example}

	In \Cref{ex:fg-volatile}, the designer is lucky in a sense: it is obvious that the model is broken, and the fix is to delete a single suspicious-looking factor. Of course, without trying the NP hard normalization, there's no way to tell that anything is wrong. In general, things could be much worse: the failure to normalize can be spread out over many nodes, and even if the factor graph normalizes, a single additional factor connected to all variables can unilaterally force the factor graph to represent an arbitrary distribution at any world that has not been marked as impossible by another factor. This global normalization process in some sense is a catch-all fix that ensures that the factor graph is well-defined, but does not preserve any local meanings whatsoever.
	
	
	By contrast, \MNs\ are unaffected by any data that is not connected  to the rest of the graph, raise red flags when things go wrong, and no individual link can override another: instead it gets stuck in an inconsistent state; we assert once again that this is much more desirable.
	
%	\todo{This section, too, requires a lot of editing. I have a list of features I want to object to, that I still need to put here in place of this}
	%This is a lot more modular (we can add and remove factors as we like). 
	%We now have a distribution that represents both beliefs, but this is not really what we were thinking of earlier.
	%Beyond simply the inevitable effects of representing our knowledge as a distribution, such as forcing us to implicitly adopt marginal distributions over the variables $S,C$, and $W$, a product of factors has additional undesirable properties that are not shared by \MNs:
%	While general, factor graphs sacrifice interpretability and important internal features of our original belief representation, so that they can represent distributions.
	
	
	There is an obvious way to view a \MN\ as a factor graph: simply ignore the directions of the edges, and use the tables as factors. If $\sfM$ is a \MN\, let $\Phi(\sfM)$ be the factor graph obtained in this way. As we would expect, there may not be a way to recover the \MN\ from the resulting factor graph. %Moreover, this process does not 
	\todo{discuss conditions under which $\bbr{\sfM}\MaxEnt = \Pr_{\Phi(\sfM)}$.}
	\todo{Discuss representation of factor graph in terms of \MN.}
	
	Similarly, let $\Phi(\mathcal B)$ be representation of a Bayesian network $\mathcal B$ as a factor graph. We now verify a few facts about the relations between the semantics of these conversions.
		
%	\begin{align*}
%		\Phi( \mathcal N, \Ed, \mathcal V, \bmu ) = (\alpha, \{ \phi_{} ) \}
%	\end{align*}

	\begin{prop}
		If $\beta$ is a BN, then $\Phi(\beta)  = \Phi(\Gamma(\beta))$
	\end{prop}


	\begin{conj}\label{thm:noninj}
		$\bbr{M}\MaxEnt = \Pr_{\Phi(M)}$
	\end{conj}
	\begin{coro}\label{coro:same-dist;different-weight}
		For every distribution $\mu \in W_{\cal V}$, there exist \MNs\ $M_1$ and $M_2$ such that $\bbr{M_1} \neq \bbr{M_2}$. 
	\end{coro}
	\begin{proof}
		For any $\mu$ we can always add marginals which are already assumed, altering probability but different free weighted distributions; by \Cref{thm:noninj}, this depends only on the probability.
	\end{proof}
	
	A \MN\ clearly encodes more information than just the distribution: this is true for both Bayesian Networks and Factor Graphs as well. In both cases, this is often cast as a flaw, as this makes them poor choices as canonical descriptions of distributions, which is why so much attention is given to I-maps in \parencite{koller2009probabilistic}. However, separation from a probability distribution has not been empirically damaging. Despite being less expressive and obscuring independence relations, BNs continue to be a more popular modeling tool. The causal picture they can provide, beyond anything in the distribution, is evidently worth a lot.

%	\begin{fact}
%		\begin{enumerate}
%			\item Any sub or super-graph of a factor graph is also a factor graph, but requires renormalization (\#P-hard) to sample.
%		\end{enumerate}
%	\end{fact}
