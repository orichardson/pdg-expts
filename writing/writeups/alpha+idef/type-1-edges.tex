\documentclass{article}


\input{pdg-preamble-v1}
\setlength\parskip{1ex}

\newcommand{\CI}{\mathbin{\bot\!\!\!\bot}}
\newcommand{\Pa}{\mathop{\mathbf{Pa}}}
\newcommand{\X}{\mathcal X}

\begin{document}

\begin{defn}
    Suppose $X$ and $Y$ are variables.
    A pair $(f, d)$, where $f : \V\!X \times U \to \V Y$ and $d : \Delta U$,
    is said to be a \emph{derandomization} of a cpd $p(Y|X)$ iff, for each $x, y \in \V(X,Y)$, we have that 
    \[
        \Pr_{u\sim d} [ f(x, u) = y] = p(Y{=}y\mid X{=}x).
        \qedhere
    \]
\end{defn}

\section{Compatibility with a Set of Type-1 Edges}
\begin{defn}
    Let $\Ar 
    %= \{ \ed {L}{X_L}{Y_L} \}%
    %_{L \in \mathrm{Labels}}
    % = \{ \ed {a}{\Src a}{\Tgt a} \}_{a \in \Ar}
    $ be a collection of type-1 arcs. 
    A joint distribution $\mu(\X)$ may be ``qualitatively compatible'', or
    \emph{q-compatible}, with $\Ar$  iff
%joe0
% First, define a pair (\omega,u) to be consistent (where u is
% derandomization of all the relevant mechanisms) if for each mechanism f:
% X -> \Delta(Y), if Xω=x  and f_u(x) = y, then Yω=y.   
% That is, (\omega,u) is consistent if the values of the variables in
% \omega are as dictated by the derandomized functions in u.
% 
% A distribution \mu on \Omega is consistent with type-1 edges if there is
% a distribution \nu on U that makes all the relevant mechanisms
% independent and a distribution  p on \Omega x U such that (a) the
% support of p consists of only consistent pairs (as defined above), (b)
% the marginal of p on \Omega is \mu, and (c) the marginal of p on U is
% \nu.              
    there exist (1) a variable $U$, 
    (2) an extended distribution $\nu(\X, U)$,
    and (3) a family of 
    % derandomization functions  
    functions
    % $\mathcal F =
    $\mathcal F = 
    \{ f_a : \V\Src a \times \V U \to  \V\Tgt a\}_{a\in \Ar} $ such that
    \begin{enumerate}[label=(\alph*)]
        \item $\mu(\X) = \nu(\X)$;
        % \item  for every $a \in \Ar$, $(f_a, \nu(U))$ is a derandomization 
        % of $p\ssub a(Y|X)$ for every $a \in \Ar$;
        % of $\mu(\Tgt a | \Src a)$;
        
        \item For every $a \in \Ar$, the pair $(f_a, \nu(U))$ is a derandomization of $\mu(\Tgt a | \Src a)$.
        \item $\nu$ has support only on ``consistent pairs''
        $(\omega, u) \in \V(\X \times U)$
        % $(\omega, u) \in \V(\X \times U)$
        such that 
        % if $\Src a \omega = s$, and $\Tgt a \omega = t$, then $f_u(\omega) = t$. 
        % we have $f(\Src a \omega, u) = \Tgt a \omega$;
        % $f(\Src a \omega, u) = \Tgt a \omega$;
        $f_a(\Src a (\omega), u) = \Tgt a(\omega)$
        for every arc $a \in \Ar$;
        % \item[\color{red}(d0)]
        % % for every $a \in \Ar$, $s \in \V \Src a$, and $t \in \V\Tgt a$, 
        % {\color{red}
        % the events 
        % \[ 
        %     \Big\{ 
        %          % \overbrace{
        %          \{ u \in \V U : f_a(s,u) = t \}
        %           % }^{f_a(s) = T}
        %         ~\Big|~a \in \Ar,\, (s,t) \in \V(\Src a, \Tgt a) \Big\}
        %         % \Big\}_{a \in \Ar,\, (s,t) \in \V(\Src a, \Tgt a)}
        % \]
        % are mutually independent according to $\nu(U)$\\[1ex]
        % \texttt{(this is the original definition from the email chain, but it doesn't work, because it's only true if every edge is deterministic. 
        % Concretely, the events 
        %     $\{u : f_a(s,u) = t\}$ and $\{u : f_a(s,u) = t'\}$ are disjoint, 
        %   and hence independent only if at least one of them has proability zero)}
        % }
        % \item
        % for every joint setting $\mat x \in \V\X$ of the variables $\X$, 
        % the events
        % \[ 
        %     \Big\{ 
        %         \{ u \in \V U : f_a(\Src a \mat x, u) = \Tgt a \mat x \} 
        %         ~\Big|~a \in \Ar \Big\}
        %         % \Big\}_{a \in \Ar,\, (s,t) \in \V(\Src a, \Tgt a)}
        % \]
        % are mutually independent according to $\nu(U)$.
        \item 
        for every subset $A \subseteq \Ar$ of arcs, 
        and every choice of settings $\{ (s_a, t_a) \in \V(\Src a, \Tgt a) \}_{a \in A}$,
        the events
        \[ 
            \Big\{ 
                \{ u \in \V U : f_a(s_a, u) = t_a \} 
                ~\Big|~a \in \Ar \Big\}
                % \Big\}_{a \in \Ar,\, (s,t) \in \V(\Src a, \Tgt a)}
        \]        
        are mutually independent according to $\nu(U)$. 
    \end{enumerate}
    Such a triple $(U, \nu, \mathcal F)$ is said to \emph{witness} that $\mu$ is q-compatible with $\Ar$. 
\end{defn}

\begin{prop}
    A distribution $\mu(\X)$ is q-compatible with the arcs $\Ar$ corresponding to a qualitative BN $G$ iff $\mu$ satisfies the independencies of $G$. 
\end{prop}
\begin{proof}
    Consider a topological ordering $\X = (X_1, \ldots, X_n)$ of the variables such that each variable comes after its parents in the BN, and write $\Src i := \Src {X_i}$ for the parents of variable $X_i$. 
    % $\Pa X_i := \Src X_i$
    
    $(\implies)$. 
    Suppose $\mu$ satisfies the independencies of $G$, meaning that each 
    node is conditionally independent of its non-descendents given its parents. 
    Let $U$ be the variable $U_1 \times \ldots \times U_n$, where each $U_i$ takes values in $[0,1]$. 
    Next, fix any ordering 
    $x^{(1)}_i, x^{(2)}_i,  \ldots, x_i^{(m)}$ of the values of $X_i$, 
    which allows us to write
    $X_i \le x_i^{(j)}$ for the event in which $X_i$ takes a value from
        $\{ x_i^{(1)}, \ldots, x_i^{(j)}\}$. 
    Now, for $y \in \V(\Src i)$, and $u \in [0,1]$, 
    define $f_i(y, u) := x_i^{(j)}$ where $j$ is the smallest index 
    such that $\mu(X_i \le x_i^{(j)} \mid \Src i {=} y) \ge u$.
    
    Define a joint distribution $\nu(\X, U)$ by taking a uniform distribution over $U$, and extending it to $\X$ deterministically as prescribed by each $f$; concretely:
    \[
        \nu(X_1, \ldots, X_n, U_1, \ldots, U_n) := 
            \mathrm{Unif}(U_1, \ldots, U_n)
            \prod_{i = 1}^n
            \delta \! f_i (X_i \mid \Src i, U_i)
    \]
    where $\delta \! f_i (X_i \mid \Src i, U_i)$ is the degenerate distribution over $X_i$ that places all mass on the value $f_i(\Src i, U_i)$.
    
    At this point, we have (b), (c), and (d) of the q-compatibility requirement by construction. (c) is explicit already. For (b), observe that:
    \begin{align*}
        &\Pr\nolimits_{\mat u \sim \mathrm{Unif}([0,1]^n)} \Big[ f_{i}(s, \mat u) = x^{(j)}_i \Big] \\
        &= \Pr\nolimits_{u_i \sim \mathrm{Unif}([0,1])} \Big[ f_{i}(s, u_i) = x^{(j)}_i \Big] \\
        ( &= \text{size of interval on which $f_i(s, -) = x^{(j)}_i $} ) \\
        % &= \argmax_{u\in [0,1]} 
    \intertext{
        The maximum such value of $u$ is the one at the boundary where the condition $\mu(X_i \le x_i^{(j)}) \ge u$ is no longer true, i.e., $\mu(X_i \le x_i^{(j)}) = u$, 
        while the minimum such value of $u$ is the one where the condition first becomes true for $j-1$, so that $j$ is no longer the smallest index satisfying the condition. Continuing with our derivation, the quantity above equals:
    }
        &= \mu(X_i \le x_i^{(j)} \mid \Src i = y) - \mu(X_i \le x_i^{(j-1)} \mid \Src i = y) \\
        &= \mu(X_i = X_i^{(j)} \mid \Src i = y),
    \end{align*}
    which is condition (b). 
    Meanwhile, (d) follows from the fact that each event that determines a mechanism is determined by an independent variable $U_i$. 
    
    It remains only to prove that the marginal of $\nu$ on $\X$ is $\mu(\X)$. 
    Here is where we rely on the fact that $\mu$ satisfies the independencies of $G$, which means that we can factor $\mu(\X)$ as 
    % \begin{align*}
    $
        \mu(\X) = \prod_{i=1}^n \mu(X_i \mid \Src i).
    $
    % \end{align*}
    But because of $(b)$ and $(d)$, we know that by margalizing out $U$, we have
    \begin{align*}
        \nu(\X) 
            % = \Ex_{ \mat u \sim \mathrm{Unif}([0,1]^n)}
            = \int_{\mat u \in [0,1]^n} \prod_{i = 1}^n  \delta \! f_i (X_i \mid \Src i, \mat u_i) \,\mathrm{d} \mat u
            &= \prod_{i = 1}^n  \int_{u \in [0,1]} \delta \! f_i (X_i \mid \Src i, u) \\
            &= \prod_{i = 1}^n  \Pr_{u \sim \mathrm{Unif}([0,1])} [ f_i (\Src i, u) = X_i] \\
            &= \prod_{i = 1}^n  \mu(X_i \mid \Src i)
            = \mu(\X).
    \end{align*}
    Therefore, if $\mu$ satisfies the independencies of $G$, then it is q-compatible with $\Ar$. 
    
    \medskip
    
    $(\impliedby)$. 
    Now for the reverse direction. Suppose that we have some $(U, \nu, \mathcal F)$ witnessing that $\mu$ is q-compatible with $\Ar$. 
    We now want to show that $\mu$ satisfies the independencies of $G$. 
    
    First, we claim that if $(U, \nu, \mathcal F)$ witnesses that $\mu$ is q-compatible with $\Ar$, then the setting $\omega \in \V\!\X$ of all variables is a deterministic function of the variable $U$ in $\nu$. This follows from condition (c) and the fact that the BN is acyclic, by induction.
    % Starting with $X_1$, which has no parents (so $S_1=\emptyset$), 
    % (c) states that $\nu$ only has support on $(u, \omega)$ such that in particular,
    % $f_1(u) = X_1(\omega)$.
    Suppose that in $\nu$, the first $k$ variables $X_1, \ldots, X_k$, for $k < n$, are determined by the value of $U$.
    Now, conditon (c) says in particular that if $(\omega, u)$ is in the support of $\nu$, then $f_{k+1}(\Src {k+1}(\omega), u) = X_{k+1}(\omega)$, so $X_{k+1}$ is a function of $u$ and $\Src {k+1}$.
    Because the varaibles are sorted in topological order, the parent variables $\Src {k+1}$ are a subset of the variables $\{X_1, \ldots, X_n\}$, and so the value of $\Src {k+1}(\omega)$ is determined by $u$.
    Therefore, the value of $X_{k+1}$ is determined by $u$. 
    The base case of $k=0$ holds vacuously---so by induction, the values of all variables $\X$ are determined by $U$ in $\nu$. 
    
    Let $\mat f: \V U \to \V \!\X$ be the function which determines the value of all variables given a value of $U$. 
    For any $\omega \in \V\!\X$, we can apply condition 
    
    (d) in the case where $s_i := \Src i(\omega)$ and $t_i := \Tgt i(\omega)$ to get that
    
    % Letting $\nu_U := \nu(U)$ denote the marginal distribution on $\nu$, 
    % Now condition (d) states that
    \begin{align*}
        \nu(\X = \omega)
        &= \nu(\mat f(U) = \omega)  \\
        &= \nu\Big( \bigcap_{i=1}^n \{ u : f_i(\Src i(\omega), u) = X_i(\omega) \} \Big)\\
        &= \prod_{i = 1}^n \nu\Big(\{ u : f_i(\Src i(\omega), u) = X_i(\omega) \} \Big) 
            &\text{by (d)}\\
        &= \prod_{i = 1}^n \nu(X_i{=}X_i(\omega) \mid \Src i {=} \Src i(\omega)) 
            &\text{by (b)}
    \end{align*}
    So  $\nu(\X) = \prod_{i=1}^n \nu(X_i \mid \Src i)$.
    
    
    Therefore $\nu(\X) = \mu(\X)$ factors as required by the BN $G$, meaning that $\mu$ has the independencies specified by $G$. (See Koller \& Friedman Thm 3.2, for instance.)
\end{proof}



\begin{prop} % \mu compatible with  [  --> X <---  ] iff \mu det
    If $\Ar = \{ \ed1{}X, ~ \ed2{}X \}$ consists of just two arcs pointing to a single variable $X$, 
    then a distribution $\mu(X)$ is q-compatible with $\Ar$ iff $\mu = \delta_x$ places all mass on a single value of $x$. 
\end{prop}
\begin{proof}
    Suppose a distribution $\mu(X)$ is q-compatible with $\Ar$. Then there must be a variable $U$, a distribution $\nu(X,U)$ whose marginal $\nu(X)$ equals $\mu(X)$, and derandomizations $f_1, f_2 : \V U \to \V X$, such that $f_1(u) = x = f_2(u)$ for every $(x,u)$ with $\nu(x,u) > 0$.
    % Thus, if $\mu(x) > 0$, then 
    % Thus for every $u$ with $\nu(u) > 0$, it must be the case that $f_1(u) = f_2(u)$.
    So, for every $x \in \V X$ with $\mu(x) > 0$, the events $f^{-1}_1(x)$ and $f_2^{-1}(x)$ have the same probability, which is also the probability of their intersection, which we will call $p$.
    Therefore, the final condition of mutual independence reads
    \[
        p = \nu(\{ u : f_1(u) {=} x, f_2(u) {=} x\}) = \nu(\{u : f_1(u) {=} x\})\nu(\{u : f_2(u) {=} x\}) = p^2,
    \]
    telling us that that $p \in \{0,1\}$. Finally we note that each of these events corresponds precisely with settings of $u$ that bring about $X=x$, so $\mu(X{=}x) = p \in \{0,1\}$. So indeed, $\mu$ is deterministic. 
    % and also $f_1^{-1}(x)$ and $f_2^{-1}(x)$ are independent according to $\nu(U)$. 
    %
    Conversely, if $\mu(X) = \delta_x(X)$, then a choice of $U = X$ and $f_1 = f_2 = \mathrm{id}_X$ witnesses q-compatibility with $\Ar$. 
\end{proof}


\begin{prop}
    Consider $\Ed = \{ \ed 1{}{\!X},~ \ed2{Y\!}{\!X} \}$.
    A distribution $\mu$ is q-compatible with $\Ed$ iff
    % \[
    %     X \underset\mu\CI X \mid Y \quad\iff\quad \text{$X$ is a function of $Y$}
    %     \quad\iff\quad \H_\mu(X|Y) = 0
    %     \qedhere
    % \] 
    $X$ is a function of $Y$ in $\mu$.
\end{prop}
\begin{proof}
    We start with the easy direction.  Suppose that $\mu(X,Y) = \mu(Y) \delta_{g(y)}(X)$, for some function $g : \V Y \to \V\! X$. 
    Let $U := Y$, and derandomize by
    \[
        f_1(u) := g(u); \qquad\qquad
        f_2(u,y) := g(y).
    \]
    It is easy to check that (b) $f_1$ and $f_2$ are indeed derandomizations of $\mu(X)$ and $\mu(X|Y)$, and that (a) the extended distribution 
    $\nu(X,Y,U) = \mu(U) \delta \mathrm{id} (Y|U)  \delta g(X|Y)$
    marginalizes to $\mu(X,Y)$ as desired.
    Consistency (c) holds by construction.
    The only interesting part  is independence (d). 
    Is it true that for every $x' \in \V X$, and $(x,y) \in \V(X,Y)$, that the events
    \[
        \{ u \in \V Y : f_1(u) = g(u) = x' \}
        \qquad\text{and}\qquad
        \{ u \in \V Y : f_2(u,y) = g(y) = x\}
    \]
    are independent? It is, because the latter event consists of all values of $U$, and so has probability 1, and hence is independent of the former (and of every event, for that matter). 
    
    Now for the reverse direction. Suppose that $(U, \nu, \mathcal F)$ witnesses that $\mu$ is q-compatible with $\{ \ed 1{}{\!X},~ \ed2{Y\!}{\!X} \}$. 
    Want to show that $X$ is a function of $Y$ in $\mu$.
    
    We have $\mu(X|Y) = \nu(X|Y) = f_2(Y,U).$
    At the same time, $\mu(X) = \nu(X) = f_1(U)$. 
    Condition (d) says, in particular, that the events
    \[
        \{ u : f_1(u) = x \} \qquad\text{and}\qquad
        \{ u : f_2(u, y) = x\}
    \]
    are independent. But consistency (c), if $\nu(u,x,y)>0$ then $f_1(u) = x = f_2(u,y)$.
    So 
    % \[
    $
        \{ u : f_1(u) = x \land \nu(u)>0\} \subseteq \{u : f_2(u,y) = x \land \nu(u)> 0\}
    $.
    Since the fomer is contained within the latter, the only way for them to be independent is if the latter occurs with probability 1 (or the former with probability zero). 
    As a result, if $\mu(x,y) > 0$, then $\mu(y|x) = \Pr_{u \sim \nu(U)}[ f_2(u,y) = x] = 1$, meaning that there is exactly one such value of $y$ for each $x$, and so $Y$ is a function of $X$ in $\mu$. 
    % \]
    % and therefore if $f_1(u) = x$, then $f_2(u,y) = x$. 
\end{proof}

    
    % 
    % \item By the same logic as the first half above, $\mu$ is q1/q2-compatible with $\{ \to\! X, ~Y \!\gets \}$ iff
    %     % $\mu(X,Y) = \mu(X)\mu(Y)$.                
    %     $X \CI_\mu Y$. 
    % 
    % Next, $\mu$ is q3-compatible with these edges if it is the marginal on $X,Y$ of some $\nu(X,Y,U_1, U_2) = \nu(U_1)\nu(U_2) \nu(X,Y|U_1,U_2)$ such that $X$ is a function of $U_1$,  $Y$ is a function of $U_2$, $U_1 \CI Y \mid X$, and $U_2 \CI X \mid Y$. 
    % The fact that $U_1$ and $U_2$ are independent means $X = f(U_1)$ and $Y = g(U_2)$ are independent, and the last two conditions can be easily satisfied in a way that does not place any constraints on the marginal $\nu(X,Y) = \mu$. 
    % So again q3-compatibility picks out the same set of distributions.
    % 
    % \item Generalizing the first example, 
    % $\mu$ is q1/q2-compatible with 
    % $\Ed = \{ \ed1{X\!}{\!Y}, ~ \ed2{X\!}{\!Y} \}$ 
    % % $\Ed = [  ] 
    % consisting of two parallel edges iff
    % \begin{align*}
    %     Y \underset\mu\CI Y \mid X \qquad
    %     &\iff\qquad \mu(Y, Y, X) \mu(X) = \mu(Y, X)\mu(Y,X)
    %     % \\&\iff\qquad \mu(X) = \mu(Y,X) \text{ or } \mu(X,Y) = 0
    %     \\&\iff\qquad \mu(X,Y) \in \{\mu(X), 0\}
    %     \\&\iff\qquad\text{the value of $Y$ is fully determined by $X$ in $\mu$}
    %     \\&\iff\qquad \H_{\mu}(Y|X) = 0            
    %     \qedhere
    % \end{align*}
% 
% 
% \begin{example}
%     Consider $\Ed = \{ \ed 1{}{\!X},~ \ed2{Y\!}{\!X} \}$.
%     A distribution $\mu$ is q-compatible with $\Ed$ iff
%     % \[
%     %     X \underset\mu\CI X \mid Y \quad\iff\quad \text{$X$ is a function of $Y$}
%     %     \quad\iff\quad \H_\mu(X|Y) = 0
%     %     \qedhere
%     % \] 
% 
%     \TODO
% \end{example}
% 
% \begin{remark}
%     Question: Does Q-compatibility distinguish between the PDGs
%     \vspace{-2ex}
%     \[
%         \begin{tikzpicture}[center base]
%             \node[dpad0] (X) {$X$};
%             \node[dpad0,right=0.6 of X] (Y) {$Y$};
%             \draw[arr2] (X) -- (Y);
%             \draw[arr2, <-] (Y) -- ++(1, 0);
%         \end{tikzpicture}
%         \quad~ \text{and}\qquad
%         \begin{tikzpicture}[center base]
%             \node[dpad0] (X) {$X$};
%             \node[dpad0,right=0.6 of X] (Y) {$Y$};
%             \draw[arr2] (X) to[bend left] (Y);
%             \draw[arr2] (X) to[bend right] (Y);
%         \end{tikzpicture}
%         ~.
%     \]
% \end{remark}



\clearpage
\section{Relationship to IDef}

\textbf{A Betting Game.} 
I think $Y$ can be predicted from $X$ alone (to some degree, at least).
How much should I bet that this is the case?

If I 

\begin{conj}
    A distribution $\mu$ is q-compatible with $\Ar$
     iff $\IDef_{\Ar}(\mu) \le 0$.
     % for all $A \subset \Ar$, 
    % $\IDef{A}(\mu) \le 0$    
\end{conj}

\begin{conj}
    A distribution $\mu$ is qualitatively compatible with the edges of an unweighted PDG $\dg N$ iff 
    % $\IDef{\dg N}(\mu) \succeq 0$. 
    the information profile vector of $\mu$ dominates the information profile vector of $\mu[\Ed]$. 
\end{conj}


\appendix
\clearpage
\section{Alternate Definitions of Compatibility with Type-1 Arcs}

\begin{defn}
    Let $\Ar 
    %= \{ \ed {L}{X_L}{Y_L} \}%
    %_{L \in \mathrm{Labels}}
    $ be a collection of type-1 arcs. 
    A joint distribution $\mu(\X)$ may be ``qualitatively compatible'' with $\Ar$ 
    in a couple of different senses; concretely, $\mu$ is said to be:
    \begin{enumerate}[label=\textbullet~\textit{q\arabic*-compatible} with $\Ar$ iff, labelwidth=-10em]
        % \item 
        \item for every pair of distinct edges $a_1, a_2 \in \Ar$, 
        we have that
        \[
            \Tgt {a_1} \underset\mu\CI \Tgt {a_2} ~\Big|~ \Src {a_1} \cup \Src {a_2}
        \]
        \item for every pair of disjoint subsets of edges $A_1, A_2 \subset \Ar$, 
        we have that
        \[
            \Tgt {A_1} \underset\mu\CI \Tgt {A_2} ~\Big|~ \Src {A_1} \cup \Src {A_2}
        \]
        \item 
         % for every pair of disjoint subsets of edges $E_1, E_2 \subset \Ed$, 
         % for every subset of edges $E \subset \Ed$, 
         $\mu(\X)$ can be written as the marginal of an extended distribution $\nu(\X, \mat U)$ in which $\mat U = \{ U_a : a \in \Ar\}$, thought of as a collection of exogenous sources of randomness, contains a distinct variable $U_a$ for each arc $a$, and
         \begin{enumerate}[label=(\alph*)]
            \item $\nu(\X) = \mu(\X)$;
            \item $\nu(\mat U) = \prod_{a \in \Ar} \nu(U_a)$,
                i.e., the exogenous variables are all independent;
            \item $\H_\nu(\Tgt a \mid \Src a,\,U_a) = 0$,
                i.e., each edge target is a deterministic function of its source and 
                    associated exogenous randomness;
            \item $U_a$ and $\Src a$ are independent in $\nu$;
            \item $U_a$ is independent of $\mat N$ given $\Src a$ and $\Tgt a$. 
        \end{enumerate}
        
        \item % factorization
        $ 
            \mu(\X) \propto \smash{\prod_{a \in \Ar}}\, \mu( \Tgt a \mid \Src a)$, 
            i.e., $\mu$ factors along its edges. 
        Note that this obviously gives us the independencies we're looking for in the case of a Bayesian Network. 

%         \item 
% %joe0
% % First, define a pair (\omega,u) to be consistent (where u is
% % derandomization of all the relevant mechanisms) if for each mechanism f:
% % X -> \Delta(Y), if Xω=x  and f_u(x) = y, then Yω=y.   
% % That is, (\omega,u) is consistent if the values of the variables in
% % \omega are as dictated by the derandomized functions in u.
% % 
% % A distribution \mu on \Omega is consistent with type-1 edges if there is
% % a distribution \nu on U that makes all the relevant mechanisms
% % independent and a distribution  p on \Omega x U such that (a) the
% % support of p consists of only consistent pairs (as defined above), (b)
% % the marginal of p on \Omega is \mu, and (c) the marginal of p on U is
% % \nu.  
% 
%             % $\mu(\mat N)$ can be written as the marginal of an extended distribution $\nu(\mat N, U)$, where $U$ is a variable that ``de-randomizes'' every edge.
%         there exists a variable $U$ and
%         a extended distribution $\nu(\X, U)$ and
%         a family of functions  
%         $\{ f_a : \V\Src a \times \V U \to  \V\Tgt a\}_{a\in \Ar} $ such that
%         \begin{enumerate}[label=(\alph*)]
%             \item $\mu(\X) = \nu(\X)$;
%             \item $(f_a, \nu(U))$ is a derandomization 
%             % of $p\ssub a(Y|X)$ for every $a \in \Ar$;
%             of $\mu(\Tgt a | \Src a)$ for every $a \in \Ar$;
%             \item $\nu$ has support only on ``consistent pairs'' $(\omega, u) \in \V(\X \times U)$
%             such that, for every edge $a \in \Ar$, 
%             % if $\Src a \omega = s$, and $\Tgt a \omega = t$, then $f_u(\omega) = t$. 
%             we have $f(\Src a \omega, u) = \Tgt a \omega$;
%             \item
%             % for every $a \in \Ar$, $s \in \V \Src a$, and $t \in \V\Tgt a$, 
%             the events 
%             \[ 
%                 \Big\{ \{ u \in \V U : f_a(s,u) = t \} 
%                     ~\Big|~a \in \Ar,\, (s,t) \in \V(\Src a, \Tgt a) \Big\}
%                     % \Big\}_{a \in \Ar,\, (s,t) \in \V(\Src a, \Tgt a)}
%             \]
%             are mutually independent according to $\nu(U)$. 
%         \end{enumerate}

    \end{enumerate}
\end{defn}

% Note that q4-compatibility .


% \begin{claim}
%     \begin{enumerate}
%         \item $\mu$ is q1-compatible with $\Ed$ iff, for every distinct pair of edges in $\Ed$, there exist independent mechanisms along them in $\mu$.
%         % \item $\mu$ is q1-compatible with $\Ed$ iff, for every disjoint pair of subsets of edges in $\Ed$, $\mu$ admits independent mechanisms along the  both.
%     \end{enumerate}
% \end{claim}

\begin{example}
    \begin{enumerate}[label=\textbf{(\alph*)}]
    \item Suppose $\Ed = \{ \ed1{}X, ~ \ed2{}X \}$ consists of just two edges pointing to $X$.
        Since there is only one pair of distinct edges edges,
        $\mu$ is q1-compatible with $\Ed$ iff 
        \begin{align*}
            X \underset\mu\CI X \qquad\iff\qquad \mu(X) = \delta_x \text{ for some }x \in \V(X),
        \end{align*}
        since the only way for a random variable to be independent of itself is if it is deterministic. 
        Since there are only two edges, the criteria for q2-compatibility is the same in this example.
        
        A distirbution is q3-compatible with $\mu$ iff there is some $\nu(X, U_1, U_2) = \nu(U_1)\nu(U_2) \nu(X|U_1,U_2)$ such that $\mu(X) = \nu(X)$, and $X$ is determined by $U_1$ and also by $U_2$. But the only way this is possible is again if $X$ is deterministic. So the q3-compatible distributions here are again the same.
        
    \item By the same logic as the first half above, $\mu$ is q1/q2-compatible with $\{ \to\! X, ~Y \!\gets \}$ iff
        % $\mu(X,Y) = \mu(X)\mu(Y)$.                
        $X \CI_\mu Y$. 
        
    Next, $\mu$ is q3-compatible with these edges if it is the marginal on $X,Y$ of some $\nu(X,Y,U_1, U_2) = \nu(U_1)\nu(U_2) \nu(X,Y|U_1,U_2)$ such that $X$ is a function of $U_1$,  $Y$ is a function of $U_2$, $U_1 \CI Y \mid X$, and $U_2 \CI X \mid Y$. 
    The fact that $U_1$ and $U_2$ are independent means $X = f(U_1)$ and $Y = g(U_2)$ are independent, and the last two conditions can be easily satisfied in a way that does not place any constraints on the marginal $\nu(X,Y) = \mu$. 
    So again q3-compatibility picks out the same set of distributions.

    \item Generalizing the first example, 
    $\mu$ is q1/q2-compatible with 
    $\Ed = \{ \ed1{X\!}{\!Y}, ~ \ed2{X\!}{\!Y} \}$ 
    % $\Ed = [  ] 
    consisting of two parallel edges iff
    \begin{align*}
        Y \underset\mu\CI Y \mid X \qquad
        &\iff\qquad \mu(Y, Y, X) \mu(X) = \mu(Y, X)\mu(Y,X)
        % \\&\iff\qquad \mu(X) = \mu(Y,X) \text{ or } \mu(X,Y) = 0
        \\&\iff\qquad \mu(X,Y) \in \{\mu(X), 0\}
        \\&\iff\qquad\text{the value of $Y$ is fully determined by $X$ in $\mu$}
        \\&\iff\qquad \H_{\mu}(Y|X) = 0            
        \qedhere
    \end{align*}
    \end{enumerate}
\end{example}


\begin{example}
    Consider $\Ed = \{ \ed 1{}{\!X},~ \ed2{Y\!}{\!X} \}$.
    A distribution $\mu$ is q1/q2-compatible with $\Ed$ iff
    \[
        X \underset\mu\CI X \mid Y \quad\iff\quad \text{$X$ is a function of $Y$}
        \quad\iff\quad \H_\mu(X|Y) = 0
        \qedhere
    \] 
\end{example}


% Now we'll focus on q5-compatibility.
% \begin{example}
% $\mu$ is q5-compatible with:
% \begin{enumerate}
%     \item the empty set of edges, iff $\mu(\mat N) \le 1$ which is true for all $\mu$. So all $\mu$ are compatible with it.
% 
%     \item No distributions 
% \end{enumerate}
% \end{example}


\begin{remark}
    From the above, we can see that neither q1 nor q2 compatibility distinguishes between the qualitative PDGs
    \vspace{-2ex}
    \[
        \begin{tikzpicture}[center base]
            \node[dpad0] (X) {$X$};
            \node[dpad0,right=0.6 of X] (Y) {$Y$};
            \draw[arr2] (X) -- (Y);
            \draw[arr2, <-] (Y) -- ++(1, 0);
        \end{tikzpicture}
        \quad~ \text{and}\qquad
        \begin{tikzpicture}[center base]
            \node[dpad0] (X) {$X$};
            \node[dpad0,right=0.6 of X] (Y) {$Y$};
            \draw[arr2] (X) to[bend left] (Y);
            \draw[arr2] (X) to[bend right] (Y);
        \end{tikzpicture}
        ~.
    \]
\end{remark}

% Next, we'll see two examples which separate q1- and q2-compatibility.
Next, we'll explore some issues with our definitions, and provide some examples that separate them from one another.

\begin{example}
    Consider the distribution $\mu(X,Y,Z)$, in which $X$ and $Y$ represent independent fair coin tosses, and $Z := X \oplus Y$.
    In this distribution, every pair of variables is independent, but not when conditioned on the value of the third.
    
    We claim that $\mu$ is q1-compatible with $\Ed = \{ \ed1{}X, ~ \ed2{}Y, ~ \ed3{}Z \}$---to see this, simply note that every pair of targets is independent. This is strange, because these edges suggest that the mechanisms defining $X$ $Y$ and $Z$ are all accounted for and independent. 
    
    However, $\mu$ is not q2-compatible with $\Ed$, because, for instance,
    $\Src {\{1,2\}} = \{X,Y\}$ are not independent of $Z = \Src {\{3\}}$ in $\mu$.
    It is also not q3-compatible with $\Ed$, because each variable would need to be a function of its associated exogenous variable, which factor as an independent product of three distributions. 
\end{example}

% \begin{example}
%     A joint distribution $\mu$ is  q-compatible with the edges of a BN iff
%     \begin{align*}
% 
%     \end{align*}
% \end{example}
\begin{prop}
    A joint distribution $\mu$ is q1-compatible with the edges corresponding to the structure of qualitative BN $\mathcal G$%
        \footnote{that is, the edges of the PDG $\PDGof{\mathcal B}$ for a BN $\mathcal B$}
    iff it satisfies the independencies of $\mathcal G$.
            % {\color{red} False!}
\end{prop}
\begin{proof}
    % {\color{red} False!}
    $(\implies)$. Suppose that $\mu$ satisfies the independencies of $\mathcal B$.
    Recall that in a BN structure, there is a 1-1 correspondence between hyper-edges $\Ed$ of $\cal B$ and the variables of $\cal B$. 
    So, let $X,Y$ be two variables of $\cal B$.
    
    To show that $\mu$ is q-compatible with $\Ed$, it suffices to show that 
    \[ X \underset\mu\CI  Y ~\Big|~ \Pa( X) \cup \Pa( Y)
        % \qquad\text{---which we do in the appendix}
        . \]
    % By RaU Thm 4.4.4 (CIRV3), it suffices to show
    % \[ \X \underset\mu\CI \mat Y \cup \Pa(\mat Y) ~\Big|~ \Pa(\X) \]
    This can be proved by appeal to d-separation. 
    Suppose, for contradiction, that $X$ and $Y$ are not d-separated given $\Pa( X)$ and $\Pa(Y)$,
     % i.e., there are variables $X \in \ X$ and $Y \in \mat Y$ that are d-connected given $\Pa(\X)$ and $\Pa(\mat Y)$.
    i.e., they are d-connected.
    By definition, this means that there is an undirected path (of edges of $\cal B$) that (1) cannot include parents of $X$ or $Y$ and (2) can only include head-to-head connections of directed edges $\cdots \to Z\gets \cdots$ at those nodes $Z$ which have a parent of $X$ or $Y$ descendent. 
    
    Now, because this path includes neither any parents of $X$ nor $Y$, the edges at the ends of the path must point inwards; the directions of the first and last edges must be: $X \to \cdots \gets Y$. 
    Such a path must necessarily have a head-to-head connection somewhere;
    %---let's call it $Z$---
    let's call $Z_1$ the node closest to $X$ at which this occurs, and analogously, let's call $Z_2$ the closest such node to $Y$.
    By the criteria for d-separatedness, every such node must have a parent of $X$ or $Y$ as a descendent (which we'll call $W_1$ and $W_2$ respectively, for $Z_1$ and $Z_2$). 
    % Without loss of generality, suppose it's a parent of $X$. 
    But this contradicts the fact that $\cal B$ is an acyclic graph! 
    
    Concretely, it must be the case that $W_1$ is not a parent of $X$ (so it is a parent of $Y$), and $W_2$ is not a parent of $Y$ (so it is a parent of $X$). 
    Because if $W_1$ were a parent of $X$, we would have a directed cycle 
    $W_1 \to X \to\cdots\to Z_1 \to \cdots \to W_1,$ 
    and if $W_2$ were a parent of $Y$, we would analogously have the directed cycle 
    $W_2 \to Y \to\cdots\to Z_2 \to \cdots\to W_2$. 
    But we're still in a bind; the only way to prevent this was to have edges $W_2 \to X$ and $W_1 \to Y$, creating the larger directed cycle
    \[
        W_2 \to X \to\!\cdots\!\to Z_1 \to\!\cdots\!\to W_1 \to Y \to\!\cdots\!\to Z_2 \to\!\cdots\!\to W_2.
    \]
    
    % Suppose that there is an undirected path from some $X \in \X$ to some $Y \in \mat Y$. Then

    
            
    $(\impliedby)$.
    Suppose that $\mu$ is 
    
    \TODO
    
\end{proof}

The analogous statement is not true for q2-compatibility.

\begin{prop}
    % There are distributions compatible with a
    It's not the case that every distribution satisfying the independencies of
    a qualitative BN $\cal B$ is also q2-compatible with the edges of $\PDGof{\cal B}$.
\end{prop}
\begin{proof}
    Counter-example:
    \begin{center}
    \begin{tikzcd}[column sep=1em,row sep=1.5ex]
        X_1 \to \cdots \ar[r] & Z \ar[d] & \ar[l] \cdots \gets Y \\
        & \vdots \ar[d] & \\
        X_2 & \ar[l] W
    \end{tikzcd}
    \end{center}
    % In the above BN, it's not the case that
    The above BN does not model the independence
    \(
        \{X_1, X_2\} \CI_{\cal B} Y ~\big|~ W.
    \)
    % But this independence is of the form 
\end{proof}

\end{document}
