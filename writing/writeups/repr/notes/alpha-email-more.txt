Hi Joe,

On Wed, May 6, 2020 at 6:39 PM Joe Halpern <halpern@cs.cornell.edu> wrote:
Hi Oliver,

Again, this seems like a small step forward, followed by two large steps 
back.  I'm afraid we're not converging.  After reading your email, here 
is where I stand:  At this point I feel that I have two intuitions for 
\alpha associated with the edge from X to Y: one is that it represents 
confidence the cpt correctly represents \Pr(Y|do(X)); the second is that 
it says that Y is causally independent of all variables other than X.  I 
can't tell which you want. 
I think with a minor tweak and elaboration on the first intuition, the two become equivalent. 
The first tweak is that I mean the "true" 
Claim 1: 

I thought we discussed the second 
interpretation at one point and rejected it.
I don't think so, though my explanation for why I wanted it only held for simple example PDGs. I also recall having mispackaged some related (and still useful) intuitions.  Moreover,  I'm not happy 
with the second intuition, since it seems counter to the spirit of PDGs: 
the edge from X to Y should tell you about a positive connections 
between X and Y, and not that other connections don't hold.

I think here the distinction is artificial, and it is just as natural to view it as a positive connection.
If I say that setting X determines Y (no matter what the context is), that feels like a positive relationship between X and Y.  Nothing keeps me from then also saying that some other variable Z determines Y, independent of the context. The two statements may be inconsistent  (although these to alone are not: for instance, X and Z might be different representations of the same variable that Y is a deterministic function of). 
Note that the \betas behave in exactly the same way.  If we say the conditional marginal on Y given X is a cpt p1, and the conditional marginal on Y given Z is a cpt p2 --- the result could well be inconsistent (e.g., if the two cpts have disjoint support). More importantly, setting a value of \beta can be seen as a negative statement about other variables: by restricting to distributions that have the cpt p1, you have also implicitly stated something negative about possible relationships between Y with other variables, and Z in particular. For example, the mean of Y must be a convex combination of the the means of the rows in p1, and also a convex combination of the means of the rows of p2; thus the convex hulls of the means of the rows must intersect.
In any case, please do tell me which intution (if either) is what you 
had in mind.   Please do *not* introduce new intuitions at this point. Your email also had a bunch of other stuff that strikes me as yet more 
directions.  As seems to be invariably the case when you go off in new 
diretions, I don't understand that at all, nor how it relates to my 
intuitions.

Understood, no more new intuitions. It's scary to hear this now because I had thought everything in the last email was an expansion of something we'd already discussed at least twice before. Some more details inline:

On 5/6/20 2:38 PM, Oliver Richardson wrote:
> Hi Joe,
>
> First, some common context that will make the inline responses you 
> have requested easier. In the following, let L be an edge X -> Y, and 
> \mu be a candidate joint distribution.
>
> Recall that I had 2 formulations of the semantics. In formulation 1, 
> \alpha_L scales the term H_\mu( Y | X), and in formulation 2, \alpha 
> scales the term  E[ H( p_L(X)) ].

Sorry; I don't find this helpful as far as intuition goes.  What is the 
intuition for scaling these particular terms?  Why is entropy relevant.  
That said, *don't* answer these questions.  They won't get me where I'm 
hoping to go.

Ahh I was just just trying to provide a roadmap and connect to other things I've said. The intuition is in the paragraphs that follow. > Recall also that the two are equivalent when \mu is consistent with 
> the cpt p_L. I have become increasingly partial to formulation 1 over 
> the last few months and most of the intuition that I have given is in 
> reference to formulation 1.  I think the intuition for formulation 2 
> breaks down in some cases.
>
> In both cases, \beta is the degree to which the cpt associated with L 
> holds observationally, and the \alpha controls a correction term which 
> makes it causal in addition
You lost me.  Where did the correction term come from?  I don't believe 
that I've heard of it before.  This seems to be yet another novel 
path.  
It's not! I've said this a lot, including in multiple exchanges in the text and content of the submission draft.  In any case, how would controlling a correction term make it 
causal?  Again, do *not* answer these questions.

> (if this is the correct causal equation, then certainly it will also 
> be the correct observational cpt).  Let me now interpret the 
> distinction between the two formulations of \alpha in terms of your 
> framing.
> *
> *
> *Formulation 2: *\alpha is your confidence that the /supplied cpt/ 
> holds causally, with the assumption that the supplied cpt holds 
> observationally.
I don't understand that.  Why is the fact that the supplied cpt holds 
observationally relevant?

"Holds causally" implies "holds observationally". (I define "holds causally" below.)For it to hold causally,  we would need it to also hold observationally; it's then reasonable to start with the latter and see what extra is required to get the former. 
> In a very weak sense, \alpha is independent \beta (by making this 
> assumption, we don't need to know what the actual value of \beta is to 
> compute \alpha), but for this formulation, the effect of \alpha is 
> best interpreted after you already know \beta, and in this sense, the 
> values are not independent.
>
> *Formulation 1:* \alpha is your confidence that /some cpt/ for this 
> edge holds causally.

What would it mean for a cpt to hold causally?  I would assume that it 
means that it gives the right probabilities for ePr(Y=y|do(X=x)).  If 
that's right, how could there not be some cpt that holds causally?  If 
that's not right, you have to explain what it means.  I'm lost.

Right, this is important. 
Less formal: A cpt p : X->Y holds causally, if the distribution on Y is equal to p(x), regardless of any additional context or interventions not on Y.
More formal:  the cpt X->Y holds causally if for any imaginable intervention Z=z (i.e., setting of variables that occurs with nonzero probability) on variables apart from Y, we have:Pr(Y | X) = Pr(Y | X, do(Z=z)). > Here \alpha and \beta are much more clearly independent. \Beta is your 
> confidence that you got the cpt correct observationally, and \alpha is 
> your confidence that the /true conditional marginal of Y given X/ ---- 
> no matter what it is, and completely independent of both \beta and the 
> given cpt --- happens to hold causally.

What you've just said now is *completely* different from what you said 
above.  First you said that alpha represents your belief there's some 
cpt that holds causally.  Now you said it represents your belief that 
that the true cpt holds causally.  
I haven't said anything at all contradictory. If some cpt holds causally, it must be the true cpt, by Claim 1 at the top of this email.  I'm totally confused.  And why 
should I care whether the true cpt holds causally?   Do *not* answer 
this question.  I don't think it will help.
>
>
>     > The information about the direction of causality is stored in the
>     > edges themselves, just as in causal BNs. Let's restrict our picture
>     > for now to just \alpha \in {0,1}. The set of edges with \alpha=1
>     are
>     > interpreted causally, and those with \alpha=0 are interpreted
>     > observationally. You choose alpha to reflect your causal picture of
>     > the world, which could be influenced by many factors, including
>     > interventions. If you've intervened on X in a controlled experiment
>     > and seen Y change, you are justified in increasing the value of
>     \alpha
>     > for X -> Y.
>     > There are of course other ways that an agent could get data to
>     inform
>     > a causal picture. Perhaps X is a concept (like energy) that you
>     > invented to explain Y (motion), and so it has \alpha = 1 by
>     > definition. Perhaps Y occurs earlier in time than X, and so you
>     know
>     > for certain that \alpha = 0.
>     >
>     I think you're missing my point here.  Suppose that we have an
>     edge from
>     Y to X.  The question is how you're interpreting the probabilities in
>     the cpt associated with the edge.   Are they interpreted as
>     \Pr(X=x|Y=y)
>     or as \Pr(X=x|do(Y=y)).  I think that you need the former
>     interpretation
>     to make sense of \beta and (as near as I can tell, but this should be
>     taken with a grain of salt) you need the latter interpretation to
>     make
>     sense of \alpha.  These interpretation lead to different numbers,
>     so you
>     have to be precise about your intended interpretation. Perhaps \beta
>     can be taken to be your confidence in the extent to which the former
>     interpretation is correct and \alpha is your confidence that the
>     latter
>     interpretation is correct. 
>
>
> This is roughly my interpretation of formulation 2.

I can see why it's vaguely related, but I find my formulation of 
plausible interest, whereas I can't see why your formulation would be of 
any interest.

They're very directly related: your value is explicitly determined by \beta and the \alpha (of formulation 2), because we must both have the cpt holding observationally, and also that it holds causally given that it holds observationally. Your parameterization  unnecessarily entangles the two values further than necessary. >
>     If that's the case, there are still
>     issues, but it would be a major step in my understanding. Some
>     issues:
>     this intuition is not consistent with some of the explanations you've
>     been giving, and it doesn't make \alpha and \beta independent (if the
>     arrows in the PDG are correctly modeling causality, then the two
>     distributions are related).  [* Please do respond to this.]
>
>
> The text at the top of this email was intended to address this 
> question. Do you agree that \alpha and \beta are independent now? Is 
> it now more consistent with other explanations I've been giving?

I'm afraid I couldn't follow the explanation at the beginning, and 
haven't got a clue of how it relates to the causal interpretation that 
you keep telling me you have.  So I can't answer your questions beyond 
saying that I'm totally lost, and I don't feel I've made any progress 
towards understanding the intuition of \alpha.  Do *not* try to explain 
this better.
>
>     > Just as I have seen you argue that the causal model itself is in
>     some
>     > sense primitive, and that the right course of action depends on the
>     > model the agent has in their head, so too do I want to make this
>     case
>     > for \alpha.
>     My concern is that not only is it a model that the agent has in
>     his her
>     head, but it's one that the PDG is not capturing at all if we
>     interpret the
>     cpts as denoting \Pr(X=x|Y=y).
>
>     > You have said it is rational to increase \beta when you see more
>     data;
>     > analogously it is rational to increase \alpha when you conduct
>     > experiments suggesting the distribution on Y can be determined by
>     > interventions on X, even controlling for other variables like Z.
>
>     This suggests that the interpretation of \alpha that I suggested
>     above
>     is correct.  If so, to repeat, we have a good basis for going
>     forward.
>     If not, I don't know what to think.
>
>     > *Set both incoming edges T -> C and (SH,S) -> C to have
>     \alpha=1/2. *
>     >
>     >     Reasonable if you don't know which is more important, and
>     this was
>     >     a cheap, fast resolution. Encodes a belief that fixing
>     either T or
>     >     (S,SH) would render the other intervention irrelevant, but
>     you're
>     >     not sure which.
>     >
>     Note that "fixing T would render (S,SH) useless" is not the same
>     as "I
>     have confidence that the table in the cpt is an accurate
>     description of
>     \Pr(T| do(SH,S)."  So it's clear that I still don't understand your
>     intuition.  So you could be saying something like
>     "\Pr(T\do(SH,S)) = \Pr(SH,S,C))".  Is that what you meant by your
>     statement?   [*Please respond to this]
>
>
> That "fixing T would render the intervention on (S,SH) irrelevant for 
> C" is the interpretation of formulation 1, whereas having confidence 
> that the table is an accurate description of the causal model is the 
> interpretation of formulation 2.
>
> I don't understand the last part of your question: " \Pr(T\do(SH,S)) = 
> \Pr(SH,S,C)) " --- the first seems to be a conditional probability on 
> T and the second a joint probability on three other variables. I don't 
> think this is an issue, but to be extra safe, I want to clarify that C 
> is the target variable for both edges in this example.
Sorry; this was a typo.  I meant to say \Pr(C|do(SH,S)) = 
\Pr(Cf|do(SH,S,T))".
>
>     > Much like a 50/50 belief about the outcome of a coin flip that has
>     > already occurred, there is no state of reality that actually
>     matches
>     > this mental state; this is primarily an expression of uncertainty
>     > (*actually the strange one for both\alphas=1 does, but ignore for
>     > now). It is reasonable because it is symmetric. As mentioned
>     before,
>     > this is appropriate in the case when you suspect that either T
>     causes
>     > C or (S,SH) causes C, but you're not sure which.  (in either
>     case, the
>     > cpts could be that T or (S,SH) are correlated). Maybe the reason
>     for
>     > this is that you have not even thought to consider a joint
>     dependence.
>
>     >
>     > /supporting data/: Intervening on anything else in the PDG (like
>     PS)
>     > does not change the value of C. For whatever reason, you are not
>     > considering a joint dependence (maybe you believe cancer has
>     precisely
>     > one cause) . No evidence of interactions between T, (S,SH). No
>     > mechanistic or temporal reason to prefer one to the other.
>     >
>     > /conflicting data: /If you were to intervene and show that changing
>     > smoking behavior influences cancer even holding tanning constant,
>     > \alpha for the link (T -> C) should decrease dramatically.
>     Conversely,
>     > intervening on T to show that (S,SH) has an effect on C even
>     fixing T,
>     > should decrease \alpha for (S,SH) -> C. Similarly, if after fixing
>     > either (S,SH) or T, C is affected by interventions on other
>     variables
>     > (e.g., PS), the corresponding value of \alpha should decrease.
>
>     OK; this seems consistent with the intuition I suggested above.
>     > /
>     > /
>     >
>     > *Leave both \alphas = 1*
>     >
>     >     Appropriate if you believe that either T or (S,SH) would be
>     >     sufficient to get the true distribution on Y, independent of any
>     >     other variables.
>     >
>
>     What does "true distribution" mean?  I suspect you're confusing
>     (or, at
>     a minimum, not being clear about) whether we're talking about the
>     conditional distribution, or the distribution that would arise after
>     interventions.   This has to be  clarified (if, as I now suspect, the
>     distinction is crucial to the difference between \alpha and \beta).
>     [*Please respond to this]
>
>
> By "true distribution", I mean the distribution that would arise after 
> interventions.
So this is not what the cpt is telling you.  (Or is it?)  Do answer this.

The cpt tells you the observational distribution. If \alpha=1, it is also the correct distribution after any set of interventions.  >
> However, we only perform interventions in proportion to their 
> observational frequency, and so there is an observational component in 
> the premise of the following.
> I'm asserting that setting both \alphas to 1 is appropriate if you 
> believe for every pair (t,(s,sh)) for which Pr(T=t,  S,SH=s,sh) > 0, that
>
> (C1) Pr(C | do(T=t)) = Pr(C | do(S,SH=s,sh)), and
As I said above, I would have thought it was \Pr(C|do(SH,S)) = 
\Pr(Cf|do(SH,S,T)).

> (C2) Pr(C | do(T=t,  S,SH=s,sh)) is a deterministic function.

What's supposed to be a deterministic function of what?  Why does it 
have to be deterministic.

C is a deterministic function of T, S, SH.   I offered an explanation further down in the original email. >
> This second condition (C2) appears because the sum of the two alphas 
> into C exceeds 1,

Why does this mean it has to be deterministic?  There's nothing in the 
intuition that I've heard so far that would suggest that.  If you think 
there is, please point out where it is.  I also don't see at all how 
this relates to any intuition that's been presented about \alpha.  
[Please do *not* answer this unless it's relevant to the two 
interpretation that I mentioned at the beginning.]

This is relevant, so don't be surprised if I bring it up again, but it is a less important consequence that we should focus on when we bring in the information profile. The intuition and relation to what I had so far was further down in the email, as I indicated in the quoted part just below. I put a lot of time into getting these descriptions just right and I feel like you comment on many things that you have not yet spent time trying to digest. 

> so it is too over-determined to admit further randomness. It might be 
> a tricky to see right away without the information theoretic lens, and 
> I have other ways of explaining this that ground my own intuition, and 
> I go further into one later in this email. You can skip over this for 
> now, but I want to make sure it's there so you don't feel like I'm 
> pulling the rug out from under you when I mention it in the future.
>
>     >     This would imply that T and (S,SH) have in common any
>     information
>     >     they share with C.
>
>     > *Give T -> C \alpha=1/10 and (SH,S) -> C  to have \alpha=9/10. *
>     >
>     >     Reasonable if you think that (S,SH) causes C, but somehow T
>     >     correlates with (S,SH).
>     >
>
>     I don't understand that, and it's inconsistent with the intuition
>     that I
>     think you've been pushing.  Correlation is not causation The fact
>     that
>     T correlates with (S,SH) should have nothing to do with the extent
>     that
>     T causes C, even if (SH,S) causes C.  It could well be that (SH,S)
>     causes C, T completely correlates (empirically) with C (correlation
>     coefficient 1), but T has no causal impact on C whatsoever. If you
>     really meant what you said, then I'm afraid that I'm completely lost
>     again. [*Please respond to this.]
>
>
> Sorry, I believe we're on the same page here, and that my original 
> description (which I quoted from before but did not fix when I 
> expanded, to keep the context) was just ambiguously worded.
>
> Here you believe with moderately high probability (0.9) that S,SH 
> causes C (regardless of T), and with low probability that T causes C 
> (regardless of S,SH). How might you be entertaining both beliefs at 
> once? And how might you think that S,SH causes C while still having a 
> cpt that says the distribution of C is not empirically independent of 
> the distribution on T? We're both suggesting the same possibility: if 
> T merely correlates with S,SH, and one but not the other causes C.
>
>
>     Set both \alphas = 0, and add a new node (T,(S,SH)) with the
>     > appropriate projections and edge from it to C with \beta=0 (so no
>     > cpt), and \alpha=1.*
>     >
>     >      Encodes a belief that you now think T and (S,SH) together
>     >     collectively determine C, in a way robust to interventions on
>     >     other variables --- but you just don't know what the joint
>     >     dependence is.
>     >
>
>     For what it's worth, this is inconsistent with the intuition for
>     \alpha
>     that your earlier examples gave.
>
>
> (I don't see this)

Your earlier intuitions did not mention robustness to interventions.
>
>     >
>     > /supporting data: /Interventions reveal C to be jointly
>     dependent on
>     > (S,SH) and T; no other variable (e.g., PS) is found to be relevant
>     > after fixing both.
>     But wouldn't this data also support giving a high alpha to the
>     edge from
>     (S,SH) to C and from T to C? 
>
>
>
> This data (that C is causally dependent on both SH and T, but no 
> others) would NOT suggest giving high \alpha to edges (S,SH) to C, or 
> T to C. For instance, the condition for having \alpha=1 on an edge T 
> -> C include among other things, that intervening on (S,SH) does not 
> affect C after you've fixed T.

So if it implies that,  I'd like to pin you down once more on what 
\alpha is saying.    At some points I thought it meant that you believed 
the probability on the cpt causally; that is, the cpt correctly 
described the effect of X on Y.  But you've also been saying frequently 
that making \alpha high also means that you believe that no other 
variables have a causal impact on Y.    So I'm confused.  Suppose that I 
have data on interventions that tells me that both X and Z have a causal 
impact on Y.  Because of this, it seems clear that I can't believe that 
that X is the only thing that affects Y, nor can Z be the only that 
effects Y.  So, given this intuition, I should have \alpha=0 both for 
the edge from X to y and the edge from Z to Y.  Is that right?  
This is correct. If not, 
why not?
Note that if it's right, then the intuition that \alpha represents your 
belief about the accuracy of the cpt viewed causally (i.e., as expressing
\Pr(Y=y|do(X=x)) is wrong, because even if the cpt captures the 
interventional probabilities perfectly, \alpha would still be 0. [Please 
do answer this.]

The cpt could capture the probabilities \Pr(Y=y | do(X=x)), but this is an averaged quantity in the abstract that can be affected by further context; we are after something stronger. In some sense, the notation is flawed: you're not just asking for the probability of Y=y given that you set X=x; you're also inserting another assumption that everything else is distributed according to Pr, and no more interventions have been performed. From a local perspective (i.e., from the point of view of someone who only ever sees a small subgraph), it is impossible to know this.  
The rest of this comment is an example scenario and/or metaphor, illustrating what is going on here and in relation to many other things I've said in the last few days. Each example ties in successively more explanations that I've been writing about.
Imagine you and I both care about the value of Y, and are trying to push it in different directions, but neither of us knows about the other. You have control of X that I'm not really thinking about, but I have control of some other variable Z that you're not thinking about. A third agent, NeurIPS reviewer #2, sees this setup and is trying to model it with a PDG.
If the review says that the edge X -> Y has \alpha=1, they are asserting you will be able to control Y (as much as it can be controlled), and more precisely, that the resulting conditional distribution of Y given X will match the observational one that was there before you intervened (regardless of whether this third agents know what the actual cpt is, which is why \alpha is independent of \beta). This will be the case no matter what I have done (unbeknownst to you) to Z, in my futile attempt to influence Y.  
Symmetrically, if the reviewer has \alpha=1 for Z -> Y, then they expect that I will not observe anything that you do to X, and the distribution on Y will exactly match the one that the true conditional distribution would predict given Y, 

A first glance might suggest that at most one of these can happen, but this is not so. If Y is equal to a constant, independent of X and Z, and the reviewer thinks that the the reason for this is because of Y's relationship to X even if Z didn't exist  (but symmetrically, if X didn't exist, Y's constancy could be causally attributed to Z for some reason) --- although they could model this equally well with any value of \alpha. If the reviewer thinks exactly one of us has the power to change Y independent of other variables, but doesn't know which, they would model this with values of \alpha < 1. In particular, if their prior says there's a 90% chance that the advisor can determine Y completely, and a 5% chance that the student could determine Y completely then they would put \alpha = 0.9 on X -> Y, and 0.05 on Z -> Y. 
We now turn to some contexts where the reviewer entertains more casual edges. If reviewer#2 is certain that Y is jointly determined by X and Z, then they would introduce the joint variable and edge {X,Z} -> Y, with \alpha = 1. If moreover, it turns out that this joint dependence was really because you had all of the power (as a particular case of joint dependence), then they could model the situation equally well with any two \alpha1 on {X+Z} -> Y and \alpha2 on {X} -> Z, such that \alpha1 + \alpha2 = 1. They could also model with \alpha1 = \alpha2 = 1, but note that this encodes beliefs that either of two separate "channels", one from X, the other from X+Z, controls Y. But if Y has randomness, where did the randomness come from? Channnel 1 or channel 2? This is another reason (in addition to the one in the previous email that was not remarked upon) why an "over-determined" If the reviewer discovers that  X and Z are actually the same variable in different representations --- that is, X causes Z and Z causes X, both with \alpha=1 --- then both of us have complete control over Y (that is if we successfully intervene). The reviewer can model this equivalently as [X <=> Z -> Y] or [Y <- X <=>Z], all with \alpha=1, but if the reviewer includes two separate links, one from X -> Y and one Z -> Y, they are again encoding the belief that there are two distinct channels that must agree on the value of Y; they therefore have implicitly encoded an assumption that Y is a deterministic function of X (or equivalently, Z). 


>
>       What data would support giving \alpha=0
>     for the links from (S,SH) to C and from T to C, and yet high
>     \alpha to
>     the edge from the new node to C?  This is a key point of
>     misunderstanding for me, so I would like your response to focus on
>     this
>     point.  [*Please respond to this.  This  is particularly important.]
>
>
> Recall the scenario in which X is chosen uniformly at random from a 
> set with 16 elements, Z is a uniformly random permutation in S_16, and 
> Y is given by the causal equation Y = Z(X). In this example, there is 
> no reason to believe that X is (even a little bit) determined after 
> fixing just one of X or Z. This is a quintessential example of a case 
> where a new edge X,Z -> Y has \alpha=1 and the others have \alpha = 0.
OK; this is like saying that X, Y, and Z can be pairwise independent, 
yet Y and Z together can determine X.
>
> The same intuition holds here. If there is evidence that changing S,SH 
> changes C even after fixing T, then you should think it unlikely that 
> the conditional marginal you have (formulation 2) is the right causal 
> equation, and also unlikely that the true, observational conditional 
> marginal on C given T (whatever it might be; formulation 1) is likely 
> to be the correct causal equation.
>
>
>     > /conflicting data: /some other variable, PS, also affects C even
>     > fixing ((S,SH),T)
>     >
>     > *Set both incoming \alphas to 0. *
>     >
>     >     Reasonable if the shattering of the belief that (S,SH)
>     determines
>     >     C now has you entertaining the possibility that something
>     entirely
>     >     different is going on In our final example with the union,
>     we set
>     >     the incoming weights to C in an analogous way.
>     >
>     >
>     > /supporting data: /Interventions on (S,SH) or T do not change C.
>     > /conflicting data: /Interventions on (S,SH) or T do change C, in
>     ways
>     > that no other links with positive values of \alpha can explain.
>     >
>     >
>     > Of course, in this example, at the moment the merge happens, we've
>     > already made the case that it's important to have a belief
>     > representation right away. We've argued that a full Bayesian
>     update is
>     > too expensive, and thinking about all of these
>     > counterfactual interventions (let alone performing them) is also
>     > prohibitively  expensive. Therefore, none of this can be used to
>     set
>     > \alpha initially, when we describe the example. We'll just get
>     another
>     > PDG. We could technically leave the values of \alpha=1 as they
>     were,
>     > but reducing both to 1/2 seems to be a much more appropriate
>     default.
>     Why? [*Please respond to this.]
>
>
> Setting both \alphas to 1/2 is an even compromise with uncertainty 
> about what actually affects Y.
> Setting both \alphas to 1 is suggesting that /both /cpts, taken 
> individually, determine Y.

Again, you seem to be interested in taking the definition \alpha is high 
on the edge from X to Y if Y is independent of all variables other than X.
This is very far from the intuition we were giving for edges in PDGs 
before.  I also think  that we've discussed that interpretation before 
and rejected it.
I'm trying to remember the examples that I had before.   What happens if 
Y is determined by tossing a die, that adding X to the outcome.  So X + 
randomness completely determines Y.  No other variable has an impact.  
And you know this.  Should the edge from X to Y have \alpha = 1? If not, 
why not?  [Please answer this.]

> This has side effects like suggesting Y has no randomness.

Why?

I explained below, and because you didn't remark on it, I don't know why you didn't buy  it. >
> To illustrate, consider the case where we've just merged two identical 
> graphs [X ->Y] (If you take issue with parallel edges, we can just 
> simulate them: consider one graph [X -> Y] and another [X <=> X' -> Y] 
> where the cpts on X <=> X' assert equality). Taking both \alphas=1/2 
> effectively gives back the original causal picture, because a 50/50 
> split between two identical causal equations is equivalent to 
> believing it with certainty. Taking taking both \alphas=1, on the 
> other hand, is like saying both causal equations are guaranteed to be 
> correct (*there's some slight of hand here, and can think harder about 
> how to make this more precise if you want). But if the two conditional 
> marginals randomness, then the outcome of sampling them might be 
> different; by modus tollens, Pr(Y | X) must not have randomness.
>
> This is a consequence of (and some intuition behind) the 
> possibly-mysterious condition (C2) I described above. By setting both 
> equal to 1/2, we've weakened both assumptions to the point that it is 
> totally consistent for Y to admit randomness on its own (Y is a 
> mixture of two identical processes).
>
>     >
>     > It seems from your other email you have one other question worth
>     > answering: why is it that \alpha, which is supposed to represent
>     > causality, is then combined with the information profile of a
>     > distribution (because it's a property of a distribution, it can't
>     > fully capture causality)? I think this is an excellent question and
>     > have an answer, but I am sleepy and don't want to overembiggen this
>     > email. We can discuss in follow-ups.
>
>     OK; I'll wait. [I do want a response to this, but I would prefer you
>     didn't address it now, unless it directly impacts one of the
>     responses
>     above.]
>     >
> I might be very wrong, but my sense is that in the dominant case I 
> understand your concerns, but am unable to articulate my resolution to 
> them because I cannot untangle it from the rest of the picture, which 
> is stored in the form of an ungodly hybrid mess of intuitions from 
> every discipline I know. Part of the reason I am eager to 
> over-formalize things is because at least then I can communicate in a 
> shared language and know I haven't left out anything.
To me formalism has to come after intuition.    If you don't have a good 
intuition for what you're trying to formalize, you get (in my opinion) a 
useless formalism.   'm afraid that I'm not prepared to work any other way.
>
> I know that neither the mixed intuitions nor the overly technical 
> descriptions are effective ways to communicate, and I actually try 
> very hard to give just single strands of the picture, but sometimes in 
> the middle of an explanation, I realize that working out all  to its 
> conclusion yields the wrong result, without controlling for the effect 
> of another thread...

Perhaps that's why I feel that I can't pin you down.
> -- Oliver

-- Joe
