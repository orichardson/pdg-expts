{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oli/Research/Joe/agent-goals/code\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/oli/Research/Joe/agent-goals/code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ../..\n",
    "%pwd\n",
    "# Should be  <BASE>/code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Experiments\n",
    "\n",
    "The idea here is to generate a lot of PDGs, perform inference on them in different ways / with different parameters, and report (1) timing in formation and (2) training curves. \n",
    "\n",
    "Inference algorithms on PDGs to pit against each other:\n",
    " * `ExpCone` on full joint distribution;\n",
    " * `ExpCone` on clique trees (automatically discovered);\n",
    " * `Pytorch` (different learning rates, optimizers: `LBFGS`; `ADAM`)\n",
    " * LIR (still needs implementation + schedule)\n",
    "\n",
    "Of course, we also need to compare against known algorithms; we can generate / use as benchmarks. \n",
    "For examples of BNs, I can use\n",
    "\n",
    "* http://constantinou.info/downloads/bayesys/bayesys_repository.pdf\n",
    "* the pgmpy example library\n",
    "* randomly generated BNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first some imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdg.pdg import PDG\n",
    "from pdg.rv import Variable as Var, Unit\n",
    "from pdg.dist import RawJointDist as RJD, CPT\n",
    "\n",
    "from random import randint, sample\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from pgmpy.models import FactorGraph\n",
    "from pgmpy.factors.discrete import DiscreteFactor\n",
    "\n",
    "from functools import reduce\n",
    "from operator import and_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make some random BNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Repeat For Factor Graphs!\n",
    "Start by making some random factor graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NVARS = 10\n",
    "NFGs = 15\n",
    "MIN_FACTORS = 2\n",
    "MAX_FACTORS = 20\n",
    "\n",
    "varis = [ Var.alph(\"X%d\"%i, randint(2,4)) for i in range(NVARS)]\n",
    "\n",
    "\n",
    "fgs = []\n",
    "pdgs = []\n",
    "\n",
    "while len(fgs) < NFGs:\n",
    "\tnfactors = randint(MIN_FACTORS, MAX_FACTORS)\n",
    "\tfg = FactorGraph()\n",
    "\tpdg = PDG()\n",
    "\n",
    "\tfor j in range(nfactors):\n",
    "\t\tselection = sample(varis, randint(1,4))\n",
    "\t\tf = np.random.rand(*[len(v) for v in selection])\n",
    "\t\tdf = DiscreteFactor(\n",
    "\t\t\t[v.name for v in selection],\n",
    "\t\t\t[len(v) for v in selection],\n",
    "\t\t\tf\n",
    "\t\t)\n",
    "\t\tfg.add_nodes_from([v.name for v in selection]) # how silly\n",
    "\t\tfg.add_factors(df)\n",
    "\t\tfg.add_edges_from([(v.name, df) for v in selection])\n",
    "\n",
    "\t\tpdg += CPT.from_matrix(Unit, reduce(and_, selection), f.reshape(1,-1)/f.sum() )\n",
    "\t\n",
    "\tif(nx.is_connected(fg)):\t\n",
    "\t\tfgs.append(fg)\n",
    "\t\tpdgs.append(pdg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pgmpy.inference import BeliefPropagation\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "fg = fgs[0]\n",
    "assert fg.check_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = nx.Graph(fg.edges())\n",
    "# [*nx.connected_components(gr)]\n",
    "# cl = list(nx.clique.find_cliques(gr))\n",
    "# list(gr.nodes())[1]\n",
    "gr2 = nx.relabel_nodes(gr, \n",
    "    { oldnode : ','.join(oldnode.variables) if hasattr(oldnode,'variables') else oldnode\n",
    "             for oldnode in gr.nodes()})\n",
    "# list(nx.clique.find_cliques(gr2))\n",
    "# len(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = BeliefPropagation(fg)\n",
    "bp.calibrate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView((('X7', 'X9'), ('X3', 'X9', 'X4'), ('X3', 'X8', 'X1', 'X4'), ('X3', 'X8', 'X5', 'X0', 'X4'), ('X3', 'X8', 'X5', 'X0', 'X2')))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.get_cliques()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the PDG inference part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdg.alg.interior_pt import cvx_opt_clusters\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
