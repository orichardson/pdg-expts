;#+STARTUP: indent

* TASKS
** TODO Figure out how to use org mode.
** TODO create a merged document for Joe


* STRUCTURE OF DOCUMENT


** Motivations and Selling Points

*** Explicate Preference Change
Necesary because people change preferences.

*** Unify Value Representations

Value: Unification of preferences, utilities, matrices, small-number-of-states, utility distributions, goals, desires.

*** Beliefs and Values Are Similar (and "Dual" in some sense?)
Probability of A <--> Choice distribution on A
Liklihood Ordering <--> Preference Ordering
Log liklihood <--> Utility

Utility trades off linearly with probability, so maybe there's an implicit Temp-parameterized softmax inside? Is this the source of optimization?



Habits are variables you (maybe indirectly) have control over / you are responsible for, and can be either explained by giving them utility, or probability

**** Want: Generalied Savage 
that pulls apart actions into any compatible pair of representations. TODO: contrast this with the "Generalized Savage" in the RaU book.

*** 
Problem with worlds as products of variables: implicitly they are right-handed handed, co-inductive types. What if you want inductive types instead? 


** Static Model


*** Examples

*** Formal Definition

*** Existing Theories that you can Recover

**** Bayesian Networks
A BN can be converted to a MCG, whose center is the singleton with the distribution that the BN represents.

**** Some factor graphs
***** [red notebook]
We can get within one d.o.f. locally of a markov network. We can also add constraints to 



**** Constraint satisfaction. Correlary: NP-hard
**** 



* To Fold In

** [writeup.1] Decision Making, 
** [writeup.2] What I want to do
** [writeup.3] Informal Examples of properties
** [writeup.4]


** Examples
*** Pardoned Prisoneer
*** Balls
*** 

* Worries
** Impossible to be both more general and require less
Fact: the total number of degrees of freedom in the system is some fixed number. As a result, it is impossible to both (1) be completely general, and (2) require very few inputs from users.

The point of preferences is to capture everything, and so they factor out a great deal of the complexity, in turn passing it on to the user. If a complaint is that they do not

** matrices might be evil

If there are multiple ways of embedding things as matrices (prefrences, for instance, can be encoded as 1 / 0, with addition and multiplication, but also with min/max, and as a symmetric matrix...) then perhaps operations I defined for orders in terms of their representations (matrices, guaranteed to exist) will only hold for some of the representatives andnot others. You can make a cannonical choice of definition, but while technically not wrong it is evil.


As a result, I have to prove coherence results for things, to make sure that every operation is representation-independent. But changes of representation are sometimes meant to do things in my framework. If I want to argue that you really need a matrix to do things properly, I Am not then entitled to say it's more general: I'm actually requiring more things from my users.


** Are you not just opitmizing for something different?
VnM / Savage says everyone is optimizing for something implicitly. You're even optimizing explicitly. What gives?

*** 
- This is what entropy term is for: general uncertainty, to spread out distribution. 
- These are all in cases where the representation is fixed. When representation can move, none of the results make quite as much sense anymore.



* Think About Later
  
** 
** Categorical Picture
   
*** Co-slices and Slices.

A setting where you have a probability distribution on everything is a co-slice category under (1). If you have a utility for everything, you are in a slice category over (U). This makes utilities that can be altered like fibred cateogiries.

*** Composition of Links: Max Entropy 
I have already proved that any model in the center is compatible with 


*** Sheaf Condition:
I'm defining a bunch of local constraints, and that the local agree on their overlap is exactly what's required to be a sheaf. The math is a bit complex and I'm not a topos theorist, so I should leave this for now, but... someday.

** Distributional rock paper scissors: cyclic gamble Preferences.
** Folk Wisdom

*** Spoiled people are less good at being people

*** You should not look further than you can see


* Examples
** Of the way it impacts culture:
*** Optimizing for things is highly prized
Maximize profits, shareholder value, get high score, max points, etc. The points capture values because that's how humans work, and then people think the points are the things that matter (which they don't; the problem is not enough things have been captured, and we don't then make metric metrics)

*** 
[what was I thinking about in the bathroom?]

** Of having inconsistent preferences

*** Customization options (e.g., emacs)

Had preference for newer software over older (esp when faster / cleaner), so wanted emacs 26. Separeately, wanted certain custmoization options I couldn't find in emacs26 and had a preference for not changing things. These two preferences were in conflict and in this particular case, they got resolved with additional information specific to the setting, only marginally nudging the general preferences they were cloned from.

*** Difficult Binary preferences 
I want to eat chips but I also don't want to get fat.

* FAQ
** How does the category theory fit in?

*** It describes mathematics: the way people think formally



 Real humans don't use their snap judgements for everything. It'd be incredibly difficult to do this.

  - Imagine if you had to write an essay in one shot, without any organizational headers. The best way to do this is definitely to
  - 

 You can think of reinfocement learning as pressing this button really hard.


*** It can be used to unify existing preference models

 Because most math can be cleanly embedded in category theory, this gives us a natural way to talk about exactly how they relate to each other. This is category theory's greatest strength: putting many related things in the same terms so it's clearer how they relate to one another




** If preferences are no different from any other nodes, then why does this have anything to do with preferences? 

In general, because the tools I build ostensibly enable the kinds of updates that are necessary for internal nodes. Potentially also because this way of thinking clarifies things in the preference case as well.

Specific Examples: 

** How is it different from IRL, where you suppose there's a "true utility" and you just get a better picture of it as you get more samples?

There's not really a "true" utility function. There may be many, or none consistent with your constraints. You have constraints, and you're trying to act in accordance with them.

Do you have a moral obligation to try to decide what is good and bad in every setting? 
 - argument for yes: you can't just be negligent and not think about the moral impact of this one thing you're doing. You have a duty to try to understand as much as possible morally (and about the world insofar as it imapacts your calculus)
 - argument for no: you don't want to overfit. Deciding A > B without evidence is arguably more irresponsible than not making a decision. You're contaminating your real decisions with arbitrary ones. Assigning a utility to a set of variables is not going to 


* Goals

** Uninterpreted and uninterpreted graphs
What does it mean that there's an arrow A -> B, independent of the interptetation? Are there any constraints on when you can put an arrow in?

Possible (worrying) analogy: static vs dynamic types. In a BN, you're guaranteed that you will produce a distribution if you just put the right numbers in. For me, you won't generate a distribution. 
:draw:
There will be a /closest correct distribution/, for a given notion of closeness, but that's not all we care about: somehow the inconsistency is both something we want to reduce, and a valuable resource for making sure you're not wrong. Don't want to use it all at once? Also intractible to use it all at once, and you're often probably generating more, so maybe not problematic to use it.
:END:
Back to dynamic vs static types: the analogy breaks down because even though there are fewer constraints before interpretation and more afterwards, it's not like there's an error if you get an inconsistent picture. It's expected, and positive (so long as it came from somewhere...), because it makes you think and re-visit things. 

Does this make it harder to worry about? Yes! Obviously, not the least because it's impossible to


**  Figure out how generalized preferences flow (backwards). 
Note: this might have something to do with 
** Reconcile backwards flow picture with joint distribution picture.
