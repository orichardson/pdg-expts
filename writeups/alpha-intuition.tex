\documentclass{article}

\usepackage{amsmath,amssymb}
\usepackage{mathtools}
\usepackage[margin=1in]{geometry}
\usepackage{parskip}

\renewcommand{\H}{\mathop{\mathrm H}}

\begin{document}
We have a weighted PDG representing our beliefs; 
our third semantics gives us a way to score an arbitrary distribution $\mu$,
based on how well it matches the picture the PDG represents.  For context, the complete distribution-scoring semantics of a PDG is given by

\begin{quote}
How does the weight parameter alpha impact which distributions are good?
\end{quote}

\section*{FORMULATION 1}
\hspace{1in}\textit{($\alpha_L$ controls the term $+\H_\mu(Y \mid X)$ )}

By including the edge $L$ with positive corresponding value of $\alpha_L$, 
an agent is indicating that this edge is somehow an ``effective way of estimating the value of $Y$'' from the value of $X$. This notion is independent of the corresponding cpt: you can believe that $Y$ can be effectively determined by $X$ even if you do not know how to do this yourself.

For each edge $L$ from $X$ to $Y$, $\alpha_L$ is the loss mu incurs, per unit of residual uncertainty in $Y$ (in expectation over $\mu$) that remains even knowing the value of $X$ (drawn from $\mu$). \textit{Note this last parenthetical implies that the uncertainty of $Y$ given $X$ depends not only on the conditional probability of $Y$ given $X$, but also on the probability of $X$ itself}. In the general case, it can be increased or decreased independent of the cpt, by changing the relative probability of values of $X$. If $\mu$ makes a value $x_0$, from which $\mu(Y | X = x_0)$ is very uncertain, then in expectation the uncertainty in $Y$ given $X$ increases, even though the conditional probability of $Y$ given $X$ remains unchanged. A distribution is penalized for this in proportion to $\alpha_L$. 

While this technically is the full role $\alpha_L$ plays, the moral looks quite different when we view this term and the one that rewards global uncertainty together. We now provide some intuition for what their sum does together.

\begin{enumerate}
\item it may still seem as though something is morally wrong in rewarding $\mu$ for simply being deterministic in this way: uncertainty in $Y$ given $X$ may not always feel like a defect of $\mu$. It is possible that you know $Y$ to be 
noisy, for instance.

This is offset by the fact that any distribution $\mu$ also gets a bonus score equal to its global uncertainty. We can think of this bonus as a (partial) reimbursement for the total uncertainty, some of which $\mu$ needed to pay for even to match the tables. From this perspective, a distribution that does not result much global randomness, but according to which edge targets $Y$ uncertain even given the values their sources $X$ (for instance, by making $Y$ difficult to guess given $X$, by making $X$ more deterministic as above, or by having many variables share state, none of which is exploited with the edges, which all detail random correlations), will ultimately result in paying a much higher price than the bonus. 

For a Bayesian Network, the best one can do is to break even.

\item As stressed in earlier presentations, and our meeting, we can re-write the sum of these terms as being an order-dependent mutual information (plus an additional term which cancels the order-dependence). Before providing a more general sketch less entwined with our information theoretic presentation, we concretely show this equation for clarity in the case where $X_1$ and $X_2$ are two variables, both of which have an edge leading to $Y$. Here, the extra information of the diagram is
\begin{align*}
	&\alpha_1 H(Y \mid X_1) + \alpha_2 \H(Y \mid X_2) - \H(X_1,X_2,Y) \\
	&\quad = (\alpha_1+ \alpha_2) \H(Y \mid X_1, X_2) + \alpha_1 \mathrm{I}(Y; X_2 \mid X_1 )+ \alpha_2 \mathrm{I}(Y ; X_1 \mid X_2)
\end{align*}

\end{enumerate}

%In many cases, the alpha parameter will not matter. For instance, if the distribution has no uncertainty, then $H(Y\mid X) = 0$, and so $\alpha$ has no effect. This is also true in less degenerate cases: in rooted Markov trees (i.e., BNs without merges), for instance, 


\section*{FORMULATION 2:}% (alpha attached to E_mu [ H(p_L(x)) ])
\hspace{1in}\textit{($\alpha_L$ controls the term $\mathbb E_{x \sim \mu} [ \H (\mathbf p_L(x)) ]$ )}


\end{document}