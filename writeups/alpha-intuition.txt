We have a weighted PDG representing our beliefs; 
our third semantics gives us a way to score an arbitrary distribution mu,
based on how well it matches the picture the PDG represents. 

How does the weight parameter alpha impact which distributions are good?

FORMULATION 1: (alpha attached to H_\mu(Y | X) )
By specifying L with positive corresponding value of alpha, 
you are indicating that this edge is somehow an "effective way of estimating the value of Y" from the value of X. In this formulation, the term is 

For each edge L from X to Y, alpha_L is the loss mu incurs, per unit of residual uncertainty in Y (in expectation over mu) that remains even knowing the value of X (drawn from mu).

Of course, this uncertainty in Y may not be something that could be overcome by using some 
other edge and the corresponding consistent with mu; it is possible that mu just makes Y very 
noisy, independent of anything else. While this term alone indeed 

This is offset by the fact that each distribution mu benefits from its uncertainty globally.

In many cases, the alpha parameter will not matter. For instance, if the distribution has no uncertainty, then H(Y|X) is always zero. This is also true in less degenerate cases: 


FORMULATION 2: (alpha attached to E_mu [ H(p_L(x)) ])

