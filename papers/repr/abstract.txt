

We introduce Probabilistic Dependency Graphs (PDGs), a new class of directed graphical models.
PDGs capture inconsistent beliefs in a natural way, and are more modular than Bayesian Networks (BNs) in that they make it easier to incorporate new information and restructure the representation, without loss of interpretability.

We provide several semantics for PDGs, each of which can be derived from a loss function on joint distributions over the variables, representing the distribution's incompatibility with the PDG. For the PDG corresponding to a BN, this function is uniquely minimized by the distribution the BN represents, showing that PDG semantics extend BN semantics.

A minor alteration of this function (which does not affect the score of a BN) yields the variational free energy of general factor graphs; we use this to explain how PDGs and factor graphs generalize BNs in orthogonal directions, and argue the relative strengths of PDGs.

We show by example how PDGs are an especially natural modeling tool.






>> probabilized diagrams?
>> Modifications to a PDG are computationally simple, but may leave it in an inconsistent state.






, which naturally extends the semantics of BNs in that this function is uniquely minimized by the distribution represented by .

show that it naturally extends the standard semantics for BNs

 such as Bayesian networks (BNs), in that they make it easier for a modeler to incorporate new information and restructure the representation, without committing to unnecessary assumptions. 

 , and explain how a small modification of a very different flavor results in the free-energy landscape of the associated factor graph, viewed as a Markov Network. 
 
derriv
