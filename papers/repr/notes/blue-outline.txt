
	{\color{blue}
	I'm not exactly sure how to structure this, but the most important things, that I think could be centerpieces of a story are:
	\begin{enumerate}
		\item Inconsistency is an important resource and can be viewed as the driver of change in many areas. However, the appeal of avoiding being ever wrong by design and fondness of soundness have occluded this in the past.
		
		\begin{enumerate}
			\item Anything that is shorthand for a distribution (e.g., BNs, Factor Graphs, Markov Networks), or lets you be strictly more agnostic about things cannot represent inconsistency. The same goes for many other notions of uncertainty: belief functions, and sets of probability distributions are under-constrained from the perspective of wanting a distribution. This seems to be the standard angle of attack against being a Bayesian---but it also seems inevitable that at some point end up with beliefs that aren't compatible with one another, even if you're extremely careful, because your possible worlds allow you to have two distinct beliefs about one thing. \textbf{This is the interaction effect between this and the second point}: your ``possible worlds'' might be impossible possible worlds. 
			
			\item Eliminating it in the representation means that the only way to interact with it is to resolve it immediately, which may be worse than waiting until there's new information. 
			
			\item Because the representation is so constrained, tasks that really don't need to be dealing with consistency (like putting two pieces of knowledge together, or updating) end up having to do this ``every time they save'', and in a way that is more ham-fisted than doing it with a dedicated algorithm. It also dramatically increases the computational cost required to do such things. 
			
			The intermediate steps are often already useful enough to get the information you care about, and so jamming everything back into the same constricted representation is not really necessary. Also, the rigidity of the representation means there is no language for analyzing what happens between ``commits'' (e.g., what an agent's mental state looks like if halfway through a Bayesian update).
			
			\item For cognitively bounded agents, the step above is often intractable: calculating normalization constants in Markov Networks and factor graphs is NP hard, as are constraint satisfiability problems.
			
			\item Bayesian updating is a greedy algorithm for finding truth. It takes one observation at a time and immediately uses all of the inconsistency in it to get a better picture of the truth. \textbf{This is only guaranteed to be independent of event order if the set of worlds is static}. Otherwise collecting all of the observations all at once and then reducing inconsistency globally could yield a different answer. Applications of Jeffrey's rule are not in general independent of event order even if the set of possible worlds is static.
		\end{enumerate}
		
		
		Questions: 
		\begin{enumerate}
			\item Is there an interesting moral analog of Godel's 2nd theorem? Can I use this 
			to argue for the potential for inconsistency? 
			\item Can all inconsistency be framed as logical inconsistency? What does the language need to include so that this is true?
		\end{enumerate}
		
		\item Nobody's subjective ``possible worlds'' are static or strictly decrease over time. This is not due entirely to failure of perfect recall: people invent concepts, learn things about the world, etc. This causes a shifting of the underlying space of what is considered possible. Common representations of uncertainty and knowledge do not deal with this well, and often posit the existence of a fixed ``true'' set of possible worlds, which needs to be known by the modeler in order to make predictions.

		\item Alternatively, I can paint a picture of defining a number of small domains where everything is locally consistent, but globally there are no guarantees; we only need to make local decisions and know things in local contexts, and so there's get away with not maintaining expensive global things like full joint distributions, so long as you also take care to clean up inconsistencies when they occur.
		
		The process of sorting through local beliefs and going from local picture to a global one can be thought of as a ``sheafification'' of belief updating.
				
	\end{enumerate}
%	Less important high level things I think are important:
%	\begin{enumerate}
%		\item as a vectorization of probability 
%	\end{enumerate}
	}
