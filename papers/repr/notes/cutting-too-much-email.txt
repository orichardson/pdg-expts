
I want to let you know that in this editing phase I don't put sentences in for no reason and usually think quite a long time going back and forth about whether or not I should include things, write much more and reduce it dramatically. 


There's not enough space in the margins of the document so I'll make some comments here:

 > As we will see, one reason these inconsistencies are difficult to avoid is our conceptual modularity:features of the world can be noticed, forgotten, and fragments of beliefs can be locally recombined long before they crystallize into global distributions or theorems.

"I would still cut this. I don't think that the average reader will know what you mean, which his bad for the second sentence of the introduction. I think the net gain for this sentence is negative."

	> This may be true of the current iteration, but my sense is that if we want to tell the story about (1) allowing for inconsistency, and (2) modularity, that we mention both in the first paragraph together. 
	
	My first impression is to say that it doesn't matter whether they totally understand what I mean; I'm soon going to provide examples to hang on this framing; I was hoping that by saying "As we will see" or something to that effect, I could keep readers from getting too hung up on it, while they still get the intuitions. 
	
	Reasons I like this sentence in particular:
	 - hints at why the two issues are related rather than introducing them separately
	 - hints at locality
	 - gives us the correct idea that we're just not doing some computation that we need to be doing to get the gold standard representations
	 - introduces another pair of concepts that should be thought of as being brought together in this representation: probabilistic and deductive inference, without giving them much weight.
	 
	Could be improved:
	 - hard to parse
	 - maybe not everyone will get the following point: more tools, more tricks, more done locally and faster => harder to maintain global invariants
	 
	 
	 
[Feature 1 of Floomp Example]
> Even though the additional information takes the form of a conditional probability table, expressing it as an edge in our Bayes Net overwrites other information: by adding a link F ! G, the Bayes Net loses all of our prior information about G

"On further thought, I don't buy this at all. If you had the "right" prior on F and the "right" CPT on G, the posterior on G should be the prior you had before"

	> I think this is an important point (in general for sure, this example has now been reduced to the point that it might be fuzzier and I have old one as context) and don't understand your complaint. 
	You have a subjective probability of both F and G, before you get a CPT. You later discover knowledge which takes the form of a CPT, but the CPT is incompatible with the two distributions. 
				
	If you're doing things the Bayesian way (I think I had a footnote about this at some point?), the problem is that this CPT doesn't get to just go in your beliefs; you have to condition on it. It's not an event, but you CAN condition (or use Jeffrey's rule) on whatever event you observed to get this belief and you're good to go.
	
	My point is that conditioning is expensive and you can't do things like merge beliefs together. You can only interact with your beliefs by conditioning. This destroys locality, because you can't keep two separate maps, and later figure out how they fit together. You've just gotta be a good Bayesian and do the updates right the first time.
	
	
	
[Footnote 2]
> One might argue that you need to resolve the inconsistency in case you need to make decisions before you can discover the truth---that it is appropriate to soften all three beliefs as appropriate rather than leave the inconsistency. This is a reasonable point of view, and still consistent with using a PDG---but one should note that this is an eager rather than lazy approach, and will in general be more expensive.

	
"I would still cut this; I donâ€™t think anyone will argue that you need to resolve the inconsistency immediately, except for those who believe that for some reason, you should always have consistent beliefs.  But if you believe that, the reasons go beyond needing to make decisions. This is too much of a distraction (so, in my view, a net negative)."
	
	> This seems backwards. 

		My argument: if you want to make decisions well with fewer resources (or other more important things), you can benefit from inconsistency, by resolving things lazily.
		
		it seems like you're stating the contrapositive: if you don't want inconsistency, then you must not care about the benefit to doing computation lazily, let alone other more important things. 
		
		... which seems less obvious. I think people who think you shouldn't have inconsistent beliefs think that because that's the way the rest of the math they've seen works out, and probabilities usually work great.  
		
	
[Footnote 3]

3 [note: This used to be the paragraph, but I moved it into a the footnote rather than cutting it. I was a bit unsure about how big a deal the concern was until I thought about it this way.] One reason to be wary of resolving the inconsistency is that the process is not invertible: from a probabilistic perspective, resolution of the inconsistency is a projection (read: non-injective) into a feasible subspace. Thus this eager resolution loses information, which might be useful in the future.

" You should cut this. It's a distraction. You really don't want to get into this at this point in the introduction"

	> I see that it's kind out of the way, but that's why it's a footnote. Also there's not a whole lot more to say, and I found the argument helpful: I honestly was worried that the "you could do better by putting it off" argument didn't hold because perhaps there was only one way of doing the computation, and you had to do it all at some point, may as well do it right away. 
	
	Do you think the irreversibility argument is not mentioning at all? Or that we should move it elsewhere?
	
	
	
[equivocate]
> ... without also providing much more information than we're prepared to equivocate on

"Say instead: without requiring us to give information that we do not have"

	> This is a more generic sentence and further from what I want to say. Your beliefs aren't really information about the world, and it's not about giving information you have, so much as putting in the thought required to make up your mind about what you believe (which you might be willing to do if forced to at gunpoint, for instance)
	
	
	
	
[discriminitive / generative footnote]
> [note: I feel uncomfortable cutting the following because discriminative graphical models super commonly used and I suspect many people reading the paper will object that this can already be done; I want to nod to it.] Models like these are well used to hardcore probabilists as well. In statistical learning theory, an `incomplete' model like this is a discriminative (or conditional) model, as compared to a generative one.
" Precisely because people have long considered qualitative BNs, I would cut this and the sentences it's a footnote to"
"Cut it. You need a focused introduction, that doesn't bring in lots of tangential details."
	
	> First, the underconstrainedness I'm talking about is quite different from using a qualitative BN, because I'm not even telling you what the links are. I'm not even imagining that such links exist. This is more like modeling an adversary taking a move than an unimplemented structure asserting that tables exist but not knowing what they are.
	
	Second, You're right about it being a tangent, but I'm still certain that by framing it this way we'll be able to get a lot of readers who do structured prediction and are thinking about conditional random fields to pay attention (It's a neat observation! the way I was taught, discriminative models were just a totally different class of thing, not a special case of something!). It's possible that it this connection is something that needs to be made better, and I'm also totally willing to drop this one, but I thought this was the ideal use case for a footnote. 
	
	More generally, I think the tangents are important! They're where I spend a lot of time and they connect it to other things I've been thinking about. While we need to tell a story, the concept itself is not a story and by failing to cross-link it in the appropriate places I feel like I'm selling short all of the wonderful things it can do
	
	

[Hailed]	
> ... hailed as a strict generalization of BNs an MNs ...

"hailed -> which is; no need for flowery language"

	> The thing is, there are a lot of asterisks on that statement. In some sense, they're all equivalently powerful because you can just add all of the edges to your Bayesian network or Markov network until it represents any probability distribution. Also, even if you clarify that you're talking about some small polynomial conversion constant, you still need to give the extra conditions on the Clifford-Hammersly Theorem for it to be accurate. 
	
	Still, it's in the folk lore as a "strict generalization" all over in online tutorials and course notes. I kind of wanted to slightly mock this, though it's a good true-in-spirit tagline, and I didn't want to get into it. Hence, "hailed". 
	
	It's frustrating because I was happy about that word choice, it's a perfectly good English word that I use regularly, and I really dislike the idea of using less flavorful words because somebody might read too far into it---especially when I know I have the math to back it up. Maybe this compromise is necessary, but it sucks.
	

[Overconstrained vs inconsistent, cut underconstrained]

	> "overconstrained" has a nice lexical contrast with "under-constrained", I still think this is a super useful framing, and even though under-constrained is a standard thing that people do, it took me a while to see it that way.
	
	Being "over-constrained" also is necessary but not sufficient for inconsistency. I'm talking about the possibility of inconsistency, not that the inconsistency exists. Ideally, this overconstrainedness looks like a verification of your beliefs, rather than a repudiation of them.
	
	
	
[The Points]
 > ... but also other non-probabilisitic notions of uncertainty
 "Cut"
	> Ok but isn't it worth mentioning that I can use them to internalize not only probability theory but also lower probabilities? This seems like a really important fact about what these models actually are mathematically when the world is fixed.
	
> ... makes it much easier to add, remove, and partially interpret parts of the model, ...
" replace with 'makes it much easier to add', compared to other graphical models"

	> Why unnecessarily short-sell this? All three are different and easier, and adding doesn't really stand for the others. It also doesn't flow as well.
	


> 5. In conjunction with the ability to merge, split, and compress variables, agents can use the inconsistency and modularity that PDGs offer to subjectively expand and contract the set of possible worlds, without necessarily interacting with one true set of them which happens to be common knowledge.
> 6. The modularity enables type-forming rules which can be used to implement deductive inference.
"Cut points 5 and 6"

	> Point 5 is poorly written and maybe it doesn't fit given our story... but I do believe this is a valuable contribution and I should flesh out the argument better if I want to include it. I will cut it for now.
	
	
	> Point 6 is also super important. Adding product nodes is the the trick that I use to get things off the ground at all, so we really can't cut out the type combinators completely. We can avoid the logic, but this also seems like a huge waste.
	

> 7. In contrast with a simple collection of constraints, inconsistencies can be more local, and individual pieces of information have limited impact on the semantics.
" This should be folded into point 1 (and perhaps 4) "

	> This means something else: it's referring to the added durability we get compared to a factor graph. I'll reword this. 
	


[Random Variables]
	> When I talked with you near the end of class, you said that it was important to frame it in terms of random variables rather than just interpreting a graph, to formalize Bayesian Networks if nothing else. But it is just book-keeping math. Maybe nice to put in an appendix? Or hide in a formalism section that people will skim?