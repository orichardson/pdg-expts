%load_ext autoreload
%autoreload 2

from utils import CopiedType
from pandas import DataFrame
import collections

class Variable(set, metaclass=CopiedType):
    PARAMS = {'name', 'default_value'}
    
    def __init__(self, vals):
        # super init inserted by metaclass
        self._ordered_set = list(vals)
        
    def __mul__(self, other):
        kwargs = {}
        if hasattr(self, 'default_value') and hasattr(other, 'default_value'):
            kwargs['default_value'] = (self.default_value, other.default_value)
        if hasattr(self, 'name') and hasattr(other, 'name'):
            kwargs['name'] = (self.name + "Ã—" + other.name)
            
        return Variable([(a,b) for b in other.ordered for a in self.ordered], **kwargs)    
        
    @property
    def ordered(self):
        self._ordered_set = [x for x in self._ordered_set if x in self] + \
            [y for y in self if y not in self._ordered_set]
        return self._ordered_set
    
# V = Variable([3, 10, 2], name='V')
# (V*V).name

class CPT(DataFrame, metaclass=CopiedType):
    PARAMS = {"nfrom", "nto"}
    _internal_names = DataFrame._internal_names + ["nfrom", "nto"]
    _internal_names_set = set(_internal_names)
    
    @classmethod
    def mk(cls, nfrom, nto, data):
        for a in nfrom:
            row = data[a]
            if not isinstance(row, collections.Mapping):
                try:
                    iter(row)
                except:
                    data[a] = { nto.default_value : row }
                else:
                    data[a] = { b : v for (b,v) in zip(nto,row)}
                    
            total = sum(v for b,v in data[a].items())
            remainder = nto - set(data[a].keys())
            if len(remainder) == 1:
                data[a][next(iter(remainder))] = 1 - total
        
        matrix = DataFrame.from_dict(data , orient='index')
        return cls(matrix, index=nfrom.ordered, columns=nto.ordered, nto=nto,nfrom=nfrom)


def binvar(name : str):
    nl = name.lower()
    return Variable([nl, "~"+nl], default_value=nl, name=name)
    
One = Variable('*', default_value='*', name='1')
# CPT.mk(One, PS, {'*': 0.3})
# V = Variable("abc")X
# CPT.mk(V*V, One, { ('a', 'a') : .2, ('a', 'b') : .1, ('a', 'c') : .3, ('b', 'a') : .4, 
#     ('b', 'b') : .7, ('b', 'c') : .9, ('c', 'a') : .8, ('c', 'b') : .6, ('c', 'c') : .5})

class LinkView:
    def __get__(self, instance, cls) -> object:
        instance.mu.keys()

    def __set__(self, obj, value) -> None:
        pass

    # def __getitem__()

class PDG:
    # links = Links()
    
    def __init__(self):
        ## these are useful for 
        # self.N = set() 
        # self.L = list() # all pairs
        
        self.V = {} # N -> Set
        self.mu = {} # L -> CPT
    
    def __setattr__(self, key, value):
        if type(value) is Variable:
            value.name = key
            self.V[key] = value
        
        else:
            self.__dict__[key] = value
    
    
    def __iadd__(self, other):
        # print(other, type(other))
        if type(other) is tuple:
            for o in other:
                self += o
            return self
            
        if isinstance(other, CPT):
            self.mu[other.nfrom.name, other.nto.name] = other
        
        return self
    # def __setitem__(self, idx, value):
    #     self.mu[(i,j)] = sequence
            
            
    # def __get__(self, obj, value):
        # if (obj == )





############""" Example Code """##############
pdg = PDG()
PS = binvar('PS')
S = binvar('S')
SH = binvar('SH')
C = binvar('C')


pdg += CPT.mk(One, PS, {'*': 0.3})
pdg += CPT.mk(PS, S, { 'ps': 0.4, '~ps' : 0.2})
pdg += CPT.mk(PS, SH, { 'ps': 0.8, '~ps' : 0.3})
pdg += CPT.mk(S * SH, C, 
    { ('s','sh') : 0.6, ('s','~sh') : 0.4,
      ('~s','sh'): 0.1, ('~s','~sh'): 0.01} )

pdg.mu[PS,S]

if False:
    # Building part by part in a context.

        
    # build by hypergraph
    G = load(" 1 -> PS ; PS -> S ; PS -> SH ; SH, S -> C")
    PDG.build(graph = G, n_vals = lambda var: 2)
    
    # pdg.add_random_links(n = 4, H = 0.5)
    
    # query consistency
    pdg.is_consistent()

    # 
    data = pdg.samples(n = 1000) # each data[i]  = (ps, s, sh, c)...

    ## replace everything with 0,1, use matrices. 
    # pdg.to_dense() ; 
    ## replace values with lower case variable names.
    # pdg.to_labeled()

    fg = pdg.to_factor_graph()
    print(fg.Pr.toCPT() == pdg.max_entropy_dist.toCPT())



    # for each spanning tree, can conver to BN
    for tree in rooted_spanning_trees(pdg.G):
        print("BN: ", BayesNet(pdg.subgr(tree)) )
        # CONJECTURE: Every Distirbution is in the convex hull
        # of the distributions generated by spanning trees.
