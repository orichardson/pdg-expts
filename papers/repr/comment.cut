\subsection{DIRECTED FACTOR GRAPHS}

One solution, by \parencite{frey2012extending} is to also enforce some local constraints, in the form of a local normalization.  While this indeed solves issues \cref{fgproblem:undirected,fgproblem:global}, directed factor graphs still leave some bits of issues \cref{fgproblem:corrob,fgproblem:reweight,fgproblem:volatile} unaddressed.

Directed factor graphs are much more explicit with their factorizations than BNs, are as expected, even more closely related to \MNs\. However, they too cannot capture scenarios such as \cref{ex:randomvars}. Consider example \ref{ex:directedfg}

\begin{example}\label{ex:directedfg}
\todo{Choose a different directed factor graph example that doesn't rely on sub-stochasticity}
\end{example}


\section{THERMODYNAMICS OF PDGS}\label{sec:thermo}
\begin{figure}[t]
\centering
\scalebox{0.9}{
\begin{tikzpicture}
\node[ellipse,draw, outer sep=4pt] (DW) at (0,0) {$\Delta W$};
\node[ellipse,draw, outer sep=4pt] (EW) at (0,2.4) {$\text{Energy}^W$};
\node[ellipse,draw, outer sep=4pt] (DDW) at (4,0) {$\Delta (\Delta W)$};
\node[ellipse,draw, outer sep=4pt] (EDW) at (4,2.4) {$\text{Energy}^{\Delta W}$};

\node[right=0.5em of EDW, blue] {$\mathcal U_\alpha(\sfM; \cdot)$};
\node[right=0.8em of DDW, blue] {$\bbr{\sfM}_{\alpha,\beta}$};
\node[left=0.8em of DW, blue] {$\mu$};
\node[left=0.5em of EW, blue] {$\log\frac{1}{\mu}$};

\draw[->, transform canvas={xshift=3pt}] (DW) -- node[right]{$E_\beta$} (EW);
\draw[->, transform canvas={xshift=-3pt}] (EW) -- node[left]{$P_\beta$} (DW);

\draw[->, transform canvas={xshift=-3pt}] (DDW) -- node[left]{$E_\beta$} (EDW);
\draw[->, dashed, transform canvas={xshift=3pt}] (EDW) -- node[right]{$P_\beta$} (DDW);

\draw[->] (DW) to[bend left=10] node[sloped,fill=white]{$D({-\Vert~})$} (EDW);

\draw[->] (EW) to[bend left=15] node[above] {$\E^*$} (EDW);
\draw[->] (EDW) to node[fill=white] {$\E$} (EW);

\draw[->] (DDW) to node[below] {$\E$} (DW);
\end{tikzpicture}}
\caption{Energy / Distribution Transformations.
%The nodes are thermodynamic objects, the arrows are ways of constructing one from another
}
\label{fig:energies-and-dists}
\end{figure}
We now look at the weighted distribution semantics of \MNs\ from a thermodynamic perspective: this will provide better rationale for the parameter choices in \Cref{sec:weighted-semantics}, and draw some more explicit contrasts between \MNs\ and factor graphs. Let $W$ be finite set of states, called ``micro-states'' on which the distribution is supported.

Our technical starting point will be the Boltzmann distribution \eqref{eq:boltzmann}, which asserts that the probability $P$ of being in a state exponentially decreases as its energy $U$ increases; the rate of exponential decay is related to the ``inverse temperature'', $\beta$; here $Z_U(\beta)$ is a normalization constant. Fixing $\beta$, we can of course, invert the Boltzmann distribution \eqref{eq:invbolz}, obtaining an energy from a probability. A probability distribution over $W$ is called a configuration, or macro-state.
  \begin{align}
 P_{\beta}(U) &:= w \mapsto  \frac{1}{Z_U(\beta)}\exp\Big(-\beta U(w)\Big) \label{eq:boltzmann} \\
  E_{\beta}(\mu) &:= w \mapsto \frac{1}{\beta} \ln \left(\frac{1}{\mu(w)}\right) \label{eq:invbolz}
  \end{align}
  Conversions between the two correspond to going up and down on the left of \Cref{fig:energies-and-dists}.
  Now $\mathcal U$, as defined in \eqref{eq:freeenergy-weighted} is an un-normalized badness score, making it like an energy; \eqref{eqn:weighted-semantics}, is the un-normalized Boltzmann distribution for this energy. The parameter $\beta$, which we described earlier as a certainty, plays the physical role of an inverse temperature: lower is more chaotic.
  
  $\mathcal U$ is not just an arbitrary construction either: it is analogous to a free energy. Why is the most favorable configuration not just a point mass as the minimum energy? Because in a world where an ambient temperature makes things more diffuse, doing things would require a lot more energy. Rather than just minimizing the average energy of a configuration $\nu$, you're better off minimizing the Gibbs free energy \eqref{eqn:gibbs-free-energy}.
  \begin{equation}
  G_E(\nu) = {\E}_\nu( E )  - T S(\nu) \label{eqn:gibbs-free-energy}
  \end{equation}
  Analogously, why not put all of your weight on the one distribution you think is most likely? Because in a slightly chaotic world, doing so could actually incur a lot more inconsistency. Instead, we're better off minimizing $\cal U$. $\alpha$ is more transparently a temperature here, with higher values indicating higher preparedness for background chaos. The higher order expectation we take in \eqref{eqn:higher-expectation} corresponds to the bottom edge of \Cref{fig:energies-and-dists}, and the diagonal, which is the natural way to construct free energies from a distribution, is a KL divergence. This can be seen directly, as well, in \Cref{ex:energy-from-distrib}.
  %
See \ref{sec:thermo-background}, and \parencite{bethe,friston} for more comprehensive background. %and \cite{} for weighted probability distributions.


It follows from \Cref{cor:}
A very weak version of this can already be seen in un-normalized factor graphs: by multiplying a factor $\phi$ by a constant $\alpha$, one obtains a free energy $G' = - \ln \alpha + G$, i.e., with a mere additive shift. However, this shift doesn't really distinguish belief states, which is part of why we're so eager to normalize the distribution.
There is also an opportunity to modify $\beta$, but in standard graphical model literature, people set $\beta = 1$ and forget about it.%
\footnote{A similar complaint, is lodged in \parencite{fixing-broken-elbo}, in which many information theoretic trade-offs are hidden by assuming $\beta = 1$}


\begin{examplex}[continues=ex:worldsonly]\label{ex:energy-from-distrib}
For the \MN\ $\sf M$ that encodes just a probability distribution $\mu$ over $W$,  $\zeta(\sfM; \nu) = \kldiv{\nu}{\mu}$. This quantity is also equal to $\mathcal G_{E(\mu)}$, the Gibbs free energy for the potential landscape associated to $\mu$ at temperature $\beta = 1$.
\end{examplex}


A priori, \Cref{thm:free-energy-strictly-more-expressive} might be thought of as merely a novel function we came up with, but in fact this is not the case--- when the \MN\ is a Bayesian network, this is just the normal Gibbs free energy.

\begin{prop}\label{prop:bn-free-energy}
For any Bayesian Network $B$,
$$\bbr{\Gamma(B)} = D(- || \Pr\nolimits_B) = \mathcal G_{E(\Pr_B)}$$
\end{prop}

For factor graphs, the connection to thermodynamic parameters has previously been made explicit \parencite{bethe}, which allows us to formulate the following, stronger result:

\begin{conj}\label{thm:fg-free-energy}
For a factor graph $\Phi$, $\bbr{\Psi(\Phi)^{(\beta)}} = \mathcal G_{E_\beta(\Phi)}$.
\end{conj}

As a result, the weighted distribution semantics co-incide exactly with the notions of free energy on standard graphical models; we therefore can view \MNs\ as implicitly providing a more expressive class of free energies, corresponding to weighted distributions, which in turn can be naturally adapted to be distributions themselves.

% \begin{prop}
% The Bethe free energy is equivalent to the Gibbs free energy of $M$ iff $M$ is strongly consistent.
% \end{prop}


% \begin{conj}\label{thm:free-energy-strictly-more-expressive}
% The weighted distributions generated by \MNs\ are strictly more expressive than those generated by BNs, Factor Graphs, or directed factor graphs.
% \end{conj}
% \begin{proof}
% The first two parts come from \Cref{thm:fg-free-energy,prop:bn-free-energy}. Since
% \end{proof}
% \begin{coro}
% Local minima of the Bethe free energy are fixed points of loopy belief propagation in \MNs 
% \end{coro}




\section{WEIGHTED MNS}

We may also consider the edges as having different strengths: if we associate a different coefficient $\beta_L$ to each edge $L$, we can define

\begin{defn}
A weighted \MN\ $(\sfM, \beta)$ is a \MN\ $\sfM$ together with a \emph{certainty} $\beta_L \in \mathbb R^{\geq 0} \cup \{\infty\}$ for each edge $L \in \Ed^\sfM$.
\end{defn}

with corresponding inconsistency $\zeta((\sfM, \beta) ; p) :=$
\[
%\inf_{p \in \Delta(W^{\mathcal V})}~
\sum_{\substack{L \in \cal L\\L = (A,B, \ell)}}\!\! \mathop{\mathbb E}_{a \sim p(A)} \left[\frac{1}{\beta_L}\kldiv[\Big]{\bmu_{L}(a) }{ p(B | A \sheq a) } \right]
\]

We an always take a \MN\ $M$ and uniformly assign every edge the same inverse temperature $\beta_0$; we'll call this $\sfM^{(\beta\colon\!=\beta_0)}$.

As a sanity check, we can verify that with $\beta = \infty$, corresponding to very low ambient uncertainty, our weighted distribution exactly gives us a point mass on the global free energy minimum, which is the maximum entropy distribution.

% \begin{prop}
% If $M$ is consistent, $\bbr{M^{\beta\!:\!=\infty}}^* = \bbr{M}\MaxEnt$.
% \end{prop}




\begin{example}[continues=ex:guns-and-floomps]
Recall the \MN\ from our first example, in figure \ref{fig:gun-floomp-diagram}. Suppose that both the of the initial edges $1 \to F$ and $1\to G$ have certainty $\beta_{1 \shortto G} = \beta_{1\shortto F} = 1$, and we give our new observation a very low certainty of $\beta_T = 10^{-3}$.
%
In this case $\zeta(\sfM; \beta)$ is very close to zero, since the inconsistency can be resolved by a revision to the table $T$, which is cheap since $\beta_T$ is small. The $\zeta$-smallest perturbation effectively deletes the new observation.

% In this example, the temperature parameters are like Barycentric coordinates over the triangle of edges, indicating how much each will would change in response to the inconsistency.
\end{example} 

\begin{example}[Dempster's rule]
Suppose $p$ and $q$ are distributions over a set $W$, corresponding to the \MN\ $\sfM$ in \Cref{fig:parallel}.  

\begin{figure}
\centering
\scalebox{0.8}{
\begin{tikzpicture}
\node[dpadded] (1) at (0,0) {$\sf 1$};
\node[dpadded] (W) at (3,0) {$W$};
\draw[arr] (1) to[bend left] node[fill=white]{$p$} (W);
\draw[arr] (1) to[bend right] node[fill=white]{$q$} (W);
\end{tikzpicture}
}
\caption{}
\label{fig:parallel}
\end{figure}
Then $\sfM$

% For those familiar with factor graphs, this example might
\end{example}



\begin{vfull}
\section{Relations to Other Representations of Uncertainty}
\expandafter\expandafter\expandafter\MakeUppercase\modelnames\ are far from the first formalism to provide a weaker notion of uncertainty than probability. Belief functions, inner measures, sets of probabilities, lower probabilities, weighted sets of probabilities, and plausibility measures have all been studied extensively in the past. One feature that each of these has in common is that they are under-specified, from the perspective of wanting probabilities for everything.

\begin{center}
\begin{tikzpicture}
\node[dpadded] (outcomes) at (0,0) {$\Omega$};
\node[dpadded] (1) at (-2,0) {$\mathsf 1$};

\draw[arr] (1) -- (outcomes); 
\end{tikzpicture}
\end{center}


The natural question now becomes: to what do these under-constrained representations of belief correspond to under-constrained bits of a \modelname?

\subsection{Conditional Probability Spaces}

\begin{center}
\begin{tikzpicture}
\node[dpadded] (outcomes) at (0,0) {$\Omega$};
\node[dpadded] (1) at (-2,0) {$\mathsf 1$};
\node[dpadded] (U) at (2,1) {$U$};
\node[dpadded] (V) at (2,-1) {$V$};


\draw[arr] (1) -- (outcomes); 
\draw[arr, ->>] (outcomes) -- (U);
\draw[arr, ->>] (outcomes) -- (V);


\end{tikzpicture}
\end{center}




\subsection{Sets of Probability Measures}
% As we discuss in section \ref{sec:set-of-distribution-semantics}



\subsection{Lower Probabilities}
\end{vfull}


\section{USING INCONSISTENCY} 
\subsection{BELIEF UPDATING} \label{sec:belief-update}
Belief revision, both through Bayes' and Jeffrey's rules, can be thought of as the addition of a new marginal to a distribution, and then a resolution of inconsistency. In Dietrich, List, Bradly \cite{dietrich2016belief}, a belief revision is an update $p \mapsto p_I$ of a belief state $p$ to a new one consistent with the input $I$.

For us, belief revision consists simply of the addition of a new edge to the picture, followed by a resolution of the resulting inconsistency.
With reference to \Cref{fig:belief-update}, an extension of \Cref{ex:randomvars}, consider the following update.
Upon noisily observing the variable $B$ to with probabilities indexed by $\pi = \{\pi_b\}_{b \in \V(B)}$, Jeffrey's rule prescribes a posterior probability $p'$ of any event $E$ by:
\[ p'(E) = \sum_{b \in B} p(E \mid B\sheq b) \pi_b \]
Bayes Rule corresponds the particular case of Jeffrey's rule, in which the variable is binary and the outcome is certain.


\begin{figure}[h]
\centering
% \scalebox{0.8}{
% \begin{tikzpicture}[center base]
% \node[dpadded] (1) at (0,3) {$\sf 1$};
% \node[dpadded] (W) at (0,0) {$\cal W$};
% \node[dpadded] (B) at (-2,1) {$B$};
% 
% \draw[arr] (1) to node[fill=white]{$p$} (W);
% \draw[arr] (1) to node[fill=white]{$\pi$} (B);
% 
% \draw[arr, gray] (W) to[bend left=10] (B);
% \draw[arr, dashed] (B) to[bend right=30] (W); 
% \end{tikzpicture}}
\scalebox{0.8}{
\begin{tikzpicture}[center base]
\useasboundingbox (-3,-1) rectangle (3.5,4);
\node[dpadded] (1) at (0,3) {$\sf 1$};
\node[dpadded] (W) at (0,0) {$W$};
\node[dpadded] (B) at (-2,1) {$B$};
\node[dpadded] (E) at (2.5, 0){$E$};
\coordinate (Q) at (6,0); % to even out controls

\draw[arr] (1) to node[fill=white]{$p$} (W);
\draw[arr] (1) to node[fill=white]{$\pi$} (B);

\draw[arr, gray, ->>] (W) to[bend left=10] (B);
\draw[arr, dashed] (B) to[bend right=30] (W); 

\draw[arr, ->>] (W) to (E);

\draw[arr,blue!50] (1) .. controls (-5.5,1.5) and (-2,-2) .. node[fill=white]{$p'(E)$} (E);
\draw[arr,orange!70] (1) .. controls (0.5,1) and (1,0.5) .. node[fill=white]{$p(E)$} (E);
\end{tikzpicture}}
\caption{\MN\ Belief Updating via Inconsistency}
\label{fig:belief-update}
\end{figure}

To understand the update visually in \Cref{fig:belief-update}, imagine the original distribution $p$ from $\sf 1$ to $W$ being replaced by the path $p' := p(W \mid B) \circ \pi$  on the left. The gray arrow on the bottom left is the definition of the random variable, as in \Cref{ex:randomvars}, and the dashed one is its inversion, which can be computed by Bayes' rule.  %that factors through $B$ via the new observation $\pi$.
To query the resulting distribution on, an arbitrary event $E$, with an indicator variable of the same name. Initially, we got a marginal on $E$ by going through $p$; we now use $p'$. Effectively, the orange path to $E$ has been replaced by the blue one.


To observe $\pi$, we simply view it as a cpt conditioned on $\star$ and add it to our collection.
Although it is likely to be inconsistent, resolving this inconsistency in a way that retains $\pi$ is a belief update.
Even failure retain $\pi$ entirely may not be a concern: so long as an they continue to observe or remember, an agent endures discomfort until $\pi$ is incorporated. This setting is arguably more natural than a standard one: without spending energy, it is easy to forget or partially reject implications of the observation. 
Once again, with a \MN, the resolution need not happen immediately. This makes the approach more convincing for cognitively bounded agents, who might have more pressing matters than sorting through beliefs, and who might do them out of order.

\section{ALGORITHMS}\label{sec:algorithms}
\subsection{BELIEF PROPAGATION}
\todo{figure out what the minimal things I can say here and still convince people  it's inconsistency reduction}


\subsection{SAMPLING}

One of the nice about directed graphical models is that the model itself is roughly a sampling algorithm. For instance, taking a Bayes Net $\cal B$ and generating samples according to the tables is an efficient way to sample $\Pr_{\mathcal B}$.

This works because there is only one path, but more generally, for any conditional marginal $Y|X$, we can think of all of the different paths in the \MN\ different ways an agent with knowledge $\sfM$ can get probabilistic estimates of the conditional distribution $\bbr{\sfM}\MaxEnt(Y | X)$. The next result states that, in a precise sense, these various estimates bound the location of the marginal for this maximum entropy distribution, which suggests an efficient sampling algorithm for $\bbr{\sfM}\MaxEnt(Y | X)$, after learning some weights.

\begin{conj}\label{thm:maxent-hull}
For any \MN\ $\sfM = \mnvars[]$ containing variables $X, Y$, the maximum entropy conditional marginal $\bbr{\sfM}\MaxEnt(y \mid x)$ is a convex mixture of the conditional marginals generated by the paths from $X$ to $Y$.  That is, there exist weights $\{\alpha_i \geq 0\}$ on the paths in $\sf M$ and a bias weight $\alpha_0$ with $\sum_i {\alpha_i} = 1$ and
$$ \bbr{\sfM}\MaxEnt(Y \mid X) = \alpha_0 \  p^{\text{unif}}_Y \sum_{p \in \bbr{\sfM}_\lambda(X, Y)} \alpha_i (p_1 \circ \ldots \circ p_k) $$ 
where $p^{\text{unif}}_Y$ is the uniform distribution on $Y$, and $\bbr{\sfM}_\lambda(X,Y)$ is the set of paths from $X$ to $Y$ generated by composition and Bayes Rule in $\sfM$.
\end{conj}

One natural choice of these $\alpha$'s is the certainty scores for each edge, given by a weighted \MN, but we do not have any further formal results in this direction.
Note that it is common for humans to make decisions in this way: to estimate whether something is realistic by following multiple chains of reasoning weighting them by strength of argument.

% \begin{conj}
% The conditional marginal of the maximum entropy distribution $\bbr{M}\MaxEnt(b \mid a)$ is in the convex hull of the compositions of paths $A \to B$.
% \end{conj}






\section{DISCUSSION}
\todo{There are many things I could write. Have to decide what I actually want to say.}


A probability distribution is in many ways the appropriate idealized object to carry around with you.

Question: if we had more mental power, would we be more or less consistent? Unclear. Do dogs have more or less consistent beliefs than we do? They may just not have as many concepts. We clearly use a lot of our computation for storing things and making up concepts.




\begin{vfull}
\subsection{Useful Avenues of Empirical study}

\begin{enumerate}
\item Figure out how to empirically measure some kind of inconsistency, and lots of imagined correlates, such as amount of indecision, other people taking advantage of you, environments that would encourage "double-think". If there's a robust, multi-feature correlation between IQ and inconsistency, one concludes that additional mental power does not lead to coherence, and therefore some logical limits may not be as relevant as previously thought.
\item
\end{enumerate}
\end{vfull}



\subsection{Probabilities Still Encode Well} 
In some sense, while we have yet to find a mental state that is not encoded in some probability distribution, the choice of underlying space is extremely important, and we argue that it changes rapidly. Moreover, sometimes one has to make up new internal mental variables, which also changes the underlying space. \MNs\ offer a way to describe distributions, together with a number of internal parameters one might not be actively aware of. The relevant parameters, can always be internalized \todo{define internalization} until we reach a distribution.

However, storing knowledge in the form of another graphical model is extremely cumbersome if the set of worlds changes quickly. 

\begin{example}
\todo{recall coin example, internalize biases, sets of dists, etc.}
\end{example}
\begin{example}
\todo{Point to appendix where we discuss factor graph conversions: these internalize the energy}
\end{example}


\begin{vfull}
\subsection{HOW TO THINK OF PDGS}
\begin{itemize}
\item A bayesian network with explicit higher order edges
\item A vectorized / bundled version of conditional probability spaces that includes torsion
\item An attention-shaped diagram into the Markov Category
\item A second-order constraint on worlds that allows you to modify free energies.
\end{itemize}
\end{vfull}

\subsection{FUTURE WORK}
\todo{Real Sentences.} Categorical representation, details of sum-product algorithm on graphs with sub-distributions, the orginal goal: modeling dynamic preferences.

\begin{vfull}
\subsection{Inconsistency} \label{sec:consistency-ethos}

Believing a logically inconsistent formula can lead you to arbitrarily bad conclusions, having an infeasible set of constraints makes all answers you could give wrong, and having inconsistent preferences can lose you infinite money. We don't want to build inconsistent systems or agents with incoherent views of the world, and so, where possible, we design them so they cannot possibly be broken in this way. Suppose, for example, that we are trying to represent some quantity that must be a point on the unit circle. We could do it with an $x$ and $y$ coordinate, but this could be problematic because $x^2+ y^2$ might not be 1 --- it would be safer and harder to go awry if we parameterize it by an angle $\theta \in [0, 2\pi)$ instead. In the absence of performance benefits (like needing to regularly use the $y$-coordinate and not wanting to compute a sine), why would we take the first approach, introducing a potentially complex data-invariant, when we could avoid it?

This line of thought, though common and defensible, is flawed if we are not perfectly confident in the design of both our system and the ways it can interact with the outside world. Using similar logic, we might ask ourselves: Why ask programmers for type annotations when all instructions are operationally well-defined at run-time?  Why use extra training data if there's already enough there to specify a function? Why estimate a quantity in two ways when they will yield different answers? Why repeat and rephrase your ideas when this could make you contradict yourself? Why write test cases when they could fail and make the project inconsistent? Why conduct an experiment if it could just end up contradicting your current knowledge?

These questions may seem silly, but there is a satisfying information theoretic answer to all of them: redundancy, though costly, is the primary tool that we use to combat the possibility of being wrong. Maintaining data invariants can be expensive but provides diagnostic information; in the example above, settings of $x$ and $y$ that don't lie on the unit circle provide diagnostic information that something has gone wrong.
In many cases, it is also possible to paper over problems by forcibly re-instating local data invariants: for instance, we could re-normalize any values of $x$ and $y$ (so long as $xy \neq 0$; we can chose an arbitrary point otherwise) at every step. While this would reduce inconsistency, it also hides red flags.

Using a Bayesian Network to represent a probability distribution is like representing a circle with $\theta \in [0, 2\pi)$.
By construction, the result must be a distribution, and nothing can possibly go wrong so long as we can always decide on exactly one distribution which is sufficient for our purposes.
% By construction, the result must be a point on the circle, and nothing can possibly go wrong so long as we're sure that we will always have exactly enough information to determine such a point (for instance, we could never be totally clueless about the point, or just know its $x$ coordinate).


The process of mechanistically forcing invariants is homologous to the standard practice for factor graphs: practitioners will often just assume that the density it defines is normalizable, and either forcibly re-normalize or cleverly avoid computing the normalization constant while still assuming that one exists; behavior is usually left unspecified in the unlikely event that it is not defined or zero.
\end{vfull}

\section{CONCLUSION}
\subsection{A LIST OF \MN\ BENEFITS}\label{sec:list-of-benefits}
\begin{enumerate}[nosep]
\item \MNs\ can represent both over-constrained and under-constrained mental states.
\item In particular, they may be inconsistent, which gives agents using \MNs\ the qualitatively new kind of `epistemic modesty': the possibility of realizing that something is wrong with their beliefs.
\item Many standard algorithms, including as belief propogation, conditioning, and belief revision, can be regarded as resolution of inconsistency.
\item \MNs\ can emulate the functionality of other graphical graphical models.
\item \MNs\ are more modular, making it much less invasive to combine, reduce, or partially interpret parts of the model, compared to alternatives.
\item The modularity enables type-forming rules which can be used to implement deductive inference.
\item The many standard ways of adding and eliminating variables provides an answer to the question, ``why these possible worlds?''
\item Compared with a standard constraint satisfaction problem, individual components have of have limited impact on the semantics.
\item The class of free energies defined by \MNs\ is strictly more expressive than those given by alternative graphical models.
\end{enumerate} % trade-off: harder to analyze.

\subsubsection*{References}
\printbibliography[heading=none]

\onecolumn
\appendix

\section{Proofs}
\thmsetconvex*
\begin{proof}
Choose any two distributions $p, q \in \bbr{M}\SD$ consistent with $M$, any mixture coefficient $\alpha \in [0,1]$, and any edge $(A,B) \in \Ed$.

By the definition of $\bbr{M}\SD$, we have $p(B = b \mid A = a) = q(B = b \mid A = a) = \bmu_{A,B}(a,b)$.
For brevity, we will use little letters ($a$) in place of events ($A = a$).
Therefore, $p(a\land b) = \bmu_{A,B}(a,b) p(a)$ and $q(ab) = \bmu_{A,B}(a,b) q(a)$. Some algebra reveals:
\begin{align*}
\Big( \alpha p + (1-\alpha) q \Big) (B = b \mid A = a) &=
\frac{\Big( \alpha p + (1-\alpha) q \Big) (b \land a)}{\Big( \alpha p + (1-\alpha) q \Big) (a)} \\
&= \frac{ \alpha p(b \land a) + (1-\alpha) q(b \land a) }{\Big( \alpha p(a) + (1-\alpha) q (a)} \\
&= \frac{ \alpha \bmu_{A,B}(a,b) p(a) + (1-\alpha) \bmu_{A,B}(a,b) q(a) }{\Big( \alpha p(a) + (1-\alpha) q (a)} \\
&=\bmu_{A,B}(a,b) \left(\frac{ \alpha  p(a) + (1-\alpha) q(a) }{\Big( \alpha p(a) + (1-\alpha) q (a)}\right)\\
&= \bmu_{A,B}(a,b)
\end{align*}
and so the mixture $\Big(\alpha p + (1-\alpha) q \Big)$ is also contained in $\bbr{M}\SD$.
\end{proof}


\thmzetaconvex*
\begin{proof}
It is well-known that $D_{KL}$ is convex, in the sense that
\[ D_{KL}(\lambda q_1 + (1-\lambda) q_2 \ ||\ \lambda p_1 + (1-\lambda) p_2) \leq \lambda D_{KL} (q_1\ ||\ p_1) + (1-\lambda) D_{KL}(q_2\ ||\ p_2) \]
Choose any edge $L \in \Ed$ from $A$ to $B$, and also any $a \in \mathcal V(A)$.
Setting $q_1 = q_2 = \bmu_L(a)$, we get
\[ D_{KL}(\bmu_L(a) \ ||\ \lambda p_1 + (1-\lambda) p_2) \leq \lambda D_{KL} (\bmu_L(a) \ ||\ p_1) + (1-\lambda) D_{KL}(\bmu_L(a)\ ||\ p_2) \]
Since this is true for every $a$ and edge, we can take a weighted sum of these inequalities for each $a$ weighted by $p(A=a)$, and therefore
\begin{align*}
\E_{a\sim p(A=a)} D_{KL}(\bmu_L(a) \ ||\ \lambda p_1 + (1-\lambda) p_2) &\leq \E_{a\sim p(A=a)}\lambda D_{KL} (\bmu_L(a) \ ||\ p_1) + (1-\lambda) D_{KL}(\bmu_L(a)\ ||\ p_2) \\
\sum_{(A, B) \in \cal L}~\E_{a\sim p(a)} D_{KL}(\bmu_L(a) \ ||\ \lambda p_1 + (1-\lambda) p_2) &\leq \sum_{(A, B) \in \cal L}~\E_{a\sim p(A)}\lambda D_{KL} (\bmu_L(a) \ ||\ p_1) + (1-\lambda) D_{KL}(\bmu_L(a)\ ||\ p_2) \\
\zeta(M ; \lambda p_1 + (1-\lambda)p_2) &\leq \lambda \zeta(M;p_1) + (1-\lambda) \zeta(M;p_2)
\end{align*}
\end{proof}





\section{Alternate Presentations}
\subsection{Random Variables}
If $\mathcal W = (W, \mathcal F, \mu)$ is a measure space, and $\mathcal X = \{ X_i: W \to \mathcal V(X_i) \}_{i \in I} $ is a collection of measurable random variables on $W$,\footnote{that is: $\mathcal V(X_i)$ is a measurable space, taking the form $(D, \mathcal D)$, and $X_i : W \to D$ is a set function such that for every $B \in \mathcal D$, the set $X_i^{-1}(B) \in \mathcal F$} and
{\color{gray}$\Ed \subseteq I \times I$ is a collection of pairs of variables such that the agent }
\todo{what is a way of phrasing this that doesn't sound like it's shoehorned in? $\Ed$ really can represent anything an agent knows. Any subjective conditional probability distribution $\mu'$ such that the only measurable subsets are ``axis aligned'', in that they involve queries on only one variable, can be represented by $\Ed$, and for other queries we can simply change variables.}, we call $(\cal W, X)$ an \emph{ensemble}.
%and $(W, \mathcal F', p)$ is a subjective probability representing an agent's belief


\begin{prop}
There is a natural correspondence between strict \MNs\ as defined in \Cref{def:model}, and ensembles such that \todo{spell this out explicitly to avoid vague categorical intuition} \ldots $\mu$'s are defined on same set and produce same values.
\end{prop}
\begin{proof}
\textit{/outline:}
On the one hand, $(\prod_{N \in \cal N} \mathcal V(N).\text{set}, \bigotimes_{N \in \cal N} \mathcal V(N).\text{algebra}, \bmu)$ is a measure space, with $\{X_N = \pi_N : \left(\prod\mathcal V(N')\right) \to  \mathcal V(N) \}_{N \in \cal N}$ a set of random variables

and  on the other, $(I, \Ed, \mathcal X', \mu|_{\cal L})$ is a strict \MN.
\end{proof}

This is the technical underpinning of our flippant, noncommittal treatment of possible worlds: any time we are thinking in terms of random variables or probability distributions on a fixed set $W$, we can instead reduce


The complexity of the representation is $O(XV + L V^2)$, compared to $O(XW)$

\subsection{Hyper Graph Conversion}\label{sec:hyper-convert}
\begin{example}[continues=ex:planet]
Earlier in example \ref{ex:planet}, we displayed the arrow from $S$ and $C$ to $L$ as a directed hyper-edge. While we would like to maintain this intuition, the way to do this is using only graphs with edges, as in \Cref{def:model}, is to use intermediate nodes:

\begin{center}
\begin{tikzpicture}
\node[dpadded] (S) at (-0.5, 2) {$S$};
\node[dpadded] (C) at (3.1, 2) {$C$};
\node[dpadded] (L) at (1.3,0) {$L$};
\node[dpadded] (W) at (-2,0) {$W$};

\node[dpadded,light pad] (SC) at (1.3, 1.4){\footnotesize $S \times C$};

\draw[arr, ->>] (SC) -- (S);
\draw[arr, ->>] (SC) -- (C);
\draw[arr] (SC) -- (L);
\draw[arr] (W) -- (L);
\end{tikzpicture}
\end{center}
We will sometimes use double headed arrows like this to emphasize degenerate conditional distributions, which are deterministic.
We can now present this \MN\ formally with the elements specified in definition \ref{def:model}.

\hfill\begin{minipage}{0.4\textwidth} 
\begin{align*}
&\mathcal N = \{S,~ C, ~L, ~W, ~S\times C \} \\
&\Ed = \{ (S \times C, L), (W, L), (S\times C, S), (S\times C, C)\} \\
\mathcal V &\left\{\begin{aligned}
\mathcal V(S) &= \{\mathit{b}, \mathit{s} \}\\
\mathcal V(C) &= \{ \mathit{r}, \mathit{g} \} \\
\mathcal V(L) &=  \{ l, \lnot l \} \\
\mathcal V(W) &= \{ \textit{none}, \textit{some}, \textit{mostly}\}\\
\mathcal V(S \times C) &= \mathcal V(S) \times \mathcal V(C)
% = \small\text{$\{(big, rocky), (small,rocky), (big, gasseous), (small,gasseous)\}$}
\end{aligned}\right.\\
\end{align*}
\end{minipage}%
\begin{minipage}{0.5\textwidth}
\begin{align*}
\bmu & \left\{~\begin{aligned}
\boldsymbol\mu[S\times&C, L] = &\boldsymbol\mu[S\times&C, S] = \\[-0.6em]
&\begin{idxmat}{{b,s}, {s,r}, {b, g}, {s,g}}{$l$,$\lnot l$}
.1 & .9 \\
.2 & .8 \\
.05 & 0.95 \\
0.001 & 0.999
\end{idxmat}
&&
\quad\begin{idxmat}{{b,s}, {s,r}, {b, g}, {s,g}}{s,b}
0 & 1 \\
1 & 0 \\
0 & 1 \\
1 & 0
\end{idxmat}
\\[0.5em]
\boldsymbol\mu[W, &L] =  &\boldsymbol\mu[S\times&C, C] =\\[-0.6em]
&\begin{idxmat}{{none}, {some}, {mostly}}{$l$,$\bar l$}
0 & 1 \\
.005 & .995 \\
.05 & 0.95 \\
\end{idxmat}
&&
\quad\begin{idxmat}{{b,s}, {s,r}, {b, g}, {s,g}}{r,g}
1 & 0 \\
1 & 0\\
0 & 1 \\
0 & 1
\end{idxmat}
\end{aligned}\right.\\[-1em]
\end{align*}
\end{minipage}
\vspace{0.5em}

This works, but the structural overhead of the additional de-sugaring: the $\boldsymbol\mu[S\times C\to S]$ and $\boldsymbol\mu[S\times C\to C]$ tables, as well as the set $\mathcal V(S \times C)$ seem like they didn't need to be specified, and one might even feel that it would be a mistake to allow any other table. Some reasons for this design decision include:
\begin{itemize}[nosep]
\item It is easier to prove things about graphs than directed hyper-graphs. Similarly, defining composition and paths becomes a lot simpler.s
\item We can eliminate the clunkiness by fusing the model with an algebra, as in \Cref{sec:algebra} --- which will give us a lot more than modeling the hyper-edges directly.
\item We will eventually also want to allow for the possibility of keeping only a relaxed, approximate representation of $\mathcal V$ and $\bmu$, and in particular, of the ones constructed logically in this way. By specifying them explicitly for now, we will have to do less work to regain manual control in \Cref{sec:abstraction}
\end{itemize}
\end{example}


The choice to formalize \MNs\ this way is a design consideration that makes some things cleaner, but we can just as well formalize multi-tailed edges directly, as follows:

\begin{defn}[\MNH]\label{def:modelhyper}
A \textit{\modelnamehyper} (\MNH) is tuple $(\N, \boldsymbol\Ed, \V, \bmu)$ where $\N$ and $\V$ are as before, $\boldsymbol\Ed \subseteq 2^\N \times 2^\N \times \mathrm{Label}$ is a set of `hyper-edges', i.e., edges whose source and target are sets of nodes, and for each edge $L = ({\bf A, B}, \ell) \in \boldsymbol\Ed$, we have a table of distributions $\bmu_L$ on \emph{joint settings} of the variables in the set $\bf B$ for each joint setting of the variables in $\bf A$.
\end{defn}

\Cref{thm:hyperequiv} shows \MNs\ and \MNH s to be equivalent, though in different cases one may seem more natural than the other, as illustrated in the following theorem.

\begin{theorem}[restate=thmhyperequiv]\label{thm:hyperequiv}
Every \MNH\ $H$ is equivalent to a \MN\ $\sfM$ with additional variables. That is, for each semantics $\bbr{-}$ we define, $\bbr{H} = \bbr{\sfM}$.
\end{theorem}
\begin{proof}
\todo{}
\end{proof}

This theorem justifies taking the \MN\ as primary, an ordinary collection of nodes and edges, which makes it cleaner to define and compose paths.


\section{Formalism for other Graphical Models}
\begin{defn}
A Baysian network (BN) is a tuple
\[
\mathcal B = \left(\mathcal N : \mathbf{FinSet}, ~~\mathrm{Par}: \mathcal N \to 2^{\mathcal N},~~ \mathcal S: \mathcal N \to \mathbf{FinSet},~~\Pr: \prod_{N : \mathcal N}  \left[ \mathcal S_N \times \left(\prod_{P : \mathrm{Par}(N)} \mathcal S_P\right)  \to [0,1] \right] \right)
\]
such that
\begin{itemize}[nosep]
\item the graph $\bigcup_{N, P \in \mathrm{Par}(N)}(N, P)$ is acyclic, i.e., there exists no cycle of nodes $N_0, N_1, \cdots, N_k = N_0$ in $\mathcal N^k$ such that $N_{i+1} \in \mathrm{Par}(N_i)$ for each $i \in \{0, 1, \cdots, k\}$.
\item For all $N \in \mathcal N$, $\Pr(N)$ is a probability distribution on $\mathcal S_N$, i.e.,
\[ \forall N\in \mathcal N.~\forall \vec{p} \in {\prod_{P : \mathrm{Par}(N)} \mathcal S_P}.~~ \sum_{n \in \mathcal S_{N}} \Pr_N(\vec{p}, n) = 1\]
\end{itemize}
\end{defn}


\begin{defn} \label{def:bnconvert-formal}
If $B = (\mathcal N, \mathrm{Par}, \mathcal S, \Pr)$ is a Bayesian Network, then let $\Gamma (B)$ denote the corresponding \MN\ given by the procedure in \Cref{sec:bn-convert}. Explicitly,
\[ \Gamma\mathcal B :=  (\mathcal N', \Ed, \mathcal V, \bmu) \]
where % $\mathcal N'$ is the original nodes, plus
\begin{align*}
\mathcal N' &=  \left\{ \Big.\{N\} \mid N \in \mathcal N\right\} \cup \left\{ \mathrm{Par}(N) ~\middle|~ N \in \cal N \right\} \\%
\Ed &= \left\{ \vphantom{\Big|}(\mathrm{Par}(N), \{N\}) \mid N \in \mathcal N \right\} \cup
\left\{\vphantom{\Big|} (P, \{X\}) \mid X \in P, P = \mathrm{Par}(N) \text{ for some }N \in \mathcal N \right\} \\
\mathcal V_N &= \prod_{X \in N} \mathcal S_X \\
% {\color{gray}\Sigma_N = \bigotimes_{X \in N} 2^{\mathcal S_X}, \text{the product algebra of discrete $\sigma$-algebras}} \\
\mathbf p &= \begin{cases}
(\mathrm{Par}(N), \{N\}) &\mapsto \lambda(p, B).~ \displaystyle\sum_{b \in  B} \Pr(b \mid p) \\
(P, X) &\mapsto, \lambda (p, B).~ \displaystyle \mathbbm 1_{\displaystyle\pi_X(p) \in B}
\end{cases}
\end{align*}
%\cpm p(\frac{a}{z}|b)
\end{defn}
All we've done is explicitly add parent nodes and projection edges to our graph, and also subtly (by adding curly braces in the right places and taking unions rather than disjoint unions) eliminated the duplicate nodes arising from edges in the original BN which only have a single parent.

\section{Thermodynamics}\label{sec:thermo-background}
Let $W$ be a finite set of states.

\textbf{From Potentials to Distributions.}
Suppose $U: W \to \mathbb R$ is a potential function, assigning an energy to each state. Imagine there's a particle that could be in any number of states, that the only consideration in transitioning from one state $w$ to another $w'$ is the energy of each state,%
\footnote{The thermodynamics, of course, ignore the kinetics of the system. Thought of an Ising model, the edges form a complete graph, and the edge weights are uniform. Thought of as a stochastic matrix, it is rank one, whose latent variable is just the energy of a state.}
and that low-energy states are more exponentially more likely,\footnote{this can also be replaced by weaker assumptions; see the thermodynamics literature for more motivation}
the unique stationary state is the Boltzmann distribution:
\begin{equation}
 \mu(w) \propto \exp( - U(w) / kT ) \label{eq:boltzmann-appendix}
\end{equation}

where $k$ is the Boltzmann constant and $T$ is the thermodynamic temperature. Note that at unboundedly high temperatures, the differences between potentials don't matter (all states are equally likely), whereas at as the temperature approaches zero, the Boltzmann distribution puts zero mass on anything that's not a global minimum, and otherwise splits the mass equally. Therefore, if $U$ achieves a unique global minimum $w^*$, the corresponding $\mu(w) = \delta_{w,w^*}$ is a point mass on the minimum energy world $w^*$.

It is standard and notationally useful to re-parameterize with the inverse temperature $\beta := 1/kT$ -- and we will refer to the Boltzmann distribution associated to a given potential $U$ (and inverse temperature $\beta$) as
\[ P_{\beta}(U) := w \mapsto  \frac{1}{Z_U(\beta)}\exp\Big(-\beta U(w)\Big) \]
Where $Z_U(\beta) = \sum_{w \in W} \exp(-\beta U(w))$ is a normalizing factor, sometimes called the ``partition function''. 

\textbf{From Distributions to Potentials}. 
On the other hand, under similar assumptions, if given a probability distribution $\mu$ over $W$, there is a natural potential energy that resulted in it,
\[ E_{\beta}(\mu) := w \mapsto \frac{1}{\beta} \ln \left(\frac{1}{\mu(w)}\right)  \]
which might be recognizable as negative log liklihood or the ``surprise'' of an event happening. By construction, $P_\beta \circ E_\beta$ is the identity on probability distributions:
\begin{align*}
 \Big(P_\beta \circ E_\beta(\mu)\Big) (w) &= \frac{1}{Z_{ E_\beta (\mu) }} \exp \left( - \ln \left(\frac{1}{\mu(w)}\right) \right) \\
 &= \left(\frac{1}{\sum\limits_{w' \in W} \mu(w')}\right)\mu(w) \\
 &= \mu(w)
\end{align*}
and $E_\beta \circ P_\beta$ is the identity on potential functions (up to a constant factor):
\begin{align*}
\Big(E_{\beta}\circ P_\beta(U)\Big)(w) &= \frac{1}{\beta} \ln \left(\frac{1}{\frac{1}{Z_U(\beta)}\exp(-\beta U(w))}\right) \\
&=  \frac{1}{\beta} \Big[\ln Z_U(\beta) - (-\beta U(w)) \Big]\\
&= U(w) + \frac{1}{\beta} \ln Z_U (\beta)
\end{align*}
The constant factor $-\frac{1}{\beta} \ln Z_U(\beta)$ coincides with the Heimholtz free energy of the system. Note that at constant temperature, this quantity is a durable feature of either a distribution or its associated energy landscape.
% 
% \begin{align*}
%  0 = -\frac{1}{\beta} \ln Z_U(\beta) &= - \frac{1}{\beta} \ln \sum_{w \in W} \exp(-\beta U(w)) \\
%  \iff 1 = \sum_{w \in W} \exp(-\beta U(w))
%%   &= -\frac{1}{\beta} \mathop{\mathrm{LSE}}_{w \in W}(-\beta U(\beta))
% \end{align*}

\textbf{Free Energy and Favorability.} Given a potential $U$, corresponding to a distribution $\mu$ as above, we now turn the question of how thermodynamically favorable a new distribution $\nu$ would be.%
\footnote{From a statistical mechanics perspective, $W$ are the micro-states of the system, and a distribution over them is a configuration, or a macro-state.}
For which we use the Gibbs free energy, $G_U(\nu) := {\E}_\nu( U ) - \frac{1}{\beta} H(\nu)$, which we think of a system as minimizing. The intuition here is that our new distribution $\nu$ is favorable if it has low average energy. However, at higher temperatures it also costs energy to compress the distribution: while a point mass at the minimum value of $U$ may be the lowest energy distribution, tightly controlling it to that degree also costs energy, when there's some ambient temperature causing randomness. From an epistemic perspective, even if a belief distribution $p$  is the one that best fits constraints, one might want to temper this by other possible configurations, and more so when there's higher ambient macroscopic uncertainty (temperature). Note also that the Gibbs Free Energy is a weighted probability distribution: it assigns a `favorability' score to distributions.

If $U$ was generated by a probability distribution $\mu$, we then have

\begin{align*}
G_\mu(\nu) &= {\E}_\nu( E_\beta(\mu) )  - T S(\nu) \\
&= \sum_{w \in W}\nu(w) \frac{1}{\beta} \ln \left(\frac{1}{\mu(w)}\right) - T \left[k \sum_{w \in W} \nu(w) \ln \left(\frac{1}{\nu(w)}\right)\right]\\
&=  \frac{1}{\beta}\left[\sum_{w \in W}\nu(w) \ln \left(\frac{1}{\mu(w)}\right) - \sum_{w \in W} \nu(w) \ln \left(\frac{1}{\nu(w)}\right)\right]\\
&=  \frac{1}{\beta}\left[\sum_{w \in W}\nu(w) \left(\ln \frac{1}{\mu(w)} - \ln \frac{1}{\nu(w)}\right)\right]\\
&= \frac{1}{\beta} D \left(\nu || \mu \right)
\end{align*}

Where $D(\nu || \mu)$ is the relative entropy from $\nu$ to $\mu$.

Note that \todo{}
\begin{enumerate}
\item By Gibbs inequality, the $D(\nu || \mu) \geq 0$, and equal to zero precisely when $\nu = \mu$, and so the free energy of a configuration $\nu$ in a potential that was designed for $\mu$ is minimized by $\mu$ itself.

\item
\end{enumerate}






\textbf{Free Energy as a Design Tool.}

This connection between thermodynamics and probability theory is already well utilized:
\begin{enumerate}
\item A Markov Random Field is specified with potentials $U_e$ for each edge; a factor graph is specified with potentials for a subset of cliques.
\item The belief propagation algorithm computes local minima of the Bethe free energy, an approximation to the true Gibbs free energy.
\end{enumerate}


The dominant representation tool for mental states is the probability distribution, rather sets or weighted sets of them. % This is partly because they are easier to compute with, and because when faced with decisions at gun point, they are the most
One issue with this is that there are distinct mental states that collapse to the same probability distribution (e.g., the coin flip: being uncertain about a process vs its outcome). The second one is that one might not have the right space for the distribution

The insight here is that these are related: one can simply internalize the structure of the uncertainty. This some precedent for this: Pearl's rule, for instance, prescribes a new random variable to describe the uncertainty. 
%%%

Consider a factor graph on a set of variables $\{ X_i \}$, with only a single factor $\phi$ which connects to every variable. The free energy is $G_\phi(U)$

\[ \frac{1}{\sum_{\vec x} \phi(\vec x)} \phi(u) \]

% The normalization constant $Z = \sum_{\vec x} \phi(\vec x)$

Any factor graph defines a free energy by \todo{finish}

The Bethe approximation to the free energy is an estimate based only on the marginals on single pairs of nodes.

With a \MN\, the free energy becomes
\[ \sum \]
\todo{Write out $\zeta$, proofs of theorems}

\section{Overview And Conversions Between Graphical Models}
\label{sec:many-relations-graphical-models}

\todo{There is a ton to do here.}


\section{Structure-editing \MN\ Operations}

While both \MNs\ and \MNH s are equivalent, and despite the fact that dealing with sets of variables is standard, we chose \MNs\ over \MNH s as the face of the paper. One of the primary reasons to do this is that it puts products on equal footing with other equally valid structural modifications we could have done instead, rather than specializing the definitions for products.

\begin{enumerate}
\item Latent variable nodes, e.g., through VAEs. Useful for representation learning and modeling bounded agents that just remember the gists of things.

\item Sums nodes. For when one is being forced to chose between two options which might otherwise be unrelated, and the basic constructor for variables from points.

\item Exponential nodes. Any positive temperature arrow can be reasoned about through expansion into its parameters.

\item Compression nodes: e.g., truncation nodes for propositions. It may not matter exactly what proof you have so long as you've proved one exists. That a variable takes a value may be just as important as it.
\end{enumerate}


\section{More Examples}\label{sec:more-examples}

\begin{example}
\label{ex:corrob}
\end{example}


\begin{vcat}
\section{Categorical Presentation}
\note{I will not put any time into this, as it's not going in the paper, but it's here as a placeholder, and I'll list some reasons why this is worth thinking about.}
One reason this works out so nicely is every construction is universal. We can in fact give a simpler categorical presentation of \MNs\ for those who already know category theory. The highlights are as follows:
\begin{enumerate}
\item A \MN\ is an attention-shaped diagram in the Markov category. That is, functor from the free category generated by the graph $(\mathcal N, \Ed)$ representing attention, to the Markov category. Indeed $\mathcal V$ is the action on objects, assigning each $\mathcal N$ to a measurable set, $\bmu$ is the action on morphisms, sending edges in $\Ed$ to Markov kernels between their associated objects.
\begin{enumerate}
\item Composition works out in general as we place no restrictions on anything, but
\item If every edge in $\Ed$ represents the causal structure of their relationship, then the image of the resulting diagram will be flat, and so effectively there will only be at most one, belief, and no possibility of conflict.
\item Interpreting with a different model of uncertainty (such as the powerset, giving us non-deterministic possibility) is simply an exchange of interpretation. However, for nice interaction with deterministic functions and logic, this notion of uncertainty must be a monad.
\end{enumerate}

\item This highlights the role of the ``qualitative'' and ``quantitative'' versions of this framework (which work out much more cleanly than for BNs in a categorical sense)

\item A limit of this diagram is a space of worlds and all of the random variables as functions. A colimit is a the strongest thing that must be true according to the model (suspicion: this is somehow related to common knowledge). There is some strangeness about how samples work that I have not yet figured out.
\end{enumerate}


\section{Algebra}\label{sec:algebra}
\begin{defn}
If $\sigma$ is a signature, a $\sigma$-\MN\ $M'$ on a \MN\ $M=(\mathcal N, \Ed, \mathcal V, \mu)$ is a \modelname\ $(\mathcal N', \Ed', \mathcal V', \mu')$ such that
\begin{itemize}
\item $\mathcal N':= T_\sigma(\mathcal N)$ is the term algebra for the signature $\sigma$ over the alphabet $\Sigma = \mathcal N$.
\item $\Ed' = \Ed \cup \Ed^\sigma$ is $\Ed$ extended with extra edges for operations that are
\end{itemize}
\end{defn}

\begin{example}
content
\end{example} 
\end{vcat}


