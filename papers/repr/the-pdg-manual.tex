% !TeX TXS-program:bibliography = txs:///bibtex
\documentclass{article}

\input{the-pdg-manual.preamble.tex}
\usepackage[margin=1in]{geometry}


\newcommand{\commentout}[1]{\ignorespaces} 
\newif\ifprecompiledfigs
\precompiledfigsfalse
% \precompiledfigstrue

\newif\ifexternalizefigures\externalizefiguresfalse
\ifexternalizefigures
	\usetikzlibrary{external}
	\tikzexternalize[prefix=tikz/]  % activate!
	\usepackage{etoolbox}
	 \AtBeginEnvironment{tikzcd}{\tikzexternaldisable} %... except careful of tikzcd...
	 \AtEndEnvironment{tikzcd}{\tikzexternalenable}
\fi

%\twocolumn
\title{The PDG Manual}
\author{Oliver Richardson  \texttt{oli@cs.cornell.edu}}

\begin{document}

	\maketitle
	\tableofcontents
	%\listoffigures
	% \listoftheorems
	\clearpage
	%some day...
	% \twocolumn 
	\part{The PDG Representation}
	\section{Introduction to PDGs}
In this paper we introduce yet another graphical for modeling beliefs,
\emph{Probabilistic Dependency Graphs} (PDGs). There are already many
such models in the literature, including Bayesian networks (BNs) and
factor graphs. (For an overview, see \citeauthor{KF09}.)
Why does the world need one more?  

Our original motivation for introducing PDGs was to be able capture
inconsistency. We want to be able to model the process of resolving
inconsistency; to do so, we have to model the inconsistency itself. But our
approach to modeling inconsistency has many other advantages. In particular,
PDGs are significantly more modular than other directed graphical models:
operations like restriction and union that are easily done with PDGs are
difficult or impossible to do with other representations.

We start with some examples to motivate PDGs and illustrate some of these properties.  

\begin{example}[the simplest inconsistency] \label{ex:guns-and-floomps}
Grok is visiting a neighboring district. From prior reading, she thinks it likely (probability
.95) that guns are illegal here. Some brief conversations with locals lead her to believe believe with
probility .1, that the law prohibits floomps.

% The obvious way to represent this as a BN involves two binary random variables,
% $F$ (taking values $\{f, \overline f\}$), indicating the legality of floomps,
% and $G$ (taking values $g, \overline g$) indicating the legality of guns. 
The obvious way to represent this as a BN is to use two random variables
$F$ and $G$ (respectively taking values $\{f, \smash{\overline f}\}$ and $g, \overline g$), indicating the respective legalities of owning floomps and guns.
%oli12 no paragraph break here.
The semantics of a 
%oli12
% Bayes Net
BN
offer her two choices: either assume that $F$ and $G$
% are independent and give (unconditional) probabilities of $F$ and $G$, or we
to be independent and give (unconditional) probabilities of $F$ and $G$, or
choose a direction of dependency, and give one of the two unconditional
probabilities and a conditional probability distribution. 
%oli12:
% As there is no reason
% to believe that either variable depends on the other, 
As there is no reason to choose either direction of dependence, the
natural choice is to 
assume independence, giving her the 
%oli12: combining figures
BN on the left of \Cref{fig:gun-floomp-diagram}.
%following BN

\begin{figure}[htb]
%joe11*: why are some parts of the figure in light gray?  I would prefer
%to make it all black.  If we use a different color, we have to
%explain why.  
  \centering
\ifprecompiledfigs
	\raisebox{-0.5\height}{\includegraphics[scale=0.8]{figure-pdfs/fg-BN}}
	% \raisebox{-0.5\height}{\includegraphics[scale=0.8]{fg-BN}}
~\vrule~
	\raisebox{-0.5\height}{\includegraphics[scale=0.8]{figure-pdfs/fg-PDG}}
	% \raisebox{-0.5\height}{\includegraphics[scale=0.8]{fg-PDG}}
\else
	% \scalebox{0.8}{
    \begin{tikzpicture}[center base, scale=0.7, AmpRep]
        % \def\figtabledist{1.4}
        % \def\fignodedist{1.2}
        % \def\figtableheight{0.22}
        \def\figtabledist{0.2}
        \def\fignodedist{1.4}
        \def\figtableheight{0.41} 

        \matrix [table with head, column 1/.style={leftrule}, anchor=south east,
             column 2/.style={rightrule}, row 2/.style={bottomrule}] at (-\figtabledist,\figtableheight) {
            \vphantom{$\overline fg$} $f$ \& \vphantom{$\overline fg$}$\overline f$\\
            .9 \& .1\\
        };
        \matrix [table with head, column 1/.style={leftrule}, anchor=south west,
             column 2/.style={rightrule}, row 2/.style={bottomrule}] at (\figtabledist,\figtableheight) {
             \vphantom{$\overline fg$}$g$ \& \vphantom{$\overline fg$}$\overline g$\\
             .05 \& .95\\
        };
        \node[dpadded, circle, fill=black!08, fill opacity=1] (floomp) at (-\fignodedist,0) {$F$};
        \node[dpadded, circle, fill=black!08, fill opacity=1] (gun) at (\fignodedist,0) {$G$};
    \end{tikzpicture}
    ~~\vrule~~
	\begin{tikzpicture}[center base]

        \def\fignodedist{2.1}
        \def\fignodeheight{1.1}
        \def\newcptX{-0.3}
        \def\newcptY{-0.1}
                     
		\node[dpadded, fill=white, draw=gray] (true)  at (0,1.8) {$\var 1$};
		\node[dpadded] (floomp) at (-\fignodedist,\fignodeheight) {$F$};
		\node[dpadded] (gun) at (\fignodedist,\fignodeheight) {$G$};			
		
		\draw[arr] (true) to[bend left=0] coordinate(A) (floomp);
		\draw[arr] (true) to[bend right=0] coordinate(B) (gun);

		\node[above left=2.0em and 1.5em of A, anchor=center] {
        %oli14 fix gray.
			% \begin{idxmat}{\!\!\!$\star$\;\;\;}{$f$, $\overline f$}
			\begin{idxmat}[\color{black}\smalltext]{\!\!\!$\star$\;\;\;}{$f$, $\overline f$}
				.90 & .10 \\
			\end{idxmat}
		};
		\node[above right=2.0em and 1.3em of B, anchor=center] {
        %oli14
        % \begin{idxmat}{\!\!\!$\star$}{$g$, $\overline g$}
			\begin{idxmat}[\color{black}\smalltext]{\!\!\!$\star$}{$g$, $\overline g$}
				.05 & .95 \\
			\end{idxmat}
		};
		\definecolor{heldout}{rgb}{0.6, 0.6, .6}	
		\draw[heldout, dashed, arr] (floomp.-30) to[bend right=7] node[pos=0.65, fill=white, inner sep=2pt] (C) {$\smash{p}\vphantom{v}$} (gun.210);
        %oli12: addes reverse arrow, edited the above line with a yshift.
        \draw[heldout, dashed, arr] (gun.190) to[bend left=5] node[pos=0.668, fill=white, inner sep=2pt] {$\smash{p'}\vphantom{v}$} (floomp.-10);
		\node[anchor=center] (newcpd) at (\newcptX,\newcptY) {
			\color{heldout}
			$\mat p =\!\!\!$\begin{idxmat}[\color{heldout}\smalltext]{$f$,$\overline f$}{$g$, $\overline g$}
%joe12
%			  .92 & 0.08 \\ .08 & .92 \\
			  .92 & .08 \\ .08 & .92 \\
          \end{idxmat}$~=~{\mat p'^{\textsf T}}$
		};
        % \node[below=3pt of newcpd] {\color{heldout}$\mat p' = \mat p^{\textsf T}$};
	\end{tikzpicture}
	% }
\fi
    %oli12 update caption accordingly.
    %oli12: note before editing caption: making it fit on one line is not easy.
	% \caption{An inconsistent PDG, requiring resolution}
%joe11
%        \caption{A BN (left), and respective PDG (right), which can
%oli19: added word "simple" BN
%joe17: why did you add it?  What is a simple BN?
%oli20: Nothing technical. It doesn't look very much like a BN and I
%wanted to assure  
% readers that nothing strange is going on here. I trust your judgement and gether you
% think it's negative, and so am pre-emptively reverting it.
        \caption{A BN (left) and corresponding PDG (right), which can
        include more cpds; $p$ or $p'$ make it inconsistent.} 
    \label{fig:gun-floomp-diagram}
\end{figure}

%oli12
% Now suppose that you later discover that
A traumatic experience a few hours later leaves Grok believing that
%joe11
%``floomp'' is likely (92\%) to be another word for gun.
``floomp'' is likely (probability .92) to be another word for gun.
%oli12: I've removed the directionality by adding arrows in both directions.
%, and come to believe that if floomps are legal (resp., illegal), then
% there's a  chance guns are as well, and vice versa. 
%joe7: r seems like a atrange letter to use, although it's not a big deal
%oli12: I don't care about the letter. let's use p? Also this notation, while 
% you might not like it, is the consensus, especially in the conference we're 
% submitting to. We're already giving them something quite out of the ordinary;
% I don't want  to push it too far.  It's also expedient here as it lets us 
% immediately indicate the direction.
Let $p(G \mid F)$ be the \emph conditional \emph probability \emph
distribution (cpd) that describes 
the belief that if floomps are legal (resp., illegal),
%joe11
%then with 92\% probability, guns are as well, and $p'(F \mid G)$ be
then with probability .92, guns are as well, and $p'(F \mid G)$ be
the reverse. 
%oli12:
% A first reaction might be to
Starting with $p$, Grok's first instinct is to
simply incorporate the conditional information by adding $F$ as a parent of
$G$, and then associating
the cpd
$p$ with $G$. But then what should she do
with the original probability she had for $G$?  Should she just discard it?
It is easy to check that there is no 
%oli12
% probability distribution 
joint distribution
that is consistent with
%oli12 inserted
both
the two original priors on $F$ and $G$ and also 
%oli12: already lots of commas in this sentence. saying "the cpd" too often also gets to be a lot....
%the cpd $\mat r$, so if she
%joe11
%$p$---so if she
$p$.  So if she
is to represent the information with a BN, which always represents a consistent
distribution, she must resolve the inconsistency. 





However,
%oli12: rewrote paragraph.
% it may be better not to sort this out right away. 
% How to resolve it may be clearer 
% if you can get confirmation that guns are indeed floomps, or read the
% laws more carefully.
sorting this out immediately may not be ideal.
For instance, if the inconsistency arises from a conflation between
two definitions 
of ``gun'', a resolution will have destroyed the original cpds. A
better use of computation may be to notice the inconsistency and look
up the actual law. 

By way of contrast, consider the corresponding PDG. In a PDG, the cpds are
attached to edges, rather than nodes of the graph.
%oli12: this discussion is a distraction; it has nothing to do with PDGs over BNs.
 % we don't mention matrices anywhere else anymore, and the matrix representation
 % in the figure is both a common and inutuitive way of describing this
%
% The cpd associated with an
% edge $e$ from $X$ to $Y$ is a matrix $\mat e$, where the element $\mat e_{x,y}$
% at row $x$ and column $y$ is the conditional probability $\Pr(Y \!\!=\!\!y \mid
% X \!\!=\!\! x)$. 
In order to represent unconditional probabilities, we introduce
a \emph{unit variable} $\var 1$ which 
%oli12: no reason to be too verbose here; more important stuff is coming.
% takes on only one possible value, which we denote
takes only one value, denoted
$\star$. 
%oli12: Thus, we have
This leads Grok to 
the PDG depicted in \Cref{fig:gun-floomp-diagram},
where the edges from $\var 1$ to $F$ and $G$ are associated with the
unconditional probabilities of $F$ and $G$, and the 
%oli12
%edge from $F$ to $G$ is associated with the cpd $p$. 
edges between $F$ and $G$ are associated with $p$ and $p'$.



%joe11: if we make everything black, we should get rid of ``black'' in
%the next line.
The original state of knowledge consists of all three nodes and the two
%oli13: the important bit is that they're solid. I'm trying to
%linguistically  exclude the blue/ dashed lines.
% black
solid
edges from $\var 1$. This is like Bayes Net that we considered above,
%joe11
%except we
except that we 
no longer
%oli12! 
explicitly
%joe11
%oli13:  :(  I think "to be" sounds way better. It's shorter, it doesn't expend
% our limited supply of "and", "that" and "are", which tiring quickly. It sounds
% cooloer. That's also definitely how I would say it in person; I
% think the "that 
% ... are" sounds like you're talking to someone you only trust to know simple 
% grammar --- but in fact, "to be" often taught earlier when people learn English
% as a foreign language, so this form is shorter and without an accesibility 
% cost.
% I believe the infinitive also strengthens the statement by not implying a 
% present tense (how is time relevant here?). I'm changing it back. If you have 
% a reason for your aesthetic preference that you think objectively outweighs this
% consideration to a significant degree, you can change it back and I will 
% accept it without argument, but ask you why later.
%
% assume that $F$ and $G$ are independent; we merely record the constraints
%joe12: if you must have ``to be''
%assume $F$ and $G$ to be independent; we merely record the constraints
take  $F$ and $G$ to be independent; we merely record the constraints
imposed by the given probabilities.  
	
The key point is that we can incorporate the new information into our original
representation (the graph in \Cref{fig:gun-floomp-diagram} without the edge from
$F$ to $G$) simply  by adding the edge from $F$ to $G$ and the associated cpd
%joe12: I could accept that the new information is in gray but then
%why are f and \overline{f}, g nad \overline{g}, and * in gray?
%oli14: Fixed. The reason is because I didn't want to draw focus towards the labels.
%$\mat r$. Doing so does not change the meaning of the original edges.  
%oli14:
% $\mat p$ (the new infromation is shown in gray). 
$p$ (the new infromation is shown in blue).
Doing so does not change the meaning of the original edges.   
%oli12: redundant.
% This
% presentation lets us simply include information, and resolve inconsistencies
% later.
Unlike a Bayesian update, the operation is even reversible: all we need
to do recover our original belief state is delete the new edge, 
%oli12: no need for 'effectively'
%effectively
making it possible to mull over and then reject an observation.
%
\end{example}


The ability of PDGs to model inconsistency, as illustrated in
\Cref{ex:guns-and-floomps}, appears to have come at a significant cost. We seem
to have lost a key benefit of BNs: the ease with which they can
capture
%joe20: it seems strange to say ``Pearl has argued'', and then
%reference a paper by Pearl, Geiger, and Verma
%(conditional) independencies, which, as Pearl \cite{pearl1989conditional} has
(conditional) independencies, which, as Pearl (\citeyear{pearl}) has
argued forcefully, are omnipresent.
%oli12*: it seems like we should add a sentence fragment here, along
%the lines of "but we will be able to easily recover them".  Also, the
%above is kind of redundant, so I keep looking at it trying to figure
%out how to re-word, but it's so well written that I can't figure out
%what I want to do to it.
%joe11: how about:
%As we shall see, we will be able to recover this information.
%oli13: Most anything we add without cutting down the text before will
%ultimately cost a line. I'm not sure this particular phrase is worth
%it, I've commented it out. 
% Counterproposal:
%joe12: Looks like you didn't finish this here
%joe13*: you still didn't finish this sentence.  I'm cutting it.
%And yet:
%oli15: The intention was to lead directly to the example. It's a
%clever but maybe  
% too-cute transition; it is free (fits on on the line) if you remove a comma. 


% most of the time, we do not make the independence
% assumption in a bn because we know for certain that the
% variables are independent; rather, we just suspect that the
% identified edges are by much more important than the
% others. determining for sure that smoking  and second hand
% smoke are independent, controlling for parents' smoking
% habits, would extremely difficult, and would require
% empiricism to validate. 


\begin{example}[emulating a BN]\label{ex:smoking}

We now consider the classic (quantitative) Bayesian network $\cal B$, which has
four binary variables indicating whether a person ($C$) develops cancer, ($S$)
smokes, ($\mathit{SH}$) is exposed to second-hand smoke, and ($\mathit{PS}$) has
parents who smoke, presented graphically in \Cref{subfig:smoking-bn}. We now
walk through what is required to represent $\cal B$ as a PDG, which we call
$\PDGof{{\mathcal B}}$, shown as the solid nodes and edges in
\Cref{subfig:smoking-pdg}. 


%oli24: To make the figure appear in the rigght place, we have to move it to
% be way earlier. Also, some magic \hfils to center it more appropriately...
\begin{figure}[ht!]
\addtocounter{figure}{1}
\centering
\hfill
%oli24: tikzexternalize doesn't work on these...
% \begin{tikzcd}[center base, column sep=1.0em, row sep=0em, dpad={fill opacity=1,fill=black!08, circle, inner sep=3pt, minimum size=2.3em, draw=gray}, 
% 	ampersand replacement=\&]
% \& S \ar[dr] \\
% PS \ar[ur]\ar[dr] \&\& C \\
% \& SH \ar[ur]
% \end{tikzcd}
% }
% \caption{The Bayesian network $\cal B$}
\ifprecompiledfigs
\raisebox{-0.5\height}{\includegraphics{figure-pdfs/smoking-BN}}
% \raisebox{-0.5\height}{\includegraphics{smoking-BN}}
\else
\begin{tikzpicture}[paperfig]
	\begin{scope}[every node/.style={dpadded, fill opacity=1,fill=black!08, circle, inner sep=2pt, minimum size=2em, draw=gray}]
		\node (PS) at (0,1.1) {$\mathit{PS}$};
		\node (SH) at (-0.6,0) {$\mathit{SH}$};
		\node (S) at (0.6,0) {$\mathit{S}$};
		\node (C) at (0,-1.1) {$\mathit{C}$};
	\end{scope}
	\draw[->] (PS) to (S);
	\draw[->] (PS) to (SH);
	\draw[->] (SH) to (C);
	\draw[->] (S) to (C);
\end{tikzpicture}
\fi
\refstepcounter{subfigure}
\label{subfig:smoking-bn}
~~\vline~~
\ifprecompiledfigs
\raisebox{-0.5\height}{\includegraphics{figure-pdfs/smoking-PDG}}
% \raisebox{-0.5\height}{\includegraphics{smoking-PDG}}
\else
\begin{tikzpicture}[paperfig]
	% \colorlet{fillcolor}{blue!80!black}
	\colorlet{mattfillcolor}{color1}
	\fill[fill opacity=0.1, mattfillcolor, draw, draw opacity=0.5] (2.73,1.35) rectangle (6.7, -1.35);
	
	%oli24: modifying positions to fit things...
	% \node[dpadded] (1) at (0,0) {$\var 1$};
	% \node[dpadded] (PS) at (1.65,0) {$\mathit{PS}$};
	\node[dpadded] (1) at (1.65,1) {$\var 1$};
	\node[dpadded] (PS) at (1.65,-0.4) {$\mathit{PS}$};
	\node[dpadded, fill=black!.16, fill opacity=0.9] (S) at (3.2, 0.8) {$S$};
	\node[dpadded, fill=black!.16, fill opacity=0.9] (SH) at (3.35, -0.8) {$\mathit{SH}$};
	\node[dpadded, fill=black!.16, fill opacity=0.9] (C) at (4.8,0) {$C$};
	
	\draw[arr1] (1) -- (PS);
	\draw[arr2] (PS) -- (S);
	\draw[arr2] (PS) -- (SH);
	\mergearr{SH}{S}{C}
	
	\node[dpadded, fill=black!.16, fill opacity=0.35, dashed] (T) at (6.15,0) {$T$};
	\draw[arr1,dashed] (T) -- (C);	

	\draw[very thick, |-|, color=mattfillcolor!50!black,text=black] (2.7, 1.35) --coordinate(Q) (6.73,1.35);%(7.13,1.35);
	\fill[white] (2.6, 1.37) rectangle (6.9,1.55);
	% \useasboundingbox (current bounding box);
	\node[above=0.05em of Q]{\small Restricted PDG in \cref{ex:grok-ablate,ex:grok-union}};
\end{tikzpicture}
\fi
	\hfill~
%oli12: I wasn't really sure what to do with this caption given that it really needs to be 2/3 of a line for the figure to look right.
% \caption{The PDG $\PDGof{{\mathcal B}}$ corresponding to ${\mathcal B}$, and a restriction of it.} 
% \caption{The PDG $\PDGof{{\mathcal B}}$, and two alterations of it.} 
	\refstepcounter{subfigure}
	\label{subfig:smoking-pdg}
\addtocounter{figure}{-1}
% \end{subfigure}
%oli24*: merging captions together + updating them. SUbfigures are a bother with AAAI...
% \caption{Graphical models representing conditional relationships in \Cref{ex:smoking,ex:grok-ablate,ex:grok-union}}
\caption{ (a) The Bayesian Network $\mathcal B$ in \cref{ex:smoking} (left), and
(b) $\PDGof{\mathcal B}$, its corresponding PDG (right). The shaded box
indicates a restriction of $\PDGof{\mathcal B}$ to only the nodes and edges it
contains, and the dashed node $T$ and its arrow to $C$ can be added in the PDG,
without taking into account $S$ and $SH$.}
\label{fig:smoking-bn+pdg}
\end{figure}

We start with the nodes corresponding to the variables in $\cal B$, together
with the special node $\sf 1$ from \Cref{ex:guns-and-floomps}; we add an edge
from ${\sf 1}$ to $\mathit{PS}$, to which we associate the unconditional
probability given by the cpd for $\mathit{PS}$ in $\cal B$. We can also re-use
the cpds for $S$ and $\mathit{SH}$, assigning them, respectively, to the edges
$PS \to S$ and $PS \to SH$ in $\PDGof{{\mathcal B}}$.
There are two remaining problems: (1) modeling the remaining table in $\cal B$,
which corresponds to the conditional probability of $C$ given $S$ and $SH$; and
(2) recovering the additional
%oli12 added
conditional
independence assumptions in the BN. 

For (1), we cannot just add the edges $S \to C$ and $SH \to C$ that are present
%joe11: line shaving
%in $\cal B$, because, as we saw in \Cref{ex:guns-and-floomps}, this would mean
in $\cal B$. As we saw in \Cref{ex:guns-and-floomps}, this would mean
supplying two \emph{separate} tables, one indicating the probability of $C$
given $S$, and the other indicating the probability of $C$ given
%joe11: more line shaving
%$\mathit{SH}$. Doing this would lose significant information that is
$\mathit{SH}$.  We would lose significant information that is
present in $\cal B$  about 
how $C$ depends jointly on $S$ and $SH$. To distinguish the joint dependence on
$S$ and $\mathit{SH}$, for now, we draw an edge with two tails---a
\emph{hyperedge}---that completes the diagram in \Cref{subfig:smoking-pdg}. 
%
With regard to (2), there are many distributions consistent with the conditional
marginal probabilities in the cpds, and the independences presumed by $\cal B$
need not hold for them. 
%oli12
% Rather than encoding the extra probabilistic information as cpds,
Rather than trying to distinguish between them with additional constraints,
we develop a a scoring-function semantics for PDGs
%oli12: hmm, the consistency is part of the scoring function. 
%    , and show that, among all distributions consistent with
%    $\PDGof{{\mathcal B}}$,
%joe11: so we're encoding the constraints in the semantics of the
%scoring function, rather than directly in the PDG.  This makes it a
%``soft'' constraint.  We could say that somewhere, but this seems
%like the wrong place.
%joe11: I don't know what ``emphasis on matching (potentially
%arbitrary) cpds'' means 
%which, despite an emphasis on matching (potentially arbitrary) cpds,
which 
is in this case uniquely minimized by the distribution 
%joe8*: I think we need to throw out hints about how we're going to
%use scoring functions.  I view this as critical
%oli12: I think the BN result is strong enough that this is too much hedging.
% for the appropriate scoring function, 
% the unique distribution with a minimum
% score is the one
%
specified by ${\mathcal B}$ (\Cref{thm:bns-are-pdgs}).
This allows us to recover the semantics of Bayesian networks without requiring the independencies that they assume.

%But now suppose that we get information beyond that captured by the
Next suppose that we get information beyond that captured by the original BN.
Specifically, we read a thorough empirical study demonstrating that people who
use tanning beds have a 10\% incidence of cancer, compared with 1\% in the
%joe7: \mat p comes out as a strange symbol in my pdf file.  Why do
%you need to use nonstandard fonts like \mat?
%oli12: It's just \mathbf. I'm surprised it comes out strange. In any case, no
% more \mat for cpds unless they're matrices.
%joe11: this was an old problem, that got fixed by the other changes
%you made.  But I prefer the current notation in an case.
control (call the cpd for this $p$); we would like to add this information to
$\cal B$. The first step is clearly to add a new node labeled $T$, for ``tanning
bed use''.  But simply making $T$ a parent of $C$ (as clearly seems appropriate,
given that the incidence of cancer depends on tanning bed use) requires a
substantial expansion of the cpd; in particular, it requires us to make
assumptions about the interactions between tanning beds and smoking.  
%
The corresponding PDG, $\PDGof{{\mathcal B}}$, on the other hand, has no
trouble: We can simply add the node $T$ with an edge to $C$ that is associated
with $\mat p$.  But note that doing this makes it possible for our knowledge to
be inconsistent. To take a simple example, if the distribution on $C$ given $S$
and $H$ encoded in the original cpd was always deterministically ``has cancer''
for every possible value of $S$ and $H$, but the distribution according to the
new cpd from $T$ was deterministically ``no cancer'', the resulting PDG would be
inconsistent.  
%
\end{example}


We have seen that we can easily add information to PDGs; removing information is
equally painless.   

\begin{example}[restriction]\label{ex:grok-ablate}
%oli12
% After the communist uprising, 
%joe11
%  After the communist party came to power,
  After the Communist party came to power,
  children were raised communally, and so parents' smoking habits no longer had any impact on them. Grok is reading her favorite book on graphical models, and she realizes that while the node $\mathit{PS}$ in \Cref{subfig:smoking-bn} has lost its usefulness, and nodes $S$ and $\mathit{SH}$ no longer ought to have $\mathit{PS}$ as a parent, the other half of the diagram---that is, the node $C$ and its dependence on $S$ and $\mathit{SH}$---should apply as before.
%oli4: this next sentence is less useful, and can be
    %removed; its purpose is to pre-emptively push against
    %a desire to margnialize and get a new BN.  
%joe4: let's remove it
% \begin{edge} 
% 	The rise of the communist party also came with changes in smoking habits, so a new unconditional distribution on $S$ could not be obtained by eliminating the variable $PS$. 
% \end{edge}
Grok has identified two obstacles to modeling deletion of information from a BN
by simply deleting nodes and their associated cpds. First, this restricted model
is technically no longer a BN (which in this case would require unconditional
distributions on $S$ and $\mathit{SH}$), but rather a \emph{conditional} BN
\cite{KF09}, which allows for these nodes to be marked as observations;
observation nodes do not have associated beliefs. Second, even regarded as a
conditional BN, the result of deleting a node may introduce \emph{new}
independence information, incompatible with the original BN. For instance, by
deleting the node $B$ in a chain $A \rightarrow B \rightarrow C$, one concludes
that $A$ and $C$ are independent, a conclusion incompatible with the original BN
containing all three nodes.   
%joe7*: shortened significantly.  I don't think it's
   %worth agonizing this over this.
%oli12: Your shortening is excellent :)
%joe11: :-)
PDGs do not suffer from either problem.  We can easily delete the
nodes labeled 1 and $PS$ in \Cref{subfig:smoking-pdg} to get the
restricted PDG shown in the figure, which captures Grok's updated information.
%oli12: I want to keep some of the material  underneath it for the
%full paper though. 
% I have rewritten a lot of it.
%joe17: I can live with this in the paper
%\begin{vfull}
The resulting PDG has no edges leading to $S$ or $\mathit{SH}$, and hence no
distributions specified on them; no special modeling distinction between
observation nodes and other nodes are required. Because PDGs do not directly
make independence assumptions, the information in this fragment is truly a
subset of the information in the whole PDG. 	
%\end{vfull}
% 
\end{example}

Being able to form a well-behaved local picture and restrict knowledge is
useful, but an even more compelling reason to use PDGs is their ability to
aggregate information. 
	
\begin{example}[PDG union]\label{ex:grok-union}
Grok dreams of becoming Supreme Leader ($\it SL$), and has come up with a plan.
She has noticed that people who use tanning beds have significantly more power
and than those who don't. Unfortunately, her mom has always told her that
%joe11
%tanning beds cause cancer%
tanning beds cause cancer;
%oli12 
%. In particular,
%joe11: I'm not a fan of dashes; there are better punctuation
%oli13: I've noticed. I'm not a purist, except about maximizing the entropy
% of my punctuation :P
%---specifically, that
specifically, that
15\% of people who use tanning beds
get it, compared to the baseline of 2\%.
%oli12: shortening
% Let $q$ be the cpd associated with this belief.
Call this cpd $q$.
Grok thinks people will make fun of her if she uses a tanning bed and
gets cancer, making becoming Supreme Leader impossible. This mental state is
depicted as  a PDG on the left of \Cref{fig:grok-combine}.
%oli12 we haven't left out anything more than we have earlier.
% (where we have left out the cpds, to avoid clutter).


Grok is reading about graphical models because she vaguely remembers that the
variables in \Cref{ex:smoking} match the ones she already knows about. When she
finishes reading the statistics on smoking and the original study on tanning
beds (associated to a cpd $\mat p$ in \Cref{ex:smoking}), but before she has
time to reflect, we can represent her (conflicted) knowledge state as the union
of the two graphs, depicted graphically on the right of \Cref{fig:grok-combine}.  


\begin{figure}
	\hfill
	\ifprecompiledfigs
%oli25: resetting all of these (I'm only marking %oli25 here), though
% I'll leave the other version commented out just in case. I believe 
% I fixed the flags so that I'm the only one who has to worry about this.
\raisebox{-0.5\height}{\includegraphics{figure-pdfs/grok-pre}}
% \raisebox{-0.5\height}{\includegraphics{grok-pre}}
\hspace{1.2em}\vline\hspace{1.2em}
\raisebox{-0.5\height}{\includegraphics{figure-pdfs/grok-post}}
% \raisebox{-0.5\height}{\includegraphics{grok-post}}
	\else
	% \colorlet{colorsmoking}{blue!50!black}
	% \colorlet{colororiginal}{orange!80!black}
	\colorlet{colorsmoking}{color2}
	\colorlet{colororiginal}{color1}
	\tikzset{hybrid/.style={postaction={draw,colorsmoking,dash pattern= on 5pt off 8pt,dash phase=6.5pt,thick},
		draw=colororiginal,dash pattern= on 5pt off 8pt,thick}}
	\centering
	\begin{tikzpicture}[paperfig, thick, draw=colororiginal, text=black]
		\node[dpadded] (C) at (0,0) {$C$};
		\node[dpadded] (T) at (2,0){$T$};
		\node[dpadded] (SL) at (1,-1.5){$\it SL$};
		
		\draw[arr] (T) to[bend right] node[above]{$q$} (C);
		\mergearr{C}{T}{SL}
	\end{tikzpicture}
	\hspace{1.6em}\vline\hspace{1.6em}
	\begin{tikzpicture}[paperfig]
		\begin{scope}[postaction={draw,colorsmoking,dash pattern= on 3pt off 5pt,dash phase=4pt,thick}]
			
			\node[dpadded,hybrid] (C) at (0,0) {$C$};
			\node[dpadded,hybrid] (T) at (2,0){$T$};
		\end{scope}
		
		\begin{scope}[thick, draw=colororiginal, text=black]
			\node[dpadded] (SL) at (1,-1.5){$\it SL$};
			\draw[arr] (T) to[bend right] node[above]{$q$} (C);
			\mergearr{C}{T}{SL}
		\end{scope}


		\begin{scope}[thick, draw=colorsmoking, text=black]
			\node[dpadded] (S) at (-1.4, 0.8) {$S$};
			\node[dpadded] (SH) at (-1.45, -0.8) {$\mathit{SH}$};
			\draw[arr] (T) to node[fill=white, fill opacity=1,text opacity=1,inner sep=1pt]{$p$} (C);
			\mergearr{S}{SH}{C}
		\end{scope}
	\end{tikzpicture}
	\fi
	\hfill~
	\caption{Grok's prior (left) and combined (right) knowledge.}
	\label{fig:grok-combine}
\end{figure}

The union of the two PDGs, even with overlapping 
%oli24:
% nodes and is still a PDG.
nodes, is still a PDG.
This is not the case in general
%oli24:
% with a BN.
for BNs.
Note that the PDG that Grok used to
represent her two different sources of information (the mother's wisdom and the
study) regarding the distribution of $C$ is a \emph{multigraph}: there are two
edges from $T$ to $C$, with inconsistent information. Had we not not allowed
multigraphs, we would need to choose between the two edges, or represent the
information some other (arguably less natural) way. As we are already allowing
inconsistency, merely recording both is much more in keeping with the way we
have handled other types of uncertainty. 
%		
%TODO: I should not say this yet. This is a related story that I haven't told yet. 
%Moreover, if Grok were to later discover that her mother had been faithfully transmitting the results of an unrelated study, she would be justified in increasing her certainty that a cpd roughly like $\mat p$ and $\mat q$ were correct.
% This suggests a result that is perhaps obvious in retrospect: the mere \emph{possibility} of inconisistency increases the value of consistency. For an agent that is guaranteed to be consistent by design, corroborating evidence has no value. 
\end{example}

Not all inconsistencies are equally egregious. For example, even though the cpds
$p$ and $q$ are different, they are numerically close, so, intuitively, the PDG on the right in
\Cref{fig:grok-combine} is not very inconsistent.
Making this precise 
%oli12:  
% will be
is
the focus of \Cref{sec:scoring-semantics}.


%joe4*: While I don't have an intrinsic problem with this paragraph,
%I'm not sure it belongs in the introduction.  Do we discuss this in
%more detail elsewhere in the paper?   If so, we have to say more
%about it.  As it stands, it seems like a letdown, after quite a
%compelling introduction.  I cut it for now.
%
%oli5: I agree with your assessment that it either needs to be followed
% up by something, or removed---although I'm not sure I agree there needs
% to be more text here. I strongly prefer to follow it up with something;
% I think path composition is one of the most important selling point of PDGs, 
% on par with the ability represent inconsistency, and showcases
% modularity in a useful, compositional way. To reflect this preference,
% I'm uncommenting this, but you're welcome to re-comment it in the next iteration.
%joe5*: commenting out, until you come up with a story for it that
%fits in the paper.  I strongly suspect that it won't make it into a
%NIPS submission, so by commenting it out, we'll be able to better
%judge space.
\begin{highlight-changes}[]
While a PDG is in some sense merely a set of constraints (the cpds), these constraints themselves have a useful computational meaning. Regarding cpds as stochastic matrices, we can get cpds corresponding to paths by multiplying them; equivalently, thought of as probabilistic functions, we can compose them.
	For instance, in \Cref{ex:grok-union}, if we were to give Grok
        unconditional probabilities in the form of vectors
        $\smash{(\vec s, \vec h, \vec t)}$ over the possible values of
        $\mathit{S, SH}$ and $\mathit T$ respectively, she could
        compute three distinct estimates for $\mathit{SL}$. This is
        perhaps clearest visually, but for clarity, if $\mat S$ is
        the cpd for the orange hyperedge that computes $C$ from
        $\mathit{S, SH}$, and $\mat L$ is the cpd for the
%joe4: the colors may not come across for some people, so you may want
%to use some other way of distinguishing them
%oli5*: Can I rely on colors to distinguish things in general? I've been using it throughout the document. I've seen papers that do this, but I can see why it might be poor taste (e.g., black and white printers). I can add letters to the hyper-edges here.
%        blue hyper edge, which computes $\mathit{SL}$ from $\mathit{C, T}$, and
%        $[\vec a; \vec b]$ is a vertical stacking of the vectors $\vec
    blue hyperedge that computes $\mathit{SL}$ from $\mathit{C, T}$, and we 
%oli5:
% use the notation 
		write
        $[\vec a; \vec b]$ for the matrix with rows $\vec
        a$ and $\vec b$, then 
	\[ \mat L \Big[\mat p \vec t; \vec t\ \Big],
		\qquad \mat L \Big[\mat q \vec t; \vec t\ \Big], \quad\text{and}
		\quad \mat L \Big[\mat S \big[\vec s; \vec h\big], \vec t\ \Big]  \]
	        are all probabilistic estimates of $\mathit{SL}$, which
                can be used in different circumstances: the first two are
        applicable even if given only $\vec t$, and the last requires
        all three values. 
	This property gives PDGs more useful structure than most
        collections of constraints.  
\end{highlight-changes}
%joe5: \end{commentout}
        
These examples give a taste of the power of PDGs.  In the coming sections, we formalize PDGs and relate them to other approaches.		
% \begin{notfocus}
%	\begin{enumerate}[nosep]
%		\item This representation more naturally matches what humans are aware of, encoding small locally consistent models rather than one giant probability distribution
%		\item It is a strictly more general representation--- we can easily convert BNs to these diagrams (section \ref{sec:convert2bn})
%		\item This allows composition of arrows to be defined, and gives meanings to paths (section \ref{sec:composition}).
%		\item Allowing variables to be added and removed makes
%		\item Changing and partially determining arrows is more reasonable.
%		\item We can now represent inconsistency, which will allow us to capture mental states which, and . While we agree with the classical picture in that inconsistency is bad, now we can talk about it
%	\end{enumerate}
% Redundency is important: types in programming languages, more data in ML systems.
% Puts gurads
% Makes it possible to combine knowledge without destroying old knowledge.
% preference updating
	

	\section{PDG Formalism}
	\subsection{PDG Syntax}
	\def\pdgvars[#1]{(\N#1, \Ed#1, \V#1, \mat p#1, \alpha#1,\beta#1)}
	\begin{defn}[sPDG]\label{def:sPDG}
		A strict PDG is a tuple $\pdgvars[]$ where
		\begin{description}[nosep]
			\item[$\N$]~is a finite collection of nodes, which are identified with variables,
			\item[$\Ed$]~is a collection of directed edges (arrows), each with a source, target, and a (possibly empty) label.
			\item[$\V$]~associates each node $N \in \N$ with a set $\V(N)$,
			representing the values that the variable $N$ can take. 
			\item[$\mathbf p$] associates, for each edge $L = (X,Y, \ell) \in \Ed$ and $x \in \V(X)$ a distribution $\bp(x)$ on $Y$, whenever $\beta_L > 0$.
			\item[$\beta$]~associates to each edge $L$, a number in $[0,\infty]$, indicating certainty in the conditional distribution $\bp(Y \mid X)$ 
			\item[$\alpha$]~associates to each edge $L$, a number in $[0,1]$, indicating degree of belief that $L$ represents a functional dependence.
		\end{description}
		\vspace{-1.4em}
	\end{defn}

	If $\dg M$ is a PDG, we reserve the names $\pdgvars[^\dg M]$
	for its components, so that we may reference one (e.g.,
	$\Ed^\dg M$) without naming them all explicitly. We may further omit the superscript in contexts where only one PDG is present. 
	We write $\V(S)$ for the set of possible joint settings of a set $S$
	of variables; in particular, 
	we write $\V(\dg M)
	= \prod_{N \in \N^\dg M} \V^\dg M(N)$
	for all settings of the variables $(\N^\dg M, \V^\dg M)$.
	
	Note that we allow multiple edges in $\Ed$ with the same source and
target; thus $(\N,\Ed)$ is a multigraph.  We occasionally write a PDG
%joe20
%as $\dg M = (\Gr,\mat p, \beta,\alpha)$, where $\Gr = (\N,\E,\V)$, and
%joe21: Note that we have three deifferent font in G-(N,E,V)
as $\dg M = (\Gr, \mat p, \alpha,\beta)$, where $\Gr = (\N,\Ed,\V)$, and
%joe21
%abuse terminology by referring to $\Gr$ as $\Gr$ as a multigraph.
abuse terminology by referring to $\Gr$ as a multigraph.
%oli22: added
%joe20: it's not a partial spefication.  
%We refer to a partial specification
We refer to 
%joe21: I think we have four different fonts here.  This is really not
%good, although I'm not going to worry about it now
%oli24: thanks for not worrying; it was an easily identifiable
% macro confusion that arose when you rewrote this bit.
${\dg N} = (\Gr, \mat p)$ as an \emph{unweighted} PDG,
%oli24: 
% pulled up from where you said this, with slight modification.
and give it semantics as though it were the (weighted) PDG $(\Gr, \mat p, \mat 1, \mat 1)$, where
$\bf 1$ is the constant function (i.e., so that $\alpha_L = \beta_L = 1$ for all $L$). 


While the definition above is sufficient to represent the class of all legal
PDGs, we often use two additional bits of syntax to represent common
constraints:  
    	
\begin{itemize}
    \item A special variable $\sf 1$ whose range consists of only element, which
    we denote $\star$. It is used to represent unconditional distributions, as
    in \Cref{ex:guns-and-floomps,ex:smoking}.  

	\item Double-headed arrows, $A \tto
      B$, which visually indicate the degenerate special
          case of a cpd that assigns probability 1 to $f(a)$
          for each $a \in A$ (corresponding to a deterministic
          function $f : A \to B$). 
\end{itemize}


\begin{constr}\label{constr:hyperedge-reducton}
We can now explain how we capture   the multi-tailed edges that 
were used in 
\Crefrange{ex:smoking}{ex:grok-union}. 
That notation can be viewed as shorthand for the graph that results by adding a new node at the junction representing the joint value of the nodes at the tails, with projections going back.  For instance,
% the diagram of the PDG in the shaded box of \Cref{subfig:smoking-pdg}
the diagram displaying Grok's prior knowledge in \Cref{ex:grok-union}, on the left of \Cref{fig:grok-combine}
%joe7: moved up from below, to save a line
%is really shorthand for the following PDG:
is really shorthand for the following PDG, where
where we insert a node labeled $C \times T$ at the junction:
\smallskip
	\begin{center}
	\ifprecompiledfigs
\raisebox{-0.5\height}{\includegraphics[scale=0.9]{figure-pdfs/widget}}
% \raisebox{-0.5\height}{\includegraphics[scale=0.9]{widget}}
	\else
		\begin{tikzpicture}[paperfig]
			\node[dpadded] (SL) at (-1.0,0) {$\mathit{SL}$};
			
			\node[dpadded,light pad] (CT) at (-2.9, 0){$\scriptstyle C \times T$};
			\node[dpadded] (C) at (-4.8, -0.6) {$C$};
			\node[dpadded] (T) at (-4.8, 0.6) {$T$};
			
	%				\node[dpadded, dashed,color=violet] (X) at (6.5,0) {$X$};
	%				\draw[arr, color=violet] (X) -- (S);
	%				\draw[arr, color=violet] (X) -- (C);
	%				\draw[arr, dashed, color=violet] (X) -- (SC);
			
			\draw[arr, ->>] (CT) -- (C);
			\draw[arr, ->>] (CT) -- (T);
			\draw[arr] (CT) -- (SL);
			\draw[arr] (T) to [bend right=90, looseness=2] (C);
	\end{tikzpicture}
	\fi
	%%%%%%%%%%%%%%%%%  smoking fragment: %%%%%%%%%%%%%%%%%%%%%%
% 		\scalebox{0.8}{
% 			\begin{tikzpicture}
% 				\node[dpadded] (C) at (-1.0,0) {$C$};
% 				\node[dpadded] (T) at (0.5,0) {$T$};
% 
% 				\node[dpadded,light pad] (SSH) at (-2.9, 0){$\scriptsize \mathit{SH} \times S$};
% 				\node[dpadded] (S) at (-4.8, 0.6) {$S$};
% 				\node[dpadded] (SH) at (-5.0, -0.6) {$\mathit{SH}$};
% 
% %				\node[dpadded, dashed,color=violet] (X) at (6.5,0) {$X$};
% %				\draw[arr, color=violet] (X) -- (S);
% %				\draw[arr, color=violet] (X) -- (C);
% %				\draw[arr, dashed, color=violet] (X) -- (SC);
% 
% 				\draw[arr, ->>] (SSH) -- (S);
% 				\draw[arr, ->>] (SSH) -- (SH);
% 				\draw[arr] (SSH) -- (C);
% 				\draw[arr] (T) -- (C);
% 		\end{tikzpicture}}
	\end{center}
	\smallskip

% That is, we inserted a node labeled $SH \times S$ at the junction.  As
% the notation suggests, $\V( \mathit{SH} \times S) = \V(\mathit{SH}) \times \V(S)$.
% The cpd for $(h,s) \in \V(\mathit{SH} \times S)$  associated with 
% the edge from $\mathit{SH} \times S$ to $\mathit{SH}$ gives probability 1 to $h$;
% similarly, the cpd for $(s,c)$  associated with 
% the edge from $ C \times C$ to $S$ gives probability 1 to $s$.
%joe7
%        That is, we inserted a node labeled $C \times T$ at the junction.
As the notation suggests, $\V( C \times T) = \V(C) \times \V(T)$.
%joe2: this is not the time to start talking about matri\mathit{SL}es
%Thus, $\V(S \times \mathit{SL}) = \V(S) \times \V(\mathit{SL})$; the matrix asso\mathit{SL}iated with
For any joint setting $(c,t) \in \V(C \times T)$ of both variables, the cpd for
the edge from $C \times T$ to $C$ gives probability 1 to $c$;
similarly, the cpd for the edge from $ C \times T$ to $T$ gives probability 1 to $t$.
\end{constr}


	\subsection{Overview of PDG Semantics}
	\subsubsection{Sets of Distributions}
	We start by interpreting a PDG as the set of distributions consistent with it.  
	\begin{defn}[set-of-distribution semantics] \label{def:set-semantics} 
		If $\dg M\!=\!\pdgvars[]$ is a PDG, let $\SD{\dg M}$ be the \emph{s}et of \emph{d}istributions over the variables in $\dg M$ whose conditional marginals are exactly those given by $\mat p$.
		That is, $\mu \in \SD{\dg M}$ iff, for all edges $L = (X,Y) \in \Ed$,  $x \in \V(X)$,  and $y \in \V(Y)$, we have that $\mu(Y = \cdot \mid X\!=\! x) = \bp(x)$.
		{
			\[ \SD[\Big]{\dg M} = \!\left\{\mu \!\in\! \Delta \V_\none (\dg M) \middle|\!
			\begin{array}{l}
				\mu(B\!\! =\!\!b \mid A\!\!=\!\!a) \geq \boldsymbol\mu_L(b \mid a) \\[0.1em]
				~\text{$\forall (A, B,\ell) \!\in\! \Ed$, $a \!\in\!\mathcal V_A$, $b \!\in\! \mathcal V_B$} \end{array}\!\!\! \right\}\]
		}
		$\dg M$ is \emph{consistent} if $\SD{\dg M}$ is inhabited (non-empty), and \emph{inconsistent} otherwise.
	\end{defn}
	
	Note that $\SD{\dg M}$ is independent of the weights $\alpha$ and $\beta$.

%joe17*: This breaks teh flow here.  If it were go anywhere, it should
%be in the appendix
%oli20: oops, I don't want it in the AAAI submission either.
	% It turns out that this semantics only results in convex sets. 
	\begin{prop}[restate=thmsetconvex] 
		\label{prop:convex}
		$\SD{\dg M}$ is convex, for all PDGs $\dg M$.
	\end{prop}
		
	This may provide useful intuition, and we will prove a stronger version of this statement that corresponds to our second semantics.
	Note that being inconsistent is not the same things as \emph{over-constrained}: 	
	\begin{defn}
		$\dg M = (\Gr,\V,\mat p)$ is over-constrained if there exists
		  \emph{some $\mat p'$} assigning cpds to the same edges as
		  $\mat p$, such that $(\Gr, \V, \mat p')$ is inconsistent
		  (i.e., $\SD{\N^\dg M, \Ed^\dg M, \V^\dg M, \mat p}
			= \emptyset$), and under-constrained if there are
		  multiple distributions in $(\Gr, \V, \mat p')$ for
		  \emph{every such $\mat p'$}, making this a property of the
		  qualitative PDG $(\Gr, \V)$.  
	\end{defn}

	We know that an under-constrained PDG is consistent without even looking at the tables. However if a we know that an \emph{over-constrained} PDG is actually consistent (when it could have easily contradicted itself), the information provides corroborating evidence, and one can take this as support in favor of the beliefs. 


	\subsubsection{Distribution Scoring Functions}\label{sec:scoring-semantics}
	\begin{defn}[\texorpdfstring{$\Inc$}{Inc}; incompatibility and inconsistency]\label{def:inc}
		The \emph{incompatibility} of a PDG $\dg M = \pdgvars[]$ with
		a joint distribution $\mu$, denoted $\Inc_{\dg M}(\mu)$, is  
		\[
		\Inc_{\dg M }( \mu) := 
		\!\!\!\sum\alle \beta_L \Ex_{x \sim \mu_{_X}}
		\left[\kldiv[\Big]{ \mu(Y\!= \cdot\mid X \!=\! x) }{\bp(x) } \right] ,
		\]
		where $\kldiv{\mu}{\nu} = \sum_{w} \mu(w) \log\frac{\mu(w)}{\nu(w)}$ is the 
		relative entropy from $\nu$ to $\mu$.
	%	
				The \emph{inconsistency} of $\dg M$, 
			denoted $\Inc(\dg M)$, is the
			minimum possible incompatibility of $\dg M$ with any
			distribution $\mu$,  
			\[ \Inc(\dg M) = \inf_{ \mu \in \Delta [W_{\cal V}]} \Inc_{\dg M}(\mu) . \]
	\end{defn}
	$\SD{\dg M}$ and $\Inc_{\dg M}$ distinguish only
	between distributions based on their compatibility with
	$\dg M$, but even among distributions that match the
	marginals, some more closely match the qualitative structure
	of the graph than others.  
	%New
	We therefore also give a score for how well a distribution qualitatively fits
	a PDG, which depends only on $\mu$ and the underlying graph $\Gr^{\dg M}$. 
		
	\begthm[\texorpdfstring{$G$}{G}-information deficiency]%
			{defn}{def:info-deficiency}
		For a multi-graph $G = (\N, \Ed)$ over a set $\N$ of variables,
		define the \emph{$G$-information deficiency}
		of a distribution $\mu$, denoted $\IDef{G}(\mu)$,
		by considering the difference between (a) and (b), 
		where we measure the amount of information needed for a description
		using (conditional) entropy: 
		\begin{equation}
			\IDef{G}(\mu) := \sum_{(X,Y) \in \Ed} \alpha_L \H_\mu(Y\mid X) - \H(\mu). 
			\label{eqn:idef}
		\end{equation}
		%\footnote{Recall that $H_\mu(Y\mid X)$, the
		Recall that $H_\mu(Y\mid X) = - \sum_{x,y \in \V(\{X,Y\})} \mu(x,y) \log \mu(y\mid x)$ is the
		\emph{conditional entropy of $Y$ given $X$} with respect to $\mu$.
		For a PDG ${\dg M}$, is we take $\IDef{\dg M} = \IDef{(\N^{\dg M}, \Ed^{\dg M})}$, the information defecit with respect to its underlying hyper-graph.
	\end{defn}
	
	This construction may seem like an arbitrary choice that we use to make 
	some corresondences work out, but in \Cref{sec:details-on-joint-scoring} we
	will argue that $\IDef{}$ both more natural than it seems, and intimately related to 
	qualitative features of distributions. In the mean time, we simply add the scores together
	% TODO follow through on this

	
	We also consider a variant of $\IDef{}$, in which we use $\Ex_{x \sim \mu_X} \H (\bp (x))$ in place of $\H_\mu(Y \mid X)$ to define the $G$-information deficit. We denote this variant with  $\IDef{}^{\mat p}$, and it is given explicitly by 
	\begin{defn}[$\IDef{}'$, a more concrete $\IDef{}$]
		\begin{equation*}
			\IDef{\dg M}^{\mat p}(\mu) := \sum\alle \H_\mu(Y\mid X) - \H_\mu
			\label{eqn:alt-extra}
		\end{equation*}
	\end{defn}

	$\IDef{\dg M}^{\mat p}$ is like $\IDef{\dg M}$ but it uses the cpds in $\dg M$, rather than the marginals of the distribution, for its calculations. This makes it a more natural choice for algorithms in which the cpds are given, but $\mu$ is not. It has the benefit of having a linear first term and enjoying strong convexity for all values of $\gamma$. For distributions $\mu \in \SD{\dg M}$, these quantities are the same; therefore, the difference lies exclusively in the way it scores distributions that are already inconsistent with the edges.
	
	We will use this variant to interpret BNs as representing maximum-entropy distributions consistent with the cpds, where we take the information necessary to spceify the cpds into account; this generalizes the result of \cite{williamson2000}.
	% \end{annotating}

		

	$\Inc({\dg M}, \mu)$ and $\IDef{\dg M},\mu)$ give us two measures of compatibility between ${\dg M}$ and a distribution $\mu$. We take the score of interest to be their sum, with the trade-off
	controlled by a parameter $\gamma \ge 0$:
	\begin{equation}
		\bbr{\dg M}_\gamma(\mu).
		:= \Inc_{\dg M}(\mu) + \gamma \IDef{\dg M}(\mu)
		\label{eqn:full-score}
	\end{equation}
	%joe9*: I think the proposition and the following sentence are
	%worth adding 

	%joe10
	%        The following just make precise that the scoring semantics
	The following just makes precise that the scoring semantics
	generalizes the first semantics.
	% \begin{prop}[restate=prop:sd-is-zeroset]\label{prop:sd-is-zeroset}
	\begthm{prop}{prop:sd-is-zeroset}
	For all PDGs $\dg M$, we have that $\SD{\dg M} = \{ \mu : \bbr{\dg
		M}_0(\mu) = 0\}$. 
	\end{prop}

	%%BEGIN_FOLD
	\subsubsection{PDGs As Unique Distributions}\label{sec:uniq-dist-semantics}
	%		
			% shows that PDGS are 
	Before we provide an interpretation of a PDG as a probability distribution, we stress that this distribution does \emph{not} capture all of the important information in the PDG---for example, a PDG can represent inconsistent knowledge states. Still, by giving a distribution, we enable comparisons with other graphical models. In the process, we will discover 
	that PDGs are a surprisingly flexible tool for articulating distributions themselves. All we need to do is select the minimizers of our loss function.
	We thus define 
			
	\begin{defn}[opt score joint distribution]
		% \begin{equation}
		$\bbr{\dg M}_\gamma^* = \arg\min_{\mu \in
			\Delta\V(\dg M)} \bbr{\dg M}_\gamma(\mu).$
		%\end{equation}   
	\end{defn}

	In general, $\bbr{\dg M}_\gamma^*$ does not give a unique distribution.  But if $\gamma$ is sufficiently small, then it does:

	\begthm[unique opt if \texorpdfstring{$\gamma$}{g} small]
			{prop}{prop:sem3}%\begin{prop}
		If $\dg M$ is a PDG and $0 < \gamma \leq \min_L \beta_L^{\dg M}$, then $\bbr{\dg M}_\gamma^*$ is a singleton. 
	\end{prop}
			
	We are especially interested in the case where $\gamma$ is small; this amounts to emphasizing the accuracy of the probability distribution as a description of probabilistic information, rather than the independence structure of the PDG.  This is what was going on in all the examples in the introduction.  This motivates us to consider what happens as $\gamma$ goes to 0.  If $S_\gamma$ is a set of probability distributions for all $\gamma \in [0,1]$, we define $\lim_{\gamma \rightarrow 0} S_\gamma$ to consist of all distributions $\mu$ such that there is a sequence $(\gamma_i, \mu_i)_{i \in \mathbb N}$ with $\gamma_i \to 0$ and $\mu_i \to \mu$ such that $\mu_i \in S_{\gamma_i}$ for all $i$. It can be further shown that

	\begthm[unique opt as \expandafter\texorpdfstring{$\gamma\to0$}{g->0}]{prop}{prop:limit-uniq}
		For all $\dg M$, $\lim_{\gamma\to0}\bbr{\dg M}_\gamma^*$ is a singleton. 
	\end{prop} 

	Let $\bbr{{\dg M}}^*$ be the unique element of $\smash{\lim\limits_{\gamma \rightarrow 0}} \bbr{{\dg M}}_\gamma^*$. 
	The semantics has an important property: 

	\begthm{prop}{prop:consist}
		$\bbr{\dg M}^* \in \bbr{\dg M}_0^*$, so if $\dg M$ is consistent,
		then $\bbr{\dg M}^* \in \SD{\dg  M}$.
	\end{prop}
	
	\moveme{In contrast with the other two semantics, $\bbr{\dg M_1 \cup
	\dg M_2}^*$ cannot be eaily calcualted from $\bbr{\dg M_1}_\gamma^*$ and
	$\bbr{\dg M_2}_\gamma^*$. We will see that it is nonetheless effectively the semantics used by other graphical models.}

	\begin{defn}
		Let $\bbr{M}'(\mu) := \Inc{\dg M}(\mu) + \IDef{\dg M}^{\mat p}(\mu)$ be the altered version of the information definition.
	\end{defn}
	\begin{prop}\label{prop:u-convex}
	$\bbr{\dg M}'_\gamma(\mu)$ is $\gamma$-strongly convex.% in $\mu$.
	\end{prop}
	\begin{proof}
		$\Inc_{\dg M}( \mu)$ is convex in $\mu$
		(\Cref{thm:inc-convex}), and $\gamma\sum\alle \Ex_{x\sim \mu_X}
		\H(\bp(x))$ is linear in $\mu$.  
		Negative entropy is $1$-strongly convex
		(\Cref{prop:neg-ent-convex}), so $- \gamma \H(\mu)$ is $\gamma$-strongly convex.
		The sum of a $\gamma$-strongly convex, linear, and
		convex functions must be $\gamma$-strongly convex. 
		%		, and strongly so when the coefficient on $-\H$ ($\gamma$) is positive. 
		%(see \cite{Rockafellar1970ConvexA})
	\end{proof}
	
	% \subsubsection{Probabilistic Automata}
	\subsection{Operation on PDGs}
	\subsection{Lax PDGs}
	% \begin{defn}[PDG]\label{def:PDG}
	% 	A (lax) PDG is a tuple $\pdgvars[]$ where
	% 	\begin{description}[nosep]
	% 		\item[$\N$]~is a finite collection of nodes, which are identified with variables
	% 		\item[$\Ed$]~is a collection of directed edges (arrows), each with a source, target, and a (possibly empty) label.
	% 		\item[$\V$]~associates each node $N \in \N$ with a set $\V(N)$,
	% 		representing the values that the variable $N$ can take. 
	% 		\item[$\mathbf p$] associates, for each edge $L = (X,Y, \ell) \in \Ed$ and $x \in \V(X)$ a distribution $\bp(x)$ on $Y$, whenever $\beta_L > 0$.
	% 		\item[$\beta$]~associates to each edge $L$, a number in $[0,\infty]$, indicating certainty in the conditional distribution $\bp(Y \mid X)$ 
	% 		\item[$\alpha$]~associates to each edge $L$, a number in $[0,1]$, indicating degree of belief that $L$ holds causally.
	% 	\end{description}
	% 	\vspace{-1.4em}
	% \end{defn}
	\section{Details on Joint Distribution Scoring Semantics}\label{sec:details-on-joint-scoring}
	\subsection{Determination}

	% \begin{annotating}[frametitle={Paths}]
	Qualitatively, an think of an edge $\ed LXY$ of a PDG $\dg M$ as a claim that the value of $Y$ can be (noisily) computed from
	$X$ alone.  
	Therefore, to best match the qualitative structure of $G$, statistical asymmetries and dependencies between variables should
	be efficiently described by giving the conditional probabilities corresponding to the edges of $G$. After all, to the extent that we believe the world has a causal structure of $G$, then these conditional probabilities describe every possible interaction between variables. 

	To formalize this, we require only the underlying multigraph $G^{\dg M} :=
	(\N^{\dg M}, \Ed^{\dg M})$ of $\dg M$. 
	Given $G$ and $\mu$, contrast the amount of
	information required to 
	\begin{enumerate}[label=(\alph*)]
		\item directly describe a joint outcome  $\mat w ~ \sim \mu$
		drawn from $\mu$, and 
		\item separately specify, for each edge $\ed LXY$, the value
		$\mat w_Y$ (the projection of $\mat w$ onto the variable
		$Y$) given the value $\mat w_X$, in expectation. 
	\end{enumerate}
	% (a)  and (b)
	When these two quantities are equal, the total length (in expectation) of specifying the outcome on each link, is precisely the same length as an optimal description of the joint outcome. That is, $\mu|_G$ carries enough information to precisely resolve all of the randomness of $\mu$. If (b) $>$ (a), then a specification of an outcome along each $L \in \Ed$ is redundant; all of the randomness in the system could have been resolved with this amount of information; we conclude that there are extra correlations in $\mu$ that are not suggested by $G$. The more (b) exceeds (a), the larger the degree of redundancy, and thus the less favorable an agent who believes $G$ to qualitatively correct, will judge $\mu$ to be. Because $\mu$ falls short of the expected level of randomness from this structure given these conditional distributions, we say that $\mu$ has a $G$-entropy deficit.

	On the other hand, if (a) $>$ (b), then a sample of $\mu$ requires additional information to specify, beyond what could be used to encode outcomes of the marginals selected by $G$. This happens, when the structure in $G$ does not fully constrain the distribution, and often happens when there are fewer links than nodes, or cycles present. Whereas before $\mu$ had a defecit of entropy with respect to $G$, it now has a $G$-information \emph{surplus}, as now $\mu$ has more randomness than we could possibly resolve by specifying link outcomes, which reflects a hedging, due to the qualitative lack of information in $G$. For a defense of this preference for higher randomness in the absence of information to the contrary, see \cite{maxent}\cite{adversarial_protection}. The more (a) exceeds (b), the more evenly $\mu$ allocates mass in contexts that $G$ says nothing about, and so the better the qualitative fit of $\mu$ to $G$.
	%oli17: IDef has two effects:
	% (Here "wherever" means for every region of the info diagram, i.e., subset
	% of variables that excludes some other subset.)
	% (1) to give a max-entropy result wherever G does not specify something
	% (think: no edges, or a cycle that allows multiple solutions), and 
	% (2) to give a min-entropy result whenever it is over-specified. For regions
	% with exactly 2 overlapping variables, this amounts to a statement of
	% independence.
	\recall{def:info-deficiency}

	
	$\IDef{}$ can be thought of as a qualitatively customize-able maximum-entropy \cite{Jaynes57} approach, in which one tries to maximize or minimize the variation with in a subset of the variables, depending on how qualitatively constrained this subset is, given the values outside of it, a notion which naturally leads to the information profile \Cref{info-profile}. We illustrate $\IDef{\dg M}$ with some simple examples.  


	\begin{example}[some example descriptions]
	Suppose that $\dg M$ has two nodes, $X$ and $Y$. If $\dg M$ has no edges, the $\IDef{\dg M}(\mu) = - H(\mu)$.
	There is no information required to specify, for each edge in ${\dg M}$ from $X$ to $Y$, the value ${\mat w}_Y$ given ${\mat w}_X$, since there are no edges. Since we view smaller numbers as representing a better fit, $\IDef{\dg M}$ in this case will prefer the distribution that maximizes entropy.

	If $\dg M$ has one edge from $X$ to $Y$, then since $H(\mu) = H_{\mu}(Y \mid X) + H_\mu(X)$ by the chain rule, $\IDef{\dg M}(\mu) = -H_{\mu}(X)$. Intuitively, while knowing the conditional probability $\mu(Y \mid X)$ is helpful, to completely specify $\mu$ we also need $\mu(X)$. Thus, in this case, $\IDef{\dg M}$ prefers distributions that maximize the entropy of the marginal on $X$. If $\dg M$ has sufficiently many parallel edges
	%an edge $1 \to X$, and also
	from $X$ to $Y$ and $H_{\mu}(Y \mid X) > 0$ (so that $Y$ is not totally determined by $X$) then we have $\IDef{\dg M}(\mu) > 0$, because the redundant edges add no information, but there is still a cost to specifying them. In this case, $\IDef{\dg M}$ prefers distributions that make $Y$ a deterministic function of $X$ will maximizing the entropy of the marginal on $X$. Finally, if ${\dg M}$ has an edge from $X$ to $Y$ and another from $Y$
	to $X$, then a distribution $\mu$ minimizes $\IDef{\dg M}$ when 
	$X$ and $Y$ are correlated (so that $H_\mu(Y \mid X) = H_\mu(X \mid Y) = 0$) while
	maximizing $H(\mu)$, for example, by taking $\mu(0,0) = \mu(1,1) = 1/2$.
	\end{example}
	\begin{example}[visualizing the information profile]
	\definecolor{subfiglabelcolor}{RGB}{0,0,0}
	\begin{figure}
		\centering
	\def\vsize{0.4}
	\def\spacerlength{0.5em}
	\scalebox{0.85}{
	%apparently  I have to manually step the figure number to make subfigures number properly.
	\stepcounter{figure}
	\makebox[\textwidth][c]{
		\refstepcounter{subfigure}
		\begin{tikzpicture}[center base]\label{subfig:justX-0}
			\node[dpad0] (X) at (0,1){$X$};
			\draw[fill=green!50!black]  (0,0) circle (\vsize)  ++(-90:.22) node[label=below:\tiny$X$]{};
	%		\useasboundingbox (current bounding box);
			\node at (-0.5, 0.6){\slshape\color{subfiglabelcolor}\thesubfigure};
		\end{tikzpicture}\!
	% \hspace{\spacerlength}
	% \adjustbox{valign=b}{
	% \renewcommand{\arraystretch}{1.2}
	\begin{tabular}{c}	
		\refstepcounter{subfigure}\label{subfig:justX-1}
		\begin{tikzpicture}[is bn]
			\node[dpad0] (1) at (-0.4,.85){$\var 1$};
			\node[dpad0] (X) at (0.4,.85){$X$};
			\draw[arr1] (1)  -- (X);
			\draw[fill=white!70!black]  (0,0) circle (\vsize) ++(-90:.22) node[label=below:\tiny$X$]{};
			\node at (-0.6,0.35){};
	%		\useasboundingbox (current bounding box);
			\node at (-0.7, 0.35){\slshape\color{subfiglabelcolor}\thesubfigure};
		\end{tikzpicture} \\[0.5em]
		\refstepcounter{subfigure}\label{subfig:justX-2}
		\begin{tikzpicture}
			\node[dpad0] (1) at  (-0.45,.85){$\var 1$};
			\node[dpad0] (X) at  (0.45,.85){$X$};
			\draw[arr1] (1) to[bend left=20] (X);
			\draw[arr1] (1) to[bend right=20] (X);
			\draw[fill=red!50!black] (0,0) circle (\vsize) ++(-90:.22) node[label=below:\tiny$X$]{};
	%		\useasboundingbox (current bounding box);
			\node at (-0.7, 0.35){\slshape\color{subfiglabelcolor}\thesubfigure};
		\end{tikzpicture}
	\end{tabular}%}
	\hspace{\spacerlength}\vrule\hspace{\spacerlength}
		%% EXAMPLE: X  Y
		% \adjustbox{valign=b}{
		\begin{tabular}{c}
		\refstepcounter{subfigure}\label{subfig:justXY}
		\begin{tikzpicture}[]  
			% \node[dpad0] (1) at (0,2){$\var 1$};
			\node[dpad0] (X) at (-0.45,.85){$X$};
			\node[dpad0] (Y) at (0.45,.85){$Y$};
			% \draw[arr] (1) to[] (X);
			% \draw[arr] (1) to[] (Y);
			\path[fill=green!50!black] (-0.2,0) circle (\vsize) ++(-110:.23) node[label=below:\tiny$X$]{};
			\path[fill=green!50!black] (0.2,0) circle (\vsize) ++(-70:.23) node[label=below:\tiny$Y$]{};
			\begin{scope}
				\clip (-0.2,0) circle (\vsize);
				\clip (0.2,0) circle (\vsize);
				\fill[green!50!black] (-1,-1) rectangle (3,3);
				% \draw[ultra thick,white] (-0.2,0) circle (\vsize);
				% \draw[ultra thick,white] (0.2,0) circle (\vsize);
			\end{scope}
			\draw (-0.2,0) circle (\vsize);
			\draw (0.2,0) circle (\vsize);
	%		\useasboundingbox (current bounding box);
			\node at (-0.8, 0.4){\slshape\color{subfiglabelcolor}\thesubfigure};
		\end{tikzpicture}\\[0.5em]
		%% EXAMPLE: X -> Y
		\refstepcounter{subfigure}\label{subfig:XtoY}
		\begin{tikzpicture}[]
			% \node[dpad0] (1) at (0,2){$\var 1$};
			\node[dpad0] (X) at (-0.45,0.85){$X$};
			\node[dpad0] (Y) at (0.45,0.85){$Y$};
			\draw[arr1] (X) to[] (Y);
			% \draw[arr] (1) to[] (Y);
			\path[fill=green!50!black] (-0.2,0) circle (\vsize) ++(-110:.23) node[label=below:\tiny$X$]{};
			\path[fill=white!70!black] (0.2,0) circle (\vsize) ++(-70:.23) node[label=below:\tiny$Y$]{};
			\begin{scope}
				\clip (-0.2,0) circle (\vsize);
				\clip (0.2,0) circle (\vsize);
				\fill[green!50!black] (-1,-1) rectangle (3,3);
				% \draw[ultra thick,white] (-0.2,0) circle (\vsize);
				% \draw[ultra thick,white] (0.2,0) circle (\vsize);
			\end{scope}
			\draw (-0.2,0) circle (\vsize);
			\draw (0.2,0) circle (\vsize);
	%		\useasboundingbox (current bounding box);
			\node at (-0.8, 0.4){\slshape\color{subfiglabelcolor}\thesubfigure};
		\end{tikzpicture}
	\end{tabular}%}
	% \hspace{\spacerlength}
	\begin{tabular}{c}
		%% EXAMPLE: X <-> Y
		\refstepcounter{subfigure}\label{subfig:XY-cycle}
		\begin{tikzpicture}[center base]
			% \node[dpad0] (1) at (0,2){$\var 1$};
			\node[dpad0] (X) at (-0.45,0.85){$X$};
			\node[dpad0] (Y) at (0.45,0.85){$Y$};
			\draw[arr1] (X) to[bend left] (Y);
			\draw[arr1] (Y) to[bend left] (X);
			\draw[fill=white!70!black] (-0.2,0) circle (\vsize) ++(-110:.25) node[label=below:\tiny$X$]{};
			\draw[fill=white!70!black] (0.2,0) circle (\vsize) ++(-70:.25) node[label=below:\tiny$Y$]{};
			\begin{scope}
				\clip (-0.2,0) circle (\vsize);
				\clip (0.2,0) circle (\vsize);
				\fill[green!50!black] (-1,-1) rectangle (3,3);
				% \draw[ultra thick,white] (-0.2,0) circle (\vsize);
				% \draw[ultra thick,white] (0.2,0) circle (\vsize);
			\end{scope}
			\draw (-0.2,0) circle (\vsize);
			\draw (0.2,0) circle (\vsize);
	%		\useasboundingbox (current bounding box.south west) rectangle (current bounding box.north east);
			\node at (-0.85, 0.4){\slshape\color{subfiglabelcolor}\thesubfigure};
		\end{tikzpicture}\\[2.5em]
	% \hspace{\spacerlength}%% EXAMPLE: 1 -> Y;1->X
	\refstepcounter{subfigure}\label{subfig:XYindep}
		\begin{tikzpicture}[center base, is bn] 
			\node[dpad0] (1) at (0,0.75){$\var 1$};
			\node[dpad0] (X) at (-0.7,0.95){$X$};
			\node[dpad0] (Y) at (0.7,0.95){$Y$};
			\draw[arr0] (1) to[] (X);
			\draw[arr0] (1) to[] (Y);
			\draw[fill=white!70!black] (-0.2,0) circle (\vsize) ++(-110:.23) node[label=below:\tiny$X$]{};
			\draw[fill=white!70!black] (0.2,0) circle (\vsize) ++(-70:.23) node[label=below:\tiny$Y$]{};
			\begin{scope}
				\clip (-0.2,0) circle (\vsize);
				\clip (0.2,0) circle (\vsize);
				\fill[red!50!black] (-1,-1) rectangle (3,3);
				% \draw[ultra thick,white] (-0.2,0) circle (\vsize);
			% \draw[ultra thick,white] (0.2,0) circle (\vsize);					
			\end{scope}
			\draw (-0.2,0) circle (\vsize);
			\draw (0.2,0) circle (\vsize);
	%		\useasboundingbox (current bounding box.south west) rectangle (current bounding box.north east);
			\node at (-0.88, 0.4){\slshape\color{subfiglabelcolor}\thesubfigure};
		\end{tikzpicture}
	\end{tabular}
	\hspace{\spacerlength}
		 %% EXAMPLE: 1 -> X -> Y
		 \refstepcounter{subfigure}\label{subfig:1XY}
		\begin{tikzpicture}[center base, is bn]
			\node[dpad0] (1) at (0.15,2){$\var 1$};
			\node[dpad0] (X) at (-0.45,1.4){$X$};
			\node[dpad0] (Y) at (0.35,1){$Y$};
			\draw[arr0] (1) to[] (X);
			\draw[arr1] (X) to[] (Y);
			\path[fill=white!70!black] (-0.2,0) circle (\vsize) ++(-110:.23) node[label=below:\tiny$X$]{};
			\path[fill=white!70!black] (0.2,0) circle (\vsize) ++(-70:.23) node[label=below:\tiny$Y$]{};
			\begin{scope}
				\clip (-0.2,0) circle (\vsize);
				\clip (0.2,0) circle (\vsize);
				% \fill[red!50!black] (-1,-1) rectangle (3,3);
				% \draw[ultra thick,white] (-0.2,0) circle (\vsize);
				% \draw[ultra thick,white] (0.2,0) circle (\vsize);					\end{scope}
			\end{scope}
			\draw (-0.2,0) circle (\vsize);
			\draw (0.2,0) circle (\vsize);
	%		\useasboundingbox (current bounding box);
			\node at (-0.7, 0.6){\slshape\color{subfiglabelcolor}\thesubfigure};
		\end{tikzpicture}
	\hspace{\spacerlength}\hspace{2.5pt}\vrule\hspace{2.5pt}\hspace{\spacerlength}
		%% EXAMPLE: 1 -> X -> Y -> Z
		 \refstepcounter{subfigure}\label{subfig:1XYZ}
		\begin{tikzpicture}[center base,is bn]
			\node[dpad0] (1) at (-0.5,2.3){$\var1$};
			\node[dpad0] (X) at (-0.5,1.5){$X$};
			\node[dpad0] (Y) at (0.35,1.25){$Y$};
			\node[dpad0] (Z) at (0.25,2.25){$Z$};subfiglabelcolor
			\draw[arr1] (1) to (X);
			\draw[arr1] (X) to[] (Y);
			\draw[arr2] (Y) to[] (Z);
			\path[fill=white!70!black] (210:0.22) circle (\vsize) ++(-130:.25) node[label=below:\tiny$X$]{};
			\path[fill=white!70!black] (-30:0.22) circle (\vsize) ++(-50:.25) node[label=below:\tiny$Y$]{};
			\path[fill=white!70!black] (90:0.22) circle (\vsize) ++(40:.29) node[label=above:\tiny$Z$]{};
			\begin{scope}
				\clip (90:0.22) circle (\vsize);
				\clip (210:0.22) circle (\vsize);
				\fill[red!50!black] (-1,-1) rectangle (3,3);
				% \draw[ultra thick,white] (210:0.2) circle (\vsize);		
				% \draw[ultra thick,white] (90:0.2) circle (\vsize);	
				\clip (-30:0.22) circle (\vsize);
				\fill[white!70!black] (-1,-1) rectangle (3,3);
				% \draw[ultra thick,white] (-30:0.2) circle (\vsize);
				% \draw[ultra thick,white] (210:0.2) circle (\vsize);		
				% \draw[ultra thick,white] (90:0.2) circle (\vsize);
			\end{scope}
			\begin{scope}
				\draw[] (-30:0.22) circle (\vsize);
				\draw[] (210:0.22) circle (\vsize);		
				\draw[] (90:0.22) circle (\vsize);
			\end{scope}
	%		\useasboundingbox (current bounding box);
			\node at (-0.7, 0.7){\slshape\color{subfiglabelcolor}\thesubfigure};
		\end{tikzpicture}
		\hspace{3pt}
	\hspace{\spacerlength}%\vrule\hspace{\spacerlength}
		%% EXAMPLE: X -> Y -> Z -> X
		\refstepcounter{subfigure}\label{subfig:XYZ-cycle}
		\begin{tikzpicture}[center base] 
			% \node[dpad0] (1) at (-0.5,2.3){$\var1$};
			\node[dpad0] (X) at (-0.5,1.75){$X$};
			\node[dpad0] (Y) at (0.35,1.25){$Y$};
			\node[dpad0] (Z) at (0.25,2.25){$Z$};
			% \draw[arr0] (1) to (X);
			\draw[arr1] (X) to[bend right=25] (Y);
			\draw[arr1] (Y) to[bend right=25] (Z);
			\draw[arr1] (Z) to[bend right=25] (X);
			%option: -- either X -> Y -> Z -> X, or <-> Y <-> Z <-> X. For the latter, uncomment the 6 lines below and comment out the next 3.
			% \draw[arr1] (Z) to[bend left=5] (Y);
			% \draw[arr1] (Y) to[bend left=5] (X);
			% \draw[arr1] (X) to[bend left=5] (Z);
			% \draw[fill=red!50!black] (210:0.22) circle (\vsize) ++(-130:.27) node[label=below:\tiny$X$]{};
			% \draw[fill=red!50!black] (-30:0.22) circle (\vsize) ++(-50:.27) node[label=below:\tiny$Y$]{};
			% \draw[fill=red!50!black] (90:0.22) circle (\vsize) ++(140:.31) node[label=above:\tiny$Z$]{};

			% grey filling for one covering.
			\draw[fill=white!70!black] (210:0.22) circle (\vsize) ++(-130:.27) node[label=below:\tiny$X$]{};
			\draw[fill=white!70!black] (-30:0.22) circle (\vsize) ++(-50:.27) node[label=below:\tiny$Y$]{};
			\draw[fill=white!70!black] (90:0.22) circle (\vsize) ++(40:.31) node[label=above:\tiny$Z$]{};

			\begin{scope}
				\clip (-30:0.22) circle (\vsize);
				\clip (210:0.22) circle (\vsize);
				% \fill[white!70!black] (-1,-1) rectangle (3,3);
				\clip (90:0.22) circle (\vsize);
				\fill[green!50!black] (-1,-1) rectangle (3,3);
			\end{scope}
			\begin{scope}
				\draw[] (-30:0.22) circle (\vsize);
				\draw[] (210:0.22) circle (\vsize);		
				\draw[] (90:0.22) circle (\vsize);
			\end{scope}
	%		\useasboundingbox (current bounding box);
			\node at (-0.7, 0.7){\slshape\color{subfiglabelcolor}\thesubfigure};
		\end{tikzpicture}
	\hspace{3pt}
	\hspace{\spacerlength}%\vrule\hspace{\spacerlength}
		%% EXAMPLE: X -> Y <- Z
		\refstepcounter{subfigure}\label{subfig:XZtoY}
		\begin{tikzpicture}[center base] 
			% \node[dpad0] (1) at (-0.5,2.3){$\var1$};
			\node[dpad0] (X) at (-0.45,1.9){$X$};
			\node[dpad0] (Y) at (0.3,1.25){$Y$};
			\node[dpad0] (Z) at (0.4,2.15){$Z$};
			% \draw[arr0] (1) to (X);
			\draw[arr0] (X) to[] (Y);
			\draw[arr1] (Z) to[] (Y);
			\path[fill=green!50!black] (210:0.22) circle (\vsize) ++(-130:.25) node[label=below:\tiny$X$]{};
			\path[fill=red!50!black] (-30:0.22) circle (\vsize) ++(-50:.25) node[label=below:\tiny$Y$]{};
			\path[fill=green!50!black] (90:0.22) circle (\vsize) ++(40:.29) node[label=above:\tiny$Z$]{};
			\begin{scope}
				\clip (-30:0.22) circle (\vsize);
				\clip (90:0.22) circle (\vsize);
				\fill[white!70!black] (-1,-1) rectangle (3,3);
			\end{scope}
			\begin{scope}
				\clip (-30:0.22) circle (\vsize);
				\clip (210:0.22) circle (\vsize);
				\fill[white!70!black] (-1,-1) rectangle (3,3);

				\clip (90:0.22) circle (\vsize);
				\fill[green!50!black] (-1,-1) rectangle (3,3);
				% \draw[ultra thick,white] (210:0.2) circle (\vsize);		
				% \draw[ultra thick,white] (90:0.2) circle (\vsize);	
				% \draw[ultra thick,white] (-30:0.2) circle (\vsize);
				% \draw[ultra thick,white] (210:0.2) circle (\vsize);		
				% \draw[ultra thick,white] (90:0.2) circle (\vsize);
			\end{scope}
			\draw[] (-30:0.22) circle (\vsize);
			\draw[] (210:0.22) circle (\vsize);		
			\draw[] (90:0.22) circle (\vsize);
	%		\useasboundingbox (current bounding box);
			\node at (-0.7, 0.7){\slshape\color{subfiglabelcolor}\thesubfigure};
		\end{tikzpicture}~
		\hspace{\spacerlength}%\vrule\hspace{\spacerlength}
			%% EXAMPLE: X <-> Y <-> Z
			\refstepcounter{subfigure}\label{subfig:XYZ-bichain}
			\begin{tikzpicture}[center base] 
				% \node[dpad0] (1) at (0.1,2.4){$\var1$};
				\node[dpad0] (X) at (-0.3,1.2){$X$};
				\node[dpad0] (Y) at (0.3,1.9){$Y$};
				\node[dpad0] (Z) at (-0.35,2.5){$Z$};
				% \draw[arr1] (1) to (X);
				% \draw[arr1] (1) to (Y);
				\draw[arr1] (X) to[bend right=15] (Y);
				\draw[arr1] (Y) to[bend right=15] (X);
				\draw[arr1] (Y) to[bend right=15] (Z);
				\draw[arr1] (Z) to[bend right=15] (Y);
				\path[fill=white!70!black] (210:0.22) circle (\vsize) ++(-130:.25) node[label=below:\tiny$X$]{};
				\path[fill=red!50!black] (-30:0.22) circle (\vsize) ++(-50:.25) node[label=below:\tiny$Y$]{};
				\path[fill=white!70!black] (90:0.22) circle (\vsize) ++(40:.29) node[label=above:\tiny$Z$]{};
				\begin{scope}
					\clip (-30:0.22) circle (\vsize);
					\clip (90:0.22) circle (\vsize);
					\fill[white!70!black] (-1,-1) rectangle (3,3);
				\end{scope}
				\begin{scope}
					\clip (90:0.22) circle (\vsize);
					\clip (210:0.22) circle (\vsize);
					\fill[red!50!black] (-1,-1) rectangle (3,3);
				\end{scope}
				\begin{scope}
					\clip (-30:0.22) circle (\vsize);
					\clip (210:0.22) circle (\vsize);
					\fill[white!70!black] (-1,-1) rectangle (3,3);

					\clip (90:0.22) circle (\vsize);
					\fill[green!50!black] (-1,-1) rectangle (3,3);
					% \draw[ultra thick,white] (210:0.2) circle (\vsize);		
					% \draw[ultra thick,white] (90:0.2) circle (\vsize);	
					% \draw[ultra thick,white] (-30:0.2) circle (\vsize);
					% \draw[ultra thick,white] (210:0.2) circle (\vsize);		
					% \draw[ultra thick,white] (90:0.2) circle (\vsize);
				\end{scope}
				\draw[] (-30:0.22) circle (\vsize);
				\draw[] (210:0.22) circle (\vsize);		
				\draw[] (90:0.22) circle (\vsize);
	%			\useasboundingbox (current bounding box);
				\node at (-0.7, 0.7){\slshape\color{subfiglabelcolor}\thesubfigure};
			\end{tikzpicture}
			}
	}
	\addtocounter{figure}{-1} %undo the thing I did to make subfigs work
	% \captionof{figure}{\label{fig:info-diagram}
	\caption{
		\itshape Illustrations of example graph information
		  functions $\{ \IDef{G_i} \}$, drawn underneath their
		  associated multigraphs $\{ G_i\}$. Each circle represents a
		  variable; an area in the intersection of circles $\{C_j\}$
		  but outside of circles $\{D_k\}$ corresponds to information
		  that is shared between all $C_j$'s, but not in any
		  $D_k$. Variation of a candidate distribution $\mu$ in a
		  green area makes its qualitative fit better (according to
		  $\IDef{}$), while variation in a red area makes its
		  qualitative fit worse; grey is neutral. Only the boxed
		  structures in blue, whose graph information functions can be
		  seen as assertions of (conditional) independence, are
		  expressible as BNs.} 

	\label{fig:info-diagram}
	\end{figure}

	The examples here are in reference to \Cref{fig:info-diagram}.
	Subfigures \ref{subfig:justX-0}, \ref{subfig:justX-1}, and \ref{subfig:justX-2} show that adding edges makes distriutions more deterministic. 
	As each edge $\ed LXY$ corresponds to an assertion about the ability to determine $Y$ from $X$, this should make some sense.
	In particular, \ref{subfig:justX-2} can be justified by the fact that if you can determine X from two different random draws, the draws probably did not have much randomness in them. Thus we can qualitatively encode a double-headed arrow as two arrows, further justifying the notation.
		%oli11: note that it does not matter for the semantics, because failing to meet the constraint imposed by a double-headed arrow will give infinite cost anyway, for any edge, as \beta > 0.
	%	
	Without any edges (e.g., \ref{subfig:justX-0},\ref{subfig:justXY}), the $G$-information rewards distributions with the most uncertainty. Each additional edge adds a penalty for a crescent, as when we move from \ref{subfig:justXY} to \ref{subfig:XtoY} to \ref{subfig:XY-cycle}.
	%
	Some graphs (\Cref{subfig:justX-1,subfig:1XY}) are \emph{universal}, in that every distribution gets the same score (so that score must be zero, beause this is the score a degenerate distribution gets). Such a graph has a structure such that \emph{any} distribution can be precisely encoded by the process in (b). 
	%	
	The $G$-information can also indicate independencies and conditional independencies, illustrated respectively in \ref{subfig:XYindep} and \ref{subfig:1XYZ}.

	So far all of the behaviors we have seen have been instances of entropy maximization / minimization, or independencies, but $G$-information captres more: for instance, if $G$ has cycles, as in \ref{subfig:XY-cycle} or \ref{subfig:XYZ-cycle}, the $G$-information prioritizes shared information between all variables. 

	In more complicated examples, where both penalties and rewards exist, we argue that the $G$-information still implicitly captures the qualitative structure. In \ref{subfig:XYZ-bichain}, $X$ and $Y$ determine one another, and $Z$ and $Y$ determine one another. It is clear that $X$ and $Z$ should be indpenedent given $Y$; it can also be argued that $Y$ should not have any randomness of its own (otherwise the draws from $X$ or $Z$ would likey not match one another) and that this structure suggests co-variation of all three variables.
	\end{example}
		
	\moveme{The alternative $G$-information deficit is the total uncertainty \emph{actually} result from each table, in the context of distribution $\mu$, minus the total entropy of the distribution. We can think of its negation as the uncertainty in $\mu$, which has not already been specified by the cpds in $\dg M$.}
	%END_FOLD
	\subsection{Localizing Uncertainty}
%   \subsection{}
    \textbf{What are you Uncertain About?}
    An idealized probabilist is uncertain only about an outcome. You see, there is some set $\Omega$ of all possible outcomes, and uncertainty takes the form of a probability distribution $\mu : \Delta\Omega$. There may also be ``random variables'' present, but these are merely functions taking an element of $\Omega$ to some set of possible values (which we denote by $\V(X)$, for a variable $X$).
    Of course, $\mu$ may result in lots of variance for a variable $X$ and none for $Y$ while another distribution on $\Omega$ does the opposite,
    but at the end of the day, uncertainty is about $\Omega$, and it is merely filtered through the variables.

    While this is indeed the formal account of probability that we share, the characterization of $\Omega$ is prior to variables may be misleading; it is common to define $\Omega$ ``at the last minute'', as the set of all realizable joint settings of the relevant variables, which can only be done after the rest of the modeling.

    \begin{example}
        For instance, we can formalize the process of including a new variable $Y$ by taking a new set of outcomes $\Omega' := \Omega \times \V(Y)$, formally setting $Y : \Omega \times \V(Y) \to \V(Y)$ to be the projection of the second component, and modifying any other variable $X : \Omega \to \V(X)$ to a variable $X' : \Omega' \to \V(X)$ on the new set of outcomes by pre-composing it with a projection to the first component, as illustrated in the following commutative diagram.
        \begin{center}
            \begin{tikzcd}[column sep = 1em]
                \Omega \ar[rr, "X"] && \V(X) \\ & \Omega \times \V(Y)  \ar[ru, "X':= X \circ \pi_1"description, dashed] \ar[rr, "Y' := \pi_2"'] \ar[lu, "\pi_1"] &&  \V(Y)
            \end{tikzcd}
        \end{center}

        We must also extend $\mu$ to a new distribution $\mu'$ on the new set $\Omega'$ of outcomes, in such a way that the marginal on $\Omega$ is preserved -- that is, we set $\mu'(\omega, y) := \mu(\omega) p(y \mid \omega)$, where $p(y \mid \omega)$ is new information not contained in the original probability space.
    \end{example}

    If the set of outcomes $\Omega$ is built up from variables in this way, then the question of which variables are ``responsible'' for uncertainty remains relevant.
%    An answer of the form
%   \[ X \text{ is responsible for 5\% of the uncertainty};\quad Y \text{ is responsible for 10\% of the uncertainty}, \ldots \]
%   is unlikely to

    \subsubsection{Joint Variables and Variable Commonality }
    Let $\Omega$ is a set of outcomes. A set of random variables $\mat X = \{ X : \Omega \to \V(X)  \mid X \in \mat X \}$ is itself a random variable, taking values $\V(\mat X) = \prod_{X \in \mat X} \V(X) $ which are joint settings of its elements. As a function $\Omega \to \V(\mat X)$ it is explicitly characterized by $\mat X(\omega) := \{ X(\omega) \}_{X \in \mat X}$.
    This identification is intuitive, and is made almost everywhere, implicitly if not explicitly (e.g., via the notation $p(x,y)$). It also has the effect of identifying a variable $X$ with the singleton $\{X\}$, and from this perspective the joint variable $\mat X$ may be seen as a union of variables $\mat X = \bigcup_{X \in \mat X} \{ X \}$.
    This is a trivial restatement of the construction, but highlights a crucial fact: $\mat X$ represents \emph{join} of the information (informally speaking) of the individual variables--- a fact which is obscured when we simply think of joint settings as sets, which do not seem to have this polarity. (In general, of course, sets are just as easily intersected as unioned.) The view of $\mat X$ as a random variable representing the join of its elements serves its purpose well, which is why so many authors, including us, make this identification. When we wish to emphasize that joint settings of $X$ and $Y$ are the join of $X$ and $Y$, or to make the tie to propositional logic explicit, we write $X \lor Y$ for the joint random variable.


    The existence of a join (``$\lor$'') makes us wonder about a \emph{meet} (``$\land$''). Does the \emph{intersection} of sets of random variables capture a useful notion of shared information? Unfortunately not.
    To illustrate, let $A, B, C, D$ be independent random variables, and $A'$ be a fifth variable that happens to take the same value as $A$ at all worlds (but is conceptually different from $A$);%
        \footnote{Some might object by saying that formally speaking $A = A'$, but we can dismiss this concern by further distinguishing $A$ and $A'$; for instance, by letting them differ slightly on a single outcome $\omega$ which necessarily has probability zero.}
    suppose further that $\mat X = \{A,B,C\}$ and $\mat Y = \{A', B, D\}$. Now $\mat X \cap \mat Y = \{B\}$, which fails to capture the fact that there is also information about $A$ (or equivalently $A'$) that is shared between $\mat X$ and $\mat Y$. Indeed, $\{A\} \cap \{A'\} = \emptyset$ which is problematic, given that $A$ shares the entirety of its probabilistic behavior with $A'$.
    Contrast this behavior with that of the union.  The joint variable $\mat X \cup \mat Y$ does not have this problem: a joint setting $(a,b,c,a',d) \in \V(\mat X \cup \mat Y)$ clearly contains precisely the union of any information in $\mat X$ or $\mat Y$. Notice that there is a harmless redundancy: the tuple contains both $a$ and $a'$ even though we know them to be equal. This minor defect of $\cup$ as a join is in some sense a reflection of the fatal flaw of $\cap$ as a meet: in both cases, the issue is that only a very strict notion of variable identity, and none of the variable's behavior, is taken into account.

    For this reason, the sets-of-variables account is brittle in many ways, and leans assumptions that a modeler has divided the world into independent, atomic variables. But what do we do when such assumptions are false? What if concepts aren't always primitive or independent? Entropy offers a compelling answer --- one that does not depend on names or even the number of variables, and is invariant under changes of variables.

    \subsection{The Information Profile: Information as a Signed Measure.}






    % \subsubsection{Constructing the Information Profile of a Distribution}

%   Some authors simply define $\H(Y \mid X)$ to be a difference of joint entropies $\H(X,Y) - \H(X)$. Similarly, we can write the mutual information as an alternating sum of joint entropies.
%   \begin{align*}
%       \I(X \land Y) &:= \H(X,Y) - \H(Y \mid X) - \H(X \mid Y)  & \text{[the Venn diagram without the sides]}\\
%           &=  \H(X,Y) - \H(X,Y) + \H(X) - \H(X,Y) + \H(Y)  &\text{[expanding conditional entropy]}\\
%           &= - \H(X,Y) + \H(X) + \H(Y)
%   \end{align*}
    Most quantities in information theory can be written as a difference of entropies.
    For instance, some authors simply define $\H(Y \mid X)$ to be $\H(X,Y) - \H(X)$.
    We now write the formulas for information shared between 1, 2, and 3 variables in a more suggestive form.
    \begin{align*}
        \textit{Information in $X_1$:}  && \I(X_1 &) = \H(X_1) ;\\
        \textit{Mutual Information between $X_1, X_2$:} && \I(X_1 &\land X_2) = \H(X_1) + \H(X_2)  \\
             &&&\qquad - \H(X_1, X_2); \\
         \textit{Interaction Information of $X_1, X_2, X_3$:}&&\I(X_1 \land &X_2 \land X_3) = \H(X_1) + \H(X_2) + \H(X_3) \\
            &&&\qquad - \H(X_1, X_2) - \H(X_2, X_3) - \H(X_1, X_3) \\
            &&&\qquad  + \H(X_1, X_2, X_3)  .\\
    \end{align*}
    This suggests that we can extend to arbitrary elements of the Boolean algebra by use of an inclusion-exclusion formula. For terms involving 3 and higher conjuncts, it is common to take such a formula to be the definition.

    More formally, let $\N$ be a set of variables, $B[\N]$ be the free Boolean algebra generated by $\N$, and $\mu$ be a joint distribution over $\V(\N)$. As we extend entropy to these new elements, we will change the symbol $\H$ to $\I$, for compatibility with the standard notation, such as the mutual information. The information of a joint variable $\I_\mu(X \lor Y)$ which we have written so far as $\H_\mu(\{X,Y\})$ or simply $\H(X,Y)$, already tells us how to measure the entropy of joins of random variables. We simply convert meets to joins using the inclusion-exclusion rule, so that
    \begin{equation}\label{eq:inclexcl}
        \I_\mu\Big(\bigwedge_{X \in S} X\Big) =  \sum_{T \subseteq S} (-1)^{|T|+1} \I_\mu\Big( \bigvee_{X \in T} X \Big) ~,
    \end{equation}
    % (and the footsteps of \cite{JakulinBratko,BellCoInformation,})
    by analogy to the
    \href{https://en.wikipedia.org/wiki/Inclusion%E2%80%93exclusion_principle}
        {the inclusion-exclusion rule} for probability and counting measures \cite[eq 2.7]{halpern2017reasoning}.

    One might worry because an element $b \in B[\N]$ of the free Boolean algebra can be represented in more than one way.

    \begin{inactive}
        In the formal definition that follows, we will first convert every $b$ to its canonical CNF for definiteness, but  afterwards we will show that the normalization is unnecessary, and that \eqref{eq:inclexcl} holds independent of the representation.

        \begin{fact}
            For every set $S$ and $b \in B[S]$, there exists a unique finite matrix $S = (s_{i,j})$ where each $s_{i,j}$ is a literal equal either $s$ or $\lnot s$, such that
            $\displaystyle b = \bigwedge_{i} \bigvee_{j} s_{i,j} $
        \end{fact}
        \begin{defn}
            The information $\I_\mu$ with respect to a distribution $\mu$ and a set $\N$ of variables, of an element $b \in B[\N]$,
            \[          \I_\mu\Big(\bigwedge_{X_x \in S} X_s\Big) =  \sum_{T \subseteq S} (-1)^{|T|+1} \H\Big( T \Big) ~. \]
            %       \begin{itemize}[itemsep=0pt, parsep=1pt]
            %           \item If $\varphi = \bigvee_i X_i$, we define $\I^\N_\mu(\varphi) := \H_\mu(X_1, \ldots, X_n)$.
            %           \item For $\varphi = \bigwedge_i X_i$, we define $\I^\N_\mu(\varphi)
            %                := \sum_{T \subseteq S} (-1)^{|T|+1} \H\Big(\bigvee_{X \in X} T\Big)$.
            %       \end{itemize}
        \end{defn}
    \end{inactive}


\begin{defn}
    We define the \emph{information} $\I_\mu^\N$ with respect to a distribution $\mu$ and a set $\N$ of variables, of a formula $\varphi \in \lang{prop}$, we inductively define
%   \[          \I_\mu\Big(\bigwedge_{X_x \in S} X_s\Big) =  \sum_{T \subseteq S} (-1)^{|T|+1} \H\Big( T \Big) ~. \]
            \begin{itemize}[itemsep=0pt, parsep=1pt]
                \item For $\varphi = \phi \lor \psi$, we define $\I^\N_\mu(\varphi) := \H_\mu(X_1, \ldots, X_n)$.
                \item For $\varphi = \bigwedge_i X_i$, we define $\I^\N_\mu(\varphi)
                     := \sum_{T \subseteq S} (-1)^{|T|+1} \H\Big(\bigvee_{X \in X} T\Big)$.
            \end{itemize}
\end{defn}

    \begin{defn}
        The information $\I_\mu$ with respect to a distribution $\mu$ and a set $\N$ of variables, of an element $b \in B[\N]$,
    \[          \I_\mu\Big(\bigwedge_{X_x \in S} X_s\Big) =  \sum_{T \subseteq S} (-1)^{|T|+1} \H\Big( T \Big) ~. \]
%       \begin{itemize}[itemsep=0pt, parsep=1pt]
%           \item If $\varphi = \bigvee_i X_i$, we define $\I^\N_\mu(\varphi) := \H_\mu(X_1, \ldots, X_n)$.
%           \item For $\varphi = \bigwedge_i X_i$, we define $\I^\N_\mu(\varphi)
%                := \sum_{T \subseteq S} (-1)^{|T|+1} \H\Big(\bigvee_{X \in X} T\Big)$.
%       \end{itemize}
    \end{defn}

    \begin{prop}
        $\I_\mu^\N$ is well-defined.
    \end{prop}

    \begin{defn}
        The \emph{information profile} of $\mu$ with respect to $\N$, denoted $\mat I_\mu^\N$, is a ($2^{|\N|} -1$) dimensional vector
    \end{defn}

    \begin{example}
        content
    \end{example}



    \begin{prop}
        There is a factorization of $\Omega = X_1 \times X_2 \times \ldots \times X_n$
    \end{prop}

    This formula is given in \cite{}.

%   and the $\mu$-entropy, $\H_\mu$, can be seen as a measure over the variables $\N$, in which every $S \subseteq \N$ is measurable.
    \subsection{Illustrations and Examples}.

    %   \subsection{}
    %   Once again, let $\N$ be a set of variables, and $\mu$ be a joint distribution over $\N$.
    %   The general idea is that for variables $X, Y, Z \in \N$

    \begin{example}
        Let $\mu$ be a distribution over the three variables $\N = \{X,Y, Z\}$.
        %       \lipsum[1-4]
        \begin{center}%{R}{3cm}
            %           \let\varnames{X,Y,Z}
            \begin{tikzpicture}
                \begin{scope}[scale=0.5]
                    \begin{scope}[blend group=hard light, opacity=0.5]
                        \draw[fill=color1!50!white]   ( 0:1.2) circle (2);
                        \draw[fill=color2!50!white] (120:1.2) circle (2);
                        \draw[fill=color3!50!white] (-120:1.2) circle (2);
%                       \draw[fill=red!50!white]   ( 0:1.2) circle (2);
%                       \draw[fill=green!50!white] (120:1.2) circle (2);
%                       \draw[fill=blue!50!white] (-120:1.2) circle (2);
                    \end{scope}

                    \draw(0:1.2) circle (2);
                    \draw(120:1.2) circle (2);
                    \draw(-120:1.2) circle (2);

                    \node at (0:3.7) {X};
                    \node at (120:3.7) {Y};
                    \node at (-120:3.7) {Z};
                \end{scope}
            \end{tikzpicture}
        \end{center}
        %       \lipsum[1-6]
    \end{example}
    \subsection{Paying for structure: a symmetric extension of \texorpdfstring{$\IDef{}$}{IDef}}
    % Show that it's a special case
	
	f
\begin{wip}  
	\section{Trace Semantics}
	Let $d$ be a distribution over $\Ed^{\dg M}$. 
	Choose a link $\ed LXY \in \Ed$, and let $\mathbf Z_L := \N^\dg M \setminus \{X, Y\}$ be the set of all other variables, so that a joint setting is characterized by a value $(x,y,\mat z)$.
	
	The link $L$ and its associated cpt $\bp$ can be extended to a transformer $\tau_L: \Delta \V(\dg M) \to \Delta \V(\dg M)$ on joint distributions in a couple of ways, such as:
\[
	\begin{aligned}
		\tau(\mu)(x,y,\mat z) :&= \mu(x,y,\mat z)\frac{\bp(y \mid x)}{\mu(y\mid x)} \\
		&= \mu(x)\; \bp(y \mid x)\; \mu(\mat z \mid x,y) 
	\end{aligned}\qquad\text{and}\qquad
	\begin{aligned}
		\tau(\mu)(x,y,\mat z) :&= \mu(x,y,\mat z) \frac{\bp(y \mid x)}{\mu(y\mid x, \mathbf z)} \\
		&= \mu(x,\mat z)\; \bp(y \mid x)
	\end{aligned}\\
\]
	
\subsection{Traces of a PDG}
The arrows of a PDG are cpds, which are probabilistic functions, and can be composed to form further probabilistic functions. 

\begin{defn}
	A \emph{schedule} $\mathbf s : \Delta[\mathbb N \to \Ed^{\dg M}]$ for a PDG $\dg M$ is distribution over sequences of $\dg M$'s edges. 
\end{defn}
\begin{defn}
   The \emph{trace distribution} of a PDG is the distribution or outputs represented by the program \texttt{trace}$_{\dg M}$
   % \begin{algorithmic}
   % 	 % TODO
   % 	\end{algorithmic}

\end{defn}
\begin{defn}[trace semantics]
	For a PDG $\dg M$ and schedule $\mathbf s$ for $\dg M$, the trace semantics is a distribution
	over the $\sigma$-algebra  whose 
	\[ \mathbb{T}_{\bf s}{\dg M} = 
		% \Big\{ 
		% \Big\}
	 \]
\end{defn}
\end{wip}
	
%	\begin{align*}
%		 \tau(\mu)(x,y,\mat z) &:= \mu(x,y,\mat z) \frac{\bp(y \mid x)}{\mu(y\mid x)} 
%			 &  \tau(\mu)(x,y,\mat z) &:= \mu(x,y,\mat z) \frac{\bp(y \mid x)}{\mu(y\mid x, \mathbf z)} \\
% 			&= \mu(x)\; \bp(y \mid x)\; \mu(\mat z \mid x,y) 
%			 &   &= \mu(x,\mat z)\; \bp(y \mid x)
%	\end{align*}
%
	
	% \section{Lax PDGs and their Semantics}
	% \subsection{Sets of Distributions}
	% \subsection{Scoring in Lax PDGs}
	% \subsection{Trace Semantics for Lax PDGs}

	\part{Capturing Other Modeling Formalisms}
	PDGs are extremely flexible, and nicely capture 

    \section{Raw Probability Distributions}
	Probability distributions themselves are a particular kind of PDG; 
	a  triple $(\Omega, \mathcal F, \Pr)$ is naturally identified with the diagram
	\begin{center}
		\begin{tikzpicture}
			\node[dpadded] (1) at (0,0) {$\var 1$};
			\node[dpadded] (W) at (3,0) {$\Omega$};

			\draw[arr] (1) to node[fill=white]{$\Pr$} (W);
		\end{tikzpicture}
	\end{center}

	% \begin{example}\label{ex:worldsonly}
	% \end{example}
		
    Let $\N$ be a set of variables whose values are given by $\V$. When we use the characterization of PDGs based on directed hyper-graphs, a joint distribution $\mu \in \Delta[\V(\N)]$ is naturally identified with a particular unweighted PDG. Specifically, the data of $\mu$ is given by the PDG $(\N, \{ E_0 \}, \V, \mat p)$ containing a single hyper-edge $E_0$ whose source is empty and whose target is all of $\N$, associated with the cpd $\bp[E](\mat x) := \mu(\mat x)$.

    \begin{example}
        For a 3-variable
    \end{example}
	


	
	
	
	\section{Probabilistic Graphical Models}
	
	\label{sec:other-graphical-models} 
	%oli21: no need to mention DNs here, right?
	%joe19: right
	%We now relate 
	We start by relating
	PDGs to two of the most popular graphical models: BNs and factor
	graphs. PDGs are strictly more general than BNs, and can emulate factor graphs
	for a particular value of $\gamma$. 
	%oli8: Unecessary, I'll get to it. Would require updating anyway. Deleted.
		% More concretely, we will see
	    %     that we can get the standard free energy of factor graphs, and
	    %     more generally, of the full exponential family that it
	    %     corresponds to, by setting each $\alpha$ to zero, and removing
	    %     an implicit  `local regularization' term in $\mathcal U$. 
	%	; for others, consult \Cref{fig:model-transformations} and its explanation in \Cref{sec:many-relations-graphical-models}.
	%joe10: can cut this to save space if needed to save space
	%oli12: done
	%joe11: reinstated, since we have the space, but I don't mind cutting
	%it again.  But it actually doesn't seem to save space in practice
	%joe17: OK; I think we have room.  But we shoudl definitely reinstate
	%the section numbers I'm pretty sure they're allowed
	%\vfull{
	\subsection{Bayesian Networks} 
	%}%\end{vfull}
	\label{sec:bn-convert}
		A (quantitative) Bayesian Network $(G, f)$ consists of two parts: its qualitative graphical structure $G$, indicating a set of
		variables and
		conditional independencies, and its quantitative data $f$, an assignment of 
		a cpd $p_i(X_i \mid \Pa(X_i))$ to each variable $X_i$.
	    %
	    %joe4: this may be true, but why bother saying it?
	    %oli5: I guess I really have a terrible model of what you view as
	    %worth saying. This might not be the most efficient use of space, but
	    %I think provides useful historical background, explains why the
	    %problem hasn't been solved yet, provides a great deal more intuititon
	    %about how this solution works than the proof. It also tells a story.  
	    %joe5: My model is ``have a clear conception of the story and
	    %ruthlessly restructure things so as to bring it out''
	            %oli5: I've changed it to vfull, as I understand we're short on space,
	    %but I remain confused about why you don't view it as worth
	    %saying---especially in contrast to the verbose expansions of
	    %sentences you employ when you rewrite my texts, and reitterations of
	    %previous points with "as we've said". 
	    %joe5: HOw does it fit the story?  We are not telling a story about
	    %BNs, but about PDGs.  Even in the full paper, it doesn't belong.
	            %oli5: I also think the narrative and reasons for dropping the independences are important for discussing BNs, which have historically had that focus.
	    % I've therefore reinstated this paragraph, and promoted the rest of the comment to the full version.
	    	The first is usually seen as more fundamental
	    %oli8: Updated to reflect new understanding of \alpha, though could use further editing
	    %	; one can think of the corresponding PDG as keeping only the second. 
	    %joe7
	    %	, but equation \eqref{eq:uniqdist}, specifically the limit as
	    %        $\gamma \to 0$, can be thought of as elevating the
	    %        quantitative data above the independence assumptions.  
	            but the third semantics ($\bbr{\dg M}^*$) can be
	            can be understood as viewing the quantitative information as
	    %joe7*: But this begs the question.  Why are we doing this?
	    %oli9: Because with BN's it's impossible to break the independece assumptions.  Worse, there's no way to sepcify constaints ---even constraints consistent with the independence assumptions--- unless they lie on one of the edges of the graph. 
	    % In a BN, independence is primary. But I think it's really easy to argue that those independencies aught to take a back seat to the data. This way you can do both at once.
	            more important that the qualitative independence assumptions.  
	    %oli5: I can do without this sentence though:
	    %	Fortunately, there is an intuitive way to recover the
	    %independencies by optimizing for a natural information-theoretic
	    %quantity: the extra information (\Cref{sec:extra}). 
	    %joe5*: Kept the sentence above. Cut the rest.  I don't even know what
	    %contravariant means in this context.
	    %oli6: I find this a useful explanation of why keeping track of 
	    % independences messes up modularity. I explain what I mean by contravarient
	    % immediately below. It can be cut for space but I'm marking it for
	    % the full paper 
	    %joe6: No!  This is a distraction.  We are not writing a paper on BNs,
	    %or what is the right way to interpret things to get modularity. Focus
	    %on the story!
    	This is the more desirable option if one cares about
    	modularity, because independencies and cpds specify a distribution in
		contravariant ways: a subset of
    	the graph, and hence of the cpds, results in a \emph{super-set} of
    	the independencies, and vice versa. It is in part for this reason
    	that a BN does not say monotonically less when edges are deleted, or
    	more when edges are added. 
	   
	
	    %joe7: I don't understand the net paragraph, so I'm just cutting it.

	    To do without the independence assumptions, one might hope
	            that maximizing entropy would recover the conditional
	            independencies, as maximizing entropy tends to make things as
	            independent as possible given the constraints --- but
	            maximizing entropy alone is not enough
	            (\Cref{ex:counterexample}).

	    	In response, some \cite{williamson2001foundations}\cite{holmes2001independence} have added alternate constraints of a causal flavor, which are perhaps smaller and more palatable than the full set of conditional independencies.  Williamson, for instance, introduces what he calls the \emph{principle of causal irrelevance}--- that extending a BN with variables $\{C_i\}$ with children $\{D_j\}$ where no $C_i$ depends on a $D_j$, restricts to the same distribution as the original.  However, these constraints are also overkill: by merely maximizing entropy one can already get the BN distribution for rooted trees, disconnected graphs, and even graphs that have nodes with multiple incoming edges, so long as every row in each such target node's cpd has the same entropy---none of which are reflected as a weakening of assumptions in a Williamson's principle of causal irrelevance.
	    	
	    
	    %oli5: I've rewritten this more dramatically and pulled it out of the comment, as a transition
	    %joe5
	    %The key insight%
	    %joe8: cut this too.  it's no longer consistent with what we do (and I
	    %never undrstaood it anyway).
	    The key insight is that we can recover the BN distribution if we control for
	    %joe5: sorry; I don't understand this.  What does it mean to control
	    %for the counterfactual nature of the cpd?  For that matter, what's
	    %counterfactult about it?
	    %oli6: This is the motivation for the extra information. We
	    %acknowledge that a cpd 
	    % results in a distribution at its target, whose entropy depends on
	    % the distribution at its 
	    % source. Therefore, the cpd results in a different constraint,
	    % depending on what the distirbution 
	    % at the source is (the cpd counterfactually contains information
	    % about the distribution at $Y$, even if the distribution at X were to
	    % be completely different). In minimizing the information we know
	    % about the distribution, we have to control for the fact that cpds
	    % have this property, making them very unlike the standard constraints
	    % that are used (e.g., for exponential families). The resulting
	            % correction gives us the extra information.
	    %joe6*: If you want to keep this, you need to slow down.  Look at a BN
	    %of the form X -> Y and point out that the cpd for X gives us the
	    %actual distribution on X, but the cpd lets us detemine the marginal
	    %probabilty of Y for all distributions on X.  In that sense, its
	    %giving us counterfactual information.  As I said in an earlier joe6*
	    %comment, you probably should say this earlier.
	            %Then exlain (slowly) how your definition does account for it.
	    %This will be a mysterious definition to many readers, so you have to
	    %motivate it much better.         
        the counterfactual nature of the cpd as a constraint, as we
        do in \Cref{sec:scoring-semantics}, allowing us to recover the
        independencies without assuming them.
	    %}        
	    Nevertheless, as we shall show, our third semantics still allows us to
	    recover the independencies.
	
	\Cref{constr:hyperedge-reducton} can be generalized to convert arbitrary Bayesian Networks into PDGs.
	%oli19: don't need to wrap in defn
	% \begin{defn}[BN to PDG]
	%oli21:
	% Given a BN $\mathcal B$, and a positive number $\beta_X$ for
	%         each variable $X$ of $\cal B$,
	%joe19
	%Given a BN $\mathcal B$, and a positive confidence $\beta_X$ for
	Given a BN $\mathcal B$ and a positive confidence $\beta_X$ for
	the cpd of each variable $X$ of $\cal B$,
	let $\PDGof{\mathcal B, \beta}$
	be the PDG comprising the cpds of $\cal B$
	in this way. %we defer the straightforward formal details to the appendix. 
	
		
		% \begin{theorem}[restate=thmbnsRpdgs]\label{thm:bns-are-pdgs}
	    % \begin{restatable}{theorem}{bnsRpdgs}\label{thm:bns-are-pdgs}
	\begthm{theorem}{thm:bns-are-pdgs}
	 	  If $\cal B$ is a Bayesian network
	%oli15:
	    % and specifies the distribution $\Pr_{\cal B}$, then 
	%joe14: for consistency
	%          and $\Pr_{\cal B}$ is the distribution it specifies, then
	          and $\Pr_{\cal B}$ is the distribution it specifies, then
	          %oli11: insert \betas, and reword because one semantics distribution is provably unique.
		% for all $\gamma > 0$,
		% we have $\bbr{\PDGof{{\mathcal B}}}_\gamma^* =
		% \bbr{\PDGof{{\mathcal B}}}^*$.  Moreover, the unique probability distribution in
		% $\bbr{\PDGof{{\mathcal B}}}^*$ is the distribution specified by
		%             ${\mathcal B}$.
	%joe14: not all vectors \beta
	%oli16*: Currently, \beta > 0 by definition; there's no need for this
	% if we keep our current definition. Therefore, reverted for now.
	%joe15*: You missed my point.  Do you want to rquire that all entries
	%are strictly positive? If so, you have to say it.  This does not
	%follow from \beta -> 0. 
	%oli17: Oh, I see what you're saying. I just assuemed "all vectors beta" was
	% valid shorthand for "all valid vectors of positive numbers, like in our
	% definition"---but you're probably right to state this
	% explicitly. I'm reinstating 
	% your version.
	%it does in one of our definitions
	          % Benefits of mandating \beta > 0:
	%  - it means a PDG always represents a unique distribtion as \gamma -> 0
	%  - we don't have to keep mentioning this condition (and we're short on space).
	% Benefits of allowing \beta=0
	%  - Can articulate an edge qualitatively without supplying a cpt (ideally
	%       we would articulate how this works better before doing this. Ideally,
	%       we could get to the point where people buy the qualitative picture in 
	%       well enough that they understand the diagrams and feel like they know
	%       what a qualitative edge does)
	%  - [works better with \alpha]: \alpha = 0 makes a lot of sense, and so 
	%       the symmetry probably worth it when we include \alpha.
	        % for all $\gamma > 0$ and all vectors $\beta$,
	%oli16: reinstated the above and commented out the below:
	        for all $\gamma > 0$ and all vectors $\beta$ such
	        that $\beta_L > 0$ for all edges $L$,
	%joe15: I will not change this, but if you don't change it back to my
	%version, then you have to weaken the requirement  \beta_X > 0 in
	%Definition 4.1.
	        %joe14
	    %    $\bbr{\PDGof{\mathcal B, \beta}}_\gamma^* = \{ \Pr_{\cal B}\}$.
	        $\bbr{\PDGof{\mathcal B, \beta}}_\gamma^* = \{ \Pr_{\cal B}\}$, 
	    %oli15: added
	    %joe14: It's not ``in particular'', since it's not a special case
	    %of the above, although it does follow from the above.
	    %oli16: does it not make sense to you to say "these two functions
	    %    are the same, so in particular, their minima are the same?" 
	%joe15: what you wrote below is certainly a logical consequence of
	%what you wrote above, but it's not a special case.   I would not say
	%(in English) ``in particular, their minima are the same''.   I would
	%say ``and so their minima are the same''.  We're arguing about
	%English here, not mathematics.
	    %oli16: whether or not this is an obvious special case might depend on your 
	    % representation of the function (it's natural to represent a convex
	    % function as a taylor expansion around its critical points, for instance).
	        %    In particular, $\bbr{\PDGof{\mathcal B, \beta}}^* = \Pr_{\cal B}$.
	and thus $\bbr{\PDGof{\mathcal B, \beta}}^* = \Pr_{\cal B}$.    
	\end{theorem}
	%oli24: added discussion 
	\Cref{thm:bns-are-pdgs} is quite robust to parameter choices: it holds for every
	weight vector $\beta$ and all $\gamma > 0$. However, it does lean heavily on
	our assumption that $\alpha = \mathbf 1$, making it our only result
	that does not have a natural analog for general $\alpha$.
	
	This is true for PDGs which are structurally just subsets of BNs, where every node has at most one incoming edge (making the BN acyclic, when viewed as a directed hyper-graph). In such a structure, every cpd can be simultaneously attained perfectly regardless of how little you are attached to them ($\beta$) and the strength of the bias towards uncertainty $(\gamma)$.
	However, not all PDGs have the particularly nice structure,
		and these parameters are important when there can be conflict between beliefs. 
		 
	% In proving \cref{thm:bns-are-pdgs}, 
	% we show that $\IDef{\PDGof{\mathcal B}}$ measures the extent to which the independencies
	% are violated, which requires $\alpha = \mathbf 1$.
	
	%oli11: For the full paper, once we add restriction & combination, add the following result for conditional BNs.
	%joe10*: If we include this, we'll need a *much* better story.  The
	%goal is not to overwhelm the reader with theorems, but to tell a
	%story.  My guess is that if this belongs anywhere, it belongs in a
	%section on  modularity, where we have a more general discussion of
	%modularity   This will be an example there.
	%joe17*: See my comment above
	%oli20: oops, agreed.
	\begin{inactive}
	    \begin{prop}
	    If $\mathcal B_1, \mathcal B_2, \ldots$ are a conditional Bayesian
	    networks containing whose sets of variables they condition on are
	    pairwise disjoint, then they can be combined into one conditional BN
	    $\cal B$, and  PDG union 
	        %	\[ \dg M} := \bigoplus_i \mathcal
	 	\[ {\dg M} := \bigoplus_i \PDGof{\mathcal B_i} \]  
				satisfies
				$\bbr{\dg M} = \bbr{\PDGof{\cal B}}$.
		\end{prop}
	\end{inactive}
	
	% d-separation? I don't have a lot to say but it the specialness of the ``colider'' or head-to-head nodes in determining connectedness  is related to the difference in interpretations I think.

	\subsection{Factor Graphs} 
	\label{sec:factor-graphs}
	%oli8: moved all of the original material to the appendix, this section is new.
	%joe7
	%	Factor graphs \cite{koller2009probabilistic}, make some
	%        similar promises to PDGs. They generalize BNs, the barrier to
	%        adding observations is extremely low, and their failure to
	%        normalize in general may be viewed as a kind of inconsistency
	%        in a very similar fashion \cite{wainwright2008graphical}.
	%joe18: we may want to cite the original paper on factor graphs here,
	%along with (probably more accessible) KF09; I on'd tfeel strongly
	%about this though.
	%oli21: added refernece; is easy to remove. I've also subsituted
	% the wainwright reference because it's much more focused on factor graphs
	% and the authors more strongly take the "factor graphs generalize BNs" position.
	% Factor graphs \cite{KF09},
	Factor graphs 
	%oli22: The original paper is actually really persuasive and arguably
	%a better introduction
	%joe20: you need to send me an updated bib file
	%\cite{wainwright2008graphical,kschischang2001sumproduct},
	\cite{kschischang2001sumproduct},
	%	like PDGs, generalize BNs and have a low barrier to adding observations.
	%joe19: we never discuss adding observations to a factor graph
	%	like PDGs, generalize BNs.
	%oli22: fair. On the other hand, they are clearly less strict and
	% anyone who knows about them will identify that they solve the "we can't 
	% legally add this information" problem.
	%oli22: also, I want to soften this b/c  while they can represent the 
	% distribution of any quantitative BN, they don't capture the 
	% indepencencies of a qualitative BN  (though directed factor graphs do) and
	% do not contain the counterfactual information that a BN does. 
	% This may seem like a technicality, but it is actually a core part of the
	% story: the factor graph representation does not exactly capture the BN; its
	% sensitivity to future additions &  depenednce on \gamma,\beta are features
	% that the BN does not have.
	%Rewording:
	%joe20: why is it just ``claim''.  They clearly do, in a precise
	%sense.  In what sense are they more modular?  I've never seen the
	%modularity of factor graphs discussed; rather, the claim is that
	%having the factors makes this more efficent computationally.  Why
	%make statements that may be controversial or unclar, that we don't
	%make se of anywhere?  This is not a paper on factor graphs.
	%like PDGs, claim to generalize BNs, and are also much more modular.
	like PDGs, generalize BNs.
	%oli22: I still would defend this, but let's not go there right now. Most
	%people would agree with
	%*%
	%joe20: maybe, but what about those that don't?  why introduce this
	%when we don't need it.
	% moreover, their failure to
	%         normalize in general may be viewed as a way of representing
	%         some inconsistency.
	%oli22: introduce one more acronym
	% In this section, we consider the relationship between factor graphs and PDGs.
	In this section, we consider the relationship between factor graphs (FGs) and PDGs.
	\begin{defn}
	%oli22: if "set" is preferable to "collection" for indexed sets when
	% we define PDGs, it's certainly prefereable here also. 
	 % A \emph{factor graph} $\Phi$ is a collection of random variables
	 A \emph{factor graph} $\Phi$ is a set of random variables
	        $\mathcal X = \{X_i\}$ and \emph{factors}
	       $\{\phi_J\colon \V(X_J) \to \mathbb R_{\geq0}\}_{J \in
	%joe19
	%\mathcal J }$ %where each $J \in \mathcal J$ is associated
	\mathcal J }$,
	%joe19
	%where each $X_J \subseteq \mathcal X$.
	%more precisely, each factor $\phi_J$ is associated with a subset
	where $X_J \subseteq \mathcal X$.  
	More precisely, each factor $\phi_J$ is associated with a subset
	$X_J\subseteq \mathcal{X}$ of variables, and maps
	joint settings of $X_J$ to non-negative real numbers.
	%
	%oli23*:moving this material inside the definition
	$\Phi$ specifies a distribution
	\[ {\Pr}_{\Phi}(\vec x) = \frac{1}{Z_{\Phi}}
	 	\prod_{J \in \cal J} \phi_J(\vec x_J), \]
	%joe21
	%where $\vec{x}$ is a joint setting on all of the variables,
	where $\vec{x}$ is a joint setting of all of the variables,
	 $\vec{x}_J$ is the restriction of $\vec{x}$ to only the
	 variables $X_J$, and $Z_{\Phi}$ is the constant required to
	 normalize the distribution.  
	\end{defn}
	
	%oli23*: moved all of this material below
	% We take a \emph{weighted factor graph} $\Psi$ to be a pair $(\Phi,\theta)$ consisting of a factor graph $\Phi$  together with a vector of non-negative weights  $\{ \theta_J \}_{J \in \mathcal J}$.
	% $\Psi$ specifies a distribution 
	%oli23: refactor, using \Phi here, no weights, \Psi later.
	% \[ {\Pr}_{\Psi}(\vec x) = \frac{1}{Z_{\Psi}}
	% \[ {\Pr}_{(\Phi,\theta)}(\vec x) = \frac{1}{Z_{\Phi,\theta}}
	% 		\prod_{J \in \cal J} \phi_J(\vec x_J)^{\theta_J} \]
	
	
	%oli23: eliminating this is a benefit of the refactor
		% A factor graph $\Phi$ defines a distribution $\Pr_\Phi$ and scoring function 
		% $\GFE_{\Phi}$ by implicitly taking every $\theta_J = 1$.
	
	%joe21: this isn't a good story
	%The cpds of a PDG straightforwardly constitute the data of a factor graph.
	%oli24: I think it's way more persuasive if we just interpret the data
	% that's already there in its natural way, rather than actively "associating".
	% Besides, the symmetry is not there. I'm doing one translation to 
	% show that PDG semantics are not just multiply-the-cpts likea  factor graph
	% would do, and the other translation to show we can emulate them; I want one
	% to succeed and the other to fail. The one I want to fail definiitely needs
	% to be set up as naturally as possible.
		% We can associate with each PDG a unique factor graph and vice versa.
		% The map from PDGs to factor graphs takes the cpds of the PDG to be the
		% facotors of the factor graph.  
	%joe22: I changed it because I don't understand the phrase ``data of a
	%factor graph''.  Databases have data; factor graphs don't.  I think
	%you're using idiosyncratic terminology.  This isn't a great disaster
	%-- I think the intent is clear -- but I don't like the terminology,
	%although I didn't change it
	%oli25: I started using the term "data" because you wrote something that way,
	% but It's certainly not my favorite term and I'm open to swapping it out.
	% More broadly though, I hope you can see why the "we can associate one to 
	% another" story I don't find satisfying. I'm changing the phrase
	% "data of a factor graph".
	%oli25
	%The cpds of a PDG straightforwardly constitute the  data of a factor graph,
	%joe23: this version is OK, as far as I''m concerned 
	The cpds of a PDG naturally constitute a collection of factors,
	so it natural to wonder how the semantics of a PDG compare to 
	simply treating the cpds as factors. To answer this question, we start by making
	the translation precise.
	%joe21
	%\begin{defn}[PDG to factor graph]\label{def:PDG2fg}
	\begin{defn}[unweighted PDG to factor graph]\label{def:PDG2fg}
	%oli22: first do this for an unweighted PDG.
	% If $\dg M$ is a PDG, define   
	If $\dg N = (\Gr, \mat p)$ is an unweighted PDG, define   
	%oli21: I'm envisioning some disagreement about this notation; putting
	%this in a macro to make this smoother
	%joe19: I think the notation is OK, but as I said above, we might as
	%well use \Psi everywhere.
	%oli22: unweighted first clarifies this.
	% the associated factor graph $(\Phi, \theta)_{\dg M}$ on the
	% the associated WFG $\WFGof{\dg M} = (\Phi,\theta)$ on the 
	the associated FG $\FGof{\dg N}$ on the 
	%oli22: Note: here's another place where we refer to variables by (N,V). I 
	% like making it clear that a variable is determined by both \N and \V, but
	% again am open to alternate notation, so long as we keep both \N,\V. Factoring
	% this also out into a macro.
		% variables $(\N, \V)$ by
	variables $(\N,\V)$ by
	%oli22: "factors given by the edges" is not quite accurate; it's the index that
	% is given by the edges $\Ed$, and the factors are given by $\bp$. 
		% taking the factors to be given by the edges in $\Ed^{\dg M}$, 
	%joe21: I couldn't parse this
	%taking $\mathcal J := \Ed^{\dg M}$ to be the set of edges,
	taking $\mathcal J$ to be the set to be the set of edges, 
	%oli22: also changing "X" to "Z" because of possible name conflict; in our
	% presentation X_{--} is already a specific variable. Also slowing down and
	% describing the translation more carefully.
	% and for an edge $L$ from $X$ to $Y$, taking $\phi_L(x,y)$ to be $(\bp^{\dg M}(x))(y)$,
	and for an edge $L$ from $Z$ to $Y$, taking $X_{L} = \{Z,Y\}$, and $\phi_L(z,y)$ to be $(\bp^{\dg M}(z))(y)$.
	%oli22: now we do the weighted case by re-using the above. 
		% and taking the weight $\theta_L = \beta_L$.
	%joe20
	%We extend transformation to one that takes a (weighted) PDG $\dg M =
	%oli23*: moving the extension to below.
	% We extend this transformation to one that takes a (weighted) PDG $\dg M =
	% (\dg N, \beta)$  
	% to a WFG $\WFGof{\dg M} := (\FGof{\dg N}, \beta)$ by setting $\theta_L = \beta_L$.
	\end{defn}
	
	
	%oli19: new text, some storytelling
	%joe19: on't call it a a trick
	%Using essentially the same trick as \cref{constr:hyperedge-reducton},
	%oli22: I prefer idea singular.
	% Using essentially the same ideas as in \cref{constr:hyperedge-reducton},
	%oli24: A transition phrase.
	It turns out we can also do the reverse. 
	Using essentially the same idea as in \cref{constr:hyperedge-reducton},
	we can encode a factor graph as an assertion about the unconditional
	probability distribution over the variables associated to each
	factor.  
	
	%joe21
	%\begin{defn}[factor graph to PDG] \label{def:fg2PDG}
	\begin{defn}[factor graph to unweighted PDG] \label{def:fg2PDG}
	%oli20: shuffle + add \theta (2 lines)
	% If $\Phi=(\{\phi_J\}_{J \in \cal J})$ is a factor graph, then $\PDGof{\Phi}$ is
	%oli21: this is fine but using WFG terminology instead:
		% For a factor graph $\Phi=(\{\phi_J\}_{J \in \cal J})$ and 
		% non-negative vector $\theta$ over $\cal J$,  let $\PDGof{\Phi,\theta}$ be
	%oli22: unweighted case first.
	% For a WFG $\Psi = (\Phi,\theta)$, let $\PDGof{\Psi}$ be
	For a FG $\Phi$, let $\UPDGof{\Phi}$ be
	%oli22: was extremely tricky to read and edit in its fragle
	%run-on-sentence form.  
	% split it into the bullets as we discussed.
	% the PDG whose variables are the variables in $\Phi$ together with $\sf 1$ and a
	% variable $X_J := \prod_{j \in J} X_j$ for every factor $J \in \mathcal J$%
	% , whose edges consist of projections $X_J \tto X_j$ for each $X_j \in X_J$ and
	% unconditional joint distributions ${\mathsf 1} \to X_J$ with
	% associated cpd $\bp[J]$ equal to the joint distribution on $X_J$ obtained by
	% %normalizing $\phi_J$; 
	the unweighted PDG consisting of
	\begin{itemize}
		\item the variables in $\Phi$ together
	   with $\var 1$ and a variable $X_{\!J} := \prod_{j \in J} X_j$ for every factor $J \in \mathcal J$%
	   , and
	   \item edges ${\var 1} \!\to\! X_{\!J}$ for each $J$ and $X_{\!J} \!\tto\! X_j$ for each $X_j \in \mat X_J$,
	\end{itemize}
	where the edges $ X_{\!J} \!\tto\! X_j$ are associated with the appropriate projections, and each ${\var 1} \!\to\! X_{\!J}$ is associated with the unconditional joint distribution on $X_J$ obtained by normalizing $\phi_J$.
	%joe19*: Are you claiming that you get the same
	%result with \alpha_L = 1 and \alpha_L = \theta?  That's strange (and
	%inconsistent with what you wrote later
	%oli22: They don't give the same result and I didn't intend to suggest
	% that they did. Hopefully this presentation is a lot clearer.
	%joe19: no \alphas here.
	%% finally, let \valpha{$\alpha_L = $}$\beta_L:= \theta_L$.
	%oli22: why remove the colon? Others (and programming languages)
	% have told me to go out of my way to distinguish between construction and
	% assertion.  Also, I thought you wanted me to put an \alpha 
	% in the translation to a factor graph? 
	% finally, let $\beta_L = \theta_L$. 
	The process is illustrated in \cref{fig:fg2PDG}.
	%oli22: now the weighted case.
	%oli23: moved below.
	\end{defn}
	
	
	
	%joe18
	%\begin{figure*}
	\begin{figure*}[htb]
		\centering
		\hfill
		\ifprecompiledfigs
	\raisebox{-0.5\height}{\includegraphics{figure-pdfs/smoking-FG}}
	% \raisebox{-0.5\height}{\includegraphics{smoking-FG}}
		\else
		\begin{tikzpicture}[center base, xscale=1.4,
			fgnode/.append style={minimum width=2.7em, inner sep=0.3em}]
			\node[factor] (prior) at (1.65,-1) {};
			\node[factor] (center) at (3.75, 0.1){};
			
			\node[fgnode] (PS) at (1.65,0.5) {$\mathit{PS}$};
			\node[fgnode] (S) at (3.1, 0.8) {$S$};
			\node[fgnode] (SH) at (3.0, -0.8) {$\mathit{SH}$};
			\node[fgnode] (C) at (4.8,0.5) {$C$};
			
			\draw[thick] (prior) -- (PS);
			\draw[thick] (PS) --node[factor](pss){} (S);
			\draw[thick] (PS) --node[factor](pssh){} (SH);
			\draw[thick] (S) -- (center) (center) -- (SH) (C) -- (center);
	
	%		\node[dpadded, fill=blue] (1) at (2.5,-2) {1};
	%					
	%		\draw[blue!50, arr] (1) -- (prior);
	%		\draw[blue!50, arr] (1) -- (center);
	%		\draw[blue!50, arr] (1) -- (pss);
	%		\draw[blue!50, arr] (1) -- (pssh);
			
			%oli24:
			% \node[fgnode, fill opacity=0.02,dashed] (T) at (4.8, -1.3) {$T$};
			\node[fgnode] (T) at (4.8, -1.3) {$T$};
			\draw[thick] (T) -- node[factor]{}  (C);	
			% \node[factor, draw=black, pattern=north east hatch] at (Q){};
		\end{tikzpicture}
		\fi
		%oli22:improving spacing.
	        % ~\vrule~
		\hfill\vrule\hfill
			% \end{subfigure}
			% \begin{subfigure}{0.5\linewidth}\centering
		\ifprecompiledfigs
	\raisebox{-0.5\height}{\includegraphics{figure-pdfs/smoking-convert}}
	% \raisebox{-0.5\height}{\includegraphics{smoking-convert}}
		\else
		\begin{tikzpicture}[center base, xscale=1.6,
	        newnode/.style={rectangle, inner sep=5pt, fill=gray!30, rounded corners=3, thick,draw}]
			\node[newnode] (prior) at (1.65,-1) {};
			\node[newnode] (center) at (4.1, 0.25){};
			
			\node[dpadded] (PS) at (1.65,0.5) {$\mathit{PS}$};
			\node[dpadded] (S) at (3.3, 0.8) {$S$};
			\node[dpadded] (SH) at (3.3, -0.6) {$\mathit{SH}$};
			\node[dpadded] (C) at (4.9,0.5) {$C$};
			
			\draw[arr, ->>, shorten <=0pt] (prior) -- (PS);
			\draw[arr, <<->>] (PS) --node[newnode](pss){} (S);
			\draw[arr, <<->>] (PS) --node[newnode](pssh){} (SH);
			\draw[arr, <<-, shorten >=0pt] (S) -- (center); 
			\draw[arr, <<-, shorten >=0pt] (SH)-- (center); 
			\draw[arr, <<-, shorten >=0pt] (C) -- (center);
			
			\node[dpadded, fill=blue] (1) at (2.7,-1.8) {1};
			
			\draw[blue!50, arr] (1) -- (prior);
			\draw[blue!50, arr] (1) to[bend right=30] (center);
			\draw[blue!50, arr] (1) to[bend right = 5] (pss);
			\draw[blue!50, arr] (1) to[bend left = 10] (pssh);
	
			
			\node[dpadded] (T) at (4.8, -1.7) {$T$};
			\draw[arr, <<->>] (T) -- node[newnode](tc){}  (C);	
	
			\draw[blue!50, arr] (1) to[bend right = 10] (tc);
		\end{tikzpicture}
		\fi
			% \end{subfigure}
		\hfill~
		\caption{
	%oli20: oops garbled. Fixing.
	% The conversion from a PDG to a factor graph to factor
	% graph, and vice versa, as defined in \Cref{def:fg2PDG}. The
	%joe18: still garbled
	%Conversion of the PDG in \cref{ex:smoking} a PDG to a factor graph
	Conversion of the PDG in \cref{ex:smoking} to a factor graph
	according to \cref{def:PDG2fg} (left), and from that factor graph back
	to a PDG by \cref{def:fg2PDG} (right). 
	%joe17
	%blue edges carry the (renormalized) cpds corresponding to the
	%joe18: what does ``renormalized'' mean here?  Why did the cpds have
	%to be renoormalized
	%oli21: because they're now being regarded as unconditional distributions. To
	%illustrate: both a cpt X -> Y and an unconditional distribution 1 -> XY are
	%matrices. In the first case, each row sums to 1, whereas in the second, the
	%whole matrix sums to 1. We're renormalizing the cpd so that they are
	%unconditional distributions. I think your original edit introduced
	%this ambiguity.
	%joe19*: I'm lost.  Why are they now being regarded as unconditional
	%distributions?  I'm OK with the current caption.
	%oli21: let me try again to write this clearly.
		% In the latter, blue edges are associated with the cpds corresponding to the
		% original factors, each leading to a new node $X_J$ (displayed as a
		% smaller darker rectangle) whose values are joint settings of the
		% variables connected to the factor $J$. 
	%
	%joe19
	%In the latter, for each $J$ we intorduce a new node $X_J$ (displayed as a
	%smaller darker rectangle) whose values are joint settings of the
	In the latter, for each $J$ we introduce a new variable $X_J$ (displayed as a
	smaller darker rectangle), whose values are joint settings of the
	variables connected it, and also an edge $1 \to X_J$ 
	%joe19
	%(blue)
	(shown in blue),
	%oli21: AAAI only begrudgingly accepts color I will make sure all the 
	% figures, etc. look good in black and white later.
	%FIXME
	%joe19
	%to which we associate with the unconditional
	to which we associate the unconditional 
	distribution given by normalizing $\phi_J$.
	} 
		\label{fig:fg2PDG}
	\end{figure*}
	
	
	%joe1: rewrote
	%Surprisingly, despite garbling the structure (see
	%\Cref{fig:fg2PDG,fig:fg-intro-examples}), when we fix $\gamma=1$, the
	%two operations preserve most of their semantics.
	PDGs are directed graphs, while factors graphs are undirected. The
	map from PDGs to factor graphs thus loses some important structure.
	As shown in
	%joe17: I get problems when I latex this.  It says ``As shown in
	%Figures 8 and 9 in Figure 9''. Moreover, the actual figure is Figure 4.
	%oli20: another problem with comments... should be fixed now. 
    \Cref{fig:fg2PDG,fig:fg-intro-examples},
	%joe11
	%the mappings can change the graphical structure signfiicantly.
	%oli24: actually it's just the second one.
	% the mappings can change the graphical structure significantly.
	this mapping can change the graphical structure significantly.
	%oli12: no \alphas, so we have something slightly different is true.
	% Nevertheless, if we take $\gamma=1$,
	%oli22: As you say in a %joe18* below, let's just state the theorems,
	% and then describe useful corolaries, instead of building up to them with
	% the theorem statements below, which are evidently quite confusing. 
		% Nevertheless, in the case where every weight is the same,
	Nevertheless,
	%oli23: not quite true; removing together with the theorem below.
	% if we start with an unweighted factor graph, then
	% applying the two conversions take us back to the same factor graph, so
	% each is the inverse of the other.  Moreover, 
	%oli23: we can substantially strengthen this claim now.
	% in the case where all the
	% weights are the same, then
	%oli24: added emphasis & cqualifier
	% both conversions preserve the semantics.
	%joe22
	%\emph{both} conversions preserve the $\gamma=1$ semantics.
	%oli25: this is related to the only other major comment in this round of
	% edits, so I'll defer discussion until then, but briefly: I think by saying
	% 'in the special case' you give the result is mroe restricted than it is;
	% this feels off to me for the same reason that 
	% "you can see the red color of a cherry in the special case in which you are
	% looking at it" seems wrong. A PDG has semantics for ALL gammma, and this is
	% a particular one. Rewording differently.
	% both conversions preserve the semantics in the special case that $\gamma=1$. 
	%joe23: Well, I think it is a special case, but Im OK with your
	%wording.  Just correcting a typo; you should probably do a spellcheck
	%both conversions preserve the semantics correpsponding to $\gamma=1$.
	both conversions preserve the semantics corresponding to $\gamma=1$.
	%joe21
	% both conversions preserve the semantics, if we associate the
	% unweighted PDG $\dg N$ with the (weighted) PDG $(\dg N,{\bf 1})$
	% (i.e., we take $\beta$ to be the constant function {\bf 1}).
	%oli24: I find this comes off as way less ad-hoc if we don't
	% make this definition last-minute. I'm introducing this convention at the
	% beginning, along with our convention about \alpha.
	
	
		\begthm{prop}{prop:fg-pdg-lossless}
			$\Phi \circ \PDGof{} = \mathrm{Id}_{\text{FG}}$. That
			is, for all factor graphs $\Phi$, we have
			$\Pr_{\Phi(\PDGof{F})} = \Pr_F$.
	%joe20*:
	% Given an unweighted FG $\Phi$, $\Phi_{\UPDGof{\Phi}} = \Phi$ 
	\end{prop}
	
	
	%oli23*: here are the unweighted analogs.
	\begthm{theorem}{thm:fg-is-pdg}
	%oli24: I placed the comment in the beginning; this is really not as ad-hoc
	% as this notation makes it seem.
	%joe22* You have to remind the reader of this convention!  It's not OK
	%to use it pages after you've defined 3 pages back (which the reader
	%probably missed) it without a reminder.  Be nice to the reader!
	%joe23*: I'm willing to live with your notation, but you *must* remind
	%the rader of it.  (I would actulaly put the definition here, rather
	%than 3 pages back, since I don't belive you use it except for here.
	%This is an instance of a general principal: define a notion when you
	%need it.  I see no class of reader for which there's a benefit it in
	%defining it on page 3 and using it for the first time on p. 6.
	%oli25*: I believe that which choice is better depends on what kind of
	%reader.  There are at least two classes of reader for which I think
	%my version is substantially better: (1) those who are skimming and
	%not tracing definitions carefully (because 
	% it's simpler and less confusing than the version with the 1, which requires
	% a little more notation tracing about what the 1 is (is it \alpha?\beta? What 
	% does that do exactly again?), (2) those who are familiar with factor
	% graphs and  
	% instintcively take unweighted = weights all 1.
	% I believe also that there are readers who would appreciate the ${\bf 1}$, but
	% I also have a strong aethetic preference to leaving it out. I think putting the
	% \bf 1 inside makes it look more complicated than it is, and that it depends on
	% more parameters than it does. The detail is technically correct and admittedly
	% makes it a more careful presentation in some ways, but you have vehemently 
	% objected to other ways in which I have wanted to do things more carefully
	% (e.g., adding my type annotations to definitions).  Again, I think making
	% a big deal of this is putting emphasis in the wrong place.
	$\Pr_{\Phi} = \bbr{\UPDGof{\Phi}}_{1}^*\;$ for all factor graphs $\Phi$.
	%joe21
	% $\Pr_{\Phi} = \bbr{(\UPDGof{\Phi},{\bf 1})}_{1}^*\;$ for all factor graphs $\Phi$.
	\end{theorem}
	\begthm{theorem}{thm:pdg-is-fg}
	%oli24: and again
	$\bbr{\dg N}_{1}^* = \Pr_{\FGof{\dg N}}\;$ for all unweighted
	%joe21*
	% $\bbr{(\dg N, {\bf 1})}_{1}^* = \Pr_{\FGof{\dg N}}\;$ for all unweighted
		PDGs $\dg N$.  
	\end{theorem}
	%oli23*: added important discussion.
	The correspondence hinges on the fact that we take $\gamma=1$, so that $\Inc$ and
	$\IDef{}$ are weighted equally.
	%oli24: important discussion.
	%joe22*: I find this discussion problematic, since we haven't
	%discussed where teh choice of \gamma is coming from. It's not at all clear
	%to me that this limitation is unproblematic.  We've solved a problem
	%by giving the modeler the freedom to choose k without explaining why
	%a particular choice is OK.  I think that the paper is worse off by
	%this addition; you're just reminding the reader of our unmotivated
	%choices (which I viewed as technical means to get a result, rather
	%than natural modeling choices).  
	%oli25*: You may view it as a technical means to get the paper to work out,
	% but I definitely do not view it that way.
	%joe23*: I understand that, but we don't exlain your point of view in
	%the paper.   We have given no basis on which to claim something is ``not
	%problematic''.   Saying it is will raise flags, so is a net negative.
	%Similarly for the claim that we can't get a factor graph to
	%``replace'' a PDG.  If a user is perfectly happy with a
	%representation using a factor graph, why should he/she want to
	%replace it by a PDG?  There is perhaps a point to be made here, but
	%it needs to be written in a way that seems reasonable to a reader who
	%hasn't read your mind and does not necessarily agree with our viewpoint.
	%Moreover, the way the
	% paper is currently 
	% written, I think that \gamma is motivated fairly well (it's a
	% trade-off between 
	% a quantiative (by which I mean, "dependent on the cpds") and qualitative (by 
	% which I mean, "dependent only on the graph structure") term, and readers
	% with some imagination will have some ideas for how to use this. I
	% certainly do. 
	% In any case, here we only say that it indexes the family of a semantics, whch
	% is just another technical fact, and I thiknk drawing attention to it strengthens
	% our point a lot.
	Because the user of a PDG gets to choose $\gamma$, the fact that the 
	translation from WFGs to PDGs holds only for $\gamma=k$ is not problematic; 
	the user can simply set $\gamma$ so as to view the original factor graph.
	However, in translating back, we lose this ability, making it very difficult for
	a factor graph replace a PDG.
	
	
	
	%joe21
	%What about weighted PDGs, of the form $(\Gr, \mat p, \beta)$?
	%Factor graphs, too, have a standard notion of weightedness, 
	%but so long as we stick with our convention of setting every $\alpha_L = 1$, 
	%we cannot say much about them.
	What about weighted PDGs $(\Gr, \mat p, \beta)$ where $\beta \ne {\bf 1}$?
	There is also a standard notion of weighted factor graph,
	but as long as we stick with our convention of taking  $\alpha = {\bf 1}$, 
	we cannot relate them to weighted PDGs.  
	%oli24: squeezing some more space
	% As we show in the next section,
	As we are about to see,
	once we drop this convention, we can do much more.

	% \subsection{Bayesian Networks}
	% \subsection{Factor Graphs}
	\subsection{Factored Exponential Families}


	A \emph{weighted factor graph (WFG)} $\Psi$ is a pair
	$(\Phi,\theta)$ consisting of a factor graph $\Phi$ 
	together with a vector of non-negative weights
	$\{ \theta_J \}_{J \in \mathcal J}$.
	$\Psi$ specifies a canonical scoring function 
	\begin{equation}
	\GFE_{\Psi}(\mu)
	%   \GFE_{(\Phi,\theta)}(\mu)
		 := \!\Ex_{\vec x\sim\mu}\left[  \sum_{J \in
	           \cal J} \theta_J \log\frac1{\phi_J(\vec
	               x_J)}\right] - \H(\mu)  , 
				   \label{eqn:free-energy}
	\end{equation}
	%joe20
	%which $\Pr_{(\Phi,\theta)}$ minimizes, called the \emph{variational
	%oli23:
	% which $\Pr_{\Psi}$ minimizes,
	called the \emph{variational
	Gibbs free energy} \cite{mezard2009information}. 
	%oli23:
	$\GFE_{\Psi}$ is uniquely minimized by the distribution
	${\Pr}_{\Psi}(\vec x) = \frac{1}{Z_{\Psi}}
	 	\prod_{J \in \cal J} \phi_J(\vec x_J)$, 
	which matches the unweighted case when every $\theta_J = 1$.
	The mapping $\theta \mapsto \Pr_{(\Phi,\theta)}$ is known as 
	%joe20
	%$\Phi$'s exponential family and is a central tool in the analysis
	$\Phi$'s \emph{exponential family} and is a central tool in the analysis  
	and development of many algorithms for graphical models \cite{wainwright2008graphical}.
	
	PDGs can in fact capture the full exponential family of a factor graph, but only
	%oli24
	by allowing values of $\alpha$ other than ${\bf 1}$. In this case, the
	only definition  
	% by allowing values of $\alpha$ other than 1. In this case, the only definition 
	that requires alteration is $\IDef{}$, which now depends on the \emph{weighted multigraph}
	$(\Gr^{\dg M}, \alpha^{\dg M})$, and is given by
	\begin{equation}
	%oli24: Let's just define it for M;
		% \IDef{G}(\mu) := \sum_{\ed LXY \in \Ed} \alpha_L \H_\mu(Y\mid X) - \H(\mu). 
		\IDef{\dg M}(\mu) := \sum_{\ed LXY \in \Ed} \alpha_L \H_\mu(Y\mid X) - \H(\mu). 
		\label{eqn:alt-extra2}
	\end{equation}
	%joe21: rewrote.  The reader won't know what (b) is
	%In ths case, each specification in~\ref{item:localinfo} may be
	%weighted by differently, so that some edges are more qualitatively
	%certain than others, and correspondingly it may be more or less
	%important to describe them properly.
	Thus, the conditional entropy $\H_\mu(Y\mid X)$ associated with the
	edge $\ed LXY$ is multiplied by the weight $\alpha_L$ of that edge.
	
	%oli23: taken from your text.
	%oli24: Softening slightly
	% The key benefit of using $\alpha$ is that we can
	One key benefit of using $\alpha$ is that we can
	capture arbitrary WFGs, not just ones with a constant weight
	vector.    All we have to do is to ensure that in our translation from
	factor graphs to PDGs, the ratio $\alpha_L/\beta_L$ is a
	constant.  (Of course, if we allow arbitrary weights, we cannot hope
	to do this if $\alpha_L = 1$ for all edges $L$.)  
	%oli23: new
	%joe21
	%We therefore define a family of translations.
	We therefore define a family of translations, parameterized by the
	ratio of $\alpha_L$ to $\beta_L$.
	\begin{defn}[WFG to PDG]\label{def:wfg2pdg}
	Given a WFG
	%joe20*: going back to the special case of \alpha=1, AS WE HAD AGREED.   What
	%do we do for edges not in \J.   I also don't think that this is quite
	%right, sonce you haven't defined \beta for edges not in \J.  I now do
	%so, although you should check 
	%$\Psi=(\Phi, \theta)$ to a PDG $\PDGof{\Psi} = (\UPDGof{\Phi},\theta, \theta)$ 
	$\Psi=(\Phi, \theta)$,
	and postive number $k$, 
	we define the corresponding PDG $\PDGof{\Psi,k} = (\UPDGof{\Phi},\alpha_{\theta}, \beta_{\theta})$ 
	%by taking both $\alpha$ and $\beta$ to be $\theta$.
	by taking $\beta_J = k \theta_J$ and $\alpha_J = \theta_J$ for the edge $1  \rightarrow X_J$, and
	%oli24:
	taking $\beta_L = k$ and $\alpha_L = 1$ for the projections $X_J \!\tto\! X_j$.
	% taking $\alpha_L = 1$, $\beta_L = k$ for the projections $X_J \!\tto\! X_j$.
	\end{defn}
	
	%joe21*: Cut  I don't like the notion of capturing data.  More
	%importantlly,
	%We now turn to extend \cref{def:PDG2fg}.  
	%Since PDGs have two sets of weights, and WFGs only have one,
	%we will not be able to capture all the data.
	We now extend Definitions~\ref{def:PDG2fg} and \ref{def:fg2PDG} to
	(weighted) PDGs and WFGs.  
	%oli24:
	%In going translating from PDGs to WFGs, 
	In translating a PDG to a WFG, 
	%oli24: the mismatch isn't just a problem for this direction
	% note that we have somewhat of a mismatch: PDGs have two sets of weights, and WFGs
	there will necessarily be some loss of information: PDGs have two sets, while WFGs have 
	%oli24:
	% only have one, So in our translation, we ingore $\alpha$, and consider
	only have one. Here we throw out $\alpha$ and keep $\beta$, 
	%oli24: added
	%joe22*: I have no clue what this addition means.  I also think it's a
	%mistake to highlight another ad hoc choice.  I strongly prefer my wording.
	%oli25*: I find it very strange what ad-hoc choices you want to hide
	% and which ones you want to expose.
	%joe23*: we can debate which ad hoc choices to hide (my own feeling
	%is: as many as possible).   What is not open
	%to debate is the fact that I didn't understand what you wrote.  To
	%the extent that I'm somewhat representative (whch I believe I am),
	%this must be rewritten.  
	%There are many places where I
	% feel there is  
	% genuinely something there, and when you don't understand my descriptions, we 
	% settle on a description of it which (in my view) far undersells our 
	% contribution. Here, this is truly an ad-hoc choice, and I have no problem 
	% admitting it (we're claiming there's not even a good choice to be had), 
	% and it seems you're trying to just state some facts so it seems our particular
	% choice is better than some other choices. It's just a choice, and I think 
	% that letting the reader know is useful.
	though in its role here as a left inverse of \cref{def:wfg2pdg},
	chosing either would suffice. 
	
	%there are more PDGs than WFGs, and so there is not a perfect way to
	%translate back. 
	%We have chosen here to preserve $\beta$.
	
	\begin{defn}[PDG to WFG]
	Given a (weighted) PDG $\dg M =
	(\dg N, \beta)$, we take its corresponding WFG to be $\WFGof{\dg M} :=
	%joe21
	%(\FGof{\dg N}, \beta)$ by setting $\theta_L := \beta_L$.
	(\FGof{\dg N}, \beta)$; that is, $\theta_L := \beta_L$ for all edges $L$.
	\end{defn}
	
	
	
	%joe19*: 
	%oli22: blank %joe19*.
	
	%oli22: I'm actually also cutting the current presentation of these theorems
	% and re-stating them below, 
	% using un-weighted objects + weights, which I think is far less confusing.
	% allows the most general theorems to be put right away without special
	% conversions and specific discussion about what to do with \alpha.
	\begin{inactive}
	\begthm{theorem}{thm:pdg-is-fg2}
	%joe18
	%If $\dg M$ is a PDG, and $\gamma$ is a number such that
	If $\dg M$ is a PDG such that for some $\gamma >0$, we have that
		$\beta_L = \alpha_L \gamma$ for all  
		%oli12 line shave
		%edges
		$L$, then
		$\bbr{\dg M}_{\gamma} = \gamma\,\GFE_{\Phi_{\dg M}} $ and
		$\bbr{\dg M}_{\gamma}^* = \{\Pr_{\Phi_{\dg M}} \}$.
		 	% $\kldiv{\mu}{\Pr_{\Phi(\dg M)}} = \bbr{\dg M}_{1}(\mu)$
			% In particular, $\Pr_{\Phi(\dg M)} = \bbr{\dg M}_*^{\gamma := 1}$
	\end{theorem}
	
	%joe19
	
	% \begin{theorem}[restate=thmfgispdg]\label{thm:fg-is-pdg}
	
	%joe18* unless I'm missing something, you need to redo Definition 4.3
	%to explain how to add the \alphas.  Will you add them in such a way
	%that the ratio of \beta_L to \alpha_L is constant?  If so, we can say
	%that because the construction made it a constant, the following result holds.
	%If the updated Definition 4.3 allows some flexibility in
	%choosing \alpha and \beta, then this would reqire more work.
	%oli21: Oops, I forgot to add those two characters; we set \alpha_L = \beta_L. 
	% In any case, I think the true things you say above can be sold better:
	%joe19: As I said, I don't believe that you want \alpha_L = \beta_L
	%oli22**: Since in general we cannot know gamma (because the translation meerely
	% supplies the data of the PDG, including alpha and beta, but a user can
	% laterquery the semantics for multiple different values of gamma),
	% we can't do any better than to set them to be proportional. 1 is a nice
	% nice multiplicative constant generally, and also is speial because that's the 
	% one we need to capture unweighted factor graphs with unweighted PDGs.
	
	%joe19*: AARGH!  I was hoping that you would discuss the more general
	%translation here, where \alpha could be arbitrar.  I don't believe
	%that the reslt will hold if \alpha_L = \beta_L.  As you ptoint out,
	%we need \beta_L = \alpha_L \gamma not \alpha_L = \beta_L.  So
	%although you spent a lot of time doing what I explicitly asked you to
	%do, you didn't address my main concerns.  You absolutely did not
	%explain how to do  the translation when you have an abtrary weight vector.
	%specify how you do the translatin here from factor graphs to PDGs.
	%I put in what I think you should have put in.
	%oli22: As stated in emails, I believe your conversion is correct but 
	% slightly deceptive. I have therefore recycled 
	The key benefit in using $\alpha$ is that we can
	capture arbitrary WFGs, not just ones with a constant weight
	vector.    All we have to do is to ensure that in our translation from
	factor graphs to PDGs, the ratio ratio $\alpha_L/\beta_L$ is a
	constant.  (Of course, if we allow arbitrary weights, we cannot hope
	to do this if $\alpha_L = 1$ for all edges $L$.)
	
	Specifically, given
	$0 < \gamma \le 1$ and a WFG $\Psi = (\Phi,\theta)$, we take the PDG
	${\dg M}_{\Psi,\gamma}$ to be defined just like the PDG ${\dg M}_\Psi$ of
	Definition~\ref{def:fg2PDG}, except that instead of having $\alpha_L =
	1$, we have $\alpha_L = \gamma\beta_L$. 
	
	
		\begthm{theorem}{thm:fg-is-pdg2}
		%oli20: we got to remove the condition!
	%joe19
	%For every factor graph $\Phi$, and EVERY vector $\theta$ over $\cal J$
	For all WFGs $\Psi = (\Phi,\theta)$ and all $\gamma$ with $0
	< \gamma \le 1$
		%, and EVERY $\gamma >0$
		we have that
		% for any joint distribution $\mu$ on $\V(\mathcal X)$, we
		        % have $\kldiv{\mu}{\Pr_\Phi} = \bbr{\PDGof{(\Phi)}}_{1}(\mu)$ 
		%joe8: again
		%oli10: adding back in
		%joe9
		        %	$\gamma \GFE_\Phi = \bbr{\PDGof{(\Phi)}}_{\gamma} + k$
		        %        where $k$ is a constant, and in particular, 
	%joe19*
	%$\GFE_\Phi = \nicefrac1{\gamma} \bbr{\PDGof{\Phi,\theta}}_{\gamma} + C$  
	$\GFE_\Psi = \nicefrac1{\gamma} \bbr{\PDGof{\Psi,\gamma}}_{\gamma} + C$  
	for some constant $C$, so
	%joe19*
	%$\Pr_{\Phi, \theta}$ is the unique element of
	%$\bbr{\PDGof{\Phi,\theta}}_{\gamma}^*$.
	$\Pr_{\Psi}$ is the unique element of
	$\bbr{\PDGof{\Psi,\gamma}}_{\gamma}^*$.  
		   % Moreover, $\Pr_{\Phi, \theta} = \bbr{\PDGof{\Phi,\theta}}^*$.
		\end{theorem}
	\end{inactive}
	
	%oli22**: big insertion: both of the above theorems + recycled material
	% from your discussion. 
	%joe20: note that I changed the label
	%\begthm{theorem}{thm:pdg-is-fg}We can can now generalize our earlier results 
	
	
	%oli23: canabalized for the above.
	% %joe20*: resinstated
	% The key benefit of using $\alpha$ is that we can
	% capture arbitrary WFGs, not just ones with a constant weight
	% vector.    All we have to do is to ensure that in our translation from
	% factor graphs to PDGs, the ratio $\alpha_L/\beta_L$ is a
	% constant.  (Of course, if we allow arbitrary weights, we cannot hope
	% to do this if $\alpha_L = 1$ for all edges $L$.)  Specifically, given
	% $0 < \gamma \le 1$ and a WFG $\Psi = (\Phi,\theta)$, we take the PDG
	% ${\dg M}_{\Psi,\gamma}$ to be defined just like the PDG ${\dg M}_\Psi$ of
	% Definition~\ref{def:fg2PDG}, except that instead of having $\alpha_L =
	% %joe20
	% %1$, we have $\alpha_L = \gamma\beta_L$.
	% 1$, we have $\alpha_L = \beta_L/\gamma$. 
	
	%oli24: double now. Also this gives me a line.
	% We now show that we can now capture the entire exponential family of a factor graph,
	We now show that we can capture the entire exponential family of a factor graph,
	%oli24: let's boast a little about this; we haven't mentioned it yet
	and even its associated free energy, 
	%joe21
	%but only for the value of $\gamma$ equal to the constant $k$ used in
	but only for $\gamma$ equal to the constant $k$ used in
	the translation.  
	
	
	\begin{theorem}\label{thm:wfg-is-pdg}
	For all WFGs $\Psi = (\Phi,\theta)$ and all $\gamma > 0$,
	we have that
	$\GFE_\Psi
	%joe20*: using notation defined above
	%= \nicefrac1{\gamma} \bbr{(\UPDGof{\Phi}, \theta, \nicefrac{1}{\!\gamma\,}\theta)}_{\gamma}
	= \nicefrac1{\gamma} \bbr{{\dg M}_{\Psi,\gamma}}_{\gamma} 
	+ C$   
	for some constant $C$, so
	$\Pr_{\Psi}$ is the unique element of
	%joe20*: switching alpha and beta again, and using \beta_\theta
	%instead of \theta
	%$\bbr{(\UPDGof{\Phi}, \theta, \nicefrac{1}{\!\gamma\,}\theta)}_{\gamma}^*$.  
	$\bbr{{\dg M}_{\Psi,\gamma}}_{\gamma}^*$.
	\end{theorem}
	
	%joe21
	%In particular,for $k\!=\!1$, so that $\theta$ is used for both
	In particular, for $k\!=\!1$, so that $\theta$ is used for both the functions
	$\alpha$ and $\beta$ of the resulting PDG,
	\cref{thm:wfg-is-pdg} strictly generalizes \cref{thm:fg-is-pdg}.
	\begin{coro}
		For all weighted factor graphs $(\Phi, \theta)$,
		we have that
		$\Pr_{(\Phi,\theta)} = \bbr{(\UPDGof{\Phi}, \theta,\theta)}_1^*$
	\end{coro}
	
	%joe21
	%Conversely, so long as the ratio of $\alpha_L$ to $\beta_L$ is constant, the
	Conversely, as long as the ratio of $\alpha_L$ to $\beta_L$ is constant, the
	reverse translation also preserves semantics.
	%oli23: insertaion
	% Conversely, we can generalize 
	% to the case where the ratio of
	% $\alpha_L$ to $\beta_L$ is a constant.
	%joe20
	%}%oli22 \end{commentout}
	\begthm{theorem}{thm:pdg-is-wfg}
	For all unweighted PDGs $\dg{N}$ and non-negative vectors $\mat v$
	over $\Ed^{\dg N}$, and all $\gamma > 0$, we have that 
	%joe20*: you're writing \beta,\alpha; switching it to \alpha \beta,
	%and making \beta = v, not \alpha = v.  Does the equality still hold?
	%$\bbr{(\dg N, \gamma  \mat v, \mat v)}_{\gamma}
	$\bbr{(\dg N, \mat v/\gamma, \mat v)}_{\gamma} 
			= \gamma\,\GFE_{(\Phi_{\dg N}, \mat v)} $ and consequently
	%joe20*
	%$\bbr{(\dg N, \gamma \mat v, \mat v)}_{\gamma}^*
	$\bbr{(\dg N, \mat v/\gamma, \mat v)}_{\gamma}^*
			= \{\Pr_{(\Phi_{\dg N}, \mat v)} \}$. 
	\end{theorem}
	% With these translations, factor graphs therefore define a particular subclass
	% of PDGs in which the weights $\alpha$ and $\beta$ are proportional.
	
	%oli23: removed
	% \noindent Note that if $\beta_L = \gamma$ for all edges $L$, then
	% 		$\alpha$ is the 
	% constant function 1 in Theorem~\ref{thm:pdg-is-fg1}, so
	% Theorem~\ref{thm:pdg-is-fg1} is a generalization of
	% Theorem~\ref{thm:pdg-is-fg}. 
	%oli23: nevermind 
	% We interpret the fact that the correspondence only holds when the constant
	% $k$ used in the translation equals $\gamma$, as a reflection of the fact
	% that there is no way to articulate a 
	
	%oli22: I've rephrased the statement of the theorem in a suggestive 
	% (but kind of clunky) way below.
	%I think this is kind of cool, and a neat story. Do you buy it?
	%joe20: It's not so much that I don't buy it, but that I can't make
	%sense of it.  Where did the product of cpts come from?  Surely you
	%must have a factor graf in the picture here.  If you can explain it
	%to me in a way that I can understand it, we may want to reinstate
	%this. 
	%misleading 
	%Thus, PDGs in which the quantitative and qualitative certainties are
	%fused, when evaluated in the semantics corresponding to the particular
	%trade-off coresponding to their cofficient of proportionality,
	%precisely generate the exponential family of the associated factor
	%graph.
	%In particular, our semantics regard an unweighted PDG as a product of
	%its cpts, when $\gamma = 1$.
	%\begin{coro}\label{coro:justafg} 
	%% For all $\dg N \!=\! (\Gr,\mat p)$,
	%% If $\dg M$ is an unweighted PDG, then 
	%	$\displaystyle\bbr{(\Gr, \mat p)}_1^* 
	%		= \frac{1}{Z_{\dg M}}\prod_{\ed LXY \in \Ed^{\dg M}} \bp^{\dg M}(Y \mid X)
	%	\propto \!\!\prod_{\ed LXY \mathrlap{\in \Ed^{\dg M}}} \bp(Y \mid X)$.
	%\end{coro}
	%joe20
	\begin{inactive}
	We have seen that only a subset of PDGs can be faithfully 
	represented as WFGs; we now show the other side of the correspondence: any
	factor graph be captured by more than one PDG (though again, only for a fixed $\gamma$).
\end{inactive}
	
	%\begthm{theorem}{thm:fg-is-pdg}
	
	
	
	
	
	%oli22: end big insertion.
	
	%joe18: cut from here.  Once we fix the second theorem, the relevant
	%discussion should go before the theorem
	%	\cref{thm:pdg-is-fg} still has a retriction, but if we can
	%        choose the values of $\alpha$ (or alternatively $\beta$), we
	%        can get the result to apply for arbitrary values of $\gamma$
	%        and $\beta$ (resp. $\alpha$). \Cref{thm:fg-is-pdg2} is
	%        substantially stronger than its counterpart: it shows that
	%        PDGs in which the quantitative and qualitative certainties are
	%        fused ($\alpha_L = \beta_L$) completely adopt the semantics of
	%        factor graphs and their exponential families, for $\gamma =
	%        1$.\footnotemark 
	%joe18*: This is the point; you have to explain how the tranlsation
	%works in the presence of \alpha!
	%\footnotetext{The result can be achieved for arbitrary
	%	$\gamma \neq 1$, if we are willing to set $\alpha$ based on
	%	$\gamma$ in our translation of factor graphs to PDGs.}}
	
	%oli19:
	% Justification for both theorems is provided by rewriting
	%joe18*: We need to add a proof for this result in teh appendix.
	%The truth of \Cref{thm:fg-is-pdg,thm:pdg-is-fg} may be seen
	%intuitively by rewriting 
	The key step in proving \Cref{thm:wfg-is-pdg,thm:pdg-is-wfg}
	(and in the proofs of a number of other results) involves 
	rewriting  
	$\bbr{\dg M}_\gamma$ as follows: 
	\begin{prop}%[restate=prop:nice-score,label=prop:nice-score]% \label{}
	% \begin{restatable}{prop}{propnicescore}\label{prop:nice-score}
	 Letting $x^{\mat w}$ and $y^{\mat w}$ denote the values of
	  $X$ and $Y$, respectively, in $\mat w \in \V(\dg M)$, 
	we have 
	\begin{equation}\label{eq:semantics-breakdown}
	\begin{split}
	\bbr{\dg M}(\mu) =  \Ex_{\mat w \sim \mu}\! \Bigg\{
	% \bbr{\dg M}(\mu) =  \!\!\!\sum_{\mat w \in \V(\dg M)} \!\!\! \mu(\mat w) \Bigg\{
	 \sum_{ X \xrightarrow{\!\!L} Y  }
	\bigg[\,
	    \color{gray}\overbrace{\color{black}
	      \!\beta_L \log \frac{1}{\bp(y^{\mat w} |x^{\mat w})}
		}^{\color{gray}\smash{\mathclap{\text{log likelihood / cross entropy}}}} +
		 % \\[-0.5em]
	    \color{gray}\underbrace{\color{black} 
	({\alpha_L}\gamma - \beta_L ) \log \frac{1}{\mu(y^{\mat w} |x^{\mat w})} 
		}_{\color{gray}\smash{\mathclap{\text{local regularization (if $\beta_L > \gamma$)}}}}\bigg] - \underbrace{\color{black}
	\gamma \log \frac{1}{\mu(\mat w)}
		}_{\color{gray}\smash{\mathclap{\text{global
	        regularization}}}}\color{black} \Bigg\} .
	\end{split}
	\end{equation}
	\end{prop}
	%joe17*: sorry; this isn't claer to me at all.  
	%assume that $\beta_L = \theta_L$.  But we did that, so that's not so
	%bad (although you should say it). Second, we get, the last term
	%becomes \gamma H(\mu), so it only matches the free energy if \gamma =
	%-1.  Finally, why should p_L(y^W | x^w) = \phi_L(x_J) (even if we
	%assume that \phi = p_L.
	%  Part of the problem is that you wronte in
	%the w  I think what you mean is the E(\gamme \log(1/\mu)
	%= \sum_\oemga \gamma \mu(w)/log(\mu) = = H(\mu).  But then ou're
	%still out by a factor of -\gamma.
	%oli20: A factor of + \gamma, but point taken. I guess it's standard
	%to effectively 
	% fix \gamma=1 for factor graph because the ratio of the \theta's to the entropy term is
	% the only thing that matters, so one can fix that scale to 1.
	%joe18: it may be standard, but not everyone knows it (I didn't).
	%  I've rewritten it so it's more correct. 
	%	The first and last terms of \eqref{eq:semantics-breakdown} are precisely
	%	$\GFE_\Phi$ for $\phi = \bp$.  
	%joe18
	%For any fixed $\gamma$, the first and last terms
	For a fixed $\gamma$, the first and last terms
	of \eqref{eq:semantics-breakdown} are equal to a scaled
	%joe18: in what sense is it equivalent?  
	%(which is essentially equivalent)
	%joe18*: I'm confused.  This statement seems technically incorrect to
	%me, on  two counts.  First, you would have to
	%multiply the first term by \gamma (there is no \gamma factor
	%currently in the first term); second, for the last term, the factor
	%is -\gamma, not \gamma.  
	%joe19*: Oliver, you did not address the joe18* immediately above,
	%which points out that, unless I'm missing someting, your claim below
	%is incorrect.    Please address this.  
	%oli22: [as resolved in email]: the sign on the entropy is correct, and
	% this conversion is not "the official one", a confusion which I've attempted
	% to further eliminate with my edit below 
	version of the free energy, $\gamma\GFE_\Phi$, 
	%oli22:
	% for $\phi_J = \bp$ and $\theta_J= \nicefrac{\beta_L}{\gamma}$
	if we set $\phi_J := \bp$ and $\theta_J := \nicefrac{\beta_L}{\gamma}$.  
	%oli19
	% Thus, if we assume that $\phi = \bp$ and in addition assume that each
	%oli20: edit for flow
	% Furthermore, if each $\beta_L = \gamma$, the local regularization term disappears, so we get 
	%joe18
	%If in addition, each $\beta_L = {$\alpha_L$}\gamma$,
	If, in addition, $\beta_L = {\alpha_L}\gamma$ for all
	edges $L$, then
	the local regularization term disappears, giving us
	%oli20:
	% an exact correspondence with $\GFE_\Phi$%
	the desired correspondence. 
	
	%oli20: paragraph break + signposting
	%joe18*: cut this; see below for why
	\begin{inactive}
	We now explain how the middle term may be viewed as a ``local'' regularization,
	and why including such a term is necessary for the semantics to 
	%joe18*: I find this statement very confusing.  Why shouldn't we take
	%them seriously?  And they *are* assertions about probability, no
	%matter how we  take them.  
	%oli21*: I agree completely! But that is not the way the semantics work, without
	% a local regularization term. I'm trying to motivate the need for the locaity.
	%joe18*[continued]: Most importantly of all, I see no way in
	%which this example tells me anything about how I shoudl view p.  It
	%shows potential probablems with the factor graph (which is what I
	%believe it was intended to do).  Some signposting would be useful, but I find
	%this completely unhelpful.
	%oli21*: I'm not sure exactly what you mean about "how you veiew p", but I assume
	% you mean something like, whether to take the cpds seriously or think of them
	% as energies. The example clearly shows that without a local regularization
	% term, the semantics effectively treats them like energies, and the interpretation
	% as a probability distribution is not preserved without the local term. As we
	% point out, this local term  
	%joe18*[continued]: We had some text here which you seem to
	%have cut, rather than commenting it out.  I though the text was fine,
	%and I'm reinstating it.  (Also, please don't just cut text.)
	%oli21: This text was not removed; it's was just at the end of the document 
	% serving a slightly different post-example analysis purpose. 
	% To be honest I'm perplexed that so many of these stories, whose delivery I take
	% quite seriously and that I edit several times before turning over to you, are
	% still entirely lost in transit....
	%take our cpds $\mat p$ seroiusly, as assertions about probability%
	view our cpds $\mat p$ as assertions about probability%
	% (instead of viwing them as each contributing to a badness, as factor
	% graphs do) 
	. 
	%oli20: pulled example from the end of the document.
\end{inactive}
	
	%joe18*: reinstating some material from before, with slight rewriting.
	\Cref{eq:semantics-breakdown} also makes it clear that 
	taking $\beta_L = {\alpha_L} \gamma$ for all edges $L$ is
	essentially necessary to get \Cref{thm:pdg-is-fg,thm:fg-is-pdg}.
	%oli21*: ! this is the opposite polarity of what we need to say.
	%. The equality HOLDING is what gives us strange behavior.  Rewriting.
	%	If this equality does not hold, then we can get some 
	%{\cref{prop:consist} does not hold unless .}
	%joe19: OK
	%oli22: oops I hadn't finished the rewrite in this document, only in 
	% DN-and-WFG. I'm updating to what I had there (2 lines).
	% Because this equality must hold, we can get
	%joe20
	%Of course, fixed $\gamma$ precludes taking $\lim_{\gamma\to0}$, so
	Of course, fixed $\gamma$ precludes taking the limit as $\gamma$ goes
	to 0, so 
	\cref{prop:consist} does apply. This is reflected in 
	%
	some strange
	behavior in factor graphs trying to capture the same phenomena as
	PDGs, as the following example shows.
	
	\begin{example}\label{ex:overdet}
	Consider the PDG $\dg M$ containing just $X$ and $1$, and two edges
	$p, q: 1 \to X$.
	%joe8:
	(Recall that such a PDG can arise if we get different information about the
	probability of $X$ from two different 
	%oli19:added, otherwise this is a reasonable inference
	% but not independent
	%joe17: I don't understand.  Such a PDG can arise whether or not the
	%sources are independent.  There is no inference going on here!  If
	%you want to say something about non-independence, it should go
	%somewhere else.
	%oli20: I'm not trying to say anything about independence, but we want the
	%example to be a clear illustration of what PDGs buy you. If I thought the
	%sources were independent, I would be justified in combining 0.7 and 0.7 to get
	%0.85. I find the example to be more powerful if we explicitly state that we
	%don't know them to be independent, so we cannot make this inference. Thoughts?
	%joe18: This is not the place to discuss these issues.  We're just
	%trying to make a point about factor graphs having strange behavior.
	%The issue of combining .7 and .7, and possibly getting .85 needs
	%*much* more discussion; this is not the place to do it.
	sources; this is a situation we
	certainly want to be able to capture!)
	Consider the simplest situation, where $p$ and $q$ are both associated
	with the same distribution on $X$%
	%oli20: added next line
	%joe18:
	%	, as the same certainty $\beta_p = \beta_q = 1$.
	; further suppose that the agent is certain about the distribution, so
	$\beta_p = \beta_q = 1$.
	%joe18*: what abou \alpha?  If we introduce it, we have to say
	%something about it here.
	For definiteness, suppose that
	$\V(X) = \{x_1,x_2\}$, and
	that the distribution associated with both edges is $\mu_{.7}$, which ascribes
	%joe9: slowing down.
	%probability $.7$ to $x_1$, then  $\bbr{\dg M} = \{\mu_{.7}\}$,
	%while it can be shown that 
	probability $.7$ to $x_1$. Then, as we would hope  $\bbr{\dg M}^* =
	\{\mu_{.7}\}$; after all, both sources agree on the information.
	However, it can be shown that 
	%oli20: some M's escaped. Added msising subscript.
	% $\Pr_{\Phi{{\dg M')}}} = \mu_{.85}$, so  $\bbr{\dg M'} = \{\mu_{.85}\}$.
	%joe18: there's a typo here: I wrote what I thought you intended
	%$\Pr_{\Phi{{\dg M)}}} = \mu_{.85}$, so  $\bbr{\dg M}_1^* = \{\mu_{.85}\}$.
	%oli21: 
	% $\Pr_{\Phi_{{\dg M)},1)}} = \mu_{.85}$, so  $\bbr{\dg M}_1^* = \{\mu_{.85}\}$.
	%joe19*: this is now inconsistent with the notation I introduced.  If
	%you're happy with what I did, it should be corrected.
	$\Pr_{\WFGof{\dg M}} = \mu_{.85}$, so  $\bbr{\dg M}_1^* = \{\mu_{.85}\}$.
	%joe18*: this arguably also shows the problem with the \bbr{\dg M}_k^*
	%semantics when k \ne 0.  We should say something about that.
	%oli21: A more accurate takeaway is that if \gamma is strictly
	%positive, then a messed 
	% up qualitative picture will impact the semantics.
	\end{example}
	
	%joe11*: is this what you mean?  Why is there only one such world?
	%optimal distribution would put all mass on the single best world; to
	%oli13: It's not guaranteed to be unique, but all mass is concentrated
	% on those worlds(s) which maximize the function. Added plural.
	%oli19: rewrote
	% If we had included only the likelihood term (the first one), 
	% an optimal distribution would put all mass on the worlds of maximum likelihood. 
	%joe17*: I don't undrstand why you made these changes.  How do you know
	%that there's a unique world of maximum likelihood?
	%oli20: it's not litterally true, but overwhelmingly likely and I don't want to
	% complicate the story unnecessarily. See the below.
	%the best distribution would put all mass on the highet likelihood world. 
	%oli20: commenting out, see discussion + replacement below.
	% the best distribution would put all mass on the worlds with maximum likelihood.
	%joe17: I really don't like ``devoid of unceratinty''!  Moreover, if
	%there isn't a unique world of maximum likelihood, why is there no
	%uncertainty?  
	%oli20*: while there may be multiple, any "uncertainty" is extremely fragile. 
	% With any real data, there is a unique best world with probability 1.If we add
	% epsilon noise to every cpt entry, there is a unique best world with probability 1.
	% In the same vein: the only way it is possible for an interior point to have any probability at all, is if the product of the factors is is the constant function. 
	%oli20: A simple example: a binary variable X, with an edge from 1 and an unconditional distribution % p(X=1) = 0.5 + \epsilon.  But X=1 is the only maximum likelihood world, so the optimal distribution is % the one that places all mass on X=1.  Taking this distribution seems hugely overconfident, and is totally in conflict with the uncertainty in the cpt. This is essentially what is hapepning in a factor graph. 
	%oli20: trying again.
	%joe18: this is not helpful  
	%The log likelihood term
	%%, which is as the cross entropy, 
	%is the only term that makes use of the cpds.
	%joe18*: in what sense is it the most important?
	%so in some sense it is the most important.  
	%oli21: (because it's the only term that depends on the cpds)
	%joe18*: Sorry, I can't make any sense of the next sentence.  In what
	%sense are the distributions miscalibrated?
	%On its own, however, the distributions it selects are badly
	%miscalibrated, placing all mass on worlds with the very highest
	%likelihood.
	%joe18*: the best distance by what metric?
	%oli21: (metric=scoring function with only log likelihood term)
	%For instance, the best distribution in \cref{ex:overdet}
	%by this metric is $\mu_{1.0}$, even if only link $p$ were given ---
	%which is in direct conflict with $p$ itself.  
	%Such a distribution is devoid of uncertainty, which usually is in direct
	%conflict with the data of the cpds $\mat p$.
	%joe17: What issue is it resolving?  How is it resolving it?
	%oli20: hopefully clearer now; I'm uncommenting and expanding.
	%joe18*: I'm afraid it's not at all clear, and I still have no idea
	%what issue is being resolved.
	%A factor graph essentially resolves this issue by
	%also including the final term,
	%oli20: added
	%joe18*: Sorry, I can't make any sense of this.  What does it mean to
	%``properly balance'' something.  How can ou tell if it's ``properly
	%balanced''.  
	%oli21*: By "balanced", I am referring technically to the situation where they
	% have the same coefficient. But saying this doesn't describe the effect:
	% When the coefficient on a regularization term, log[ 1 / \mu(x) ], equals the
	% coefficient on the energy term, log [ 1 / p(x)], for some fixed p, the
	% distribution \mu that minimizes the total is p (because their sum is then the KL
	% divergence from \mu to p).  If the regularization term
	% had a smaller coefficient, the optimal \mu would be distorted to be more
	% deterministic than p, and if it had a smaller one, it would be more spread
	% out. I claim that if p is meant as a description of the actual probability and
	% not just some measure of relative goodness, then balancing the two terms is
	% important.  
	%
	%which imposes a cost for uncertainy. For the PDG consisting of only
	%$p : 1 \to X$ from \cref{ex:overdet}, this results in $\bbr{1 \to
	%p}^* = p$. As we have seen, adding $q$ . It seems that as long as our
	%regularization term remains agnostic to the number of links in the
	%graph, and which nodes they attach to, it cannot properly balance the
	%likelihood so that the cpt is satisfied.    
	
	%joe18*: The next sentence should go earlier, after we've talked about
	%that first and last terms of (5) captring the free energy.
	%oli21: I keep trying to tell a story about what the equation does by building
	% up the terms, but I'm not getting through. I think without communicating the
	% instability + overconfidence of the likelihood term, and its standard 
	% resolution which involves the free energy, it's not really worth saying this anymore.
	%The scoring function that we use for PDGs can thus be viewed as
	%joe19: moved up from below, with minor changes to make it flow better.
	Although both $\theta$ and $\beta$ are measures of confidence, 
	%joe17
	%the way $\theta$ that a factor graph varies with $\theta$
	%joe19
	%the way that a factor graph varies with $\theta$
	%is quite different from the way a PDG
	the way that the Gibbs free energy varies with $\theta$ 
	is quite different from the way that the score of a PDG
	varies with $\beta$. 
	The scoring function that we use for PDGs can be viewed as
	extending ${\GFE}_{\Phi,\theta}$ by including
	the local regularization term.
	As $\gamma$ approaches zero,
	%joe18: it's not the strength, but the importance
	%oli21: Huh, I've always heard the adjective "strength" used to
	%describe the magnitude 
	% of the coefficient of a regularization term.  
	%the strenth of global regularization
	%drops and the strength of local regularization increases. 
	the importance of the global regularization terms decreases relative
	%joe19
	%to that of the local regularization term.
	to that of the local regularization term, so the PDG scoring function
	becomes quite different from Gibbs free energy.
	
	
	%joe11*: why do we want to express uncertainty?   What is it
	%uncertainty about.  I'm trusting you that ``regularization'' will be
	%meaningful in this context to others.  It's certainly not meaningful
	%to me. You have the space to add a sentence of clarification.
	%oli13: "Uncertainty" was maybe not the best word choice. Let's try this:
	% to capture $\bbr{\dg M}_\gamma(\mu)$, we need to include 
	%joe13*: this doesn't make sense to me.  Where did overfitting come
	%from?  We're not doing machine learning?  Since you haven't told me
	%the objective function, so to speak, I find this worse than useless.
	%It makes me think of things that ought to be irrelevant. At a
	%minimum, to include them, you must explain the goal (i.e., give some
	%intution!).  
	%to avoid overfitting these particular distributions, we need to include 
	%\emph{regularization terms} \todo{cite}.  
	%oli15
	% the regularization terms are needed to capture the inconsistency and
	% information deficiency of $\mu$ relative to ${\dg M}$.
	%joe14: I put ``regulararization'' in quotes
	%the regularization terms are thus necessary to model uncertainty.
	%You need to say something about how, although they're not
	%regluarization terms as the term is used in the ML community (since
	%we are *not* doing machine learning), they have some of the same spirit.
	%joe15*: Why are regularization terms necessary to model uncertainty?
	%All that you can say is here is that they're necessary to capture
	%this particular socirng function
	%oli17*: No, this is much weaker than what I want to say. These terms
	%are  necessary to have an optimal distribution $\mu$ that is not a
	%point mass on a particular world. 
	%oli17: Unsure if helpful, but the thermodynamic analogy is
	%temperature=0 Kelvin, 
	% so that everything is in its very minimum energy state, and the distribution of possible
	% configurations is a point mass on the single best one. 
	%oli17: Again, the point is: if we want it to even be possible for the minimum
	% of this function to be a non-degenerate distribution (i.e., one with uncertainty),
	% then we need the regularization terms. 
	%oli17: rewrote more explicitly, in the hopes that this was convincing.
	%
	%the ``regularization'' terms are thus necessary to model uncertainty.
	% the ``regularization'' terms are thus necessary to capture $\bbr{\dg
	  % M}_\gamma$. 
	%joe16*: Cut.  I do not understand what this means, or why it's
	%important.  This hurts far more than it helps.
	%the ``regularization'' terms are thus necessary for these
	%distributions to have any uncertainty. 
	%oli19: rewriting.
	% By contrasting equation
	% \eqref{eq:semantics-breakdown} with the expression for $\GFE_\Phi$, we see
	% that, although both $\theta$ and $\beta$ are measures of confidence, the way
	% that a factor graph varies with $\theta$ is quite different from the way a PDG
	% varies with $\beta$. 
	%joe17: Cut this.  I 
	%The fact that the local term varies with $\beta_L$ has important
	%modeling consequences. 
	
	%joe17*: I don't undersatnd teh rest of this.  I couldn't see anywhere
	%in the example where these points were illustrated.  Indeed, the
	%exampe doesn't mention \beta at all.  If you could rewrite the exmple
	%to illustrate these points, we might consider reinstating this.
	%oli20: fair enough, reinstated and added missing details. 
	%joe18*: I still can't make sense out of any of this.  As an aside,
	%this is *not* what I asked you to do.  I asked you just to focus on
	%the technical material, which is all I was (and am) comfortable with.
	%$\theta_J$ controls the strength of the potential associated to $J$;
	%joe18*: I don't understand this.  Why does increasing one
	%terms \theta_J for a specific J, make distributions more
	%deterministic.  If you increase all of them, I can see how it wuld
	%make distributions more determininstic, but only if all the ffactors 
	%were different numbers.  But why do we are about this?  We're writing
	%a paper about PDGs.  What does this tell us about PDGs.
	%increasing it results in optimal distributions which are more
	%deterministic.  
	%oli21: You raise a good point about an individual $\theta_J$;
	% thanks for adding the context.  
	%oli20: added
	%joe18*: I have no idea how a generaic atatement about properties. I
	%would *strongly* prefer to return this to its previous state (modlo
	%the technical concerns I've raised).
	%of \theta_J could follow from an Example.  But even if you meant that
	%Example 5 illustrates your point, I can't see any way in which you've
	%argued that doubling J makes things more deterministic.  The next
	%sentence just feels like a complete non sequitur.  
	%This follows from \cref{ex:overdet} the fact that doubling $\theta_J$
	%is equivalent to duplicating factor $J$. By contrast, $\beta_L$
	%controls both the likelihood and the local uncertainty together: as
	%described in our motivation for $\Inc$, increasing the reliability of
	%$\beta$ in a PDG increases the cost of failing to match the given cpd.  
	%\\\contentious{
	%joe19*: Please do not spend time doing this, Oliver.  Put your
	%efforts dealing with the issues that we agreed were the important
	%issues.  I don't understand any of the discussion below. I don't know
	%what it means for a factor graph to ``fuse'' things, nor why we have
	%to have \alpha_L = \beta_L (indeed, as I pointed out above, we
	%definitely do *not* want to assume this). Since we have no intuition
	%for \alpha_L, we can make no claim about what is appropriate for it.
	%I cut all this.
	%The behavior in \cref{ex:overdet} also sheds some light on the nature
	%of $\alpha$. 
	%Because a factor graph fuses $\alpha_L = \beta_L$, adding a new edge
	%effectively doubles both (it doubles $\theta_L$). If one believes
	%that both $p$ and $q$ are from independent sources, and thus
	%constitute separate qualitative determinations of $X$, then
	%effectively doubling $\alpha_p$ is appropriate. If, on the other
	%hand, you merely have two distinct sets of observations which agree,
	%and have no reason to believe they are independent or have anything
	%to do with the causal structure of the world, then effectively
	%doubling $\alpha_p$ is not appropriate.   
	% }
	%
	%joe13*: the equation says nothing abut \theta.  This is even more
	%confusing because in the tranlsation you take \beta_L = \theta_L.  My
	%preference would be to ut the rest of the paragraph, although I didn't
	%do it.  I think it hurts more than helps.
	%\eqref{eq:semantics-breakdown} shows further that, although
	%oli15
	% \eqref{eq:semantics-breakdown} helps show  that, although
	%oli12: added the technical details and fused with next sentence
	%joe11*: typo, I assume.  If not, then it's unclear
	%For a factor graph, $\beta$ controls the importance of the likelihood
	%term, while in a PDG it also increases the strength of the local
	%oli13: you're right. This enables further simplification
	% For a factor graph, $\theta$ controls the importance of the likelihood
	% term, while in a PDG, $\beta$ it also increases the strength of the
	%joe13: I don't know what ``jointly controls'' means.  After changing
	%the next few lines, I cut them.   It's true that \beta affets both
	%the likelihood term and the local regularaization term, but I don't
	%wee why that makes it different from theta; there is no theta in the
	%equation above
	%oli15: I've reverted because the story makes more sense with this in than out. 
	% It's true and I think it won't be too difficult to follow from the equation.
	%%$\beta$ jointly controls the importance of the likelihood and local
	%oli15 modified
	%joe14*: In what sense does it balance them?  I'm lost.  If you say
	%``affects'' it's fine.  If not, you must explain what ``balance'' means.
	%oli16: the strength of the regularization must match the strength of
	%the likelihood. Only then is the function minimized by the cpd on the
	%edge, rather than a more deterministic one (if the former is
	%stronger) or a more random one (if the latter is stronger). 
	    % $\beta$ balances the likelihood and local
	    % regularization terms [[REWRITE]], while 
	    % $\theta$ affects only the former.
	%oli16: rewritten so that now it is clear, but much too long. I like my shortening above,
	% and do not think it needs anything else, but I'll let you shorten this one as you like. It also double-covers material from the next sentence.)
	%joe15*: Sorry; it is *not* clear (at least, not to me).  I don't know
	%what it means that they ``remain balanced''.  I also don't like the
	%use of terms of agency (``controls'').  Are you saying anything other
	%than \beta affects the difference between the terms.  Is that what
	%balance is supposed to mean?  If so, it's an awfully complicated way
	%of saying it.  If not, what is it saying that's different?  I cut
	%most of it.  I think that what you wrote is a net negative; in
	%expectation, it will hurt more than it will help.  Do NOT
	%make further changes without discussion (other than correcting typos)
	%$\beta$ simultaneously controls both the local likelihood and local
	%regularization terms, so that the two remain balanced, and making a
	%link more or less random never does better than exactly matching the
	%cpt.  
	%oli17: \beta preserves the ratio between the first and second 
	% terms (in the limit as \gamma -> 0)
	%joe16: As a technical matter, I don't see why this is true.  I don't
	%see in what sense \beta preserves anything.  It's just a number that
	%you miltiply the difference between the terms by.  
	%oli17: and the cpds that that optimize it remain the same.
	%joe16: The same as what?  I'm totally lost
	%oli17: This is very different from just increasing the strength of the 
	% likelihood because it makes things more determinisitc. I maintain that this
	% is a critical point, but I will not modify the text here to make it until we
	% agree...
	%joe16: good.  I truly have no idea what you said above, and I
	%strongly suspect that I would not understand anything you tried to
	%say here.
	%oli19: I don't need this anymore either
	%joe17: reinstated, because I cut what you added
	%oli20: removed again. I don't think this says very much, and I've tried
	% to address your concerns again.
		% In (\ref{eq:semantics-breakdown}), 
		% $\beta$ affects the difference between the local likelihood and
		% local regularization terms; on the other hand, in $\GFE_\Phi$,
		% $\theta$ affects only the likliehood.
	% %oli17
	% $\theta$ affects only the likelihood.
	%$\theta$ only controls the likliehood, and so as it
	%increases the benefits of reporting an uncertain distribution fade as
	
	%oli21: Here's the paragraph that I didn't cut before, but now it's above so I'm cutting it.
	% \Cref{eq:semantics-breakdown} also makes it clear that 
	% taking $\beta_L = {$\alpha_L$} \gamma$ for all edges $L$ is
	% essentially necessary to get \Cref{thm:pdg-is-fg,thm:fg-is-pdg}.
	% However, the analogue of \Cref{prop:consist} does not hold
	% in general for such choices, leading to some arguably unacceptable
	% behavior in factor graphs trying to capture the same phenomena as PDGs.
	
	%joe9: cut; folded some material into the next section
	%oli20: I rewrote this section and brought it up in case 
	%joe18: I commented it out again, after making minor changes.  Nothing
	%in what you've written explains the connection between PDGs and
	%directed factor networks.  THere's no point in giving a (not
	%particularly useful) introduction to directed factor graphs.  We're
	%not writing a paper about factor graphs.  If you have something
	%useful to say about the connection between diredcted factor graphs
	%and PDGs (e.g, we can prove an analogue of THeorems 4.4 and 4.5 for
	%them), then it would be worth saying.  Otherwise, this is a poor use
	%of space.
	\begin{inactive}
	
		\subsection{Directed Factor Graphs}
		% Directed Factor graphs \cite{frey2012extending} impose constraints on factor graphs to resolve some of their issues and bring them more in line with BNs, but they have no semantics if the constraints are not satisfied, making them a way of visualizing factor graphs more than a novel modeling tool.
	%joe18
	%While PDGs can be thought as a loosening the restrictions on
	While PDGs can be thought as a loosening of the restrictions on
		Bayesian Networks, 
	%joe18
	%Directed Factor Graphs \cite{frey2012extending} go the
	\emph{directed Factor Graphs} \cite{frey2012extending} go in the
		opposite direction: they  
	%joe18: I don't know what ``better-behaved'' means.  Better behaved
	%than what?
	%extend factor graphs with better-behaved directed edges,
	are variant of factor graphs where edges are directed,
		allowing them to represent a larger class of independencies,
	%joe18
	%including those of Bayesian Networks. Such an directed edge
	including those of Bayesian Networks. A directed edge
		indicates that the product of incoming edges normalize to 1,
		an invariant which must be enforced and maintained as the
		model is changed. As a result, directed factor graphs are
		well-suited to visually describing the structure of
		distributions, but less well suited to modelding beliefs that
		change quickly, or could be inconsistent. 
	\end{inactive}
	
	%oli22*: I'm still working on this section. THere's no need to edit it
	% at this point, because I plan to reduce it massively myself.
	% (also much of it has been heavily modified without marks) 
	% I do have a question: is it worth dding a plots which emperically suggest
	% that these results are true, even without theorems?
	\begin{wip}
	\subsection{Dependency Networks}
	
	PDGs are closely related to Dependency Networks, or DNs
	\cite{heckerman2000dependency}. The data of a DN is also an unstructured
	collection of cpds, but the cpds are attached to nodes rather than edges, so
	there must be exactly one per node.  \citeauthor{heckerman2000dependency} also
	emphasize the benefit of being able to supply arbitrary data in the cpds,
	without enforcing the consistency constraints.
	
	
	\begin{defn}
	%joe20
	%A Dependency Network is a tuple $\mathcal D = (\Gr, \mat p) $, where
	A \emph{dependency network} is a tuple $\mathcal D = (\Gr, \mat p) $, where
	$\Gr$ is a 
	%joe20
	%directed graph of variables, and $\mat p$, gives for each $X \in \N$ a
	directed graph of variables and $\mat p$ gives, for each $X \in \N$ a
	%joe20*: misplaced footnote mark.  More importantly, does Heckerman
	%require p to be positive in the defintion, or only n the theorem.
	%The definitions make perfect sense even without this assmption.
	%positive 
	%	\footnote{that is, each cpd $\bp[X]$ has no zero entries}
	%cpd $\bp[X](X \mid \Pa^{\Gr}(X))$,
	positive cpd $\bp[X](X \mid \Pa^{\Gr}(X))$ (i.e., all entries in $\bp[X]$ are
	psoitive),
	where $\Pa^{\Gr}(X)$ are the parents of $X$ in $\Gr$.
	Together with a total order $\prec$ on $\N$,
	$\mathcal D$ defines a joint distribution $\Pr^\prec_{\mathcal D}$ on $\V(\N)$ via an \emph{ordered Gibbs sampler}. 
	Concretely,
	%joe20
	%initialize $\mat X^{(0)}$ to any joint setting of variables, and
	%for $t= 1,2, \ldots$, and for $i=1,2,\ldots$, we draw
	initialize $\mat X^{(0)}$ to an arbitrary joint setting of variables, and
	for $t= 1,2, \ldots$ and $i=1,2,\ldots$, define
	\[
		 X_i^{(t)} \sim \bp[i]\left(X_i ~\big|~ x_1^{(t)}, \ldots,
	%joe20
	%x_{i-1}^{(t)}, x_{i+1}^{(t-1)}, \ldots, x^{(t-1)}_{n} \right)
	x_{i-1}^{(t)}, x_{i+1}^{(t-1)}, \ldots, x^{(t-1)}_{n} \right).  
	%		= \bp[i](X_i \mid \mat{pa}^{\Gr}(i)) 
	\]
	%joe20*: what does rotating through the variables have to do with it?
	%After each full rotation through the variables, we get a new sample
	%which depends only on $\mat X^{(t)}$> Thus we have a Markov chain of
	Note that $\mat X^{(t+1)}$
	depends only on $\mat X^{(t)}$. Thus, we have a Markov chain of
	joint variable settings 
	$ \mat X^{(0)} \to \mat X^{(1)} \to \ldots \to \mat X^{(t)} \to \ldots$.
	%joe20
	%that, so long as each $\bp[X]$ is positive, ensures that the chain is
	Since each matrix $\bp[X]$ is positive,
	the chain is
	%joe20: you need a reference (perhaps Puterman's book), and need to
	%explain ergodic. 
	ergodic, 
	%joe20
	%and thus limits to a unique stationary distribution on $\mat X$,
	and thus has a unique stationary distribution on $\mat X$ as its limit.
	%joe20
	%which we take to be the definition of $\Pr^\prec_{\mathcal D}$.
	We define $\Pr^\prec_{\mathcal D}$ as this stationary distribution,
	\end{defn}
	
	% << This is what was written in your email. It's still more detailed
	% than I have written but I don't want to finish integrating it until after
	% I've proven some results. >>
	%
	%This is clearer than what's written, but it's different from what you 
	%wrote in our writeup, as near as I can tell.  But I think I see what's 
	%going on, and how it should be explained (at least for me to understand 
	%it).  First, you have tell me how to initialize x_1, ..., x_n (i.e., 
	%what is x_1^0, ..., x_n^0).  We then define X_n^t by induction on t.  We 
	%take X_0^t = (x_1^0, ..., x_n^0) (which I'm assuming is given somehow).  
	%If t = nt'+i, we assume that we have defined x_j^0, \ldots, x_j^{t'} for 
	%j < i and x_j^0, \ldots, x_j^{t'-1} for j \ge i.  We then define x_i^t' 
	%to be the result of drawing a value according to the distribution 
	%p_i(.|x_1^{t'}, ..., x_{i-1}^{t'}, x_i^{t'-1}, ...,  x_n^{t'-1}).   Then 
	%we define X^t = (x_1^{t'}, x_i^{t'}, x_{i+1}^{t'-1}, ..., x_n^{t'-1}).
	%
	%Notice how different this description is from years.  Now you can point 
	%out that the sequence X^0, X^1, ... can be viewed as a Markov chain.  
	%However, you can't just say "you take the limiting distribution", 
	%because the limiting distribution does not exist in general.  This is 
	%where the fact that all the cpds (not *local distibutions, which is an 
	%undefined term) are positive comes in; it ensures that the Markove chain 
	%is irreducible, which in turn guarantees that there's a unique 
	%stationary distribution. This should be pointed out.
	
	The dependence on the order is artificial in the case that the DN is
	``consistent'', which in the authors parlance implies that it also has 
	% their favored independencies.\footnote{Interestingly, any BN $\mathcal B$ is an ``inconsistent'' dependency network, despite the fact that the Gibbs sampler whose order $\prec$ is a topological sort  of $\cal B$, generates $\Pr_{\mathcal B}$.}
	%joe24
	%their favored independencies.\footnote{Interestingly, any BN $\mathcal
	their favored independencies.\footnote{Interestingly, a BN $\mathcal
	B$ is an ``inconsistent'' dependency network, despite the fact that
	the Gibbs sampler whose order $\prec$ is a topological sort  of $\cal
	B$, generates $\Pr_{\mathcal B}$.} 
	\begthm[\citeauthor{heckerman2000dependency}]{theorem}{thm:dns-uniq}
	%Theorem 1. (wrapped into definiton above)
	%An ordered Gibbs sampler applied to a dependency network for $\mat X$, where each $X_i$ is discrete and each local distribution $\bp[X](x \mid \mat{pa}(X))$ is positive, has a unique stationary joint distribution for $\mat X$.  
	If a dependency network $\mathcal D \!=\! (\Gr, \mat p)$ over variables $\N$ is consistent with a positive joint distribution $p$,
	in that $p(X \mid \N\setminus \{X\}) = \bp[X](X \mid \Pa^{\Gr}(X))$ for all $X \in \N$,
	 then $\Pr_{\mathcal D}^\prec = p$.
	\end{theorem}
	
	%joe24
	%A dependency network $\mathcal D$, together with any a vector of
	A dependency network $\mathcal D$, together with a vector of
	confidences $\beta$ for the cpds on each variable 
	% (defaulting to $\beta_X=1$) 
	can be naturally regarded as a PDG $\PDGof{\mathcal D, \beta}$ 
	via the same translation used for a Bayesian Network.
	Although on the surface PDG and DN semantics are quite
	different,
	the former subsumes the latter, as the next results show.
	
	
	%\begin{lemma}
	%	A distribution $\mu$ that locally minimizes $\IDef{\PDGof{\mathcal D, \beta}}$ satisfies all of the independencies of $\mathcal D$.
	%\end{lemma}
	
	
	\begthm{conj}{thm:dns-are-pdgs}
	%oli22: updating theorem statement
	% If $\mathcal D = (\N, \Ed, \V, \mathcal P)$ is a consistent dependency network with a positive stationary distribution $p^*$ of its sampling procedure, then the PDG $\PDGof{\mathcal D} = (\N, \mathit{merge}(\Ed), \V, $$\mathcal P, \mat 1{, $\mat 1$})$, then $\bbr{\PDGof{\mathcal D}} = p^*$.
	If $\mathcal D$ is a consistent dependency network,
	%with positive local distributions,
	then for all positive vectors $\beta$, and all orders $\prec$, we have that
	%$\SD{\PDGof{\mathcal D, \beta}} =  \{ \Pr_{\cal D}^\prec \}$.
	$\bbr{\PDGof{\mathcal D, \beta}}^* =  \Pr_{\cal D}^\prec$.
	%, where $\Pr_{\cal D}^\prec$ is the unique stationary distribution of the $\prec$-ordered Gibbs sampling procedure. 
	\end{conj}
	
	Inconsistent DNs still define a unique distribution, but we cannot hope that it 
	will be the same one as generated by the PDG, owing to the fact that
	the Gibbs sampler defined by \citeauthor{heckerman2000dependency} is dependent
	on the (arbitrary) fixed order used in sampling.
	A PDG can simulate the effect of the order with the reliability $\beta$.
	
	\begin{conj}
	If $\mathcal D$ is a dependency network over the variables
	$X_1 \prec X_2  \ldots  \prec X_n$ is a total order on the variables, and $\beta$ is a vector over the edges
	%oli22: to preemptively eliminate some confusion:
	% (which have a 1-1 correspondence with variables in a DN) 
	such that  $\beta_1 \ll\beta_2 \ll \ldots \ll \beta_n$, 
	then $\Pr_{\cal D}^{\prec} = \bbr{\dg M; \beta}^*$
	\end{conj}
	
	A \emph{random scan} Gibbs sampler, rather than cycling though variables in a 
	particular order, draws the next variable index to update randomly.
	Given a distribution $d$ over $\N$,
	let $\mathit{RScan}(d)$ be the random scan Gibbs sampling procedure that draws
	the next variable to update from $d$. $\mathit{RScan}(d)$ also has a
	unique stationary distribution, $\Pr_{\mathcal D}^d$, which is equal
	%joe24
	%to $\Pr_{\cal D}^{\prec}$ for any $d$ and $\prec$ if $\mathcal D$ is a
	to $\Pr_{\cal D}^{\prec}$ for all $d$ and $\prec$ if $\mathcal D$ is a
	consistent DN. This more symmetric procedure is captured nicely by PDG
	semantics. 
	
	\begin{conj}\label{thm:dns-are-completely-pdgs}
		Let $d(X) \propto \beta_X$. Then
		$\Pr_{\mathcal D}^d = \bbr{\PDGof{\mathcal D, \beta}}^*$, whether or not $\mathcal D$ is consistent.
	\end{conj}
	
\end{wip}




	\section{Databases}
	\subsection{Deterministic Databases}
	\begin{defn}[deterministic typed database]
	  A (typed) database $\D$ is a tuple $\D = (\Attrs, \Idx, \Doms, \sch, \Rels)$, where

      \def\oftype#1{{$:#1$}}

    \renewcommand{\arraystretch}{1.3}
    \begin{tabular}{@{~~~}r@{}lp{12cm}}
    	$\Attrs$ & \oftype{\FinSet} & is a finite set of attribute names, \\
    	$\Idx$ & \oftype{\FinSet} & is a finite set of table names,\\
    	$\Doms$ & \oftype{\Attrs \to \Set} & gives a domain of possible values for each attribute, and \\
    	$\sch$ & \oftype{\Idx \to \Attrs \to \two,} & called the \emph{schema} of $\D$, assigns a subset of the attributes $\Attrs$ to each table name (corresponding to the table columns).
 \\[0.5em]\multicolumn{3}{@{}p{\textwidth}@{}}{
 	In this way, $\sch$ gives the database type structure: it encodes the data necessary to ensure that any cell in column $A$ of the $j^\text{th}$ table comes from the specific domain $\Doms_A$. The arity function can be defined by flattening all of the type information in the schema, and reducing $\sch_j$ to its length: $\arity(j) := | \sch_j |$.
	Together, $\sch$ and $\Doms$ determine a product domain
%	$\mat D_j := \prod_{A \in \sch_j} \Doms_{A}$
	$\Doms (\sch_j) := \prod_{A \in \sch_j} \Doms_{A}$
	of valid tuples in the relation $R_j$. With this, we can define the final and most important component of a database, the tables themselves:
		} \\
%    	 \rule{0pt}{1.3\normalbaselineskip} $\Rels$ & \oftype{(j:\Idx) \to \prod_{i \in \sch_i} \Doms_{j} \to 2}&
%    	 \rule{0pt}{1.3\normalbaselineskip} $\Rels$ & \oftype{(j:\Idx) \to \mat D_j \to \two}&
    	 \rule{0pt}{1.3\normalbaselineskip} $\Rels$ & \oftype{(j:\Idx) \to \Doms(\sch_j) \to \two}&
    	is an $\Idx$-indexed collection $ \{ R_j \}_{j \in \Idx}$ of relations, where each $R_j \subseteq \Doms(\sch_j)$.
    \end{tabular}

%    \def\oftype#1{{\!\!$:#1\qquad$}}
%    \begin{itemize}[itemsep=-0.8ex]
%    	\item[$\Attrs$] \oftype{\Set}
%    		is a finite set of attribute names.
%    	\item[$\Doms$] \oftype{\Attrs \to \Set}
%    		assigns a set of possible values to each attribute name.
%    	\item[$\Idx$] \oftype{\Set}
%    		is a finite set of table names.
%%    	\item[$\arity$] \oftype{\Idx \to \mathbb N}
%%    		is the arity function, so that $\arity(i)$ is the number of columns in the $i^\text{th}$ table.
%    	\item[$\sch$] \oftype{\Idx \to \Attrs \to 2,}
%    		%\oftype{\Idx \to \{1, \ldots, \arity(i)\} \to  N,}
%    		called the \emph{schema} of $\D$, gives the database type structure by ensuring that the $j^\text{th}$ column ($j < \arity(i)$) of the $i^\text{th}$ table comes from the specific attribute $\sch_{i,j} \in \Attrs$.
%    \end{itemize}

%    $\mathcal D$ is a collection of finite domains (the domain for each attribute),
%	again $\arity: I \to \mathbb N$ determines the arity of , but now

%	For $i \in I$ and $j \in \{1, \ldots, \arity(i)\}$, we write $A_{i,j}$ for the $j^{\text{th}}$ component of the relation $R_i$, so that the relation $R_i$

%	Once again $\mathcal R =$ is a finite collection of relations, though now their types are determined by $\Att$. Let
%	$$\mat D_{i} :=  \prod \Att_i = \prod_{j =1}^{\arity(i)} \Att_{i,j}$$
%	be the possible tuples that could

%	$R_i \subseteq \prod \Att_i = \prod_{j =1}^{\arity(i)} \Att_{i,j} $
	\smallskip
	Since $\Idx$, and $\Attrs$ are implicit in the type of $\sch$, and $\Doms$ is implicit in the definition of $\Rels$,
	we sometimes use the abbreviated form $\D = (\sch, \Rels)$. %where $\sch$ is understood to be packaged with appropriate data for $\Idx, \Attrs$, and $\arity$.
\end{defn}
\medskip
%\begin{defn}
%	The component $\Att^\D$ of a typed database $\D = (\mathcal D, I, \arity, \Att, \mathcal R)$, is the \emph{schema} of $\D$. %$(I, \Att)$ defines a hypergraph.
%\end{defn}

%\begin{remark}
%	$(I, \Att)$ is a hyper-graph, and $D$ assigns
%\end{remark}

\begin{remark}\label{rem:typed-db-better}
    The definition of an untyped database with underlying domain $D$ is a special case of a typed database, in which $\Attrs := \mathbb N$ corresponding to the argument index, set every $\Doms_n := D $, and every $\sch_{i,j} = \mathbbm1[j \le \arity(i)]$.
    In some sense, the two are equally expressive: we can also simulate a typed database $\D$ with an untyped one. Simply set $D := \uplus_j \mathcal D_j$ to be the disjoint union of all domains, and $\arity(i) := |\sch_i|$. Now any table $R_i \in \Rels^\D$ can be directly used as a table in the untyped database, since
    \[R_i \subseteq \mat D_i = \prod_{j \in \sch_i} \mathcal D_{j}
		\subseteq \prod_{j \in \sch_i} D = \prod_{j = 1}^{\arity(i)} D =
        D^{\arity(i)} .\]
  	The definitions are not equivalent, and the typed version is more expressive, because it disallows some rows by fiat (which has a different meaning from being absent from the relation), encoding type-level constraints. This is nice even within the context of databases, since a ds. By naming $A$, we can explicitly restrict the  allowable collections of attributes, which with which we will be able to define classes of databases which behave like other specific graphical models.
\end{remark}

\begin{figure}
	\centering
		\subcaptionbox{ The three tables of $\D$\label{subfig:tables} }{
		\begin{tikzpicture}[baseline=0, tablename/.style={inner sep=1pt,circle,text=black,font={}}]
			%fill=gray!20
			\node at (1,1.5){\textbf{Database}};

			\node[tablename] (R1) at (-1.3,1.2) {\large$\mathbf R_1$};
			\node[below right=-0.2em and -1.2em of R1] (table1) {
				\begin{tabular}{ccc@{}}
					$\var A$ & $\var B$ & $\var C$\\\hline
					$a_1$ & $b_1$ & $c_1$ \\ $a_2$ & $b_2$ & $c_2$
				\end{tabular}
			};
			\draw[] ($(R1.south)+(.3,.1)$) -- ++(-0.3,-0.15) -- ++(0,-1);
			\draw[] ($(R1.south)+(.28,.12)$) -- ++(-0.3,-0.15) -- ++(0,-1);
			\fill[white] ($(R1.south)+(.29,.12)+(-0.3,-0.15)$) rectangle ++(-0.1,-1);


			\node[tablename] (R3) at (-0.5,-0.8) {\large$\mathbf R_3$};
			\node[below right=-0.6em and -0.6em of R3] (table1) {
				\begin{tabular}{cc@{}}
					$\var C$ & $\var D$\\\hline
					$c_2$ & $d_1$ \\ $c_1$ & $d_3$
				\end{tabular}
			};
			\draw[] ($(R3.south east)+(.2,.1)$) -- ++(-0.2,-0.2) -- ++(0,-1);
			\draw[] ($(R3.south east)+(.18,.12)$) -- ++(-0.2,-0.2) -- ++(0,-1);
			\fill[white] ($(R3.south east)+(.19,.12)+(-0.2,-0.2)$) rectangle ++(-0.1,-1);

			%        \node[draw,circle,inner sep=0.2pt,fill=gray!50] (R2) at (1.3,1) {\large$R\mspace{-3.5mu}R_2$};
			\node[tablename] (R2) at (1.6,0.7) {\large$\mathbf R_2$};%\mspace{-12.5mu}R
			\node[below right=-0.2em and -1.2em of R2] (table2) {
				\begin{tabular}{cc@{}}
					$\var B$ & $\var D$ \\\hline
					$b_2$ & $d_1$ \\ $b_3$ & $d_2$ \\
					$b_4$ & $d_3$
				\end{tabular}
			};
			\draw[] ($(R2.south)+(.3,.1)$) -- ++(-0.3,-0.15) -- ++(0,-1.6);
			\draw[] ($(R2.south)+(.28,.12)$) -- ++(-0.3,-0.15) -- ++(0,-1.6);
			\fill[white] ($(R2.south)+(.29,.12)+(-0.3,-0.15)$) rectangle ++(-0.1,-1.6);
		\end{tikzpicture}
	}
	\hfill\vline\hfill
	\subcaptionbox{ Its schema $\sch^\D$, as an undirected hypergraph\label{subfig:schema}}{
		\begin{tikzpicture}[baseline=0]
			\node at (0,1.5) {\textbf{Relational Schema}};
			\node[dpadded] (A) at (-2,-0.4){$\var A$};
			\node[dpadded] (B) at (-0.5, 0.5){$\var B$};
			\node[dpadded] (C) at (-0.5,-1.3){$\var C$};
			\node[dpadded] (D) at (1.5,0.5){$\var D$};

			\coordinate (ABC) at (barycentric cs:A=1,B=1,C=1);
			\node[above left=1pt and -4pt of ABC]{$R_1$};

			\draw[arr, -, shorten >=0, shorten <=1.5pt] (A) -- (ABC) (B) -- (ABC) (C) -- (ABC);
			\draw[arr, -, shorten >=0] (D) -- node[above]{$R_2$} (B);

			\draw[arr, -, shorten >=0] (D) -- node[below right]{$R_3$} (C);
		\end{tikzpicture}
	}
	\hfill\vline\hfill
	\subcaptionbox{ The PDG $\PDGof{\sch^\D}$\label{subfig:indexed}}{
		\begin{tikzpicture}[baseline=0]
			\node at (1.5,1.5) {\textbf{Explicit Indices}};
			\node[dpadded] (A) at (-0.6,-1.2){$\var A$};
			\node[dpadded] (C) at (1.4,-1.5){$\var C$};
			\node[dpadded] (B) at (0.5, 0.5){$\var B$};
			\node[dpadded] (D) at (3.3,0.6){$\var D$};

			\node[dpadded,inner sep=2pt] (R1) at (barycentric cs:A=1,B=1.5,C=1){$\var R_1$};
			\node[dpadded,inner sep=2pt] (R2) at (barycentric cs:B=1,D=1){$\var R_2$};
			\node[dpadded,inner sep=2pt] (R3) at (barycentric cs:C=1,D=1){$\var R_3$};
			% \node[above left=1pt and -4pt of ABC]{$R_1$};

			\begin{scope}[->, thick, shorten <=0pt, shorten >=0pt]
				\draw (R1) -- (A);
				\draw (R1) -- (B);
				\draw (R1) -- (C);
				\draw (R2) -- (B);
				\draw (R2) -- (D);
				\draw (R3) -- (D);
				\draw (R3) -- (C);
			\end{scope}
		\end{tikzpicture}
	}

	\caption{A simple relational database $\D$ \subref{subfig:tables}, its schema \subref{subfig:schema}, and an encoding as a PDG \subref{subfig:indexed} with a hallucinated ``variable'' serving as each index. Note that where multiple arrows are incident an attribute, as in the case of $B$, we interpret them separately and not as a joint dependence: we have a way of getting the value of $B$ from either a row of table 1 or a row of table 2. Therefore this directed representation must be interpreted as a PDG, rather than a BN.} \label{fig:sketches}
\end{figure}

\begin{defn}[keyed database]
	A \emph{keyed} database $(\D, \mathcal K)$ is a relational database $\D$ % $(\Attrs, \Idx, \Doms, \sch, \Rels)$,
	equipped with key rings $\mathcal K : \Idx \to \two^{\sch_j}$ and a function $\textit{lookup} : \prod\Doms(K) \to \{\none\} \cup \V(\sch_j)$. Concretely, each $\mathcal K_j$ is the ``key ring'' for table $j$, and consists of a set of candidate keys --- each key $K \in \mathcal K_j$ of which is itself a subset of attributes which jointly index table $j$. This is captured by the lookup function: for each key $K \in \mathcal K_j$, $\textit{lookup}_K : \prod\Doms(K) \to  \{\none\} \cup \V(\sch_j)$ returns the unique full tuple $t$ in the database that matches the attributes of $K$, if $t \in \mathcal R_j$, and $\none$ otherwise.
\end{defn}

We now proceed by defining our query language. 
\def\Varis{\V\kern-.65pt\mathit{ars}}%
\def\Bmid{\mathrel{\Big|}}%
Let $\Varis$ be a set of variable symbols.
\begin{defn}[Relational Calculus, RC]
	The language $\lang{RC}_{(\Varis, \sch, \Doms)}$ consists of first order formulae generated by the BNF
	grammar
	\[ Q ::= (u=v) \Bmid R(\mat x)  \Bmid \exists x. Q_1 \Bmid Q_1 \land Q_2 \Bmid Q_2 \lor Q_2 \Bmid \lnot Q_1 ~, \]
	where $u,v \in \Varis \cup \Doms$ are variables
	%\footnote{or constants, which we model as variables that can take only a single value} 
 	or constants, $x \in \Varis$ is a variable,
 	$R \in \Idx$ is a relation symbol, $\mat x  : \sch_j \to {\Varis }$ is an assignment of variables to each of $R_j$'s attributes (i.e., $\sch_j$), and $Q_1, Q_2 \in \lang{RC}_{\Varis,\sch}$.
\end{defn}

We will generally omit the subscripts $\Varis,\sch,\Doms$ and simply refer to $\lang{RC}$; when applied to a specific database $\D$, $\sch$ and $\Doms$ will be clear from context, while $\Varis$ is generally a fixed infinite set of variables for queries. 

For a fixed total ordering $\leq_\Attrs$ on $\Attrs$, assignments $\sch_j \to \Varis$ are in bijection with vectors over $\Varis$ of arity $\arity(j)$. This allows us to regard $\mat x$ as a vector in $\Varis^{\arity(j)}$. 

We are particularly interested in a distinguished subclass of $\emph{conjunctive queries}$. 
\begin{defn}[CQ,UCQ]
	The languages $\lang{CQ}$ and $\lang{UCQ}$ are respectively generated by the first four and five production rules. Explicitly,
	\begin{align*}
		\lang{CQ} &:= Q ::= (u=v) \Bmid R(\mat x)  \Bmid \exists x. Q_1 \Bmid Q_1 \land Q_2 ~; \\
		\lang{UCQ} &:= Q ::= (u=v) \Bmid R(\mat x)  \Bmid \exists x. Q_1 \Bmid Q_1 \land Q_2 \Bmid Q_2 \lor Q_2  
	\end{align*}
\end{defn}

\subsubsection{Query Semantics for PDGs}

% \subsubsection{Query Semantics}
We now define a binary operation $\qq : \PDG \times \lang{UCQ} \to \PDG$ which executes UCQ.
\begin{defn}[\texorpdfstring{$\qq$}{>}]
  If $\dg M$ is a PDG, and $Q \in \lang{UCQ}$ is a UCQ query with free variables $\mat X$, we define the PDG $\dg M \qq Q$ by structural induction, as follows.
  
  \begin{itemize}
  	\item $\dg M \qq  (u = v) :=  \dg M \cup (\{u,v\}, \{u\shortrightarrow v, v\shortrightarrow u\}, \V(), \delta_{u}, \delta_{v}).$
	% \item $\dg M \qq  R(\mat x) :=  \dg M \cup \tikz[center base,scale=0.8]{
	% 	\node[dpad1](uEv) at (0:1){u=v};
	% 	\node[dpad1](u) at (120:1){u};
	% 	\node[dpad1](v) at (-120:1){v};
	% 	\coordinate (up) at (u.south);
	% 	\coordinate (vp) at (v.north);
	% 	\mergearr{up}{uEv}{v}
	% 	\mergearr{vp}{uEv}{u}
	% 	% \draw (0,0) rectangle (2,1); 
	% }$.
  \end{itemize}
\end{defn}

\begin{inactive}
\begin{prop}
  For all PDGs $\dg M$ and all joint distributions $\mu_1, \mu_2 \in \Delta\V(\dg M)$, we have
  $\bbr{\dg M}(\mu_{1}) \le \bbr{\dg M}(\mu_{2})$ iff $\mu_{1}$
\end{prop}
\end{inactive}

\begin{prop}[PDG/DB Query Equivalence]
  If $\D$ is a typed database, and $Q(\mat X) \in \lang{UCQ}$ is a union of conjunctive queries with free variables $\mat X$,then
  \begin{enumerate}[label=(\alph*)]
	\item $\bbr{\PDGof{\D} \qq Q}^{*}(\mat x \mid Q \ne \none) > 0$ iff $\mat x \in Q(\D)$.
	\item For all $\mu \in \SD{\PDGof{\D} \qq Q}$, $\mu(\mat X = \mat x \mid Q \neq\none) > 0$ iff $\mat x \in Q(\D)$.
  \end{enumerate}
\end{prop}

\begin{prop}
  If $\D$ is a typed database, and $Q(\mat X) \in \lang{UCQ}$ is a union of conjunctive queries with free variables $\mat X$, then
  for all settings $\mat x \in \V(\mat X)$.
  $\bbr{\PDGof{\D}}^{*}(\mat x) > 0$ iff $\mat x \in Q(\D)$.
\end{prop}
\subsection{Probababilistic Databases}
% a
% \begin{leftbar}
% 	P
% 	asd;fk slkdfj asdlkf a;lskdf al;kdf lsk;adj flkasdj flkasdj flksdj aflkdsj fal;dsfj awoei faodsifj ;alfj ;oeifj ;awoijf a;sldifh elkbv lkjvslakdjf aslkdjfskl jdfh sdlkajf halskdjfh sdkljfhklsajd fhksa;djfh s;aldj fl;ksdajf lksdj 
% \end{leftbar}

\section{Automata}


\part{Applications of PDGs}

\part{The Categorical View}

\part{Misc}
\section{Philosophy}
\section{Scratch}
	
\begin{inactive}
	\subsection{}
	The data of a PDG, alternately put, is the set of nodes + an $\alpha$ matrix for each pair of them, the set of cpts, a $\beta$ for each cpt, and 
	
	\begin{prop}
		% what I want to say: IDef entails the independencies of D, in that 
		% it causes the region of the information profile
		% associated with any independence of the DN, to be red. 
		For any sets of variables $\mat X, \mat Y, \mat Z$, for which $\mat  X \CI_{\mathcal D} \mat Y \mid \mat Z$, we have
		\[ \frac{\partial \IDef{\cal D}}{\partial \I(\mat X; \mat Y \mid \mat Z)}(\mu) < 0 \]
		where $\I(\mat X; \mat Y \mid \mat Z)(\mu)$ is the conditional information between $\mat X$ and $\mat Y$ given $\mat Z$, a non-negative quantity which is zero iff $\mat X \CI_{\mu} \mat Y \mid \mat Z$. 
	\end{prop}
\end{inactive}

\begin{annotating}[frametitle={Matroids}]
	\subsection{Matroids}
	Does the set of hyper-edges of a PDG form a matroid?
	In the case of joint distributions (hyper-edges have only heads and not tails), then clearly it
	is downward closed, as we can find the marginal on any subspace. 
	
	
	If the PDG is consistent
\end{annotating}



A probabilistic prgram $\tau_{\dg M} : \Delta\V(\dg M) \to \Delta \V(\dg M)$
\begin{algorithmic}
	\State $i = 3$
	\For{$t = 1, 2, 3, \ldots$}
	    \State Choose \texttt{qual} with probability $\nicefrac{\gamma}{1+\gamma}$ and \texttt{quant} otherwise (probability $\nf1{1+\gamma}$).
		
		\If{\texttt{quant}}
			\State {Let} $\hat \beta$ be the normalized vector of $\beta$s, such that $\sum_L\hat\beta_L = 1$.
			\State \textbf{Draw}  $L \sim \hat\beta$;
			\State {Let} $X:= \src L;\quad Y := \tgt L;\quad Z:= \N \setminus\{X,Y\}$;
			\State \textbf{Update} $\mu^{t+1} \gets \mu^t(X) \bp(Y \mid X) \mu^t(Z \mid X,Y)$
		\ElsIf{\texttt{qual}}
			\State \textbf{Update} $\mu^{t+1} \gets $
		\EndIf
		
	\EndFor
\end{algorithmic}

{
    % \small
    \bibliographystyle{alpha}
    \bibliography{allrefs,z,joe}        
}


	\part*{Appendix}
	\addcontentsline{toc}{part}{Appendix}
	\appendix
	\section{Background Material}	
    \subsection{Information Theory}

    \begin{defn}\label{def:entropy}
        The entropy of a random variable $X : \Omega \to \V(X)$ is with respect to a probability distribution $\mu : \Delta \Omega$ given by
        \[ \H_\mu(X) = \sum_{x \in \V(X)} \mu_X(x) \log \frac{1}{\mu_X(x)} ,\]
        where $\mu_X$ is the marginal of $\mu$ on $X$.
    \end{defn}

    \begin{fact}
        For all random variables $X,Y$ over the space of outcomes $\Omega$, if there is a function $f$ such that $Y(\omega) = f(X(\omega))$ for all $\omega$ with $\mu(\omega) > 0$, then $\H_\mu(X) \leq \H_\mu(Y)$.
    \end{fact}
    One consequence is that entropy is independent of the particular representation.
    \begin{prop}[invariance with respect to change of variables]
        If $X : \Omega \to \V(X)$ and $Y : \Omega \to \V(Y)$ are a pair of random variables over $\Omega$ and there exist functions $f : \V(X) \to \V(Y)$ and $g : \V(Y) \to \V(X)$ such that $f(X(\omega)) = Y(\omega)$ and $g(Y(\omega)) = X(\omega)$ for all $\omega \in \Omega$, then $\H_\mu(X) = \H_\mu(Y)$ for all $\mu$.
%       are a pair of functions that commute with the variables (that is, $f(X(\omega)) = Y(\omega)$ and $g(Y(\omega)) = X(\omega)$ for all $\omega \in \Omega$), then $\H_\mu(X) = \H_\mu(Y)$ for all $\mu$.
    \end{prop}

    The setting of the above
    \begin{center}
        \begin{tikzcd}[column sep=1em]
            &\Omega\ar[dl, "X"']\ar[dr, "Y"]\\
            \V(X) \ar[rr, "f"] && \V(Y)
        \end{tikzcd}
    \end{center}

    \subsection{Boolean Algebra}
%   $\mu$ is a measure over $\V(\N) = \prod_{N \in \N}\V(N)$ and if $\N$ and each $\V(N)$ is finite, then every subset of $\V(\N)$ is measurable.

    \begin{defn}[Boolean algebra, atom, natural order, and the free Boolean algebra generated by a set]
        A \emph{Boolean algebra} $B = (S, \land,\lor,\lnot,0,1)$ is a carrier set $S$, together with interpretations of the binary boolean operations $\land $ and $\lor$ as functions $S\times S \to S$, the unary operation $\lnot$ as a function $S \to S$, and distinguished elements $0, 1 \in S$, such that for all $a, b, c \in S$,
        \begin{enumerate}[itemsep=0pt, parsep=1pt,label={BA\arabic*.}]
            \item $\land, \lor$ are associative and commutative,
            \item $a \lor 0 = s$ and $a \land 1 = a$ for all $a \in S$,
            \item $a \lor(b \land c) = (a \lor b) \land (a \lor c)$ and $a \land(b \lor c) = (a \land b) \lor (a \land c)$,  and finally
            \item $a \lor \lnot a = 1$ and $a \land \lnot a = 0$.
        \end{enumerate}
        A Boolean algebra $B$ defines a partial order called the \emph{natural order} (which is a partial order) by declaring $a \leq b$ iff $a \lor b = b$, and declaring that $a < b$ iff $a \leq b$ and $a \neq b$.
        The \emph{atoms} of $B$, denoted $\At B$ are those non-zero elements of $a \in S$ such that there does not exist a nonzero element $x \in S, x \ne 0$ such that $x < a$. Equivalently the atoms of $B$ are those elements $a\in S$ which can only expressed as a disjunction $a = x \lor y$ if either $x = a$ or $y=a$.
        %       \[ \mathit{At}(B) := \{ \} \]
        If $G$ is a set, the \emph{free boolean algebra generated by $G$} is the unique smallest Boolean algebra containing $G$ that does not satisfy any additional equations, beyond {BA1-4}.
    \end{defn}
    \begin{example}
        If $G = \{a, b\}$, the free boolean algebra $BG$ generated by $G$ consists of the sixteen elements

        \medskip
        \begin{minipage}{0.3\textwidth}
            \begin{center}%{R}{3cm}
                %           \let\varnames{X,Y,Z}
                \begin{tikzpicture}
                    \begin{scope}[scale=0.4]
                        \begin{scope}[blend group=hard light, opacity=0.5]
                            \draw[fill=color1!50!white]   ( 0:1.2) circle (2);
                            \draw[fill=color3!50!white] (-180:1.2) circle (2);
                        \end{scope}

                        \draw(0:1.2) circle (2);
                        \draw(-180:1.2) circle (2);

                        \node[yshift=1cm] at (0:2) {$b$};
                        \node[yshift=1cm] at (-180:2) {$a$};
                        \node at (-5,0){$\scriptstyle  \lnot a \land \lnot b$};
                        \node at (0,0){$\scriptstyle a \land b$};
                        \node at (-180:2){$\scriptstyle a \land \lnot b$};
                        \node at (0:2){$\scriptstyle  \lnot a \land b$};
                    \end{scope}
                \end{tikzpicture}
                \refstepcounter{figure}\label{fig:ven2BA}
                %           \caption[a]{B}
            \end{center}
        \end{minipage}\begin{minipage}{0.65\textwidth}
            \begin{equation} \left\{\;
                \begin{aligned}
                    a \land b,\; a \land \lnot b,\; \lnot a \land b,\; \lnot a \land \lnot b,\; \\
                    %           \smash{\overbracket{ a \land b,\; a \land \lnot b,\; \lnot a \lansd b,\; \lnot a \land \lnot b,\;}^{\text{the atoms of $B$}}} \\
                    (a\land b) \lor(\lnot a \land \lnot b),\; (a\land \lnot b) \lor (\lnot a \land b),\; 0,\; 1,\;\\
                    a \lor b,\; a \lor \lnot b,\;  \lnot a \lor b,\; \lnot a \lor \lnot b,\; \\
                    a,\; \lnot a,\; b,\; \lnot b,\;
                \end{aligned}\;
                \right\} \label{eq:exba2} \end{equation}
        \end{minipage}
        \par\smallskip\noindent
        corresponding to the $2^{2^2} = 16$ distinct boolean expressions that can be constructed with the two primitve symbols $\{a, b\}$. The atoms of $BG$ are those elements that appear on the first line of \eqref{eq:exba2}, and correspond to the four ``atomic'' regions of the Venn diagram to their left.
    \end{example}

    \subsection{Hyper-Graphs and Information}
    We originally formalized the structure of PDGs with regular edges, which have a single source and target. However, $\IDef{}$ is most naturally understood in a setting where PDGs are modeled as hyper-graphs; we now provide an characterization in these terms.%
        \footnote{For a translation into the original formulation consult \cref{apx:hyper-vs-graph}.}
    \begin{defn}[hyper graph] \label{defn:hypergraph}
        A \emph{directed multi-hyper-graph}, (which we abbreviate \emph{hyper-graph}), is a set $\N$ of variables, and a set $\Ed = \{ \mat X \to \mat Y \}$ of hyper edges. Each edge $E \in \Ed$ has a subset of the variables $\src(E) \subseteq \N$ which we call the \emph{source} of $E$, and a second subset of variables $\tgt(E) \subseteq \N$ that we call the \emph{target} of $E$. We will often specify an edge $E$ along with its source $\mat X = \src(E)$ and target $\mat Y = \tgt(E)$ by writing $\ed E{\mat X}{\mat Y}$.
    \end{defn}
%   Although this is not always made explicit, any computation involving entropy depends on the values
%   \begin{defn}[variable hypergraph]
%       A \emph{variable hypergraph} is a tuple $(\N, \Ed, \V)$ where $(\N, \Ed)$ is a (directed multi-)hyper graph, whose vertices $\N$ correspond to variables with values $\V$. Concretely, $\V(N)$ is the set of possible values that a variable $N \in \N$ can take.
%   \end{defn}

    \begin{defn}[PDH IDef] \label{defn:idef}
        If $\Gr = (\N, \Ed)$ is a variable hypergraph, and $\mu {\Delta [ \prod_{N\in\N}\V(N)]}$ is a joint probability distribution over variables $\mathcal X \supseteq \N$, then the $\Gr$-information deficiency of $\mu$ is given by
        \begin{equation}
            \IDef{\Gr}(\mu) := \bigg[~\sum_{\ed E{\mat X}{\mat Y}} \H_\mu(\mat Y\mid \mat X)\bigg] - \H_\mu(\N).
% same but with src/tg instead of arrow notation
%           \IDef{\Gr}(\mu) := \bigg[~\sum_{\ed E{\mat X}{\mat Y}} \H_\mu(\mat{tgt} E\mid \mat{src} E)\bigg] - \H_\mu(\N).
            \label{eq:idef}
        \end{equation}
%       where $\H(\mat Y \mid \mat X)$ is the conditional entropy of $\mat Y$ given $\mat X$ with respect to $\mu$
%       (see \cref{apx:info} for more details)
%       , and $\H_\mu(\N)$, often written simply $\H(\mu)$, is the total entropy of $\mu$ across all variables.
    \end{defn}

    % Define the signed measure.

\end{document}
