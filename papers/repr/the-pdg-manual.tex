% !TeX TXS-program:bibliography = txs:///bibtex
\documentclass{article}

\input{the-pdg-manual.preamble.tex}
%\twocolumn
\title{The PDG Manual}
\author{Oliver Richardson  \texttt{oli@cs.cornell.edu}}

\begin{document}

	\maketitle
	\tableofcontents
	%\listoffigures
	%\listoftheorems
	\clearpage
	%some day...
	% \twocolumn 
	
	\section{PDGs}
	\def\pdgvars[#1]{(\N#1, \Ed#1, \V#1, \mat p#1, \alpha#1,\beta#1)}
	\begin{defn}[sPDG]\label{def:sPDG}
		A strict PDG is a tuple $\pdgvars[]$ where
		\begin{description}[nosep]
			\item[$\N$]~is a finite collection of nodes, which are identified with variables,
			\item[$\Ed$]~is a collection of directed edges (arrows), each with a source, target, and a (possibly empty) label.
			\item[$\V$]~associates each node $N \in \N$ with a set $\V(N)$,
			representing the values that the variable $N$ can take. 
			\item[$\mathbf p$] associates, for each edge $L = (X,Y, \ell) \in \Ed$ and $x \in \V(X)$ a distribution $\bp(x)$ on $Y$, whenever $\beta_L > 0$.
			\item[$\beta$]~associates to each edge $L$, a number in $[0,\infty]$, indicating certainty in the conditional distribution $\bp(Y \mid X)$ 
			\item[$\alpha$]~associates to each edge $L$, a number in $[0,1]$, indicating degree of belief that $L$ holds causally.
		\end{description}
		\vspace{-1.4em}
	\end{defn}

	If $\dg M$ is a PDG, we reserve the names $\pdgvars[^\dg M]$
	for its components, so that we may reference one (e.g.,
	$\Ed^\dg M$) without naming them all explicitly. We may further omit the superscript in contexts where only one PDG is present. 
	We write $\V(S)$ for the set of possible joint settings of a set $S$
	of variables; in particular, 
	we write $\V(\dg M)
	= \prod_{N \in \N^\dg M} \V^\dg M(N)$
	for all settings of the variables $(\N^\dg M, \V^\dg M)$.
	
	\subsection{Semantics}
	\subsubsection{Sets of Distributions}
	We start by interpreting a PDG as the set of distributions consistent with it.  We will later (\Cref{sec:db-universal-relation}) see that this is 
	\begin{defn}[set of distribution semantics] \label{def:set-semantics} 
		If $\dg M\!=\!\pdgvars[]$ is a PDG, let $\SD{\dg M}$ be the \emph{s}et of \emph{d}istributions over the variables in $\dg M$ whose conditional marginals are exactly those given by $\mat p$.
		That is, $\mu \in \SD{\dg M}$ iff, for all edges $L = (X,Y) \in \Ed$,  $x \in \V(X)$,  and $y \in \V(Y)$, we have that $\mu(Y = \cdot \mid X\!=\! x) = \bp(x)$.
		{
			\[ \SD[\Big]{\dg M} = \!\left\{\mu \!\in\! \Delta \V_\none (\dg M) \middle|\!
			\begin{array}{l}
				\mu(B\!\! =\!\!b \mid A\!\!=\!\!a) \geq \boldsymbol\mu_L(b \mid a) \\[0.1em]
				~\text{$\forall (A, B,\ell) \!\in\! \Ed$, $a \!\in\!\mathcal V_A$, $b \!\in\! \mathcal V_B$} \end{array}\!\!\! \right\}\]
		}
		$\dg M$ is \emph{consistent} if $\SD{\dg M}$ is inhabited (non-empty), and \emph{inconsistent} otherwise.
	\end{defn}

\subsubsection{Scoring Functions}
\begin{defn}[incompatibility and inconsistency]\label{def:inc}
	The \emph{incompatibility} of a PDG $\dg M = \pdgvars[]$ with
	a joint distribution $\mu$, denoted $\Inc_{\dg M}(\mu)$, is  
	\[
	\Inc_{\dg M }( \mu) := 
	\!\!\!\sum \alle \beta_L \E_{x \sim \mu_{_X}}
	\left[\kldiv[\Big]{ \mu(Y\!= \cdot\mid X \!=\! x) }{\bp(x) } \right] ,
	\]
	where $\kldiv{\mu}{\nu} = \sum_{w} \mu(w) \log\frac{\mu(w)}{\nu(w)}$ is the 
	relative entropy from $\nu$ to $\mu$.
%	
			The \emph{inconsistency} of $\dg M$, 
		denoted $\Inc(\dg M)$, is the
		minimum possible incompatibility of $\dg M$ with any
		distribution $\mu$,  
		\[ \Inc(\dg M) = \inf_{ \mu \in \Delta [W_{\cal V}]} \Inc_{\dg M}(\mu) . \]
\end{defn}
$\SD{\dg M}$ and $\Inc_{\dg M}$ distinguish only
between distributions based on their compatibility with
$\dg M$, but even among distributions that match the
marginals, some more closely match the qualitative structure
of the graph than others.  

% \begin{annotating}[frametitle={Paths}]
Qualitatively, an think of an edge $\ed LXY$ of a PDG $\dg M$ as a claim that the value of $Y$ can be (noisily) computed from
$X$ alone.  
Therefore, to best match the qualitative structure of $G$, statistical asymmetries and dependencies between variables should
be efficiently described by giving the conditional probabilities corresponding to the edges of $G$. After all, to the extent that we believe the world has a causal structure of $G$, then these conditional probabilities describe every possible interaction between variables. 

To formalize this, we require only the underlying multigraph $G^{\dg M} :=
(\N^{\dg M}, \Ed^{\dg M})$ of $\dg M$. 
Given $G$ and $\mu$, contrast the amount of
information required to 
\begin{enumerate}[label=(\alph*)]
	\item directly describe a joint outcome  $\mat w ~ \sim \mu$
	drawn from $\mu$, and 
	\item separately specify, for each edge $\ed LXY$, the value
	$\mat w_Y$ (the projection of $\mat w$ onto the variable
	$Y$) given the value $\mat w_X$, in expectation. 
\end{enumerate}
% (a)  and (b)
When these two quantities are equal, the total length (in expectation) of specifying the outcome on each link, is precisely the same length as an optimal description of the joint outcome. That is, $\mu|_G$ carries enough information to precisely resolve all of the randomness of $\mu$. If (b) $>$ (a), then a specification of an outcome along each $L \in \Ed$ is redundant; all of the randomness in the system could have been resolved with this amount of information; we conclude that there are extra correlations in $\mu$ that are not suggested by $G$. The more (b) exceeds (a), the larger the degree of redundancy, and thus the less favorable an agent who believes $G$ to qualitatively correct, will judge $\mu$ to be. Because $\mu$ falls short of the expected level of randomness from this structure given these conditional distributions, we say that $\mu$ has a $G$-entropy deficit.

On the other hand, if (a) $>$ (b), then a sample of $\mu$ requires additional information to specify, beyond what could be used to encode outcomes of the marginals selected by $G$. This happens, when the structure in $G$ does not fully constrain the distribution, and often happens when there are fewer links than nodes, or cycles present. Whereas before $\mu$ had a defecit of entropy with respect to $G$, it now has a $G$-information \emph{surplus}, as now $\mu$ has more randomness than we could possibly resolve by specifying link outcomes, which reflects a hedging, due to the qualitative lack of information in $G$. For a defense of this preference for higher randomness in the absence of information to the contrary, see \cite{maxent}\cite{adversarial_protection}. The more (a) exceeds (b), the more evenly $\mu$ allocates mass in contexts that $G$ says nothing about, and so the better the qualitative fit of $\mu$ to $G$.
%oli17: IDef has two effects:
% (Here "wherever" means for every region of the info diagram, i.e., subset
% of variables that excludes some other subset.)
% (1) to give a max-entropy result wherever G does not specify something
% (think: no edges, or a cycle that allows multiple solutions), and 
% (2) to give a min-entropy result whenever it is over-specified. For regions
% with exactly 2 overlapping variables, this amounts to a statement of
% independence.
\begin{defn}[$G$-information deficit]\label{def:info-deficiency}
	For a multi-graph $G = (\N, \Ed)$ over a set $\N$ of variables,
	define the \emph{$G$-information deficiency}
	of distribution $\mu$, denoted $\IDef{G}(\mu)$,
	by considering the difference between (a) and (b), 
	where we measure the amount of information needed for a description
	using (conditional) entropy: 
	\begin{equation}
		\IDef{G}(\mu) := \sum_{(X,Y) \in \Ed} \H_\mu(Y\mid X) - \H(\mu). 
		\label{eqn:idef}
	\end{equation}
	%\footnote{Recall that $H_\mu(Y\mid X)$, the
	Recall that $H_\mu(Y\mid X) = - \sum_{x,y \in \V(\{X,Y\})} \mu(x,y) \log \mu(y\mid x)$ is the
	\emph{conditional entropy of $Y$ given $X$} with respect to $\mu$.
	For a PDG ${\dg M}$, is we take $\IDef{\dg M} = \IDef{(\N^{\dg M}, \Ed^{\dg M})}$, the information defecit with respect to its underlying hyper-graph.
\end{defn}

The $G$-information deficit is the total uncertainty \emph{actually} result from each table, in the context of distribution $\mu$, minus the total entropy of the distribution. We can think of its negation as the uncertainty in $\mu$, which has not already been specified by the cpds in $\dg M$. 	

$\IDef{.}$ can be thought of as a qualitatively customize-able maximum-entropy \cite{Jaynes57} approach, in which one tries to maximize or minimize the variation with in a subset of the variables, depending on how qualitatively constrained this subset is, given the values outside of it, a notion which naturally leads to the information profile \Cref{info-profile}. We illustrate $\IDef{\dg M}$ with some simple examples.  


\begin{example}[some example descriptions]
Suppose that $\dg M$ has two nodes, $X$ and $Y$. If $\dg M$ has no edges, the $\IDef{\dg M}(\mu) = - H(\mu)$.
There is no information required to specify, for each edge in ${\dg M}$ from $X$ to $Y$, the value ${\mat w}_Y$ given ${\mat w}_X$, since there are no edges. Since we view smaller numbers as representing a better fit, $\IDef{\dg M}$ in this case will prefer the distribution that maximizes entropy.

If $\dg M$ has one edge from $X$ to $Y$, then since $H(\mu) = H_{\mu}(Y \mid X) + H_\mu(X)$ by the chain rule, $\IDef{\dg M}(\mu) = -H_{\mu}(X)$. Intuitively, while knowing the conditional probability $\mu(Y \mid X)$ is helpful, to completely specify $\mu$ we also need $\mu(X)$. Thus, in this case, $\IDef{\dg M}$ prefers distributions that maximize the entropy of the marginal on $X$. If $\dg M$ has sufficiently many parallel edges
%an edge $1 \to X$, and also
from $X$ to $Y$ and $H_{\mu}(Y \mid X) > 0$ (so that $Y$ is not totally determined by $X$) then we have $\IDef{\dg M}(\mu) > 0$, because the redundant edges add no information, but there is still a cost to specifying them. In this case, $\IDef{\dg M}$ prefers distributions that make $Y$ a deterministic function of $X$ will maximizing the entropy of the marginal on $X$. Finally, if ${\dg M}$ has an edge from $X$ to $Y$ and another from $Y$
to $X$, then a distribution $\mu$ minimizes $\IDef{\dg M}$ when 
$X$ and $Y$ are correlated (so that $H_\mu(Y \mid X) = H_\mu(X \mid Y) = 0$) while
maximizing $H(\mu)$, for example, by taking $\mu(0,0) = \mu(1,1) = 1/2$.
\end{example}
\begin{example}[visualizing the information profile]
\definecolor{subfiglabelcolor}{RGB}{0,0,0}
\begin{figure}
	\centering
\def\vsize{0.4}
\def\spacerlength{0.5em}
k\\
\scalebox{0.85}{
%apparently  I have to manually step the figure number to make subfigures number properly.
\stepcounter{figure}
\makebox[\textwidth][c]{
	\refstepcounter{subfigure}
	\begin{tikzpicture}[center base]\label{subfig:justX-0}
		\node[dpad0] (X) at (0,1){$X$};
		\draw[fill=green!50!black]  (0,0) circle (\vsize)  ++(-90:.22) node[label=below:\tiny$X$]{};
%		\useasboundingbox (current bounding box);
		\node at (-0.5, 0.6){\slshape\color{subfiglabelcolor}\thesubfigure};
	\end{tikzpicture}\!
% \hspace{\spacerlength}
% \adjustbox{valign=b}{
% \renewcommand{\arraystretch}{1.2}
\begin{tabular}{c}	
	\refstepcounter{subfigure}\label{subfig:justX-1}
	\begin{tikzpicture}[is bn]
		\node[dpad0] (1) at (-0.4,.85){$\var 1$};
		\node[dpad0] (X) at (0.4,.85){$X$};
		\draw[arr1] (1)  -- (X);
		\draw[fill=white!70!black]  (0,0) circle (\vsize) ++(-90:.22) node[label=below:\tiny$X$]{};
		\node at (-0.6,0.35){};
%		\useasboundingbox (current bounding box);
		\node at (-0.7, 0.35){\slshape\color{subfiglabelcolor}\thesubfigure};
	\end{tikzpicture} \\[0.5em]
	\refstepcounter{subfigure}\label{subfig:justX-2}
	\begin{tikzpicture}
		\node[dpad0] (1) at  (-0.45,.85){$\var 1$};
		\node[dpad0] (X) at  (0.45,.85){$X$};
		\draw[arr1] (1) to[bend left=20] (X);
		\draw[arr1] (1) to[bend right=20] (X);
		\draw[fill=red!50!black] (0,0) circle (\vsize) ++(-90:.22) node[label=below:\tiny$X$]{};
%		\useasboundingbox (current bounding box);
		\node at (-0.7, 0.35){\slshape\color{subfiglabelcolor}\thesubfigure};
	\end{tikzpicture}
\end{tabular}%}
\hspace{\spacerlength}\vrule\hspace{\spacerlength}
	%% EXAMPLE: X  Y
	% \adjustbox{valign=b}{
	\begin{tabular}{c}
	\refstepcounter{subfigure}\label{subfig:justXY}
	\begin{tikzpicture}[]  
		% \node[dpad0] (1) at (0,2){$\var 1$};
		\node[dpad0] (X) at (-0.45,.85){$X$};
		\node[dpad0] (Y) at (0.45,.85){$Y$};
		% \draw[arr] (1) to[] (X);
		% \draw[arr] (1) to[] (Y);
		\path[fill=green!50!black] (-0.2,0) circle (\vsize) ++(-110:.23) node[label=below:\tiny$X$]{};
		\path[fill=green!50!black] (0.2,0) circle (\vsize) ++(-70:.23) node[label=below:\tiny$Y$]{};
		\begin{scope}
			\clip (-0.2,0) circle (\vsize);
			\clip (0.2,0) circle (\vsize);
			\fill[green!50!black] (-1,-1) rectangle (3,3);
			% \draw[ultra thick,white] (-0.2,0) circle (\vsize);
			% \draw[ultra thick,white] (0.2,0) circle (\vsize);
		\end{scope}
		\draw (-0.2,0) circle (\vsize);
		\draw (0.2,0) circle (\vsize);
%		\useasboundingbox (current bounding box);
		\node at (-0.8, 0.4){\slshape\color{subfiglabelcolor}\thesubfigure};
	\end{tikzpicture}\\[0.5em]
	%% EXAMPLE: X -> Y
	\refstepcounter{subfigure}\label{subfig:XtoY}
	\begin{tikzpicture}[]
		% \node[dpad0] (1) at (0,2){$\var 1$};
		\node[dpad0] (X) at (-0.45,0.85){$X$};
		\node[dpad0] (Y) at (0.45,0.85){$Y$};
		\draw[arr1] (X) to[] (Y);
		% \draw[arr] (1) to[] (Y);
		\path[fill=green!50!black] (-0.2,0) circle (\vsize) ++(-110:.23) node[label=below:\tiny$X$]{};
		\path[fill=white!70!black] (0.2,0) circle (\vsize) ++(-70:.23) node[label=below:\tiny$Y$]{};
		\begin{scope}
			\clip (-0.2,0) circle (\vsize);
			\clip (0.2,0) circle (\vsize);
			\fill[green!50!black] (-1,-1) rectangle (3,3);
			% \draw[ultra thick,white] (-0.2,0) circle (\vsize);
			% \draw[ultra thick,white] (0.2,0) circle (\vsize);
		\end{scope}
		\draw (-0.2,0) circle (\vsize);
		\draw (0.2,0) circle (\vsize);
%		\useasboundingbox (current bounding box);
		\node at (-0.8, 0.4){\slshape\color{subfiglabelcolor}\thesubfigure};
	\end{tikzpicture}
\end{tabular}%}
% \hspace{\spacerlength}
\begin{tabular}{c}
	%% EXAMPLE: X <-> Y
	\refstepcounter{subfigure}\label{subfig:XY-cycle}
	\begin{tikzpicture}[center base]
		% \node[dpad0] (1) at (0,2){$\var 1$};
		\node[dpad0] (X) at (-0.45,0.85){$X$};
		\node[dpad0] (Y) at (0.45,0.85){$Y$};
		\draw[arr1] (X) to[bend left] (Y);
		\draw[arr1] (Y) to[bend left] (X);
		\draw[fill=white!70!black] (-0.2,0) circle (\vsize) ++(-110:.25) node[label=below:\tiny$X$]{};
		\draw[fill=white!70!black] (0.2,0) circle (\vsize) ++(-70:.25) node[label=below:\tiny$Y$]{};
		\begin{scope}
			\clip (-0.2,0) circle (\vsize);
			\clip (0.2,0) circle (\vsize);
			\fill[green!50!black] (-1,-1) rectangle (3,3);
			% \draw[ultra thick,white] (-0.2,0) circle (\vsize);
			% \draw[ultra thick,white] (0.2,0) circle (\vsize);
		\end{scope}
		\draw (-0.2,0) circle (\vsize);
		\draw (0.2,0) circle (\vsize);
%		\useasboundingbox (current bounding box.south west) rectangle (current bounding box.north east);
		\node at (-0.85, 0.4){\slshape\color{subfiglabelcolor}\thesubfigure};
	\end{tikzpicture}\\[2.5em]
% \hspace{\spacerlength}%% EXAMPLE: 1 -> Y;1->X
\refstepcounter{subfigure}\label{subfig:XYindep}
	\begin{tikzpicture}[center base, is bn] 
		\node[dpad0] (1) at (0,0.75){$\var 1$};
		\node[dpad0] (X) at (-0.7,0.95){$X$};
		\node[dpad0] (Y) at (0.7,0.95){$Y$};
		\draw[arr0] (1) to[] (X);
		\draw[arr0] (1) to[] (Y);
		\draw[fill=white!70!black] (-0.2,0) circle (\vsize) ++(-110:.23) node[label=below:\tiny$X$]{};
		\draw[fill=white!70!black] (0.2,0) circle (\vsize) ++(-70:.23) node[label=below:\tiny$Y$]{};
		\begin{scope}
			\clip (-0.2,0) circle (\vsize);
			\clip (0.2,0) circle (\vsize);
			\fill[red!50!black] (-1,-1) rectangle (3,3);
			% \draw[ultra thick,white] (-0.2,0) circle (\vsize);
		% \draw[ultra thick,white] (0.2,0) circle (\vsize);					
		\end{scope}
		\draw (-0.2,0) circle (\vsize);
		\draw (0.2,0) circle (\vsize);
%		\useasboundingbox (current bounding box.south west) rectangle (current bounding box.north east);
		\node at (-0.88, 0.4){\slshape\color{subfiglabelcolor}\thesubfigure};
	\end{tikzpicture}
\end{tabular}
\hspace{\spacerlength}
	 %% EXAMPLE: 1 -> X -> Y
	 \refstepcounter{subfigure}\label{subfig:1XY}
	\begin{tikzpicture}[center base, is bn]
		\node[dpad0] (1) at (0.15,2){$\var 1$};
		\node[dpad0] (X) at (-0.45,1.4){$X$};
		\node[dpad0] (Y) at (0.35,1){$Y$};
		\draw[arr0] (1) to[] (X);
		\draw[arr1] (X) to[] (Y);
		\path[fill=white!70!black] (-0.2,0) circle (\vsize) ++(-110:.23) node[label=below:\tiny$X$]{};
		\path[fill=white!70!black] (0.2,0) circle (\vsize) ++(-70:.23) node[label=below:\tiny$Y$]{};
		\begin{scope}
			\clip (-0.2,0) circle (\vsize);
			\clip (0.2,0) circle (\vsize);
			% \fill[red!50!black] (-1,-1) rectangle (3,3);
			% \draw[ultra thick,white] (-0.2,0) circle (\vsize);
			% \draw[ultra thick,white] (0.2,0) circle (\vsize);					\end{scope}
		\end{scope}
		\draw (-0.2,0) circle (\vsize);
		\draw (0.2,0) circle (\vsize);
%		\useasboundingbox (current bounding box);
		\node at (-0.7, 0.6){\slshape\color{subfiglabelcolor}\thesubfigure};
	\end{tikzpicture}
\hspace{\spacerlength}\hspace{2.5pt}\vrule\hspace{2.5pt}\hspace{\spacerlength}
	%% EXAMPLE: 1 -> X -> Y -> Z
	 \refstepcounter{subfigure}\label{subfig:1XYZ}
	\begin{tikzpicture}[center base,is bn]
		\node[dpad0] (1) at (-0.5,2.3){$\var1$};
		\node[dpad0] (X) at (-0.5,1.5){$X$};
		\node[dpad0] (Y) at (0.35,1.25){$Y$};
		\node[dpad0] (Z) at (0.25,2.25){$Z$};subfiglabelcolor
		\draw[arr1] (1) to (X);
		\draw[arr1] (X) to[] (Y);
		\draw[arr2] (Y) to[] (Z);
		\path[fill=white!70!black] (210:0.22) circle (\vsize) ++(-130:.25) node[label=below:\tiny$X$]{};
		\path[fill=white!70!black] (-30:0.22) circle (\vsize) ++(-50:.25) node[label=below:\tiny$Y$]{};
		\path[fill=white!70!black] (90:0.22) circle (\vsize) ++(40:.29) node[label=above:\tiny$Z$]{};
		\begin{scope}
			\clip (90:0.22) circle (\vsize);
			\clip (210:0.22) circle (\vsize);
			\fill[red!50!black] (-1,-1) rectangle (3,3);
			% \draw[ultra thick,white] (210:0.2) circle (\vsize);		
			% \draw[ultra thick,white] (90:0.2) circle (\vsize);	
			\clip (-30:0.22) circle (\vsize);
			\fill[white!70!black] (-1,-1) rectangle (3,3);
			% \draw[ultra thick,white] (-30:0.2) circle (\vsize);
			% \draw[ultra thick,white] (210:0.2) circle (\vsize);		
			% \draw[ultra thick,white] (90:0.2) circle (\vsize);
		\end{scope}
		\begin{scope}
			\draw[] (-30:0.22) circle (\vsize);
			\draw[] (210:0.22) circle (\vsize);		
			\draw[] (90:0.22) circle (\vsize);
		\end{scope}
%		\useasboundingbox (current bounding box);
		\node at (-0.7, 0.7){\slshape\color{subfiglabelcolor}\thesubfigure};
	\end{tikzpicture}
	\hspace{3pt}
\hspace{\spacerlength}%\vrule\hspace{\spacerlength}
	%% EXAMPLE: X -> Y -> Z -> X
	\refstepcounter{subfigure}\label{subfig:XYZ-cycle}
	\begin{tikzpicture}[center base] 
		% \node[dpad0] (1) at (-0.5,2.3){$\var1$};
		\node[dpad0] (X) at (-0.5,1.75){$X$};
		\node[dpad0] (Y) at (0.35,1.25){$Y$};
		\node[dpad0] (Z) at (0.25,2.25){$Z$};
		% \draw[arr0] (1) to (X);
		\draw[arr1] (X) to[bend right=25] (Y);
		\draw[arr1] (Y) to[bend right=25] (Z);
		\draw[arr1] (Z) to[bend right=25] (X);
		%option: -- either X -> Y -> Z -> X, or <-> Y <-> Z <-> X. For the latter, uncomment the 6 lines below and comment out the next 3.
		% \draw[arr1] (Z) to[bend left=5] (Y);
		% \draw[arr1] (Y) to[bend left=5] (X);
		% \draw[arr1] (X) to[bend left=5] (Z);
		% \draw[fill=red!50!black] (210:0.22) circle (\vsize) ++(-130:.27) node[label=below:\tiny$X$]{};
		% \draw[fill=red!50!black] (-30:0.22) circle (\vsize) ++(-50:.27) node[label=below:\tiny$Y$]{};
		% \draw[fill=red!50!black] (90:0.22) circle (\vsize) ++(140:.31) node[label=above:\tiny$Z$]{};

		% grey filling for one covering.
		\draw[fill=white!70!black] (210:0.22) circle (\vsize) ++(-130:.27) node[label=below:\tiny$X$]{};
		\draw[fill=white!70!black] (-30:0.22) circle (\vsize) ++(-50:.27) node[label=below:\tiny$Y$]{};
		\draw[fill=white!70!black] (90:0.22) circle (\vsize) ++(40:.31) node[label=above:\tiny$Z$]{};

		\begin{scope}
			\clip (-30:0.22) circle (\vsize);
			\clip (210:0.22) circle (\vsize);
			% \fill[white!70!black] (-1,-1) rectangle (3,3);
			\clip (90:0.22) circle (\vsize);
			\fill[green!50!black] (-1,-1) rectangle (3,3);
		\end{scope}
		\begin{scope}
			\draw[] (-30:0.22) circle (\vsize);
			\draw[] (210:0.22) circle (\vsize);		
			\draw[] (90:0.22) circle (\vsize);
		\end{scope}
%		\useasboundingbox (current bounding box);
		\node at (-0.7, 0.7){\slshape\color{subfiglabelcolor}\thesubfigure};
	\end{tikzpicture}
\hspace{3pt}
\hspace{\spacerlength}%\vrule\hspace{\spacerlength}
	%% EXAMPLE: X -> Y <- Z
	\refstepcounter{subfigure}\label{subfig:XZtoY}
	\begin{tikzpicture}[center base] 
		% \node[dpad0] (1) at (-0.5,2.3){$\var1$};
		\node[dpad0] (X) at (-0.45,1.9){$X$};
		\node[dpad0] (Y) at (0.3,1.25){$Y$};
		\node[dpad0] (Z) at (0.4,2.15){$Z$};
		% \draw[arr0] (1) to (X);
		\draw[arr0] (X) to[] (Y);
		\draw[arr1] (Z) to[] (Y);
		\path[fill=green!50!black] (210:0.22) circle (\vsize) ++(-130:.25) node[label=below:\tiny$X$]{};
		\path[fill=red!50!black] (-30:0.22) circle (\vsize) ++(-50:.25) node[label=below:\tiny$Y$]{};
		\path[fill=green!50!black] (90:0.22) circle (\vsize) ++(40:.29) node[label=above:\tiny$Z$]{};
		\begin{scope}
			\clip (-30:0.22) circle (\vsize);
			\clip (90:0.22) circle (\vsize);
			\fill[white!70!black] (-1,-1) rectangle (3,3);
		\end{scope}
		\begin{scope}
			\clip (-30:0.22) circle (\vsize);
			\clip (210:0.22) circle (\vsize);
			\fill[white!70!black] (-1,-1) rectangle (3,3);

			\clip (90:0.22) circle (\vsize);
			\fill[green!50!black] (-1,-1) rectangle (3,3);
			% \draw[ultra thick,white] (210:0.2) circle (\vsize);		
			% \draw[ultra thick,white] (90:0.2) circle (\vsize);	
			% \draw[ultra thick,white] (-30:0.2) circle (\vsize);
			% \draw[ultra thick,white] (210:0.2) circle (\vsize);		
			% \draw[ultra thick,white] (90:0.2) circle (\vsize);
		\end{scope}
		\draw[] (-30:0.22) circle (\vsize);
		\draw[] (210:0.22) circle (\vsize);		
		\draw[] (90:0.22) circle (\vsize);
%		\useasboundingbox (current bounding box);
		\node at (-0.7, 0.7){\slshape\color{subfiglabelcolor}\thesubfigure};
	\end{tikzpicture}~
	\hspace{\spacerlength}%\vrule\hspace{\spacerlength}
		%% EXAMPLE: X <-> Y <-> Z
		\refstepcounter{subfigure}\label{subfig:XYZ-bichain}
		\begin{tikzpicture}[center base] 
			% \node[dpad0] (1) at (0.1,2.4){$\var1$};
			\node[dpad0] (X) at (-0.3,1.2){$X$};
			\node[dpad0] (Y) at (0.3,1.9){$Y$};
			\node[dpad0] (Z) at (-0.35,2.5){$Z$};
			% \draw[arr1] (1) to (X);
			% \draw[arr1] (1) to (Y);
			\draw[arr1] (X) to[bend right=15] (Y);
			\draw[arr1] (Y) to[bend right=15] (X);
			\draw[arr1] (Y) to[bend right=15] (Z);
			\draw[arr1] (Z) to[bend right=15] (Y);
			\path[fill=white!70!black] (210:0.22) circle (\vsize) ++(-130:.25) node[label=below:\tiny$X$]{};
			\path[fill=red!50!black] (-30:0.22) circle (\vsize) ++(-50:.25) node[label=below:\tiny$Y$]{};
			\path[fill=white!70!black] (90:0.22) circle (\vsize) ++(40:.29) node[label=above:\tiny$Z$]{};
			\begin{scope}
				\clip (-30:0.22) circle (\vsize);
				\clip (90:0.22) circle (\vsize);
				\fill[white!70!black] (-1,-1) rectangle (3,3);
			\end{scope}
			\begin{scope}
				\clip (90:0.22) circle (\vsize);
				\clip (210:0.22) circle (\vsize);
				\fill[red!50!black] (-1,-1) rectangle (3,3);
			\end{scope}
			\begin{scope}
				\clip (-30:0.22) circle (\vsize);
				\clip (210:0.22) circle (\vsize);
				\fill[white!70!black] (-1,-1) rectangle (3,3);

				\clip (90:0.22) circle (\vsize);
				\fill[green!50!black] (-1,-1) rectangle (3,3);
				% \draw[ultra thick,white] (210:0.2) circle (\vsize);		
				% \draw[ultra thick,white] (90:0.2) circle (\vsize);	
				% \draw[ultra thick,white] (-30:0.2) circle (\vsize);
				% \draw[ultra thick,white] (210:0.2) circle (\vsize);		
				% \draw[ultra thick,white] (90:0.2) circle (\vsize);
			\end{scope}
			\draw[] (-30:0.22) circle (\vsize);
			\draw[] (210:0.22) circle (\vsize);		
			\draw[] (90:0.22) circle (\vsize);
%			\useasboundingbox (current bounding box);
			\node at (-0.7, 0.7){\slshape\color{subfiglabelcolor}\thesubfigure};
		\end{tikzpicture}
		}
}
\addtocounter{figure}{-1} %undo the thing I did to make subfigs work
% \captionof{figure}{\label{fig:info-diagram}
\caption{
	\itshape Illustrations of example graph information
	  functions $\{ \IDef{G_i} \}$, drawn underneath their
	  associated multigraphs $\{ G_i\}$. Each circle represents a
	  variable; an area in the intersection of circles $\{C_j\}$
	  but outside of circles $\{D_k\}$ corresponds to information
	  that is shared between all $C_j$'s, but not in any
	  $D_k$. Variation of a candidate distribution $\mu$ in a
	  green area makes its qualitative fit better (according to
	  $\IDef{}$), while variation in a red area makes its
	  qualitative fit worse; grey is neutral. Only the boxed
	  structures in blue, whose graph information functions can be
	  seen as assertions of (conditional) independence, are
	  expressible as BNs.} 

\label{fig:info-diagram}
\end{figure}

The examples here are in reference to \Cref{fig:info-diagram}.
Subfigures \ref{subfig:justX-0}, \ref{subfig:justX-1}, and \ref{subfig:justX-2} show that adding edges makes distriutions more deterministic. 
As each edge $\ed LXY$ corresponds to an assertion about the ability to determine $Y$ from $X$, this should make some sense.
In particular, \ref{subfig:justX-2} can be justified by the fact that if you can determine X from two different random draws, the draws probably did not have much randomness in them. Thus we can qualitatively encode a double-headed arrow as two arrows, further justifying the notation.
	%oli11: note that it does not matter for the semantics, because failing to meet the constraint imposed by a double-headed arrow will give infinite cost anyway, for any edge, as \beta > 0.
%	
Without any edges (e.g., \ref{subfig:justX-0},\ref{subfig:justXY}), the $G$-information rewards distributions with the most uncertainty. Each additional edge adds a penalty for a crescent, as when we move from \ref{subfig:justXY} to \ref{subfig:XtoY} to \ref{subfig:XY-cycle}.
%
Some graphs (\Cref{subfig:justX-1,subfig:1XY}) are \emph{universal}, in that every distribution gets the same score (so that score must be zero, beause this is the score a degenerate distribution gets). Such a graph has a structure such that \emph{any} distribution can be precisely encoded by the process in (b). 
%	
The $G$-information can also indicate independencies and conditional independencies, illustrated respectively in \ref{subfig:XYindep} and \ref{subfig:1XYZ}.

So far all of the behaviors we have seen have been instances of entropy maximization / minimization, or independencies, but $G$-information captres more: for instance, if $G$ has cycles, as in \ref{subfig:XY-cycle} or \ref{subfig:XYZ-cycle}, the $G$-information prioritizes shared information between all variables. 

In more complicated examples, where both penalties and rewards exist, we argue that the $G$-information still implicitly captures the qualitative structure. In \ref{subfig:XYZ-bichain}, $X$ and $Y$ determine one another, and $Z$ and $Y$ determine one another. It is clear that $X$ and $Z$ should be indpenedent given $Y$; it can also be argued that $Y$ should not have any randomness of its own (otherwise the draws from $X$ or $Z$ would likey not match one another) and that this structure suggests co-variation of all three variables.
\end{example}
	
\begin{remark}
	We have also considered the variant, where we use $\E_{x \sim \mu_X} \H (\bp (x))$ in place of $\H_\mu(Y \mid X)$ to define the $G$-information deficit, as in 
	\begin{equation}
		\IDef{\dg M}^{\mat p}(\mu) := \sum\alle \H_\mu(Y\mid X) - \H_\mu
		\label{eqn:alt-extra}
	\end{equation}

	This has the benefit of having a linear first term and enjoying strong convexity for all values of $\gamma$. However, it is a more complex and less qualitatively separated. For distributions $\mu \in \Inc_{\dg M}$, these quantities are the same; therefore, the difference lies exclusively in the way it scores distributions that are already inconsistent with the edges.
	We can use this fact to give us a stronger maximum-entropy theorem for Bayesian Networks than has previously be given in \cite{williamson2000}.
\end{remark}
% \end{annotating}

	

$\Inc({\dg M}, \mu)$ and $\IDef{\dg M},\mu)$ give us two measures of compatibility between ${\dg M}$ and a distribution $\mu$. We take the score of interest to be their sum, with the trade-off
controlled by a parameter $\gamma \ge 0$:
\begin{equation}
	\bbr{\dg M}_\gamma(\mu).
	:= \Inc_{\dg M}(\mu) + \gamma \IDef{\dg M}(\mu)
	\label{eqn:full-score}
\end{equation}
%joe9*: I think the proposition and the following sentence are
%worth adding 

%joe10
%        The following just make precise that the scoring semantics
The following just makes precise that the scoring semantics
generalizes the first semantics.
% \begin{prop}[restate=prop:sd-is-zeroset]\label{prop:sd-is-zeroset}
\begthm{prop}{prop:sd-is-zeroset}
For all PDGs $\dg M$, we have that $\SD{\dg M} = \{ \mu : \bbr{\dg
	M}_0(\mu) = 0\}$. 
\end{prop}

%%BEGIN_FOLD
\subsubsection{PDGs As Unique Distributions}\label{sec:uniq-dist-semantics}
%		
		% shows that PDGS are 
Before we provide an interpretation of a PDG as a probability distribution, we stress that this distribution does \emph{not} capture all of the important information in the PDG---for example, a PDG can represent inconsistent knowledge states. Still, by giving a distribution, we enable comparisons with other graphical models. In the process, we will discover 
that PDGs are a surprisingly flexible tool for articulating distributions themselves. All we need to do is select the minimizers of our loss function.
We thus define 
		
\begin{defn}[Optimal Distributions]
	\begin{equation}
		\bbr{\dg M}_\gamma^* = \arg\min_{\mu \in
			\Delta\V(\dg M)} \bbr{\dg M}_\gamma(\mu).
	\end{equation}   
\end{defn}

In general, $\bbr{\dg M}_\gamma^*$ does not give a unique distribution.  But if $\gamma$ is sufficiently small, then it does:

\begthm{prop}{prop:sem3}%\begin{prop}
	If $\dg M$ is a PDG and $0 < \gamma \leq \min_L \beta_L^{\dg M}$, then $\bbr{\dg M}_\gamma^*$ is a singleton. 
\end{prop}
		
We are especially interested in the case where $\gamma$ is small; this amounts to emphasizing the accuracy of the probability distribution as a description of probabilistic information, rather than the independence structure of the PDG.  This is what was going on in all the examples in the introduction.  This motivates us to consider what happens as $\gamma$ goes to 0.  If $S_\gamma$ is a set of probability distributions for all $\gamma \in [0,1]$, we define $\lim_{\gamma \rightarrow 0} S_\gamma$ to consist of all distributions $\mu$ such that there is a sequence $(\gamma_i, \mu_i)_{i \in \mathbb N}$ with $\gamma_i \to 0$ and $\mu_i \to \mu$ such that $\mu_i \in S_{\gamma_i}$ for all $i$. It can be further shown that

\begthm{prop}{prop:limit-uniq}
	For all $\dg M$, $\lim_{\gamma\to0}\bbr{\dg M}_\gamma^*$ is a singleton. 
\end{prop} 

Let $\bbr{{\dg M}}^*$ be the unique element of $\smash{\lim\limits_{\gamma \rightarrow 0}} \bbr{{\dg M}}_\gamma^*$. 
The semantics has an important property: 

\begthm{prop}{prop:consist}
	$\bbr{\dg M}^* \in \bbr{\dg M}_0^*$, so if $\dg M$ is consistent,
	then $\bbr{\dg M}^* \in \SD{\dg  M}$.
\end{prop}
	
In contrast with the other two semantics, $\bbr{\dg M_1 \cup
\dg M_2}^*$ cannot be eaily calcualted from $\bbr{\dg M_1}_\gamma^*$ and
$\bbr{\dg M_2}_\gamma^*$. We will see that it is nonetheless effectively the semantics used by other graphical models.

\begin{defn}
	Let $\bbr{M}'(\mu) := \Inc{\dg M}(\mu) + \IDef{\dg M}^{\mat p}(\mu)$ be the altered version of the information definition.
\end{defn}
\begin{prop}\label{prop:u-convex}
$\bbr{\dg M}'_\gamma(\mu)$ is $\gamma$-strongly convex.% in $\mu$.
\end{prop}
\begin{proof}
	$\Inc_{\dg M}( \mu)$ is convex in $\mu$
	(\Cref{thm:inc-convex}), and $\gamma\sum\alle \E_{x\sim \mu_X}
	\H(\bp(x))$ is linear in $\mu$.  
	Negative entropy is $1$-strongly convex
	(\Cref{prop:neg-ent-convex}), so $- \gamma \H(\mu)$ is $\gamma$-strongly convex.
	The sum of a $\gamma$-strongly convex, linear, and
	convex functions must be $\gamma$-strongly convex. 
	%		, and strongly so when the coefficient on $-\H$ ($\gamma$) is positive. 
	%(see \cite{Rockafellar1970ConvexA})
\end{proof}

%END_FOLD

	\subsection{Lax PDGs}
	% \begin{defn}[PDG]\label{def:PDG}
	% 	A (lax) PDG is a tuple $\pdgvars[]$ where
	% 	\begin{description}[nosep]
	% 		\item[$\N$]~is a finite collection of nodes, which are identified with variables
	% 		\item[$\Ed$]~is a collection of directed edges (arrows), each with a source, target, and a (possibly empty) label.
	% 		\item[$\V$]~associates each node $N \in \N$ with a set $\V(N)$,
	% 		representing the values that the variable $N$ can take. 
	% 		\item[$\mathbf p$] associates, for each edge $L = (X,Y, \ell) \in \Ed$ and $x \in \V(X)$ a distribution $\bp(x)$ on $Y$, whenever $\beta_L > 0$.
	% 		\item[$\beta$]~associates to each edge $L$, a number in $[0,\infty]$, indicating certainty in the conditional distribution $\bp(Y \mid X)$ 
	% 		\item[$\alpha$]~associates to each edge $L$, a number in $[0,1]$, indicating degree of belief that $L$ holds causally.
	% 	\end{description}
	% 	\vspace{-1.4em}
	% \end{defn}
	


	\section{Understanding the Information Defecit}

	\subsection{Localizing Uncertainty}
%   \subsection{}
    \textbf{What are you Uncertain About?}
    An idealized probabilist is uncertain only about an outcome. You see, there is some set $\Omega$ of all possible outcomes, and uncertainty takes the form of a probability distribution $\mu : \Delta\Omega$. There may also be ``random variables'' present, but these are merely functions taking an element of $\Omega$ to some set of possible values (which we denote by $\V(X)$, for a variable $X$).
    Of course, $\mu$ may result in lots of variance for a variable $X$ and none for $Y$ while another distribution on $\Omega$ does the opposite,
    but at the end of the day, uncertainty is about $\Omega$, and it is merely filtered through the variables.

    While this is indeed the formal account of probability that we share, the characterization of $\Omega$ is prior to variables may be misleading; it is common to define $\Omega$ ``at the last minute'', as the set of all realizable joint settings of the relevant variables, which can only be done after the rest of the modeling.

    \begin{example}
        For instance, we can formalize the process of including a new variable $Y$ by taking a new set of outcomes $\Omega' := \Omega \times \V(Y)$, formally setting $Y : \Omega \times \V(Y) \to \V(Y)$ to be the projection of the second component, and modifying any other variable $X : \Omega \to \V(X)$ to a variable $X' : \Omega' \to \V(X)$ on the new set of outcomes by pre-composing it with a projection to the first component, as illustrated in the following commutative diagram.
        \begin{center}
            \begin{tikzcd}[column sep = 1em]
                \Omega \ar[rr, "X"] && \V(X) \\ & \Omega \times \V(Y)  \ar[ru, "X':= X \circ \pi_1"description, dashed] \ar[rr, "Y' := \pi_2"'] \ar[lu, "\pi_1"] &&  \V(Y)
            \end{tikzcd}
        \end{center}

        We must also extend $\mu$ to a new distribution $\mu'$ on the new set $\Omega'$ of outcomes, in such a way that the marginal on $\Omega$ is preserved -- that is, we set $\mu'(\omega, y) := \mu(\omega) p(y \mid \omega)$, where $p(y \mid \omega)$ is new information not contained in the original probability space.
    \end{example}

    If the set of outcomes $\Omega$ is built up from variables in this way, then the question of which variables are ``responsible'' for uncertainty remains relevant.
%    An answer of the form
%   \[ X \text{ is responsible for 5\% of the uncertainty};\quad Y \text{ is responsible for 10\% of the uncertainty}, \ldots \]
%   is unlikely to

    \subsubsection{Joint Variables and Variable Commonality }
    Let $\Omega$ is a set of outcomes. A set of random variables $\mat X = \{ X : \Omega \to \V(X)  \mid X \in \mat X \}$ is itself a random variable, taking values $\V(\mat X) = \prod_{X \in \mat X} \V(X) $ which are joint settings of its elements. As a function $\Omega \to \V(\mat X)$ it is explicitly characterized by $\mat X(\omega) := \{ X(\omega) \}_{X \in \mat X}$.
    This identification is intuitive, and is made almost everywhere, implicitly if not explicitly (e.g., via the notation $p(x,y)$). It also has the effect of identifying a variable $X$ with the singleton $\{X\}$, and from this perspective the joint variable $\mat X$ may be seen as a union of variables $\mat X = \bigcup_{X \in \mat X} \{ X \}$.
    This is a trivial restatement of the construction, but highlights a crucial fact: $\mat X$ represents \emph{join} of the information (informally speaking) of the individual variables--- a fact which is obscured when we simply think of joint settings as sets, which do not seem to have this polarity. (In general, of course, sets are just as easily intersected as unioned.) The view of $\mat X$ as a random variable representing the join of its elements serves its purpose well, which is why so many authors, including us, make this identification. When we wish to emphasize that joint settings of $X$ and $Y$ are the join of $X$ and $Y$, or to make the tie to propositional logic explicit, we write $X \lor Y$ for the joint random variable.


    The existence of a join (``$\lor$'') makes us wonder about a \emph{meet} (``$\land$''). Does the \emph{intersection} of sets of random variables capture a useful notion of shared information? Unfortunately not.
    To illustrate, let $A, B, C, D$ be independent random variables, and $A'$ be a fifth variable that happens to take the same value as $A$ at all worlds (but is conceptually different from $A$);%
        \footnote{Some might object by saying that formally speaking $A = A'$, but we can dismiss this concern by further distinguishing $A$ and $A'$; for instance, by letting them differ slightly on a single outcome $\omega$ which necessarily has probability zero.}
    suppose further that $\mat X = \{A,B,C\}$ and $\mat Y = \{A', B, D\}$. Now $\mat X \cap \mat Y = \{B\}$, which fails to capture the fact that there is also information about $A$ (or equivalently $A'$) that is shared between $\mat X$ and $\mat Y$. Indeed, $\{A\} \cap \{A'\} = \emptyset$ which is problematic, given that $A$ shares the entirety of its probabilistic behavior with $A'$.
    Contrast this behavior with that of the union.  The joint variable $\mat X \cup \mat Y$ does not have this problem: a joint setting $(a,b,c,a',d) \in \V(\mat X \cup \mat Y)$ clearly contains precisely the union of any information in $\mat X$ or $\mat Y$. Notice that there is a harmless redundancy: the tuple contains both $a$ and $a'$ even though we know them to be equal. This minor defect of $\cup$ as a join is in some sense a reflection of the fatal flaw of $\cap$ as a meet: in both cases, the issue is that only a very strict notion of variable identity, and none of the variable's behavior, is taken into account.

    For this reason, the sets-of-variables account is brittle in many ways, and leans assumptions that a modeler has divided the world into independent, atomic variables. But what do we do when such assumptions are false? What if concepts aren't always primitive or independent? Entropy offers a compelling answer --- one that does not depend on names or even the number of variables, and is invariant under changes of variables.

    \subsubsection{Information Quantities}

    \begin{defn}\label{def:entropy}
        The entropy of a random variable $X : \Omega \to \V(X)$ is with respect to a probability distribution $\mu : \Delta \Omega$ given by
        \[ \H_\mu(X) = \sum_{x \in \V(X)} \mu_X(x) \log \frac{1}{\mu_X(x)} ,\]
        where $\mu_X$ is the marginal of $\mu$ on $X$.
    \end{defn}

    \begin{fact}
        For all random variables $X,Y$ over the space of outcomes $\Omega$, if there is a function $f$ such that $Y(\omega) = f(X(\omega))$ for all $\omega$ with $\mu(\omega) > 0$, then $\H_\mu(X) \leq \H_\mu(Y)$.
    \end{fact}
    One consequence is that entropy is independent of the particular representation.
    \begin{prop}[invariance with respect to change of variables]
        If $X : \Omega \to \V(X)$ and $Y : \Omega \to \V(Y)$ are a pair of random variables over $\Omega$ and there exist functions $f : \V(X) \to \V(Y)$ and $g : \V(Y) \to \V(X)$ such that $f(X(\omega)) = Y(\omega)$ and $g(Y(\omega)) = X(\omega)$ for all $\omega \in \Omega$, then $\H_\mu(X) = \H_\mu(Y)$ for all $\mu$.
%       are a pair of functions that commute with the variables (that is, $f(X(\omega)) = Y(\omega)$ and $g(Y(\omega)) = X(\omega)$ for all $\omega \in \Omega$), then $\H_\mu(X) = \H_\mu(Y)$ for all $\mu$.
    \end{prop}

    The setting of the above
    \begin{center}
        \begin{tikzcd}[column sep=1em]
            &\Omega\ar[dl, "X"']\ar[dr, "Y"]\\
            \V(X) \ar[rr, "f"] && \V(Y)
        \end{tikzcd}
    \end{center}

    \subsubsection{Boolean Algebra}
%   $\mu$ is a measure over $\V(\N) = \prod_{N \in \N}\V(N)$ and if $\N$ and each $\V(N)$ is finite, then every subset of $\V(\N)$ is measurable.

    \begin{defn}[Boolean algebra, atom, natural order, and the free Boolean algebra generated by a set]
        A \emph{Boolean algebra} $B = (S, \land,\lor,\lnot,0,1)$ is a carrier set $S$, together with interpretations of the binary boolean operations $\land $ and $\lor$ as functions $S\times S \to S$, the unary operation $\lnot$ as a function $S \to S$, and distinguished elements $0, 1 \in S$, such that for all $a, b, c \in S$,
        \begin{enumerate}[itemsep=0pt, parsep=1pt,label={BA\arabic*.}]
            \item $\land, \lor$ are associative and commutative,
            \item $a \lor 0 = s$ and $a \land 1 = a$ for all $a \in S$,
            \item $a \lor(b \land c) = (a \lor b) \land (a \lor c)$ and $a \land(b \lor c) = (a \land b) \lor (a \land c)$,  and finally
            \item $a \lor \lnot a = 1$ and $a \land \lnot a = 0$.
        \end{enumerate}
        A Boolean algebra $B$ defines a partial order called the \emph{natural order} (which is a partial order) by declaring $a \leq b$ iff $a \lor b = b$, and declaring that $a < b$ iff $a \leq b$ and $a \neq b$.
        The \emph{atoms} of $B$, denoted $\At B$ are those non-zero elements of $a \in S$ such that there does not exist a nonzero element $x \in S, x \ne 0$ such that $x < a$. Equivalently the atoms of $B$ are those elements $a\in S$ which can only expressed as a disjunction $a = x \lor y$ if either $x = a$ or $y=a$.
        %       \[ \mathit{At}(B) := \{ \} \]
        If $G$ is a set, the \emph{free boolean algebra generated by $G$} is the unique smallest Boolean algebra containing $G$ that does not satisfy any additional equations, beyond {BA1-4}.
    \end{defn}
    \begin{example}
        If $G = \{a, b\}$, the free boolean algebra $BG$ generated by $G$ consists of the sixteen elements

        \medskip
        \begin{minipage}{0.3\textwidth}
            \begin{center}%{R}{3cm}
                %           \let\varnames{X,Y,Z}
                \begin{tikzpicture}
                    \begin{scope}[scale=0.4]
                        \begin{scope}[blend group=hard light, opacity=0.5]
                            \draw[fill=color1!50!white]   ( 0:1.2) circle (2);
                            \draw[fill=color3!50!white] (-180:1.2) circle (2);
                        \end{scope}

                        \draw(0:1.2) circle (2);
                        \draw(-180:1.2) circle (2);

                        \node[yshift=1cm] at (0:2) {$b$};
                        \node[yshift=1cm] at (-180:2) {$a$};
                        \node at (-5,0){$\scriptstyle  \lnot a \land \lnot b$};
                        \node at (0,0){$\scriptstyle a \land b$};
                        \node at (-180:2){$\scriptstyle a \land \lnot b$};
                        \node at (0:2){$\scriptstyle  \lnot a \land b$};
                    \end{scope}
                \end{tikzpicture}
                \refstepcounter{figure}\label{fig:ven2BA}
                %           \caption[a]{B}
            \end{center}
        \end{minipage}\begin{minipage}{0.65\textwidth}
            \begin{equation} \left\{\;
                \begin{aligned}
                    a \land b,\; a \land \lnot b,\; \lnot a \land b,\; \lnot a \land \lnot b,\; \\
                    %           \smash{\overbracket{ a \land b,\; a \land \lnot b,\; \lnot a \lansd b,\; \lnot a \land \lnot b,\;}^{\text{the atoms of $B$}}} \\
                    (a\land b) \lor(\lnot a \land \lnot b),\; (a\land \lnot b) \lor (\lnot a \land b),\; 0,\; 1,\;\\
                    a \lor b,\; a \lor \lnot b,\;  \lnot a \lor b,\; \lnot a \lor \lnot b,\; \\
                    a,\; \lnot a,\; b,\; \lnot b,\;
                \end{aligned}\;
                \right\} \label{eq:exba2} \end{equation}
        \end{minipage}
        \par\smallskip\noindent
        corresponding to the $2^{2^2} = 16$ distinct boolean expressions that can be constructed with the two primitve symbols $\{a, b\}$. The atoms of $BG$ are those elements that appear on the first line of \eqref{eq:exba2}, and correspond to the four ``atomic'' regions of the Venn diagram to their left.
    \end{example}

    \subsection{Hyper-Graphs and Information}
    We originally formalized the structure of PDGs with regular edges, which have a single source and target. However, $\IDef{}$ is most naturally understood in a setting where PDGs are modeled as hyper-graphs; we now provide an characterization in these terms.%
        \footnote{For a translation into the original formulation consult \cref{apx:hyper-vs-graph}.}
    \begin{defn}[hyper graph] \label{defn:hypergraph}
        A \emph{directed multi-hyper-graph}, (which we abbreviate \emph{hyper-graph}), is a set $\N$ of variables, and a set $\Ed = \{ \mat X \to \mat Y \}$ of hyper edges. Each edge $E \in \Ed$ has a subset of the variables $\src(E) \subseteq \N$ which we call the \emph{source} of $E$, and a second subset of variables $\tgt(E) \subseteq \N$ that we call the \emph{target} of $E$. We will often specify an edge $E$ along with its source $\mat X = \src(E)$ and target $\mat Y = \tgt(E)$ by writing $\ed E{\mat X}{\mat Y}$.
    \end{defn}
%   Although this is not always made explicit, any computation involving entropy depends on the values
%   \begin{defn}[variable hypergraph]
%       A \emph{variable hypergraph} is a tuple $(\N, \Ed, \V)$ where $(\N, \Ed)$ is a (directed multi-)hyper graph, whose vertices $\N$ correspond to variables with values $\V$. Concretely, $\V(N)$ is the set of possible values that a variable $N \in \N$ can take.
%   \end{defn}

    \begin{defn}[Information Deficiency] \label{defn:idef}
        If $\Gr = (\N, \Ed)$ is a variable hypergraph, and $\mu \oftype{\Delta [ \prod_{N\in\N}\V(N)]}$ is a joint probability distribution over variables $\mathcal X \supseteq \N$, then the $\Gr$-information deficiency of $\mu$ is given by
        \begin{equation}
            \IDef{\Gr}(\mu) := \bigg[~\sum_{\ed E{\mat X}{\mat Y}} \H_\mu(\mat Y\mid \mat X)\bigg] - \H_\mu(\N).
% same but with src/tg instead of arrow notation
%           \IDef{\Gr}(\mu) := \bigg[~\sum_{\ed E{\mat X}{\mat Y}} \H_\mu(\mat{tgt} E\mid \mat{src} E)\bigg] - \H_\mu(\N).
            \label{eq:idef}
        \end{equation}
%       where $\H(\mat Y \mid \mat X)$ is the conditional entropy of $\mat Y$ given $\mat X$ with respect to $\mu$
%       (see \cref{apx:info} for more details)
%       , and $\H_\mu(\N)$, often written simply $\H(\mu)$, is the total entropy of $\mu$ across all variables.
    \end{defn}

    % Define the signed measure.

    \subsection{The Information Profile: Information as a Signed Measure.}






    \subsubsection{Constructing the Information Profile of a Distribution}

%   Some authors simply define $\H(Y \mid X)$ to be a difference of joint entropies $\H(X,Y) - \H(X)$. Similarly, we can write the mutual information as an alternating sum of joint entropies.
%   \begin{align*}
%       \I(X \land Y) &:= \H(X,Y) - \H(Y \mid X) - \H(X \mid Y)  & \text{[the Venn diagram without the sides]}\\
%           &=  \H(X,Y) - \H(X,Y) + \H(X) - \H(X,Y) + \H(Y)  &\text{[expanding conditional entropy]}\\
%           &= - \H(X,Y) + \H(X) + \H(Y)
%   \end{align*}
    Most quantities in information theory can be written as a difference of entropies.
    For instance, some authors simply define $\H(Y \mid X)$ to be $\H(X,Y) - \H(X)$.
    We now write the formulas for information shared between 1, 2, and 3 variables in a more suggestive form.
    \begin{align*}
        \textit{Information in $X_1$:}  && \I(X_1 &) = \H(X_1) ;\\
        \textit{Mutual Information between $X_1, X_2$:} && \I(X_1 &\land X_2) = \H(X_1) + \H(X_2)  \\
             &&&\qquad - \H(X_1, X_2); \\
         \textit{Interaction Information of $X_1, X_2, X_3$:}&&\I(X_1 \land &X_2 \land X_3) = \H(X_1) + \H(X_2) + \H(X_3) \\
            &&&\qquad - \H(X_1, X_2) - \H(X_2, X_3) - \H(X_1, X_3) \\
            &&&\qquad  + \H(X_1, X_2, X_3)  .\\
    \end{align*}
    This suggests that we can extend to arbitrary elements of the Boolean algebra by use of an inclusion-exclusion formula. For terms involving 3 and higher conjuncts, it is common to take such a formula to be the definition.

    More formally, let $\N$ be a set of variables, $B[\N]$ be the free Boolean algebra generated by $\N$, and $\mu$ be a joint distribution over $\V(\N)$. As we extend entropy to these new elements, we will change the symbol $\H$ to $\I$, for compatibility with the standard notation, such as the mutual information. The information of a joint variable $\I_\mu(X \lor Y)$ which we have written so far as $\H_\mu(\{X,Y\})$ or simply $\H(X,Y)$, already tells us how to measure the entropy of joins of random variables. We simply convert meets to joins using the inclusion-exclusion rule, so that
    \begin{equation}\label{eq:inclexcl}
        \I_\mu\Big(\bigwedge_{X \in S} X\Big) =  \sum_{T \subseteq S} (-1)^{|T|+1} \I_\mu\Big( \bigvee_{X \in T} X \Big) ~,
    \end{equation}
    % (and the footsteps of \cite{JakulinBratko,BellCoInformation,})
    by analogy to the
    \href{https://en.wikipedia.org/wiki/Inclusion%E2%80%93exclusion_principle}
        {the inclusion-exclusion rule} for probability and counting measures \cite[eq 2.7]{halpern2017reasoning}.

    One might worry because an element $b \in B[\N]$ of the free Boolean algebra can be represented in more than one way.

    \begin{inactive}
        In the formal definition that follows, we will first convert every $b$ to its canonical CNF for definiteness, but  afterwards we will show that the normalization is unnecessary, and that \eqref{eq:inclexcl} holds independent of the representation.

        \begin{fact}
            For every set $S$ and $b \in B[S]$, there exists a unique finite matrix $S = (s_{i,j})$ where each $s_{i,j}$ is a literal equal either $s$ or $\lnot s$, such that
            $\displaystyle b = \bigwedge_{i} \bigvee_{j} s_{i,j} $
        \end{fact}
        \begin{defn}
            The information $\I_\mu$ with respect to a distribution $\mu$ and a set $\N$ of variables, of an element $b \in B[\N]$,
            \[          \I_\mu\Big(\bigwedge_{X_x \in S} X_s\Big) =  \sum_{T \subseteq S} (-1)^{|T|+1} \H\Big( T \Big) ~. \]
            %       \begin{itemize}[itemsep=0pt, parsep=1pt]
            %           \item If $\varphi = \bigvee_i X_i$, we define $\I^\N_\mu(\varphi) := \H_\mu(X_1, \ldots, X_n)$.
            %           \item For $\varphi = \bigwedge_i X_i$, we define $\I^\N_\mu(\varphi)
            %                := \sum_{T \subseteq S} (-1)^{|T|+1} \H\Big(\bigvee_{X \in X} T\Big)$.
            %       \end{itemize}
        \end{defn}
    \end{inactive}


\begin{defn}
    We define the \emph{information} $\I_\mu^\N$ with respect to a distribution $\mu$ and a set $\N$ of variables, of a formula $\varphi \in \lang{prop}$, we inductively define
%   \[          \I_\mu\Big(\bigwedge_{X_x \in S} X_s\Big) =  \sum_{T \subseteq S} (-1)^{|T|+1} \H\Big( T \Big) ~. \]
            \begin{itemize}[itemsep=0pt, parsep=1pt]
                \item For $\varphi = \phi \lor \psi$, we define $\I^\N_\mu(\varphi) := \H_\mu(X_1, \ldots, X_n)$.
                \item For $\varphi = \bigwedge_i X_i$, we define $\I^\N_\mu(\varphi)
                     := \sum_{T \subseteq S} (-1)^{|T|+1} \H\Big(\bigvee_{X \in X} T\Big)$.
            \end{itemize}
\end{defn}

    \begin{defn}
        The information $\I_\mu$ with respect to a distribution $\mu$ and a set $\N$ of variables, of an element $b \in B[\N]$,
    \[          \I_\mu\Big(\bigwedge_{X_x \in S} X_s\Big) =  \sum_{T \subseteq S} (-1)^{|T|+1} \H\Big( T \Big) ~. \]
%       \begin{itemize}[itemsep=0pt, parsep=1pt]
%           \item If $\varphi = \bigvee_i X_i$, we define $\I^\N_\mu(\varphi) := \H_\mu(X_1, \ldots, X_n)$.
%           \item For $\varphi = \bigwedge_i X_i$, we define $\I^\N_\mu(\varphi)
%                := \sum_{T \subseteq S} (-1)^{|T|+1} \H\Big(\bigvee_{X \in X} T\Big)$.
%       \end{itemize}
    \end{defn}

    \begin{prop}
        $\I_\mu^\N$ is well-defined.
    \end{prop}

    \begin{defn}
        The \emph{information profile} of $\mu$ with respect to $\N$, denoted $\mat I_\mu^\N$, is a ($2^{|\N|} -1$) dimensional vector
    \end{defn}

    \begin{example}
        content
    \end{example}



    \begin{prop}
        There is a factorization of $\Omega = X_1 \times X_2 \times \ldots \times X_n$
    \end{prop}

    This formula is given in \cite{}.

%   and the $\mu$-entropy, $\H_\mu$, can be seen as a measure over the variables $\N$, in which every $S \subseteq \N$ is measurable.




    \subsection{Information Quantities are Inner Products with $\mat I_\mu$}
    \subsection{Illustrations and Examples of $\IDef{}$}.

    %   \subsection{}
    %   Once again, let $\N$ be a set of variables, and $\mu$ be a joint distribution over $\N$.
    %   The general idea is that for variables $X, Y, Z \in \N$

    \begin{example}
        Let $\mu$ be a distribution over the three variables $\N = \{X,Y, Z\}$.
        %       \lipsum[1-4]
        \begin{center}%{R}{3cm}
            %           \let\varnames{X,Y,Z}
            \begin{tikzpicture}
                \begin{scope}[scale=0.5]
                    \begin{scope}[blend group=hard light, opacity=0.5]
                        \draw[fill=color1!50!white]   ( 0:1.2) circle (2);
                        \draw[fill=color2!50!white] (120:1.2) circle (2);
                        \draw[fill=color3!50!white] (-120:1.2) circle (2);
%                       \draw[fill=red!50!white]   ( 0:1.2) circle (2);
%                       \draw[fill=green!50!white] (120:1.2) circle (2);
%                       \draw[fill=blue!50!white] (-120:1.2) circle (2);
                    \end{scope}

                    \draw(0:1.2) circle (2);
                    \draw(120:1.2) circle (2);
                    \draw(-120:1.2) circle (2);

                    \node at (0:3.7) {X};
                    \node at (120:3.7) {Y};
                    \node at (-120:3.7) {Z};
                \end{scope}
            \end{tikzpicture}
        \end{center}
        %       \lipsum[1-6]
    \end{example}

    \subsection{Paying for structure: a symmetric extension of $\IDef{}$}

    % Show that it's a special case
    \subsubsection*{Distributions are a specific kind of PDG}
    Let $\N$ be a set of variables whose values are given by $\V$. When we use the characterization of PDGs based on directed hyper-graphs, a joint distribution $\mu \in \Delta[\V(\N)]$ is naturally identified with a particular unweighted PDG. Specifically, the data of $\mu$ is given by the PDG $(\N, \{ E_0 \}, \V, \mat p)$ containing a single hyper-edge $E_0$ whose source is empty and whose target is all of $\N$, associated with the cpd $\bp[E](\mat x) := \mu(\mat x)$.

    \begin{example}
        For a 3-variable
      \end{example}


	  
	\section{Generalized Semantics}
	Let $d$ be a distribution over $\Ed^{\dg M}$. 
	Choose a link $\ed LXY \in \Ed$, and let $\mathbf Z_L := \N^\dg M \setminus \{X, Y\}$ be the set of all other variables, so that a joint setting is characterized by a value $(x,y,\mat z)$.
	
	The link $L$ and its associated cpt $\bp$ can be extended to a transformer $\tau_L: \Delta \V(\dg M) \to \Delta \V(\dg M)$ on joint distributions in a couple of ways, such as:
\[
	\begin{aligned}
		\tau(\mu)(x,y,\mat z) :&= \mu(x,y,\mat z)\frac{\bp(y \mid x)}{\mu(y\mid x)} \\
		&= \mu(x)\; \bp(y \mid x)\; \mu(\mat z \mid x,y) 
	\end{aligned}\qquad\text{and}\qquad
	\begin{aligned}
		\tau(\mu)(x,y,\mat z) :&= \mu(x,y,\mat z) \frac{\bp(y \mid x)}{\mu(y\mid x, \mathbf z)} \\
		&= \mu(x,\mat z)\; \bp(y \mid x)
	\end{aligned}\\
\]
	I have yet to discover which of these things is correct. 
%	\begin{align*}
%		 \tau(\mu)(x,y,\mat z) &:= \mu(x,y,\mat z) \frac{\bp(y \mid x)}{\mu(y\mid x)} 
%			 &  \tau(\mu)(x,y,\mat z) &:= \mu(x,y,\mat z) \frac{\bp(y \mid x)}{\mu(y\mid x, \mathbf z)} \\
% 			&= \mu(x)\; \bp(y \mid x)\; \mu(\mat z \mid x,y) 
%			 &   &= \mu(x,\mat z)\; \bp(y \mid x)
%	\end{align*}
%	

	\section{Scratch}
	
	\begin{inactive}
		\subsection{}
		The data of a PDG, alternately put, is the set of nodes + an $\alpha$ matrix for each pair of them, the set of cpts, a $\beta$ for each cpt, and 
		
		\begin{prop}
			% what I want to say: IDef entails the independencies of D, in that 
			% it causes the region of the information profile
			% associated with any independence of the DN, to be red. 
			For any sets of variables $\mat X, \mat Y, \mat Z$, for which $\mat  X \CI_{\mathcal D} \mat Y \mid \mat Z$, we have
			\[ \frac{\partial \IDef{\cal D}}{\partial \I(\mat X; \mat Y \mid \mat Z)}(\mu) < 0 \]
			where $\I(\mat X; \mat Y \mid \mat Z)(\mu)$ is the conditional information between $\mat X$ and $\mat Y$ given $\mat Z$, a non-negative quantity which is zero iff $\mat X \CI_{\mu} \mat Y \mid \mat Z$. 
		\end{prop}
	\end{inactive}
		
	\begin{annotating}[frametitle={Paths}]
		\subsection{Traces of a PDG}
		The arrows of a PDG are cpds, which are probabilistic functions, and can be composed to form further probabilistic functions. 
		
		\begin{defn}
			A \emph{schedule} $\mathbf s : \Delta[\mathbb N \to \Ed^{\dg M}]$ for a PDG $\dg M$ is distribution over sequences of $\dg M$'s edges. 
		\end{defn}
		\begin{defn}
		   The \emph{trace distribution} of a PDG is the distribution or outputs represented by the program \texttt{trace}$_{\dg M}$
		   \begin{algorithmic}
			 \State $X \gets m$
			 % TODO

		\end{defn}
		\begin{defn}[trace semantics]
			For a PDG $\dg M$ and schedule $\mathbf s$ for $\dg M$, the trace semantics is a distribution
			over the $\sigma$-algebra  whose 
			\[ \mathbb{T}_{\bf s}{\dg M} = 
				% \Big\{ 
		 		% \Big\}
			 \]
		\end{defn}
	\end{annotating}
	
	\begin{annotating}[frametitle={Matroids}]
		\subsection{Matroids}
		Does the set of hyper-edges of a PDG form a matroid?
		In the case of joint distributions (hyper-edges have only heads and not tails), then clearly it
		is downward closed, as we can find the marginal on any subspace. 
		
		
		If the PDG is consistent
	\end{annotating}
	
	
	
	A probabilistic prgram $\tau_{\dg M} : \Delta\V(\dg M) \to \Delta \V(\dg M)$
	\begin{algorithmic}
		\State $i = 3$
		\For{$t = 1, 2, 3, \ldots$}
		    \State Choose \texttt{qual} with probability $\nicefrac{\gamma}{1+\gamma}$ and \texttt{quant} otherwise (probability $\nf1{1+\gamma}$).
			
			\If{\texttt{quant}}
				\State {Let} $\hat \beta$ be the normalized vector of $\beta$s, such that $\sum_L\hat\beta_L = 1$.
				\State \textbf{Draw}  $L \sim \hat\beta$;
				\State {Let} $X:= \src L;\quad Y := \tgt L;\quad Z:= \N \setminus\{X,Y\}$;
				\State \textbf{Update} $\mu^{t+1} \gets \mu^t(X) \bp(Y \mid X) \mu^t(Z \mid X,Y)$
			\ElsIf{\texttt{qual}}
				\State \textbf{Update} $\mu^{t+1} \gets $
			\EndIf
			
		\EndFor
	\end{algorithmic}
\end{document}
