
* Motivating Examples

** For Interpreting Arrows By Themselves, not guaranteeing independence
*** Framing Problems?
 These are a better motivating example for preferences?

*** Separate Sources of Information which merge
**** Newcomb Problem
**** Sun and Tanning Beds
**** Paradoxes
Illustrations of your own inconsistency are even a valuable resource that people actively seek in mathematics: paradoxes and intuition-bending pathological examples (which actually work, even on people who try very hard to be mathematically consistent!) are popular and help fix your view of the world.
** For adding new variables

*** Keeping around old model while knowing the specific case 
Rain and office example? Or find a more convincing one?

*** Discovering new correlations
*** For forgetting least important things


* Why EDGs are good

** Problem: sometimes you don't have a distribution. Sometimes overconstrained; other times under-constrained

Mention: under-constrained = "discriminitive model" in ML; 
single distribution = "generative model". 
Over-constrained is a run-time error.

** Other graphical models represent single distributions, arguably not the best form for an epistemic state. 

** We make it easy to add and remove nodes from the graph.

You can do this for a BN, but this is not normally done. We do everything by adding additional nodes to graphs and compressing / forgetting. 

Examples
 - Update beliefs with new data by adding new node w / observation link, then using dempster's rule to combine
 - Alternatively, no need to ever throw out anything. Just get new data.
 - Model new correlations you're aware of by adding new links or variables
 - Abstraction: merging, compressing, and splitting nodes
 - This allows for new concepts that an agent can spontaneously form
 - ... in addition to those imposed by a modeler

*** TODO (future: Connection to Single Static Assignment?)

** Can simulate BNs
Max Entropy Center of consistent distribution. 

* Definitions and Semantics
** Define an EDG:
A directed graph with some type information in the nodes (e.g., products, internal homs), which force certain constraints to be true

** Interpretation of EDGs
Interpretation = assignments of data to edges and nodes. Edge data: normally conditional (sub)probabilities;  

:aside:
This lines up with the definition of a functor, a denotational semantics for programming languages, categorical diagrams, and the interpretations of logics / algebras, which is why I want to do it this way, rather than closer to the BN approach
:END:
*** Example

***  Interpretation with sub-probability measures
**** Motivation: escaping, increasing expressive power by allowing disjunction, conditioning, making it possible to embed a logic
**** Additional effect: can now represent general factor graphs!!!
**** Mention relation to a particular (uninteresting) class of Dempster-Shafer Belief functions


*** Example Dinky Interpretation:
Give edges (+ / -), show this is equivalent to the formalism of Epistemic Graphis in Hunter, Polberg, Poltia's paper.

Note: Many fewer parameters than a full conditional table, and just like 1/0 neurons.

Note: same structure as protien / ligand interaction graphs in endocrinology

Note: can also simulate this by giving binary variables and restricting to symmetric matrices on edges.


*** Interpreting nodes as more than sets
(And then the arrows can be interpreted as ~structure preserving operations, but I promise not to say the word functor). 

**** Ordered Sets
For things like preferences, relative liklihood, 

**** Convex / mixture spaces
For things like utility domains, resource counters of other kinds, etc.

**** Weighted Points
For things like utilities, probabilities.
Note: these can be externalized in links the most obviously

**** Kernel-reproducing Hilbert Spaces
Places you want to use: need a stronger similarity metric for kernel learning

*** Externalization: most of these can be moved into their own nodes, with their own edges.  
Examples: utilities, probabilities are obvious. Ordered sets work like plausibility / preferences.
... but then you still need at least one ordered node, one node with an RKHS, etc.,?



*** Maybe for later: figure out what exactly needs to be true of the the target domain of interpretation for useful results to follow



** Partially Interpreted Models
With part of the model filled in you can determine it to be inconsistent.

** Consistency Semantics:
*** Binary version of consistency results in set of distributions
*** Continuous one is a weighted set of distributions
*** Taking the one with the highest consistency-entropy score interprets it as a single distribution. 
**** Conjecture: this results in normalizing a factor graph, and 


* Reducing Inconsistency
** Discussion of Inconsistency
 - Inconsistency is still bad but now we can model it.
 - It can happen simply by the world changing in subtle ways under your feet, so long as your model isn't 100% causal

Consistency between node data is the local algorithm; if links can communicate through data, this is a message passing  / belief propagation algorithm; Global consistency between all links is hard to compute. 

Different degrees of inconsistency:

   1. Exact Match, maximum entropy
   2. Exact match, non-trivial correlations are not captured (~incomplete)
   3. Have to change some things to match, but all correlations modeled (~unsound)
   4. Infinite distance to match, but all correlationsm modeled (~very unsound)
   5. Every link must be changed an infinite amount, totally incompatible with all. Also unmodeled correlations exist.
      
*** Examples for all of these are not too hard to produce, maybe not the best use of space.

** Consistency of node structure
(this is degenerate for nodes that are just sets)

*** Pairwise Consistency (local)
The original measure I presented: minimize distortion from chanels for all of the variables locally, but at once. 

**** TODO some analysis of this
I suspect there's a strong connection when internal node data is expressed as an edge to another node

** Consistency for Edges
Given a joint distribution, and a model, how well does the distribution fit the model?

**** Pairwise Consistency (local)
The original measure I presented: maximize information capacity of chanels locally. Can do this stochastically or get the full gradient at each time step.

**** Binary Consistency
 Is there a joint distribution consistent with constraints?

***** Note: hard constraint satisfaction problem with continuous probabilities illustrates that "soft" and "probabilistic" generalizations of CSPs are different.

**** Continuous Consistency
 Minimize some distance from metric. Relative entropy makes sure hard constraints don't move. 

***** Examples: show how the ones in the intro are resolved.

***** TODO investigate whether variational distance does anything.



* Simulating Other Things
** Other Descriptions of Uncertainty
*** Probability (obviously)
*** Belief Functions
**** TODO Can enforcment of belief function properties be done cleanly? Or am I just forcing everything I need to be true?

*** More generally, lower probability distributions
(but requres a huge number of nodes to keep the whole thing, or alternatively a single node that explicitly tracks them)

** Expected Utility
(more in other paper. This is an excellent illustration of why composition is important, but maybe better left to the other paper?)

** Simulation of BNs with max entropy
*** Conversion from BN to EDG in constant space
*** Theorem: Center of this EDG is the distribution encoded 

** Belief Updating
*** Regular Conditioning
*** Jeffrey's Rule by minimizing inconsistency
Reference and analyze more carefully Dietrich List Bradley paper
*** Pearl's Rule by adding nodes and then minimizing inconsistency

** Constraint Satisfaction Problems
Factor Graphs are generalizations of them, except they encode good heuristics as well. However, people think of them as representing distributions, which is only a small part of what they represent. 

*** Problem with Factor Graphs: Normalization done globally so you can't control things that happen.
**** Security / voting analogy: 
anyone can throw off and totally change your normalization to an arbitrary value if they go after you. The most recent factor can make anything happen to non-zero probabilities. 

**** Voting Example

*** Richer picture of inconsistency than factor graphs because I can actually see how far off each constraint is off and assign blame properly.

**** Example: anything with nesting constraints
such as any example that's compelling for a  Dempster-Shafer belief function that's not also a probability

* Learning Problems

** Learning your BN online from observations
Worse fit than learning directly, better fit than 

Related: Learning by fitting a BN, and then marginalizing

** Supervised Learning in this framework, with losses
*** Illustration that the addition of additional losses outside can be done exactly once,  
And for the log liklihood loss, adding it explicitly as a node (internalizing it) does not change the outside-level loss (I think. TODO: make sure this is true)

** View DNNs as instances of this model
At multiple abstractions:
 1. Each neuron is a node
 2. Each layer is a node
 3. Whole network can be put together

For non feed-forward architectures, things get interesting: non-dense connections encode lack of known dependence (though obviously there are dependences) 

Note: skip-layer connections result in merges! They are resolved with a sum or product + renormalization

*Conjecture*: this is the minimization of local inconsistency in some sense

But note: this is not even close to the semantics of a BN.

*** TODO ? Does recognizing this inconsistency rather than normalizing it away protect from going off of 
This could be tested empirically.

** Abstraction
*** Talk about information compression
reducing the complexity of the interpretation of a variable, dropping the variable completely, dropping links, etc. (to be within some resource bound?)

*** TODO Relate to Fixing a Broken Elbo paper
 Compression by looking at rate-distortion can be thought of as a bounded best approximation to a path of two elements, and the minimization of the appropriate relative entropies seems simililar to my metric of inconsistency.

* Properties

** Theorem: NP-hard to minimize consistency in general.

** Belief Propagation
*** can be done just like in a BN. 
*** The sum-product or max-product algorithms can be implemented without additional space if we enrich our sets to be weighted.
*** Conjecture: has a guaranteed convergence rate for sub-distributions.

** Information Theoretical View
Beliefs as noisy information chanels connecting concepts. Can now look at information capacity (informs whether you want to keep it), encoding / decoding problems, rate / distortion, etc.

** Thermodynamics Analogy

*** Minimizing Lexicographical Free Energy gives a distribution. 
**** In particular, this computes normalization constant and hence the distribution for factor graphs

*** Setting a positive temperature allows for a trade-off between inconsistency and entropy. 
This means you are now allowed to change your beliefs in order to maintain consistency and a smaller description size.

Note that if you're not allowed to pay in consistency, then the best fit distribution will marginalize out to whatever you have. In this case, the best fit could be different from your current beliefs. 

**** Conjecture: there are stable points to this process that are not globally maximum entropy




* Background (write at end)
** Bayesian Networks
*** Belief Propogation
** Markov Networks (MRFs)
*** Relation to Gibbs Random Fields, Hammersly Clifford Theorem
*** Normalization NP-hard
** Factor Graphs (alternative characterization of most MRFs)

