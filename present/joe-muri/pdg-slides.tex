%  Beamer Style
\documentclass[xcolor={dvipsnames,rgb}]{beamer}
% \includeonlyframes{current}
\setbeamertemplate{navigation symbols}{}
%\usetheme{Antibes}
\usecolortheme{whale}
\setbeamertemplate{footline}[frame number]
\newcommand{\commentout}[1]{}


\usepackage{lmodern}
\usepackage[utf8]{inputenc}
%\usetheme{Boadilla}% Beamer Theme Customization...
%	\setbeamersize{description width=0.57cm}
%	\usefonttheme[st1illsansserifsmall]{serif}
%		% \usefontthxxeme{structuresmallcapsserif}
%	\usefonttheme[onlylarge]{structuresmallcapsserif}
%		% \usefonttheme[onlymath]{serif}
%		% \usefonttheme[onlysmall]{structurebold}
%	\setbeamerfont{item}{series=\bfseries}
%	\setbeamerfont{block title}{series=\bfseries}
%	% \setbeamerfont{title}{family=\rmfamily}

	\relax%%% color definitions %%...
        %		\colorlet{structurecolor}{RoyalPurple!50!black}
        		\colorlet{structurecolor}{BlueViolet}
		\colorlet{alertcolor}{YellowOrange}
			% \colorlet{alertcolor}{structurecolor>wheel,1,3}
		\colorlet{benchcolor1}{Emerald!85!black}
			% \colorlet{benchcolor1}{structurecolor>wheel,2,3}
		\colorlet{benchcolor2}{YellowOrange!25!magenta}
	\usecolortheme[named=structurecolor]{structure}
		% \usecolortheme{beaver}
		% \setbeamercolor*{palette primary}{bg=color1, fg = green}
		% \setbeamercolor*{palette secondary}{bg=color2, fg = green}
		% \setbeamercolor*{palette tertiary}{bg=color3, fg = green}
		% \setbeamercolor*{palette quaternary}{bg=color4, fg = green}
		% \makeatletter
		% \definecolor{beamer@blendedblue}{rgb}{0.2,0.2,0.7}
		% \colorlet{beamer@blendedblue}{color2}
		% \makeatother
	\setbeamercolor{description item}{bg={structurecolor!20!white}}
	\setbeamercolor{alerted text}{fg=alertcolor}

	\newbool{precompiledfigs}% ...
		% \setbool{precompiledfigs}{true}
		\setbool{precompiledfigs}{false}
		% the etoolbox way, which works with beamer.
	% \setbeamercovered{dynamic}

\relax %%%%%%%%  Beamer and slide-specific macros  %%%%%%%%%%%%%%%%%%%
	\newcommand<>{\hl}[2][alertcolor]{\begingroup%
		\setbeamercolor{alerted text}{fg=#1}\alert#3{#2}\endgroup}
	\colorlet{notationcolor}{structurecolor!40}
	\def\notation#1{\!\hl[notationcolor]{#1$\quad$}}
	\def\notation#1{\!\hl[notationcolor]{#1$\quad$}}
	% \newcommand<>{\alertwith}[2]{\begingroup\only#3{\setbeamercolor{alerted text}{fg=#1}}#2\endgroup} % DOESN'T WORK THIS WAY
	\newenvironment{localfocusenv}{\only{\setbeamercolor{local structure}{fg=alertcolor}}}{}
	\newenvironment<>{hidemeenv}{%
		\only#1{\setbeamercolor{alerted text}{fg=black!60}}%
		\begingroup\begin{alertenv}#1%
		}{\end{alertenv}\endgroup}
	\newenvironment<>{tikzpicture||precompiled}[2][]{
			\ifbool{precompiledfigs}{\includegraphics[width=0.8\linewidth]{figure-pdfs/#2}
				}\begingroup\only#3\begingroup\begin{tikzpicture}[#1]
		}{\end{tikzpicture}\endgroup\endgroup}
	\newcommand<>{\extra}[2][]{%
		\only#3{%
			% \tikzmark{call point};%
			\tikzro \node[inner sep=0pt,outer sep=0pt] (call point) {};%
			\begin{tikzpicture}[overlay,remember picture]
				\node[anchor=north west, inner sep=0.8em,
				 			fill=alertcolor!30!structurecolor!30!white,
							draw=structurecolor!70!black, draw opacity=0.5,
							below=1em of call point, #1]{#2};
			\end{tikzpicture}%
		}}
	\newcommand{\tikzro}[1][]{\tikz[remember picture, overlay,#1]}
	\def\Set{\mathbf{Set}}
	\makeatletter
	\newcommand{\shorteq}{%
	  \settowidth{\@tempdima}{-}% Width of hyphen
	  \resizebox{\@tempdima}{\height}{=}%
	}
	\makeatother
	% \newcommand{\tikzmark}[1][last mark]{\tikzro \node (#1){};}

%%%%%%%            Relevant part of PDG Preamble        %%%%%%%%%%%%%%%%
\usepackage{tikz}
	\usetikzlibrary{positioning,calc, arrows, shapes}

	\tikzset{AmpRep/.style={ampersand replacement=\&}}
	\tikzset{center base/.style={baseline={([yshift=-.8ex]current bounding box.center)}}}
	\tikzset{paperfig/.style={center base,scale=0.9, every node/.style={transform shape}}}

	\tikzset{dpadded/.style={rounded corners=2, inner sep=0.6em, draw, outer sep=0.2em, fill={black!50}, fill opacity=0.08, text opacity=1}}
	\tikzset{light pad/.style={outer sep=0.2em, inner sep=0.5em, draw=gray!50}}
	\tikzset{arr/.style={draw, ->, thick, shorten <=3pt, shorten >=3pt}}
	\tikzset{arr0/.style={draw, ->, thick, shorten <=0pt, shorten >=0pt}}
	\tikzset{arr1/.style={draw, ->, thick, shorten <=1pt, shorten >=1pt}}
	\tikzset{arr2/.style={draw, ->, thick, shorten <=2pt, shorten >=2pt}}

	\newcommand{\drawbb}%
		{\draw (current bounding box.south west) rectangle (current bounding box.north east);}
	\ifbool{precompiledfigs}{}{
		\usetikzlibrary{fit, decorations,shapes.geometric}
		\usetikzlibrary{tikzmark}
		\usetikzlibrary{backgrounds}
		\pgfdeclarelayer{foreground}
		\pgfsetlayers{background,main,foreground}

		\pgfdeclaredecoration{arrows}{draw}{
			\state{draw}[width=\pgfdecoratedinputsegmentlength]{%
				\path [every arrow subpath/.try] \pgfextra{%
					\pgfpathmoveto{\pgfpointdecoratedinputsegmentfirst}%
					\pgfpathlineto{\pgfpointdecoratedinputsegmentlast}%
				};
		}}

		\tikzset{dpad0/.style={outer sep=0.05em, inner sep=0.3em, draw=gray!75, rounded corners=4, fill=black!08, fill opacity=1}}
		\tikzset{dpad/.style args={#1}{every matrix/.append style={nodes={dpadded, #1}}}}
		\tikzset{is bn/.style={background rectangle/.style={fill=blue!35,opacity=0.3, rounded corners=5},show background rectangle}}
		% \usetikzlibrary{backgrounds}
		% \usetikzlibrary{patterns}
		\usetikzlibrary{cd}

		\tikzset{fgnode/.style={dpadded,inner sep=0.2em, circle,minimum width=2.3em},
				 factor/.style={light pad, fill=black, outer sep=0pt,draw=none}}


		\newcommand\cmergearr[4]{
			\draw[arr,-] (#1) -- (#4) -- (#2);
			\draw[arr, shorten <=0] (#4) -- (#3);
			}
		\newcommand\mergearr[3]{
			\coordinate (center-#1#2#3) at (barycentric cs:#1=1,#2=1,#3=1.2);
			\cmergearr{#1}{#2}{#3}{center-#1#2#3}
			}
		\newcommand\cunmergearr[4]{
			\draw[arr,-, , shorten >=0] (#1) -- (#4);
			\draw[arr, shorten <=0] (#4) -- (#2);
			\draw[arr, shorten <=0] (#4) -- (#3);
			}
		\newcommand\unmergearr[3]{
			\coordinate (center-#1#2#3) at (barycentric cs:#1=1.2,#2=1,#3=1);
			\cunmergearr{#1}{#2}{#3}{center-#1#2#3}
			}


		\usetikzlibrary{matrix}
		\tikzset{toprule/.style={%
		        execute at end cell={%
		            \draw [line cap=rect,#1]
		            (\tikzmatrixname-\the\pgfmatrixcurrentrow-\the\pgfmatrixcurrentcolumn.north west) -- (\tikzmatrixname-\the\pgfmatrixcurrentrow-\the\pgfmatrixcurrentcolumn.north east);%
		        }
		    },
		    bottomrule/.style={%
		        execute at end cell={%
		            \draw [line cap=rect,#1] (\tikzmatrixname-\the\pgfmatrixcurrentrow-\the\pgfmatrixcurrentcolumn.south west) -- (\tikzmatrixname-\the\pgfmatrixcurrentrow-\the\pgfmatrixcurrentcolumn.south east);%
		        }
		    },
		    leftrule/.style={%
		        execute at end cell={%
		            \draw [line cap=rect,#1] (\tikzmatrixname-\the\pgfmatrixcurrentrow-\the\pgfmatrixcurrentcolumn.north west) -- (\tikzmatrixname-\the\pgfmatrixcurrentrow-\the\pgfmatrixcurrentcolumn.south west);%
		        }
		    },
		    rightrule/.style={%
		        execute at end cell={%
		            \draw [line cap=rect,#1] (\tikzmatrixname-\the\pgfmatrixcurrentrow-\the\pgfmatrixcurrentcolumn.north east) -- (\tikzmatrixname-\the\pgfmatrixcurrentrow-\the\pgfmatrixcurrentcolumn.south east);%
		        }
		    },
		    table with head/.style={
			    matrix of nodes,
			    row sep=-\pgflinewidth,
			    column sep=-\pgflinewidth,
			    nodes={rectangle,minimum width=2.5em, outer sep=0pt},
			    row 1/.style={toprule=thick, bottomrule},
	  	    }
			}
		\input{labelmatrix}
		\tikzset{onslide/.code args={<#1>#2}{%
		  \only<#1>{\pgfkeysalso{#2}} % \pgfkeysalso doesn't change the path
			}}
		}

\usepackage{booktabs,microtype}
\usepackage{mathtools, amsfonts, nicefrac, amssymb, bbm} % mathtools loads amsmath
\usepackage{amsthm,thmtools}

	% \theoremstyle{plain}
	% \let\theorem\relax
	% \newtheorem{theorem}{Theorem}%[section]
	% \newtheorem{coro}{Corollary}[theorem]
	\newtheorem{prop}[theorem]{Proposition}
	% \newtheorem{lemma}[theorem]{Lemma}
	% \newtheorem{fact}[theorem]{Fact}

	\theoremstyle{definition}
	\declaretheorem[name=Definition%,qed=$\square$,numberwithin=section
		]{defn}
	% \declaretheorem[name=Construction,qed=$\square$,sibling=defn]{constr}
	% \declaretheorem[qed=$\square$]{example}
	\theoremstyle{remark}
	\newtheorem*{remark}{Remark}
\relax % Macros (\relax is for folding)
	\let\Horig\H
	\let\H\relax
	\DeclareMathOperator{\H}{\mathrm{H}} %
	\DeclareMathOperator{\I}{\mathrm{I}} %
	\DeclareMathOperator*{\Ex}{\mathbb{E}} %
	\DeclareMathOperator*{\argmin}{arg\;min}
	\newcommand{\CI}{\mathrel{\perp\mspace{-10mu}\perp}} %
	\newcommand\mat[1]{\mathbf{#1}}
	\newcommand\Pa{\mathbf{Pa}}

	\DeclarePairedDelimiterX{\infdivx}[2]{(}{)}{#1\;\delimsize\|\;#2}
	\newcommand{\thickD}{I\mkern-8muD}
	\newcommand{\kldiv}{\thickD\infdivx}

	\newcommand{\tto}{\rightarrow\mathrel{\mspace{-15mu}}\rightarrow}

	\newcommand{\ssub}[1]{_{\!_{#1}\!}}
	\newcommand{\bp}[1][L]{\mat{p}\ssub{#1}}
        %	\newcommand{\V}{\mathcal V}
        	\newcommand{\V}{V}
        %	\newcommand{\N}{\mathcal N}
        	\newcommand{\N}{N}
                %	\newcommand{\Ed}{\mathcal E}
                	\newcommand{\Ed}{E}

	\DeclareMathAlphabet{\mathdcal}{U}{dutchcal}{m}{n}
	\DeclareMathAlphabet{\mathbdcal}{U}{dutchcal}{b}{n}

        %	\newcommand{\dg}[1]{\mathbdcal{#1}}
        	\newcommand{\dg}[1]{{#1}}
	\newcommand{\pdgunit}{\mathrlap{\mathit 1} \mspace{2.3mu}\mathit 1}

	\newcommand{\IDef}[1]{\mathit{IDef}_{\!#1}}
	\newcommand\Inc{\mathit{Inc}}
	\newcommand{\PDGof}[1]{{\dg M}_{#1}}
	\newcommand{\UPDGof}[1]{{\dg N}_{#1}}
	\newcommand{\WFGof}[1]{\Psi_{{#1}}}
	\newcommand{\FGof}[1]{\Phi_{{#1}}}
	\newcommand{\Gr}{\mathcal G}
	\newcommand\GFE{\mathit{G\mkern-4mu F\mkern-4.5mu E}}

	\newcommand{\ed}[3]{%
		\mathchoice%
		{#2\overset{\smash{\mskip-5mu\raisebox{-3pt}{${#1}$}}}{\xrightarrow{\hphantom{\scriptstyle {#1}}}} #3} %display style
		{#2\overset{\smash{\mskip-5mu\raisebox{-3pt}{$\scriptstyle {#1}$}}}{\xrightarrow{\hphantom{\scriptstyle {#1}}}} #3}% text style
		{#2\overset{\smash{\mskip-5mu\raisebox{-3pt}{$\scriptscriptstyle {#1}$}}}{\xrightarrow{\hphantom{\scriptscriptstyle {#1}}}} #3} %script style
		{#2\overset{\smash{\mskip-5mu\raisebox{-3pt}{$\scriptscriptstyle {#1}$}}}{\xrightarrow{\hphantom{\scriptscriptstyle {#1}}}} #3}} %scriptscriptstyle

	\DeclarePairedDelimiterX{\SD}[1]{\{}{\}}{\,\llap{\delimsize\{}#1\rlap{\delimsize\}}\,}
	%better version.
	\DeclarePairedDelimiterX{\bbr}[1]{[}{]}
		{\mspace{3mu}\mathllap{\delimsize[}#1\mathrlap{\delimsize]}\mspace{3mu}}
	\DeclarePairedDelimiterX{\aar}[1]{\langle}{\rangle}
		{\mspace{3mu}\mathllap{\delimsize\langle}#1\mathrlap{\delimsize\rangle}\mspace{3mu}}
	\DeclarePairedDelimiterXPP{\aard}[1]{}{\langle}{\rangle}{_{\!_\downarrow}}
		{\mspace{-3.5mu}\delimsize\langle#1\delimsize\rangle\mspace{-3.5mu}}
                \newcommand{\green}{\color{green}}
                \newcommand{\blue}{\color{blue}}
%Information to be included in the title page:
\title{Thrust 1: Probabilistic Dependency Graphs}
	\author[O.~Richardson, J.~Halpern]{Oliver~E.~Richardson \and Joseph~Y.~Halpern}
	\institute[Cornell]{Cornell University\\Department of Computer Science}
	\date{}

\begin{document}
\frame{\titlepage}


\begin{frame}\frametitle{Yet Another Probabilistic Graphical Model}
	We introduce \textit{probabilistic dependency graphs} (PDGs), a new class of graphical models
	for representing uncertainty.

	\pause
	\bigskip
	{\centering\Large Why do we need another one?\par}

	\bigskip
	\pause
	\begin{itemize}[<+-|alert@+>]
%joe1
        \item We are interested in how people resolve inconsistency
          \begin{itemize}
            \item How people resolve inconsistency may explain some
              cognitive biases
              \begin{itemize}
                \item e.g., \emph{confirmation bias} results from resolving
                  inconsistency by ignoring information
                  \end{itemize}
	  \item To reason about how people resolve inconsistency, we
            must first model it;
%joe1: added
            PDGs let us do so.
            %joe1
            \end{itemize}
            %	  \item In doing so, we get much more \ldots
          \item It turns out that they let us do much more
            \ldots
	\end{itemize}
\end{frame}




	\begin{frame} %%%%%%%%%%%        REVIEW OF BNS      %%%%%%%%%%%%%%%%
%joe1
          %	  \frametitle{Two aspects of Bayesian Networks (BNs)}
          	  \frametitle{Bayesian Networks (BNs): A Review}
%		\begin{description}
%			\item<+->[{\color{benchcolor2!70!black}Qualitative}
%BN,~~$\Gr$]~\\
Recall: A BN consists of a directed acyclic graph $G$, whose nodes
correspond to random variables, $+$ a \emph{cpd} (\emph{conditional
probability distribution}) for each node $X$, that gives the
probability of $X$ conditional on all possible values of its parents
in the graph.


\begin{itemize}
  \item the graph $G$ describes conditional independencies between the
    variables:
				\begin{itemize}\small
					\item {\color{gray} $X \CI_{G}
                                          Y \mid \Pa(X)$, for all
                                          non-descendents $Y$ of $X$}
				\end{itemize}\medskip
              				\end{itemize}\medskip

%		\vspace{2em}
		\begin{center}
			\begin{tikzpicture}[paperfig]
				\begin{scope}[every node/.style={dpadded, fill opacity=1,fill=black!08, circle, inner sep=2pt, minimum size=2em, draw=gray}]
					\node (PS) at (0,0) {$\mathit{PS}$};
					\node (SH) at (1.5, 0.6) {$\mathit{SH}$};
					\node (S) at (1.5, -0.6) {$\mathit{S}$};
					\node (C) at (3, 0) {$\mathit{C}$};
					\end{scope}
				\draw[->] (PS) to (S);
				\draw[->] (PS) to (SH);
				\draw[->] (SH) to (C);
				\draw[->] (S) to (C);
				\end{tikzpicture}
			\end{center}

A BN determines a unique probability distribution that satisfies all
the conditional independencies and has the appropriate marginal
distributions given by the cpds.
\end{frame}



%\section{Modeling Examples}
%	\subsection{Inconsistencies}
		\newlength{\bncolwidth}
		\begin{frame} %%%%%%%%%       GUN FLOOMP: BN vs PDG       %%%%%%%%%%
			%% 1 -- Just BN
			%% 2 -- add PDG.
			%% 3 -- List appears, arbitrary new info.
			%% 4 -- list highlighted, p appears both diagrams (dashed), green box.
			%% 5 -- inconsistent PDG?
			%% 6-8 -- variants of BN w / different info. Final point visible.
			\frametitle{Modeling Example: Flames and Guns}
			% \framesubtitle{The Legality of Flames and Guns}
			\only<1-3>{
				{\centering	Alice thinks it likely (.95) that guns are illegal,\\
				but that flames (local slang) are legal (.90).\par}
			}
			\pause
			\colorlet{heldout}{benchcolor1!80!black}

			% \only<2->{ % Headers "BN" and "PDG"
				\vspace{1.2em}
				\begin{columns}[c]
					\Large\color{structurecolor}
					\begin{column}{.45\textwidth}\centering% Add BN to diagram
						\only<4,5>{\color{structurecolor!20}}%
						\textbf{BN}\\[-1em]
						\rule{2.2cm}{0.95pt}\end{column}
					\only<3->{ % add PDG to diagram
						% \vrule
						\begin{column}{.5\textwidth}\centering%
							\only<6->{\color{structurecolor!20}}%
							\textbf{PDG}\\[-1em]
							\rule{2.7cm}{0.95pt}\end{column}
						}
					\end{columns}
				\vspace{0.0em}
				% }


			\begin{columns}[c] %% (both diagrams) ...
				\setlength{\bncolwidth}{0.45\textwidth}
				\only<6->{\setlength{\bncolwidth}{0.51\textwidth}}
				\begin{column}{\bncolwidth} % BN Diagram
					% \begin{block}{BN}
						\centering
						% \hspace{-2.5em}
						\begin{tikzpicture||precompiled}{fg-BN}[AmpRep, scale=0.9]
							\def\figtabledist{0.50}
							\def\fignodedist{0.8}
							\def\figtableheight{0.32}

							%% Time to unify the notation for cpds.
							% \matrix [table with head, column 1/.style={leftrule}, anchor=south east,
							% 	 column 2/.style={rightrule}, row 2/.style={bottomrule}] at (-\figtabledist,\figtableheight) {
							% 	\vphantom{$\overline fg$} $f$ \& \vphantom{$\overline fg$}$\overline f$\\
							% 	.9 \& .1\\
							% };
							% \matrix [table with head, column 1/.style={leftrule}, anchor=south west,
							% 	 column 2/.style={rightrule}, row 2/.style={bottomrule}] at (\figtabledist,\figtableheight) {
							% 	 \vphantom{$\overline fg$}$g$ \& \vphantom{$\overline fg$}$\overline g$\\
							% 	 .05 \& .95\\
							% };
							\node[% F's cpd ...
									anchor=south east]
							 	at (-\figtabledist,\figtableheight) {%
								\hspace{-1.2em}%
								\only<1-6,8>{\begin{idxmat} [\color{gray!60}\smalltext]
									{\!\!}{$f$,$\overline f$}
										.90 & .10 \\
									\end{idxmat}}%
								\only<7>{ \begin{idxmat}[\color{gray!60}\smalltext]
									{$g$,$\overline g$}{$f$,$\overline f$}
										.92 & .08 \\
										.08 & .92 \\
									\end{idxmat}\hspace{-1em}\;}%
								};
							\node[% G's cpd ...
									anchor=south west]
								at (\figtabledist,\figtableheight) {%
								\hspace{-1.2em}%
								\only<1-7>{\begin{idxmat}[\color{gray!60}\smalltext]
									{\!\!}{$g$,$\overline g$}
									.05 & .95 \\
									\end{idxmat}}%
								\only<8>{\begin{idxmat}[\color{gray!60}\smalltext]
									{$f$,$\overline f$}{$g$,$\overline g$}
										.92 & .08 \\
										.08 & .92 \\
									\end{idxmat}}%
								% \hspace{-0.5em}~%
								};
							\node[% F (floomp) ...
								dpadded, inner sep=0.5em, circle, fill=black!08, fill opacity=1]
								(floomp) at (-\fignodedist,0) {$F$};
							\node[% G (gun) ...
								dpadded, inner sep=0.5em, circle, fill=black!08, fill opacity=1]
								(gun) at (\fignodedist,0) {$G$};
							% \node (leftbounds) at (-3,0){};
							% \node (rightbounds) at (3,0){};

							\only<7,8>{ \draw[thick, ->, onslide=<8>{<-}, benchcolor2]
								(gun) -- node[below,align=center,font=\tiny]{must\\choose\\direction} (floomp); }

							\only<6->{\node[align=left,% show which cpds are incorporated...
									rounded corners=5, inner sep=0.5em,
									fill=structurecolor!50!benchcolor1!10,
									draw=structurecolor!50!benchcolor1!50] (incorporated)
							 		at (0,-1.5)
								{ \textit{Incorporated}:\\\Large
									\hspace{1em}
									\hl[benchcolor1]<6,8>{$\mu\ssub F$}
									\hspace{1em}
									\hl[benchcolor1]<6,7>{$\mu\ssub G$}
									\hspace{1em}
									\hl[benchcolor1]<8>{$p$}
									\hspace{1em}
									\hl[benchcolor1]<7>{$p'$}
								};\node[below=1em of incorporated]{};}

							\only<4-6>{		\node[text=alertcolor] at (0,+0.8){$p$??};		}
							\only<4,5>{ \fill[white,opacity=0.8] (-3, -0.8) rectangle (3,1.8); }
							\useasboundingbox (-2.7, -0.8) rectangle (2.7,1.8);
							\end{tikzpicture||precompiled}
					% \end{block}
					\vspace{-0.8em}
					\end{column}
				\only<3,4>{{\color{gray}\vrule}}
				\begin{onlyenv}<3->\begin{column}{0.95\textwidth-\bncolwidth}
					\only<6->{{~\hspace{-2em}~}}
					% \centering
					\begin{tikzpicture||precompiled}{fg-PDG}[]
						\def\fignodedist{1.5}
						\node[% for  "1"  /  "true"  ...
							dpadded, fill=gray!20, draw=gray!70, inner sep=0.35em, outer sep=0.37em]
							(true)  at (0,1.3) {$\pdgunit$};
						\node[dpadded] (floomp) at (-\fignodedist, 0) {$F$};
						\node[dpadded] (gun) at (\fignodedist, 0) {$G$};

						\begin{pgfonlayer}{foreground}
							\draw[arr1,{onslide=<6,8>{benchcolor1}}]
								(true.-165) -- %to[bend right=0]
									(floomp.60)
									node[pos=.5,{onslide=<6->{above left}}] (A)
										{\only<6->{$\mu\ssub F$}}
									;
							\draw[arr1,{onslide=<6,7>{benchcolor1}}]
								(true.-15) -- %to[bend left=0]
									(gun.120)
									node[pos=.5,{onslide=<6->{above right}}] (B)
									 	{\only<6->{$\mu\ssub G$}}
									;
							\end{pgfonlayer}

						\node[, % CPT for F...
							above left=1.5em and 2.5em of A.center, anchor=center] {%
							\color<5>{alertcolor}
							\alt<6->{}{
								\hspace{-0.8em}%
								\begin{idxmat}
									[\color{gray!60}\color<5>{alertcolor!50}\smalltext]
									%[\color{black}\smalltext]
									{$\star$}{$f$, $\overline f$}
									.90 & .10 \\
								\end{idxmat}
								\hspace{-1em}~}
							};
						\node[, % CPT for G...
							above right=1.5em and 2.3em of B.center, anchor=center] {
							\color<5>{alertcolor}
							\alt<6->{}{
								\hspace{-0.8em}
								\begin{idxmat}
									[\color{gray!60}\color<5>{alertcolor!50}\smalltext]
									%[\color{black}\smalltext]
									{$\star$}{$g$, $\overline g$}
									.05 & .95 \\
								\end{idxmat}
								\hspace{-1em}~}
							};
						\only<4->{ % Show p & arrows, after initial diagrams...
							\begin{pgfonlayer}{foreground}
								\draw[arr,
										onslide=<4>{heldout, dashed},
								 		{onslide=<8>{benchcolor1}},
										onslide=<5>{text=alertcolor} ]
								 	(floomp.-33) to[bend right=6] node[pos=0.65, fill=white, inner sep=2pt] (C) {$\smash{p}\vphantom{v}$} (gun.210);
								\draw[arr,
										onslide=<4>{heldout, dashed},
										{onslide=<7>{benchcolor1}},
										onslide=<5>{text=alertcolor} ]
								 	(gun.190) to[bend left=5] node[pos=0.668, fill=white, inner sep=2pt] {$\smash{p'}\vphantom{v}$} (floomp.-10);
								\end{pgfonlayer}
							}
						\only<6->{ \fill[white,opacity=0.8] (-2.6, -1) rectangle (2.7,2); }%
						\useasboundingbox (-2.7, -0.8) rectangle (2.7,2.0);
						\end{tikzpicture||precompiled}
					\vspace{-1em}
					\end{column}\end{onlyenv}
				\end{columns}
				\only<-5>{\vspace{1em}}
			\begin{itemize} %% bullet points
				\item<3-| alert@3> The cpds of a PDG are attached to edges, not nodes.
				\item<4-| alert@4> PDGs can incorporate arbitrary new probabilistic information.
				\only<4>{ % New Information! The green block with cpts
					\vspace{0.7em} \color{black}
					\begin{exampleblock}{}
						% You come to believe that Flames and Guns share legal status (92\%).
						{\small Alice
						learns that Flames and Guns have the same legal status (probability .92)}
						\vspace{-0.6em}
						$$ {\color{heldout}p(G \!\mid\! F)} =
							\begin{idxmat}[\color{gray!50}\smalltext]
									{$f$,$\overline f$}{$g$, $\overline g$}
								.92 & .08 \\ .08 & .92 \\
							\end{idxmat}
							~=~ {\left(\;{\color{heldout} p'(F \!\mid\! G)}\;\right)^{\textsf T}}$$
						\end{exampleblock}}
				\item<5-| alert@5> PDGs can be inconsistent\only<6>{,}
					\begin{itemize}
						\item<6- | alert@6->
                                                  \textellipsis but
         BNs must resolve the
         inconsistency first
         \begin{itemize}
         \item There's no obvious way to do this
           \end{itemize}

						\end{itemize}
				\end{itemize}
			\end{frame} %------------%

		\begin{frame} %%%%%%%%%        SMOKING: BN vs PDG         %%%%%%%%%%
			\frametitle{Bayesian Networks as PDGs}
			% \framesubtitle{Smoking and Cancer}
			\colorlet{heldout}{benchcolor1}
			\begin{center}
			  \hfill
				\begin{tikzpicture||precompiled}[paperfig]{smoking-BN}
					\begin{scope} % BN Nodes...
						[every node/.style={dpadded, fill opacity=1,fill=black!08, circle, inner sep=2pt, minimum size=2em, draw=gray}]
						\node[
							% onslide=<6->{opacity=0.2, text opacity=0.2}
							] (PS) at (0,0) {$\mathit{PS}$};
						\node (SH) at (1.5, 0.6) {$\mathit{SH}$};
						\node (S) at (1.5, -0.6) {$\mathit{S}$};
						\node (C) at (3, 0) {$\mathit{C}$};
						\end{scope}
					\draw[->,
						%oli1:
						% onslide=<6->{opacity=0.2}
						] (PS) to (S);
					\draw[->,
						%oli1:
						% onslide=<6->{opacity=0.2}
						] (PS) to (SH);
					\draw[->] (SH) to (C);
					\draw[->] (S) to (C);

%\commentout{
					% \only<6->{% Describe why restriction of BN is not a BN
					% 	\node[below left=0.65 and 0.4 of PS,anchor=north west] (condBNtext)
					% 	{\parbox{2.0in}{\small\raggedright\color{benchcolor1!60!alertcolor}
					% 		Must now give distributions on $\mathit{SH}$ and $\mathit{S}$, or distinguish them as ``observed'' (a \emph{conditional} BN). %
					% 		}};%
					% }
%}
				\end{tikzpicture||precompiled}%
%                                }
				\hfill\pause
				\vrule\hfill
				\begin{tikzpicture||precompiled}[paperfig]{smoking-PDG}

					\node[dpadded] (1) at (0,0) {$\pdgunit$};
					\node[dpadded] (PS) at (1.65,0) {$\mathit{PS}$};
					\node[dpadded, % (S) ...
					 	% onslide=<5->{fill=black!.16, fill opacity=0.9}
						]
						(S) at (3.2, 0.8) {$\mathit S$};
					\node[dpadded, % (SH)...
					 	% onslide=<5->{fill=black!.16, fill opacity=0.9}
						]
						(SH) at (3.35, -0.8) {$\mathit{SH}$};
					\node[dpadded, % (C) ...
					 	% onslide=<5->{fill=black!.16, fill opacity=0.9}
						]
						(C) at (4.8,0) {$\mathit C$};

					\mergearr{SH}{S}{C} % duplicated below; this one is to get coordinates right
					\onslide<3>{ % Draw cpts attached to each edge...
						% \node;
						\begin{scope}[thick,benchcolor1,dashed]
							\draw[] ($(1)!0.4!(PS)$) -- ++(0,0.85)
								node[above] {$p(\mathit{PS})$};
							\draw[] ($(PS)!0.5!(S)$) -- ++(-0.4,1.1)
								node[above] {$p(\mathit{S}\!\mid\!\mathit{PS})$};
							\draw[] ($(PS)!0.48!(SH)$) -- ++(-0.6,-0.75)
								node[below left] {$p(\mathit{SH}\!\mid\!\mathit{PS})$};
							\draw[] ($(center-SHSC)!0.11!(S)$) -- ++(0.6,0.75)
								node[above right] {$p(\mathit{C}\!\mid\!\mathit{S}, \mathit{SH})$};
							\end{scope}
						}

					\draw[arr1] (1) -- (PS);
					\draw[arr2] (PS) -- (S);
					\draw[arr2] (PS) -- (SH);
					\mergearr{SH}{S}{C}

					\onslide<4->{ % Add Tanning Beds & arrow...
						\node[dpadded,
							 	onslide=<4>{fill=benchcolor1!36, fill opacity=0.75,
								 	draw=benchcolor1!20!black, dashed},
								% onslide=<5->{fill=black!.16, fill opacity=0.9}
								]
							(T) at (6.25,0) {$T$};
						\draw[arr1,onslide=<4>{dashed,draw=benchcolor1!60!black}] (T) -- (C);
						}
					% \onslide<5>{ % Draw matt & label for restriction...
					% 	\draw[very thick, |-|, color=blue!50!black,text=black] (2.7, 1.35) --coordinate(Q) (6.83,1.35);%
					% 	\fill[white] (2.6, 1.36) rectangle (7.0,1.55);
					% 	\node[above=0.05em of Q]{\small Restricted PDG};
					% 	}
					% \onslide<6-7>{ % Dim this picture for BN description...
					% 	\fill[white, opacity=0.8] (current bounding box.south west) rectangle (current bounding box.north east); }
					\end{tikzpicture||precompiled}
				% }
				\hfill
			\end{center}
			\vspace{1em}
% \commentout{
	% 		\only<7->{%
	% 			\begin{tikzpicture}[overlay,yshift=3.5em,xshift=2.3in]
	% 				%        \pgftransformshift{\pgfpointanchor{current page}{center}}
	% 				\begin{scope}
	% 						[every node/.style={dpadded, fill opacity=1,fill=benchcolor2!10, circle, inner sep=2pt, minimum size=2em, draw=gray!50!benchcolor2}]
 %
	% 					\node[] (A) at (1,0) {$A$};
	% 					\node[right=0.5 of A, fill opacity=0.4, dashed] (B) {$B$};
	% 					\node[right=0.5 of B] (C) {$C$};
	% 				\end{scope}
 %
	% 				\draw[arr] (A) -- (B);
	% 				\draw[arr] (B) -- (C);
	% 				\node[anchor=south west] at (-0.5,0.4) {\parbox{2.5in}{\small\raggedright\color{benchcolor2}%
	% 						In a qualitative BN: \emph{removing} data results in \emph{new} knowledge: $A \CI C$. \note{this is a larger set of distributions.} }};
 % %}
	% 			\end{tikzpicture}}%
			\pause
% }
			In contrast with BNs:
			\begin{itemize}%[<+-| alert@+>]
				\item<+-| alert@+> edge composition has \emph{quantitative} meaning, since edges have cpds;
				\item<+-| alert@+> a variable can be the target of more than one cpd;
				\item<+-| alert@+> arrbitrary PDGs can be combined to obtain a new PDGs.
					% {\small\begin{itemize}
					% 	\item<+-| alert@+-+(1)> The analogue is false for BNs!
					% \end{itemize}}
			\end{itemize}
			\end{frame}%------------%

%	\subsection{Combining and Restricting PDGs}
		\colorlet{colorsmoking}{blue!50!black}
		\colorlet{colororiginal}{benchcolor1!85!black}
		\begin{frame} %%%%%%%%%%         UNION OF PDGs         %%%%%%%%%%%%
			\frametitle{Combining PDGs}
			% \framesubtitle{Smoking and Cancer}
			\colorlet{heldout}{benchcolor1}
				\tikzset{hybrid/.style={postaction={draw,colorsmoking,dash pattern= on 5pt off 8pt,dash phase=6.5pt,thick},
					draw=colororiginal,dash pattern= on 5pt off 8pt,thick}}
			\begin{center}
					\begin{tikzpicture||precompiled}
							[center base, thick, draw=colororiginal, text=black]{grok-pre}

						\node[dpadded] (C) at (0,0) {$\mathit C$};
						\node[dpadded] (T) at (1.5,0){$\mathit T$};
						\node[dpadded] (SL) at (.75,-1.5){$\mathit{SL}$};

						\draw[arr] (T) to[bend right] node[above]{$q$} (C);
						\mergearr{C}{T}{SL}
						\end{tikzpicture||precompiled}
				\only<1-3>{
						\vspace{0.7em}
						\begin{exampleblock}{Alice
                                                    wants to be
                                                    supreme leader
                                                    ($\mathit{SL}$).}

						\begin{itemize}[<+->]
							\item She notices that those who use tanning beds have more power,\\[-0.4em]
							\item \textellipsis but mom says $q(C \mid T) = \begin{idxmat}
								{$t$,$\overline t$}{$c$,$\overline c$}
									.15 & .85 \\ .02 & .98
								\end{idxmat}$.\\[0.9em]
							\item Alice worries getting cancer from a tanning bed will make $\mathit{SL}$ impossible.
						\end{itemize}
						\end{exampleblock}
					}
				\pause
				{\Large$\boldsymbol+$}
				% \hfill{\Large$+$}\hfill
				\begin{tikzpicture||precompiled}[paperfig, text=black]{}
					\fill[fill opacity=0.1, blue!80!black, draw, draw opacity=0.5]
					 	(-2.07,1.35) rectangle (2.07, -1.35);

					% \begin{scope}
						\node[dpadded, fill=black!.16, fill opacity=0.9] (C) at (0,0) {$\mathit C$};
						\node[dpadded, fill=black!.16, fill opacity=0.9] (T) at (1.6,0){$\mathit T$};
						\node[dpadded, fill=black!.16, fill opacity=0.9] (S) at (-1.4, 0.8) {$\mathit S$};
						\node[dpadded, fill=black!.16, fill opacity=0.9] (SH) at (-1.45, -0.8) {$\mathit{SH}$};
						% \end{scope}

					\draw[arr1] (T) to node[above]{$p$} (C);
					\mergearr{S}{SH}{C}
					\end{tikzpicture||precompiled}
				% \hfill%
				\pause
				{\Large$\boldsymbol=$~}
				% \hfill%
				\begin{tikzpicture||precompiled}[paperfig]{grok-post}
					\begin{scope}[postaction={draw,colorsmoking,dash pattern= on 3pt off 5pt,dash phase=4pt,thick}]

						\node[dpadded,hybrid] (C) at (0,0) {$\mathit C$};
						\node[dpadded,hybrid] (T) at (2,0){$\mathit T$};
						\end{scope}

					\begin{scope}[thick, draw=colororiginal, text=black]
						\node[dpadded] (SL) at (1,-1.5){$\it SL$};
						\draw[arr] (T) to[bend right] node[above]{$q$} (C);
						\mergearr{C}{T}{SL}
						\end{scope}

					\begin{scope}[thick, draw=colorsmoking, text=black]
						\node[dpadded] (S) at (-1.4, 0.8) {$S$};
						\node[dpadded] (SH) at (-1.45, -0.8) {$\mathit{SH}$};
						\draw[arr] (T) to node[fill=white, fill opacity=1,text opacity=1,inner sep=1pt]{$p$} (C);
						\mergearr{S}{SH}{C}
						\end{scope}
					\end{tikzpicture||precompiled}
				\end{center}
			\vspace{1em}
			\begin{itemize}[<+(1)-|alert@+(1)>]
				\item Arbitrary PDGs may be combined without loss of information
				\item They may have parallel edges (e.g., $p,q$), which directly conflict.
				\end{itemize}

			\end{frame}%------------%



	\begin{frame} %%%%%%%%%%%       Definition of a PDG          %%%%%%%%

	 % \frametitle{Formal Definition}
	{\bf Definition:} [Probabilistic Dependency Graph]
			A PDG is a tuple $\dg M =
			(\N,\Ed,\V, p, \alpha, \beta)$, where
			\begin{itemize}
				\item $\N$
					is a finite set of nodes (variables)
		%oli1: describes -> gives,  to avoid $X$ all alone on a line
		% \item $\V$ describes the range $\V(X)$ of possible
		\item $\V$ gives the range $\V(X)$ of possible
                  values of each variable $X$;

\pause				\item $\Ed$
				is a set of labeled edges $\{ \ed LXY \}$
					\pause
\item			associated to each $\ed LXY$, there is:

\begin{itemize}
	\item		a cpd $\bp(Y \mid X)$;
				\item $\alpha\ssub L$:
	a confidence in the functional dependence $X \to Y$%
			\item $\beta\ssub L$:
							a confidence in the reliability of	$\bp$
\end{itemize}
\end{itemize}

		\end{frame}

	\begin{frame}
%          <1-4>[label=semantics] %%%%%%%%%          SEMANTICS           %%%%%%%%%%%%
		\frametitle{PDG Semantics}
%		{	\setbeamersize{description width=1.2cm}
%			\setbeamercovered{transparent=30}
%			\begin{description}
%				\item<uncover@1,2,8,9>
%[\only<8->{\color{structurecolor}1.~}\alert<2,8,9>{$\SD{\dg M}$}]
                        %%\notation{$:\mathcal P{\Delta \V(\dg M)}$}

                        The ``obvious'' semantics for a PDG $M$:
\begin{itemize}
\item $\SD{ \dg M}$: The set of joint distributions consistent with $\dg M$;
%					\only<2-7>{\visible<2->{\uncover<2>{
						\[ \Big\{
                                                \mu						 	\in \Delta[\V(\dg M)]:~\text{for all } \ed LXY \in \Ed.~~\mu(Y\!\mid\!X) = \bp(Y\!\mid\! X)  \Big\} \]
\end{itemize}
{\bf Problem:} All inconsistent PDGs will have the same semantics: $\emptyset$
\smallskip

We want something more nuanced.
%oli1: this pause creates a duplicate slide. Removed.
% \pause

        \end{frame}

        \begin{frame}\frametitle{A scoring semantics}

{\bf Idea:} We associate with each PDG $M$ a function that measures how
far a probability distribution $\mu$ is from what is being described
by the PDG.  The function has two components:
\begin{itemize}
  \item $\Inc_{\dg M}(\mu)$: How far the distribution $\mu$ is from being
    consistent with the PDG $M$
    (measured using relative entropy, but different measures could be
    used)
    \item $\IDef{\dg M}(\mu)$: How far the distribution is from
      satisfying the causal constraints described by the PDG
\end{itemize}
We then weight these components using $\gamma \ge 0$.

        \end{frame}

	\begin{frame}[t] %%%
		\frametitle{The Scoring Function }

$\bbr{\dg M}_\gamma(\mu) := {\blue {\Inc_{\dg M}(\mu)}}
					+ \gamma
					\IDef{\dg M}(\mu)$

\begin{itemize}
\item				\textbf{Intuition:} beyond stating
  whether or not $\mu$ is consistent with $\dg M$, we score $\mu$'s
  compatibility with $\dg M$.
\end{itemize}
%oli1: add pause
\pause
			{\color{structurecolor}\scshape{Motivating Examples}.}
			% \begin{center}
			\hfill
			$\dg M := \quad$
			\begin{tikzpicture}[paperfig]
				\node[dpadded] (1) {$\pdgunit$};
				\node[dpadded, right=1 of 1] (X) {$X$};
				\draw[arr1] (1) to[bend left=30] node[above] {$q$} (X);
				\draw[arr1] (1) to[bend right=30] node[below] {$p$} (X);
			\end{tikzpicture}
			\hfill~
			% \end{center}
			\vspace{-1em}

			\begin{itemize}
				\item If $p
                                  = \begin{idxmat}{$\star$}{$x_1$,$x_2$}
                                    .4 & .6 \end{idxmat} = q$, then
                                  $\dg M$ is consistent, and
                                  compatible with the joint
                                  distribution $\mu(X) = p$.
\pause
\item				  If $p = \begin{idxmat}{$\star$}{$x_1$,$x_2$} .4 & .6 \end{idxmat}$ and
						$q = \begin{idxmat}{$\star$}{$x_1$,$x_2$} .5 & .5 \end{idxmat}$,
						then $\dg M$ is not consistent, but
						%oli1: remove paragraph break
						%
						$\mu = \begin{bmatrix}%{$\star$}{$x_1$,$x_2$}
						 	.45 & .55 \end{bmatrix}$ matches better than
						$\mu = \begin{bmatrix} .9 & .1 \end{bmatrix}$.

                                                \pause

\item If $p = \begin{bmatrix} .4 & .6 \end{bmatrix}$ and
						$q = \begin{bmatrix} 0 & 1 \end{bmatrix}$,
						then $\dg M$ is much more inconsistent than before, even though $\SD{\dg M} = \emptyset$ in both cases.
			\end{itemize}


        \end{frame}


	\begin{frame}[t] %%%
		\frametitle{The Scoring Function }

$\bbr{\dg M}_\gamma(\mu) := {\blue {\Inc_{\dg M}(\mu)}}
					+ \gamma
					\IDef{\dg M}(\mu)$
\medskip

{\bf Definition:} The \emph{incompatibility} of
%oli1: killing the stray \alt which deletes the space \& letter "s":
% a joint distribution $\mu$ with $\dg M$\alt is given by
a joint distribution $\mu$ with $\dg M$ is given by
$$		\Inc_{\dg M}(\mu) :=
		\sum_{\mathclap{\ed LXY}}\; {\beta_L} \kldiv{ \mu_{Y|X} }{ \bp }
					$$

\begin{itemize}
\item $\displaystyle\kldiv\mu\nu = \sum_{\mathclap{w \in \mathop{Supp}(\mu)}} \mu(w) \log \frac{\mu(w)}{\nu(w)}$
				% is the relative entropy \\[-1.2em] from $\nu$ to $\mu$.
	%oli1: this negative spacing works well for right-alignment. Here it is a problem.
	% You can use this...
				% is the relative entropy from $\nu$ to $\mu$.
	%oli1: ... or, since we're already on two lines, and having $\mu$ alone on a line
	% is strange, here's maybe a clearer, longer wording....
					% is the relative entropy of $\nu$ with respect to $\mu$.}
	%oli1: ... but actually, I think this looks the best:
					is the relative entropy \\[-1.2em] \hfill of $\nu$ with respect to $\mu$.
					%oli1: extra spacing
					\vspace{1ex}
      \begin{itemize}
			%oli1: replaced "distance" with "divergence" since relative entropy is
			% neither semetric nor satisfies the triangle ienquality
			% \item It works well, but other distance functions could be used.
      \item It works well, but other divergences could be used instead.
      \end{itemize}
              \end{itemize}

\pause

The \emph{inconsistency} of $\dg M$ is the smallest possible incompatibility,
		\[ \Inc(\dg M) := \!\!\inf_{ \mu \in \Delta\V(\dg M)}\!\! \Inc_{\dg M}(\mu) . \]




        \end{frame}

	\begin{frame}[t] %%%
		\frametitle{The Scoring Function }

$\bbr{\dg M}_\gamma(\mu) := {\Inc_{\dg M}(\mu)}
					+ \gamma
					{\blue \IDef{\dg M}(\mu)}$

\smallskip
				\textbf{Intuition:} each edge $\ed LXY$ indicates that $Y$ is determined (perhaps noisily) by $X$ alone.
%oli1: add pause
\pause
                                \begin{itemize}
                                  \item So a $\mu$ with uncertainty in
                                    $Y$ after $X$ is known
beyond pure noise is qualitatively worse.
\begin{itemize}
\item $H(Y \mid X)$ measures uncertainty in $Y$ after $X$ is known:
  the number of bits needed to determine $Y$, given $X$.
\item $H(\mu)$ measures the amount of ``pure noise'': the number of
  bits needed to
  determine all the variables.
\end{itemize}
   \end{itemize}

%oli1: adding pause to be consistent with previous frame
\pause

{\bf Definition:}
%oli1: I think you preferred "information deficiency", which is in the paper.
% The \emph{information deficit} of a distribution $\mu$ with respect to
The \emph{information deficiency} of a distribution $\mu$ with respect to
$\dg M$ is
					$$\IDef{\dg M}(\mu) :=
\sum_{\mathclap{\ed LXY}} \alpha_L \H_\mu(Y \mid X)  - H(\mu).$$


        \end{frame}

\begin{frame}
        \frametitle{PDG Semantics}

        \begin{enumerate}
\item $\SD{\dg M}$: The set of joint distributions consistent with $\dg M$;
\item $\bbr{\dg M}_\gamma$: A loss function (parameterized by
  $\gamma$), scoring a joint distribution's compatibility with $\dg M$;
\item {\blue $\bbr{\dg M}^*$: the
``best'' joint distribution
                  (in the quantitative limit).}
					  \[
\bbr{\dg M}^* :=      \lim_{\gamma\to 0} \argmin_\mu \bbr{\dg M}_\gamma(\mu) \]
\end{enumerate}

\pause
{\bf Proposition:} \emph{(the second semantics extends the first)}
$\SD{\dg M} \!= \big\{ \mu : \bbr{\dg M}_0(\mu) \!=\! 0 \big\}$.


\pause \medskip
{\bf Proposition:} (\emph{If there there are distributions consistent with $\dg M$, the best distribution is one of them.})
	$\bbr{\dg M}^* \in \bbr{\dg M}_0^*$, so if $\dg M$ is consistent,
	then $\bbr{\dg M}^* \in \SD{\dg  M}$.

\end{frame}


	\begin{frame}
		\frametitle{Capturing Bayesian Networks}
		Let $\PDGof{\mathcal B, \beta}$ be the PDG
		corresponding to the BN $\mathcal B$, with weights $\beta$.

                \smallskip

                {\bf Theorem:} (BNs are PDGs)
			If $B$ is a BN and $\Pr_{ B}$ is the distribution it specifies, then for all $\gamma > 0$ and all vectors $\beta$,
			$$
			%oli1: needs a gamma.
		% \bbr{\PDGof{ B, \beta}}^* = \Pr\nolimits_{B}.$$
		\bbr{\PDGof{ B, \beta}}^*_\gamma = \Pr\nolimits_{B}.$$


                \pause

		\begin{center}
		\begin{tikzpicture}[remember picture,center base]
			% \fill[benchcolor1,opacity=0.5] (0.1,0) -- (-1,1) -- (-2,0.7) -- (-2.5,-0.1) -- (-1.5, -0.5) -- cycle;
			% \node[align=center] (sd) at (-1.3,0.2) {$\SD{\dg M}$};
			%oli1: compressing shape due to larger font size (previous shape above)
			\fill[benchcolor1,opacity=0.5] (0.1,0) -- (-0.5,1) -- (-1.6,0.7) -- (-2,-0.1) -- (-1.2, -0.5) -- cycle;
			\node[align=center] (sd) at (-1.0,0.2) {$\SD{\dg M}$};
			%oli1: compressing shape due to larger font size
			% \fill[benchcolor2,opacity=0.5] (-0.1,0) -- (0.5,0.2)  -- (1, 1) -- (2, -0.5) -- cycle;
			\fill[benchcolor2,opacity=0.5] (-0.1,0) -- (0.5,0.2)  -- (1, 1) -- (1.5, 0.2) -- (1.5, -0.5) -- cycle;
			\node[align=center] (ind) at (1,0.2) {$\CI_{B}$};

			\node[left=0.6 of sd, inner sep=0.5pt, align=left, font=\small,
					text=benchcolor1!40!black] {
				space of distributions\\ consistent with $\dg M_{B,\beta}$\\
				(which minimize $\Inc$)
			};
			\node[right=0.2 of ind, inner sep=0.5pt, align=right, font=\small,
				text=benchcolor2!40!black] {
				space of distributions\\ with independencies of $B$\\
				(which can be shown \\ to minimize $\IDef{}$)
			};

			\node[fill=black, circle,inner sep=0.1em] (dot) at (0,0){};
			\node[below=0.5em of dot] (dotl) {$\Pr_{ B}$};
			\draw (dotl) -- (dot);
		\end{tikzpicture}

		\end{center}

%oli1: added \pause
\pause

{\bf Bottom line:} $\Pr_B$ is the unique distribution that minimizes
%oli1: inserted
both
%oli1: fixing the \IDef macro
% $\Inc(M_B)$ and $\IDef(M_B)$.
%oli1: (the \IDef macro works differently, because of the back-and-forth in the original paper.)
% $\Inc(M_B)$ and $\IDef{}(M_B)$.
%oli1:... but this isn't the notation you introduced earlier; there the PDG was in the subscript. This also doesn't have a \beta. For consistency, you might want to instead write:
$\Inc_{\PDGof{B,\beta}}$ and $\IDef{\PDGof{B,\beta}}$.
	\end{frame}





\begin{frame}
  \frametitle{Inference via Inconsistency Reduction}



Since we can model  inconsistency in a PDG, we can investigate
inconsistency reduction/resolution:
\medskip

	\textbf{Conditioning as inconsistency resolution.}\\
			To condition on $Y\!=\!y$ in PDG $\dg M$,
			simply add the edge $\ed {\delta_y}{\pdgunit}
                        Y$  to get the PDG ${\dg M} \cup {Y=y}$.
			Then $\bbr{{\dg M} \cup (Y = y)}^* = \bbr{\dg M}^* \mid (Y\!=\!y)$.

%oli1: reducing bigskip to \medskip so skips are even
% \bigskip \pause
\medskip \pause

		\textbf{Querying $\Pr(Y\mid X)$ in a PDG $\dg M$.}
		\begin{itemize}
			\item We can add $\ed pXY$ to $\dg M$ with a cpt $p$, to get ${\dg M}^{+p}$.
			\item The cpd $p$ that minimizes the
                          inconsistency of $\dg M^{+p}$ (which is
                          strongly convex and smooth in $p$) is $\Pr(Y
													%oli1: fixing \mid
                          % ]mid X)$ in           $\bbr{\dg M}^*$,
                          \mid X)$ in           $\bbr{\dg M}^*$,
			\item so oracle access to inconsistency yields fast inference by gradient descent.
		\end{itemize}


		%oli1:adding pause and space
		\pause\medskip
                {\bf Theorem:} Unfortunately, as with Bayesian networks,
                \begin{itemize}
                \item Deciding if $M$ is consistent is NP-hard
                  \item Computing $\bbr{\dg M}_\gamma$ is \#P-hard.
                \end{itemize}

\end{frame}

	\begin{frame}
		\frametitle{Summary}
		PDGs\textellipsis
		\begin{itemize}[<+-|alert@+>]
			\item capture inconsistency, including conflicting information
			from multiple sources with varying reliability.
			\item
				are especially modular; to combine info from two sources, simply take a PDG union.
				This incorporates new data (edge cpds) and concepts (nodes) without affecting previous information.
%			\item cleanly separate quantitative info (the cpds)
%				from qualitative info (the edges), with variable confidence
%				in both (the weights $\beta$ and $\alpha$).
%				This is captured by terms $\Inc$ and $\IDef{}$ in our scoring function.
			\item have (several) natural semantics; one of them allows us to
				pick out a unique distribution.  Using this distribution, PDGs
				can capture BNs (and factor graphs).

%oli1*: Next bullet hasn't been addressed in these slides at all!
% Perhaps change the title to something other than ``Summary''?
%
%oli1: I'm also separating it out from the other bullet points:
%oli1: end itemize early and \pause, to try to separate out from list.
% \item The
\pause[\thebeamerpauses] \end{itemize} \alert<.(1)>{In addition, the
%oli1: Realy it's the inconsistency. But if you want to revert it, I'd use "loss function" over "scoring function" to keep it distinct.
% loss function of PDGs can capture many standard loss
 inconsistency of PDGs happens to capture many standard loss
%oli1: "in the literature" seems like overkill for slides; we've already said they're standard. They're also used in practice.
  % functions in the literature in a natural way:
  functions in a natural way:
	%oli1:
	% \begin{itemize}
	}\pause\begin{itemize}[<+-|alert@+>] \small
		%oli1: (1) "surprisal" is the more common name.
		%oli1: (2) added  cross entropy, as it is almost certainly the most widely used.
		%oli1: (3) VAEs are a model; their loss function is (a variant of) the ELBO.
    % \item surprise, accuracy, mean squared error, variational
    %   autoencoders, R\'enyi divergence, Bhattacharya distance, \ldots
    \item surprisal, accuracy, mean squared error, cross entropy, the ELBO (e.g., for variational autoencoders), R\'enyi divergence, Bhattacharya distance, \ldots
    \item Can also capture regularizers
      \item Instead of appealing to a loss function, appeal to a
        model!
        \end{itemize}
			%oli1:
		% \end{itemize}
\end{frame}

        \begin{frame}

In terms of this MURI, PDGs give us a tool for understanding how
agents manage inconsistency and information, and studying how this may
lead to biases:
\begin{itemize}
  \item As mentioned, confirmation bias can be viewed as  an approach to
    inconsistency
    \begin{itemize}
			%oli: I prefer the following: (I like "internal conflict" but I've left "inconsistency" uncommented because I think you'll prefer that)
      % \item Give edges that comes from opposing views lower confidence
			\item Reduce inconsistency by giving edges from opposing views low confidence
			% \item Reduce internal conflict by giving edges from opposing views low confidence
    \end{itemize}
  \item Suppose we limited the number of edges in a PDG
    \begin{itemize}
		%oli1: added "necessarily"
    \item What biases would that lead to?
    \end{itemize}
\end{itemize}
\end{frame}


\end{document}
        \pause[\thebeamerpauses]
		\medskip
		\textit{But there is much more to be done!}
		\end{frame}


%joe1: moved here
                        The
%              \only<7>{{\color{benchcolor1}(unique)}}
                                          ``best'' joint distribution
                              %\only<7>{{\small\color{benchcolor1}~
                             (in the quantitative limit).
%					\only<2-7>{\visible<4-7>{
					  \[ \bbr{\dg M}
                                          %\only<4-6>{
                                          _\gamma^* :=
                                            %\only<7>
      \lim_{\gamma\to 0} \argmin_\mu \bbr{\dg M}_\gamma(\mu) \]


                }
\begin{itemize}
\item 			So a $\mu$ with

						uncertainty in $Y$ after $X$ is known
					(beyond
                                                pure noise is qualitatively worse.
\end{itemize}

\end{document}



					\vspace{-5em}
					\begin{prop}[{\itshape\normalfont {uniqueness for small $\gamma$}}]
						\begin{enumerate}
						\item If  $0 < \gamma \leq \min_L \beta_L^{\dg M}$, then
						$\bbr{\dg M}_\gamma^*$ is a singleton.
						\item
     $\displaystyle\lim_{\gamma\to0}\bbr{\dg
                                                  M}_\gamma^*$ exists
                                                  and is unique.
						\end{enumerate}
						\end{prop}


%			\only<8->{
				\begin{prop}[{\normalsize{\it the second semantics extends the first\;}}]
						$\SD{\dg M} \!= \big\{ \mu : \bbr{\dg M}_0(\mu) \!=\! 0 \big\}$.
					\end{prop}

				\onslide<9->{
					\begin{prop}[{\normalsize{\it If there there are distributions consistent with $\dg M$, the best distribution is one of them.\;}}]\label{prop:consist}
							$\bbr{\dg M}^* \in \bbr{\dg M}_0^*$, so if $\dg M$ is consistent,
							then $\bbr{\dg M}^* \in \SD{\dg  M}$.
						\end{prop}
					}
			}
		\end{frame}

	\relax % frame setup
		\colorlet{localcolor}{Lavender!80!black}
		\colorlet{globalcolor}{Sepia!80!orange}
		% \def\INCfst{2}
		\def\INCmotfst{2}
			\def\INCmotlen{4}

		\edef\INCfst{\the\numexpr \INCmotfst + \INCmotlen \relax}
			\def\INClen{5}
			\edef\INClst{\the\numexpr\INCfst+\INClen-1\relax}
			\def\INCrange{\INCfst-\INClst}
			\def\INC+#1{\atslide{\INCfst+#1}}

		% \def\INCexfst{7}
		\edef\INCexfst{\the\numexpr \INClst + 1 \relax}
			\def\INCexlen{0}
			\edef\INCexlst{\the\numexpr\INCexfst+\INCexlen-1\relax}
			\def\INCexrange{\INCexfst-\INCexlst}
			\def\INCex+#1{\atslide{\INCexfst+#1}}

		\edef\IDEFmotfst{\the\numexpr \INCexlst + 1 \relax}
			\def\IDEFmotlen{3}
			\def\IDEFmot+#1{\atslide{\IDEFmotfst+#1}}

		% \def\IDEFfst{12}
		\edef\IDEFfst{\the\numexpr \IDEFmotfst + \IDEFmotlen \relax}
			\def\IDEFlen{3}
			\edef\IDEFlst{\the\numexpr\IDEFfst+\IDEFlen-1\relax}
			\def\IDEFrange{\IDEFfst-\IDEFlst}
			\def\IDEF+#1{\atslide{\IDEFfst+#1}}

		% \def\IDEFexfst{15}
		\edef\IDEFexfst{\the\numexpr \IDEFlst + 1 \relax}
			\def\IDEFexlen{4}
			\edef\IDEFexlst{\the\numexpr\IDEFexfst+\IDEFexlen-1\relax}
			\def\IDEFexrange{\IDEFexfst-\IDEFexlst}
			\def\IDEFex+#1{\atslide{\IDEFexfst+#1}}

		% \def\INCandIDEF{19}
		\edef\INCandIDEFfst{\the\numexpr\IDEFexlst + 1 \relax}
			\edef\INCandIDEF{\INCandIDEFfst-}
			\def\IIboth+#1{\atslide{\IDEFexlst + 1 + #1}}
			\edef\beforeINCandIDEF{-\the\numexpr\INCandIDEFfst - 1\relax}
			% \show\INCandIDEF
		\def\atslide#1{\the\numexpr#1\relax}
		\def\aitem@#1+#2{\item<\atslide{\csname#1fst\endcsname+#2}-|alert@\atslide{\csname#1fst\endcsname+#2}>}
		\def\halfblocks{\INCexrange,\IDEFexrange,\INCandIDEF}
	\begin{frame}[t] %%%
		\frametitle{The Scoring Function }
		\only<\IIboth+1->{
			\begin{itemize}
				\item<\IIboth+1-|alert@\IIboth+1> A BN strictly enforces the qualitative picture (large $\gamma$)
				\item<\IIboth+2-|alert@\IIboth+2> we are interested in the quantitative limit (small $\gamma$)
			\end{itemize}
			\bigskip

%joe1: moved here



                }

		{\alt<\INCexrange,\IDEFexrange>{\vspace{-0.5em}\small}{\centering}\only<\INCandIDEF>{\centering}
			$\displaystyle%
				\bbr{\dg M}_\gamma(\mu) := \hl[alertcolor!30!benchcolor1!99!structurecolor]%
						<2-\INClst,\INCexrange,\INCandIDEF>{\Inc_{\dg M}(\mu)}
					+ \gamma%
					\extra<\IIboth+0->[below right=0.5em and -1 em of call point,
						inner sep=0.3em, font=\small, name=tp, draw=alertcolor, text=alertcolor!40!black,
						fill=alertcolor!10]{\small tradeoff parameter $\gamma \ge 0$}
					%
					\;\hl[alertcolor!30!benchcolor2!99!structurecolor]<\IDEFmotfst->{\IDef{\dg M}(\mu)}$\par}
				\only<\IIboth+0->{\tikzro{%
						\draw[alertcolor] ([yshift=-0.2em,xshift=-0.3em]call point.center) -- ([xshift=1.0em]tp.north west);}}

		{\medskip}
		\setlength\pdgdefnwidth{0.95\textwidth}
		\only<\halfblocks>{\setlength\pdgdefnwidth{0.43\textwidth}}

		\only<2-\atslide{\INCfst-1}> {
			\smallskip
			{\centering\parbox{0.8\textwidth}{\raggedright
				\textbf{Intuition:} beyond stating whether or not $\mu$ is consistent with $\dg M$, we score $\mu$'s compatibility with $\dg M$.}\par}

			{\color{structurecolor}\scshape{Motivating Examples}.}
			% \begin{center}
			\hfill
			$\dg M := \quad$
			\begin{tikzpicture}[paperfig]
				\node[dpadded] (1) {$\pdgunit$};
				\node[dpadded, right=1 of 1] (X) {$X$};
				\draw[arr1] (1) to[bend left=30] node[above] {$q$} (X);
				\draw[arr1] (1) to[bend right=30] node[below] {$p$} (X);
			\end{tikzpicture}
			\hfill~
			% \end{center}
			\vspace{-1em}

			\begin{itemize}
				\aitem@{INCmot}+1 If $p = \begin{idxmat}{$\star$}{$x_1$,$x_2$} .4 & .6 \end{idxmat} = q$, then $\dg M$ is consistent, and compatible with the joint distribution $\mu(X) = p$.
				\aitem@{INCmot}+2 If $p = \begin{idxmat}{$\star$}{$x_1$,$x_2$} .4 & .6 \end{idxmat}$ and
						$q = \begin{idxmat}{$\star$}{$x_1$,$x_2$} .5 & .5 \end{idxmat}$,
						then $\dg M$ is not consistent, but

						$\mu = \begin{bmatrix}%{$\star$}{$x_1$,$x_2$}
						 	.45 & .55 \end{bmatrix}$ matches better than
						$\mu = \begin{bmatrix} .9 & .1 \end{bmatrix}$.
						\medskip

				\aitem@{INCmot}+3 If $p = \begin{bmatrix} .4 & .6 \end{bmatrix}$ and
						$q = \begin{bmatrix} 0 & 1 \end{bmatrix}$,
						then $\dg M$ is much more inconsistent than before, even though $\SD{\dg M} = \emptyset$ in both cases.
			\end{itemize}
		}

		\begin{columns}[c]
			\only<\INCrange,\INCexrange,\INCandIDEF>{{ %%%%%%%%%% INC %%%%%%%%%%%%%%%
				\begin{column}{\pdgdefnwidth}
				\setbeamercolor{block title}{bg=benchcolor1!80!structurecolor!50}
				\setbeamercolor{block body}{bg=benchcolor1!80!structurecolor!20}
				\setbeamercovered{transparent=35}
				\only<\INCexrange>{\setbeamertemplate{blocks}[rounded][shadow=false]}
				\only<\INCexrange,\INCandIDEF>{\small}
				\begin{defn}[$\Inc$]<\INCrange,\INCandIDEF>\label{def:inc}
				The \emph{incompatibility} of
				\only<\INCrange>{a joint distribution }$\mu$ with $\dg M$\alt<\INCrange>{ is given by}{:}
				\def\fullnotate{\atslide{\INCfst+3}}
				\alt<-\INC+2,\INCex+0->{ \[ % The simpler, less clear notation
						\Inc_{\dg M}(\mu) :=
							\sum_{\mathclap{\ed LXY}}\; \visible<\INC+1->{\alert<\INC+1>{\beta_L}} \;
							\tikzmark{relentD}
							\kldiv{ \mu_{Y|X} }{ \bp }
					\] }{ \[ % The notation used in our paper
						\Inc_{\dg M }( \mu) :=
							\sum_{\mathclap{\ed LXY}} \beta_L \alert<\INC+3>{ \Ex_{x \sim \mu_{_X}} }
							\tikzmark{relentD}
							\kldiv[\Big]{ \mu \alert<\INC+3>{(Y \mid X \!=\! x)} }{\bp \alert<\INC+3>{(x)} }. \] }
				%
				\only<\INC+2-\INC+3>{
					\extra[name=Dexplain, below=1cm of pic cs:relentD, align=right,
								fill=benchcolor1!40!structurecolor!20!white]{%
							$\displaystyle\kldiv\mu\nu = \sum_{\mathclap{w \in \mathop{Supp}(\mu)}} \mu(w) \log \frac{\mu(w)}{\nu(w)}$
							is the relative entropy \\[-1.2em] from $\nu$ to $\mu$.
						}
					\tikzro \draw[thick,structurecolor!70!black,draw opacity=0.5]
					 	([xshift=0.5em,yshift=-0.2em]pic cs:relentD) -- ([xshift=0.5em]Dexplain.north); }

				{\setbeamercovered{invisible}
					\onslide<\INClst->{
						The \emph{inconsistency} of $\dg M$ is \only<-\INClst>{the smallest possible incompatibility,}
						\[ \Inc(\dg M) := \!\!\inf_{ \mu \in \Delta\V(\dg M)}\!\! \Inc_{\dg M}(\mu) . \]	 }}
				\end{defn}
				\end{column}
				}}
			\only<\INCexrange>{
				\column{\textwidth-\pdgdefnwidth}
				\vspace{-1em}
				{\centering\Large\color{structurecolor}\textsc{Examples}\par}
				\begin{center}
					\begin{tikzpicture}[throughlab/.style={fill=white, fill opacity=1,text opacity=1,inner sep=1pt}]
						\node[dpadded,thick] (C) at (0,0) {$\mathit C$};
						\node[dpadded,thick] (T) at (2,0){$\mathit T$};
						\draw[arr,draw=colororiginal,text=black] (T) to[bend right] node[throughlab]{$q$} (C);
						\draw[arr, draw=colorsmoking] (T) to node[throughlab]{$p$} (C);
						\end{tikzpicture}
					\end{center}

				\setlength{\leftmargini}{1em}
				\begin{itemize}
					\aitem@{INCex}+1 if $p = q$, then $\Inc(\dg M) = 0$.
					\aitem@{INCex}+2 if {\small $p =\begin{idxmat}%
								[\alt<\INCex+2>{\color{alertcolor!40}}{\color{gray!50}}\smalltext]
							{$t$,$\bar t$}{$c$} 0.4 \\ 0.1 \end{idxmat}$} and
						{\small $q = \begin{idxmat}%
								[\alt<\INCex+2>{\color{alertcolor!40}}{\color{gray!50}}\smalltext]
							{$t$,$\bar t$}{$c$} 0.9 \\ 0.1 \end{idxmat}$}, then \\[0.05em] still $\Inc(\dg M) = 0$
							(maybe nobody uses tanning beds).\vspace{0.4em}

					\aitem@{INCex}+3 {\small Not all inconsistencies are equally bad; \\
						\!\!$\Inc\!\left\{\!p \shorteq\!\! \begin{bmatrix} .55 \\ .12 \end{bmatrix}\!\!;
		 				q \shorteq\!\! \begin{bmatrix} .45 \\ .15 \end{bmatrix}\! \right\}\! < \!
						\Inc\! \left\{ \!p \shorteq\!\!\begin{bmatrix} .3 \\ .4 \end{bmatrix}\!\!;
						q \shorteq\!\! \begin{bmatrix} .9 \\ .1 \end{bmatrix}\! \right\}\!$}

					\end{itemize}
			}
			\only<\IDEFmotfst-\atslide{\IDEFfst-1}>{{
				\begin{column}{0.75\textwidth}

				\bigskip

				\textbf{Intuition:} each edge $\ed LXY$ indicates that $Y$ is determined (perhaps noisily) by $X$ alone.

				\bigskip
				\bigskip
				\bigskip

				\onslide<\IDEFmot+1->{
					So a $\mu$ with
					\tikzmark{beg-ce}%
						\hl[localcolor]<\IDEFmot+2->{uncertainty in $Y$ after $X$ is known}\tikzmark{end-ce}
					(beyond
					\tikzmark{beg-e}\hl[globalcolor]<\IDEFmot+2->{pure noise}\tikzmark{end-e})
					is qualitatively worse.

					\only<\IDEFmot+2>{
						\tikzro{ \draw[very thick,localcolor] ([yshift=0.8em]pic cs:beg-ce) -- %
							([yshift=1em]pic cs:beg-ce) --
								node[above,inner sep=2pt] {{\small\itshape measured by $\H(Y\mid X)$}}
							([yshift=1em]pic cs:end-ce) -- ([yshift=0.8em]pic cs:end-ce);}

						\tikzro{ \draw[very thick,globalcolor] ([yshift=-0.40em]pic cs:beg-e) --
								([yshift=-0.60em]pic cs:beg-e) -- node[below,inner sep=2pt] {$\H(\mu)$}
								([yshift=-0.60em]pic cs:end-e) -- ([yshift=-0.40em]pic cs:end-e);}
					}
				}

				\end{column}
				}}
			\only<\IDEFfst->{{ %%%%%%%%%% IDEF %%%%%%%%%%%%%
				\begin{column}{\pdgdefnwidth}
				\setbeamercolor{block title}{bg=benchcolor2!80!structurecolor!50}
				\setbeamercolor{block body}{bg=benchcolor2!80!structurecolor!20}
				\setbeamercovered{transparent=35}
				\only<\IDEFexrange>{\setbeamertemplate{blocks}[rounded][shadow=false]\small}
				\only<\IDEFexrange,\INCandIDEF>{\small}
				\end{column}}}
			\only<\IDEFexrange>{ %%%%%%%%%% IDEF EXAMPLES %%%%%%%%%%
				\column{\textwidth-\pdgdefnwidth}
				\vspace{-2em}

				{\centering\Large\color{structurecolor}\textsc{Examples}\par}

				\medskip
				\setlength{\leftmargini}{1.5em}
				\begin{itemize}
					\aitem@{IDEFex}+0
						{$\dg M_0=\quad$\color<\IDEFex+0>{alertcolor!60!black}\begin{tikzpicture}[paperfig]
							\node[dpadded] (X) {$X$};
							\node[dpadded,right=0.8 of X] (Y) {$Y$};
						\end{tikzpicture}\hfill}~\\[0.3em]
						{\small\!$\IDef{\dg M_0}\!(\mu)\! =\!  - \H_\mu(X,Y)$}
						{\footnotesize\color<\IDEFex+0>{alertcolor!70!benchcolor2}%
						\\[-0.3em](optimal $\mu$ maximizes entropy of $X,Y$)}~ \\[0.2em]
					\aitem@{IDEFex}+1
						{$\dg M_1=\quad$\color<\IDEFex+1>{alertcolor!60!black}\begin{tikzpicture}[paperfig]
							\node[dpadded] (X) {$X$};
							\node[dpadded,right=0.8 of X] (Y) {$Y$};
							\draw[arr2] (X) -- (Y);
						\end{tikzpicture}\hfill}~\\[0.3em]
						{\small\!$\IDef{\dg M_1}\!(\mu)\! =\! -\!\H_\mu(X)$}
						{\footnotesize\color<\IDEFex+1>{alertcolor!70!benchcolor2}\\[-0.3em]%
							(optimal $\mu$ maximizes entropy of $X$)}~  \\[0.2em]
					\aitem@{IDEFex}+2
						{$\dg M_2=\quad$\color<\IDEFex+2>{alertcolor!60!black}\begin{tikzpicture}[paperfig]
							\node[dpadded] (X) {$X$};
							\node[dpadded,right=0.8 of X] (Y) {$Y$};
							\draw[arr2] (X) to[bend left=15] (Y);
							\draw[arr2] (X) to[bend right=15] (Y);
						\end{tikzpicture}\hfill}~\\[0.3em]
						{\small\!$\IDef{\dg M_2}\!(\mu)\! =\!  - \H_\mu(X) + \H_\mu(Y\mid X)$}
						{\footnotesize\\\color<\IDEFex+2>{alertcolor!70!benchcolor2}%
							(optimal $\mu$ maximizes entropy for $X$, and\\[-0.4em] makes $Y$ a function of $X$)}  \\[0.2em]
					\aitem@{IDEFex}+3
						{$\dg M_3=\quad$  \color<\IDEFex+3>{alertcolor!60!black}\begin{tikzpicture}[paperfig]
							\node[dpadded] (X) {$X$};
							\node[dpadded,right=0.8 of X] (Y) {$Y$};
							\draw[arr2] (X) to[bend left=10] (Y);
							\draw[arr2] (Y) to[bend left=10] (X);
						\end{tikzpicture}\hfill}~\\[0.3em]
						{\small\!$\IDef{\dg M_3}\!(\mu)\! =\!  - \I_\mu(X;Y)$}
						{\footnotesize\\[-0.3em]\color<\IDEFex+3>{alertcolor!70!benchcolor2}%
							(opt. $\mu$ makes $X,Y$ functions of each other)}
				\end{itemize}
			}
			\end{columns}

						\item<uncover@1,4-7,9> [\only<8->{\color{structurecolor}3.~}\alert<4-7,9>{$\bbr{\dg M}^*\only<4-6>{_\gamma}$}] %\notation{$:{\Delta \V(\dg M)}$}
					The \only<7>{{\color{benchcolor1}(unique)}} ``best'' joint distribution\only<7>{{\small\color{benchcolor1}~(in the quantitative limit)}}.
					\only<2-7>{\visible<4-7>{
						\[ \bbr{\dg M}\only<4-6>{_\gamma}^* := \only<7>{{\color{benchcolor1}\lim_{\gamma\to 0}}} \argmin_\mu \bbr{\dg M}_\gamma(\mu) \]

		\end{frame}

\end{document}

	\begin{theorem}[{\it PDGs capture factor graphs}]
		We can naturally translate factor graphs and their exponential families%
			\note{(the natural notion of confidence in a factor graph)}%
			, into PDGs, in a way which preserves their semantics.
	\end{theorem}

	\bigskip
	Roughly speaking,
	\begin{itemize}
		\item a factor graph is a PDG in which qualitative and quantitative parameters are balanced $(\beta = \alpha\gamma)$.

		\item They have undesirable properties that do not occur in the quantitative limit.
	\end{itemize}
	% a factor graph is a PDG in which qualitative and quantitative parameters are balanced $(\beta = \alpha\gamma)$. They have undesirable properties that do not occur in the quantitative limit.


	See the paper for details!

	% \begin{center}
	% 		\begin{tikzpicture}[center base, xscale=1.3,
	% 			fgnode/.append style={minimum width=2.4em, inner sep=0.2em}]
	% 			\node[factor] (prior) at (1.65,-1) {};
	% 			\node[factor] (center) at (3.75, 0.1){};
	%
	% 			\node[fgnode] (PS) at (1.65,0.5) {$\mathit{PS}$};
	% 			\node[fgnode] (S) at (3.1, 0.8) {$\mathit S$};
	% 			\node[fgnode] (SH) at (3.0, -0.8) {$\mathit{SH}$};
	% 			\node[fgnode] (C) at (4.8,0.5) {$\mathit C$};
	%
	% 			\draw[thick] (prior) -- (PS);
	% 			\draw[thick] (PS) --node[factor](pss){} (S);
	% 			\draw[thick] (PS) --node[factor](pssh){} (SH);
	% 			\draw[thick] (S) -- (center) (center) -- (SH) (C) -- (center);
	%
	%
	% 			\node[fgnode] (T) at (4.8, -1.3) {$\mathit T$};
	% 			\draw[thick] (T) -- node[factor]{}  (C);
	% 			\end{tikzpicture}
	% 		~{\Large$\rightsquigarrow$}~
	% 		\pause
	% 		\begin{tikzpicture}[center base, xscale=1.5,
	% 	        newnode/.style={rectangle, inner sep=5pt, fill=gray!30, rounded corners=3, thick,draw}]
	% 			\node[newnode] (prior) at (1.65,-1) {};
	% 			\node[newnode] (center) at (4.1, 0.25){};
	%
	% 			\node[dpadded] (PS) at (1.65,0.5) {$\mathit{PS}$};
	% 			\node[dpadded] (S) at (3.3, 0.8) {$\mathit S$};
	% 			\node[dpadded] (SH) at (3.3, -0.6) {$\mathit{SH}$};
	% 			\node[dpadded] (C) at (4.9,0.5) {$\mathit C$};
	%
	% 			\draw[arr, ->>, shorten <=0pt] (prior) -- (PS);
	% 			\draw[arr, <<->>] (PS) --node[newnode](pss){} (S);
	% 			\draw[arr, <<->>] (PS) --node[newnode](pssh){} (SH);
	% 			\draw[arr, <<-, shorten >=0pt] (S) -- (center);
	% 			\draw[arr, <<-, shorten >=0pt] (SH)-- (center);
	% 			\draw[arr, <<-, shorten >=0pt] (C) -- (center);
	%
	% 			\node[dpadded, fill=blue] (1) at (2.7,-1.8) {$\pdgunit$};
	%
	% 			\draw[blue!50, arr] (1) -- (prior);
	% 			\draw[blue!50, arr] (1) to[bend right=30] (center);
	% 			\draw[blue!50, arr] (1) to[bend right = 5] (pss);
	% 			\draw[blue!50, arr] (1) to[bend left = 10] (pssh);
	%
	%
	% 			\node[dpadded] (T) at (4.8, -1.7) {$T$};
	% 			\draw[arr, <<->>] (T) -- node[newnode](tc){}  (C);
	%
	% 			\draw[blue!50, arr] (1) to[bend right = 10] (tc);
	% 			\end{tikzpicture}
	% 		\end{center}
	%
	% 	Conversely, PDG semantics behave like a factor graph at $\gamma=1$. But PDGs have nice properties that factor
	% 	graphs do not! See the full paper.
	\end{frame}

	\begin{frame}\frametitle{Inference and Inconsistency: a Glimpse.}
		\textbf{Conditioning as inconsistency resolution.}\\
		% \parbox{2.6in}{\raggedright
			To condition on $Y\!=\!y$, in $\dg M$,
			simply add the edge $\ed {\delta_y}{\pdgunit} Y$  to get ${\dg M}_{Y\!=y}$.
			Then $\bbr{{\dg M}_{Y\!=y}}^* = \bbr{\dg M}^* \mid (Y\!=\!y)$.
			% This generalizes to Jeffrey's rule.
		\bigskip\pause

		\textbf{Querying $\Pr(Y\mid X)$ in a PDG $\dg M$.}
		\begin{itemize}[<+-|alert@+>]
			\item We can add $\ed pXY$ to $\dg M$ with a cpt $p$, to get ${\dg M}^{+p}$.
			\item The choice of cpd $p$ that minimizes the inconsistency of $\dg M^{+p}$ (which is strongly convex and smooth in $p$) is $\bbr{\dg M}^*(Y\!\mid \!X)$,
			\item so oracle access to inconsistency yields fast inference by gradient descent.
		\end{itemize}
		% Roughly, the quality of an answer $p$ is the inconsistency of $\dg M^{+p}$.  The function $p \mapsto \Inc({\dg M^{+p}})$ is minimized by $p = \bbr{\dg M}^*(Y\!\mid\! X)$, and is smooth and convex in $p$; with oracle access to $\Inc(-)$ (or an approximation), we can compute optima by gradient methods.

		\pause[\thebeamerpauses]


		\parbox{0.5\textwidth}{This is closely related to  \\ standard variational techniques!}
		\centering
		\begin{tikzpicture}[center base]
			\node[dpadded] (1) {$\pdgunit$};
			\node[dpadded,right=1.0 of 1] (Z) {$Z$};
			\node[dpadded,right=1.5 of Z] (X) {$X$};
			\draw[arr1] (1) to node[above,name=pri] {$p(Z)$} (Z);
			\draw[arr1] (Z) to[bend left=15] node[above,name=dec] {$p(X \!\mid\! Z)$} (X);

			\path[gray!80] (dec) -- ++(0,0.2) node[above,inner sep=1pt]{\small decoder};
			\path[gray!80] (pri) -- ++(0,0.2) node[above,inner sep=1pt]{\small prior};
			\onslide<4->{
				\draw[arr1,onslide=<+(1)->{alertcolor}] (X) to[bend left=15] node[below,name=enc,inner sep=1pt] {$q(Z \!\mid\! X)$} (Z);
				\path[gray!80] (enc) -- ++(0,-0.2) node[below,inner sep=1pt]{\small encoder};}
		\end{tikzpicture}\par

		% }
		% \begin{tikzpicture}[center base]
		% 	% \useasboundingbox (-3,-1) rectangle (3.5,4);
		% 	\node[dpadded] (1) at (0,3) {$\pdgunit$};
		% 	\node[dpadded] (W) at (0,0) {$W$};
		% 	\node[dpadded] (B) at (-2,1) {$B$};
		% 	\node[dpadded] (E) at (2.5, 0){$E$};
		% 	\coordinate (Q) at (6,0); % to even out controls
		%
		% 	\draw[arr] (1) to node[fill=white]{$p$} (W);
		% 	\draw[arr] (1) to node[fill=white]{$\pi$} (B);
		%
		% 	\draw[arr, gray, ->>] (W) to[bend left=10] (B);
		% 	\draw[arr, dashed] (B) to[bend right=30] (W);
		%
		% 	\draw[arr, ->>] (W) to (E);
		%
		% 	\draw[arr,blue!50] (1) .. controls (-5.5,1.5) and (-2,-2) .. node[fill=white]{$p'(E)$} (E);
		% 	\draw[arr,orange!70] (1) .. controls (0.5,1) and (1,0.5) .. node[fill=white]{$p(E)$} (E);
		% \end{tikzpicture}
		%

		\end{frame}

	\begin{frame}
		\frametitle{Summary}
		PDGs\textellipsis
		\begin{itemize}[<+-|alert@+>]
			\item capture inconsistency, including conflicting information
			from multiple sources with varying reliability.
			\item
				are especially modular; to combine info from two sources, simply take a PDG union.
				This incorporates new data (edge cpds) and concepts (nodes) without affecting previous information.
			\item cleanly separate quantitative info (the cpds)
				from qualitative info (the edges), with variable confidence
				in both (the weights $\beta$ and $\alpha$).
				This is captured by terms $\Inc$ and $\IDef{}$ in our scoring function.
			\item have (several) natural semantics; one of them allows us to
				pick out a unique distribution.  Using this distributiondistributiondistribution, PDGs
				can capture BNs and factor graphs.
				% In the latter case, a simple parameter shift in the corresponding PDG eliminates
				% arguably problematic behavior of a factor graph.
			\end{itemize}

		\pause[\thebeamerpauses]
		\medskip
		\textit{But there is much more to be done!}
		\end{frame}
\end{document}

%joe1: moved here
                        The
%              \only<7>{{\color{benchcolor1}(unique)}}
                                          ``best'' joint distribution
                              %\only<7>{{\small\color{benchcolor1}~
                             (in the quantitative limit).
%					\only<2-7>{\visible<4-7>{
					  \[ \bbr{\dg M}
                                          %\only<4-6>{
                                          _\gamma^* :=
                                            %\only<7>
      \lim_{\gamma\to 0} \argmin_\mu \bbr{\dg M}_\gamma(\mu) \]


                }
\begin{itemize}
\item 			So a $\mu$ with

						uncertainty in $Y$ after $X$ is known
					(beyond
                                                pure noise is qualitatively worse.
\end{itemize}


	\relax % frame setup
		\colorlet{localcolor}{Lavender!80!black}
		\colorlet{globalcolor}{Sepia!80!orange}
		% \def\INCfst{2}
		\def\INCmotfst{2}
			\def\INCmotlen{4}

		\edef\INCfst{\the\numexpr \INCmotfst + \INCmotlen \relax}
			\def\INClen{5}
			\edef\INClst{\the\numexpr\INCfst+\INClen-1\relax}
			\def\INCrange{\INCfst-\INClst}
			\def\INC+#1{\atslide{\INCfst+#1}}

		% \def\INCexfst{7}
		\edef\INCexfst{\the\numexpr \INClst + 1 \relax}
			\def\INCexlen{0}
			\edef\INCexlst{\the\numexpr\INCexfst+\INCexlen-1\relax}
			\def\INCexrange{\INCexfst-\INCexlst}
			\def\INCex+#1{\atslide{\INCexfst+#1}}

		\edef\IDEFmotfst{\the\numexpr \INCexlst + 1 \relax}
			\def\IDEFmotlen{3}
			\def\IDEFmot+#1{\atslide{\IDEFmotfst+#1}}

		% \def\IDEFfst{12}
		\edef\IDEFfst{\the\numexpr \IDEFmotfst + \IDEFmotlen \relax}
			\def\IDEFlen{3}
			\edef\IDEFlst{\the\numexpr\IDEFfst+\IDEFlen-1\relax}
			\def\IDEFrange{\IDEFfst-\IDEFlst}
			\def\IDEF+#1{\atslide{\IDEFfst+#1}}

		% \def\IDEFexfst{15}
		\edef\IDEFexfst{\the\numexpr \IDEFlst + 1 \relax}
			\def\IDEFexlen{4}
			\edef\IDEFexlst{\the\numexpr\IDEFexfst+\IDEFexlen-1\relax}
			\def\IDEFexrange{\IDEFexfst-\IDEFexlst}
			\def\IDEFex+#1{\atslide{\IDEFexfst+#1}}

		% \def\INCandIDEF{19}
		\edef\INCandIDEFfst{\the\numexpr\IDEFexlst + 1 \relax}
			\edef\INCandIDEF{\INCandIDEFfst-}
			\def\IIboth+#1{\atslide{\IDEFexlst + 1 + #1}}
			\edef\beforeINCandIDEF{-\the\numexpr\INCandIDEFfst - 1\relax}
			% \show\INCandIDEF
		\def\atslide#1{\the\numexpr#1\relax}
		\def\aitem@#1+#2{\item<\atslide{\csname#1fst\endcsname+#2}-|alert@\atslide{\csname#1fst\endcsname+#2}>}
		\def\halfblocks{\INCexrange,\IDEFexrange,\INCandIDEF}
